{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rtHVti8i9NV4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Tuple, Any\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score as accuracy, f1_score\n",
        "from sklearn.preprocessing import scale\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib2 import Path\n",
        "from os.path import join\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Der8STJzGL-r"
      },
      "source": [
        "**Pre-Processing Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iTTWDMy5ILXX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#IMPORT FROM dataset.py CNNpred-pytorch\n",
        "class WholeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, target):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(\"Accessing data at index\", idx, \"with shape:\", self.data[idx].shape)\n",
        "        return self.data[idx], self.target[idx]\n",
        "\n",
        "#IMPORT FROM dataset.py CNNpred-pytorch\n",
        "def generate_batches(dataset, #ONLY GENERATES TWO BATCHES\n",
        "                     batch_size,\n",
        "                     shuffle=True,\n",
        "                     drop_last=False,\n",
        "                     device=\"cpu\",\n",
        "                     n_workers=0):\n",
        "    dataloader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last=drop_last,\n",
        "                            num_workers=n_workers,\n",
        "                            pin_memory=False)\n",
        "\n",
        "    for data, labels in dataloader:\n",
        "        #data = torch.unsqueeze(data, 1).float()\n",
        "        data = data.float()\n",
        "        labels = labels.float()\n",
        "        yield data.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "#Personally I think this should be applied to the data before it is split into\n",
        "#train, test, and val, but following CNNpred code, the test set losses seq_len\n",
        "#points with this method\n",
        "def create_windows(X, y, seq_len):\n",
        "  series = []\n",
        "  target = []\n",
        "  for i in range(len(X) - seq_len + 1):\n",
        "    series.append(X[i: i + seq_len])\n",
        "    target.append(y[i + seq_len - 1])\n",
        "\n",
        "  return np.array(series), np.array(target)\n",
        "\n",
        "\n",
        "def scale_X(X_train, X_val, X_test):\n",
        "  # Shapes of the arrays\n",
        "  num_samples_train, seq_length, num_stocks, num_features = X_train.shape\n",
        "  num_samples_val = X_val.shape[0]\n",
        "  num_samples_test = X_test.shape[0]\n",
        "\n",
        "  # Initialize a scaler for each feature\n",
        "  scalers = [StandardScaler() for _ in range(num_features)]\n",
        "\n",
        "  # Scale training data and prepare to scale validation and test data\n",
        "  X_train_scaled = np.empty_like(X_train)\n",
        "  X_val_scaled = np.empty_like(X_val)\n",
        "  X_test_scaled = np.empty_like(X_test)\n",
        "\n",
        "  # Scale each feature\n",
        "  for i in range(num_features):\n",
        "      # Extract the feature across all training data\n",
        "      feature_data_train = X_train[:, :, :, i].reshape(num_samples_train, seq_length * num_stocks)\n",
        "      \n",
        "      # Fit and transform training data\n",
        "      scalers[i].fit(feature_data_train)  # Fit only on training data\n",
        "      scaled_feature_data_train = scalers[i].transform(feature_data_train)\n",
        "      \n",
        "      # Transform validation data\n",
        "      feature_data_val = X_val[:, :, :, i].reshape(num_samples_val, seq_length * num_stocks)\n",
        "      scaled_feature_data_val = scalers[i].transform(feature_data_val)\n",
        "      \n",
        "      # Transform test data\n",
        "      feature_data_test = X_test[:, :, :, i].reshape(num_samples_test, seq_length * num_stocks)\n",
        "      scaled_feature_data_test = scalers[i].transform(feature_data_test)\n",
        "      \n",
        "      # Reshape scaled data back and store it in the correct position\n",
        "      X_train_scaled[:, :, :, i] = scaled_feature_data_train.reshape(num_samples_train, seq_length, num_stocks)\n",
        "      X_val_scaled[:, :, :, i] = scaled_feature_data_val.reshape(num_samples_val, seq_length, num_stocks)\n",
        "      X_test_scaled[:, :, :, i] = scaled_feature_data_test.reshape(num_samples_test, seq_length, num_stocks)\n",
        "\n",
        "  return X_train_scaled, X_val_scaled, X_test_scaled\n",
        "  # Now X_train_scaled, X_val_scaled, and X_test_scaled contain the appropriately scaled data\n",
        "\n",
        "\n",
        "def preprocess(data: dict,\n",
        "               seq_len: int,\n",
        "               Val_first: bool,\n",
        "               Trim_end: str,\n",
        "               Split_Date1: str,\n",
        "               Split_Date2: str,\n",
        "               n_day_predict: int = 1,) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "\n",
        "\n",
        "  X_all = []\n",
        "  y_all = {}\n",
        "\n",
        "  for index, df in data.items():\n",
        "\n",
        "    #Ensure it is sorted\n",
        "    df = df.sort_index()\n",
        "\n",
        "    #Get y\n",
        "    y_i = (df['close'][n_day_predict:] / df['close'][:-n_day_predict].values).astype(int)\n",
        "    y_i = y_i[:-n_day_predict]\n",
        "\n",
        "\n",
        "    #touch up data\n",
        "    X_i = df.fillna(0)\n",
        "    X_i = X_i[:-n_day_predict]\n",
        "    X_i = X_i[n_day_predict:]\n",
        "\n",
        "    X_all.append(X_i) \n",
        "    y_all[index] = y_i\n",
        "\n",
        "    #Get Trim index\n",
        "    Trim_index   = df.index.get_loc(Trim_end)\n",
        "    Split_index1 = df.index.get_loc(Split_Date1)\n",
        "    Split_index2 = df.index.get_loc(Split_Date2)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  y = {}\n",
        "    \n",
        "  for index, df in data.items():\n",
        "    X, y[index] = create_windows(np.transpose(np.array(X_all), (1, 0, 2)), np.array(y_all[index]).flatten(), seq_len)\n",
        "  \n",
        "  y_train = {}\n",
        "\n",
        "  y_test = {}\n",
        "\n",
        "  y_val = {}\n",
        "\n",
        "  TESTAMOUNT = 365 #THIS IS HARD CODED AS ****, the 30 is HARD CODED\n",
        "  if Val_first: #Puts the validation first\n",
        "     X_val = X[Trim_index:Split_index1]\n",
        "     X_train = X[Split_index1:Split_index2]\n",
        "     X_test = X[Split_index2:Split_index2+TESTAMOUNT]\n",
        "     for index, _ in data.items():\n",
        "        y_val[index]   = y[index][Trim_index:Split_index1]\n",
        "        y_train[index] = y[index][Split_index1:Split_index2]\n",
        "        y_test[index]  = y[index][Split_index2:Split_index2+TESTAMOUNT] \n",
        "  else:\n",
        "    X_train = X[Trim_index:Split_index1]\n",
        "    X_val = X[Split_index1:Split_index2]\n",
        "    X_test = X[Split_index2:Split_index2+TESTAMOUNT]\n",
        "    for index, _ in data.items():\n",
        "      y_train[index]   = y[index][Trim_index:Split_index1]\n",
        "      y_val[index] = y[index][Split_index1:Split_index2]\n",
        "      y_test[index]  = y[index][Split_index2:Split_index2+TESTAMOUNT]\n",
        "  \n",
        "\n",
        "  #Scaling\n",
        "  X_train, X_val, X_test = scale_X(X_train, X_val, X_test)\n",
        "  \n",
        "\n",
        "  return X_train, y_train, X_test, y_test, X_val, y_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCiFDpaiT6Gj"
      },
      "source": [
        "**Utility Functions** Might combine with preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Urt_zmA6A1i1"
      },
      "outputs": [],
      "source": [
        "#Use for deriving next model filename\n",
        "def next_file(file, path):\n",
        "  #Ensure dicectory exists\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  #Get root and extension\n",
        "  filename, ext = os.path.splitext(file)\n",
        "\n",
        "  #Get list of files\n",
        "  files = os.listdir(path)\n",
        "  num = []\n",
        "  for file in files:\n",
        "    if file.startswith(filename):\n",
        "      num.append(int(re.findall(r'\\d+', file.split('-')[-1])[0]))\n",
        "\n",
        "  #Find next iteration number\n",
        "  file_iteration_number = max(num) + 1 if len(num) else 1\n",
        "  return join(path, filename + \"-\" + str(file_iteration_number) + ext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KoOV7hsvU22"
      },
      "source": [
        "**Engine Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzAp2PS4lsPF",
        "outputId": "e3f2deb9-8bca-412e-a0b1-ac6e77acfd13"
      },
      "outputs": [],
      "source": [
        "#Main.py script\n",
        "#Define Model and preprocessing params\n",
        "config_path = \"./Configs/year5_CNNpred.yaml\" #TODO: Define config file, this will be done in command line\n",
        "with open(config_path, \"r\") as file:\n",
        "  config = yaml.safe_load(file)\n",
        "\n",
        "with open(config['preprocess']['dataset_path'], 'rb') as file:\n",
        "  data = pickle.load(file)\n",
        "\n",
        "\n",
        "preparams = {\n",
        "    \"data\": data,\n",
        "    \"seq_len\": config['preprocess']['seq_len'],\n",
        "    \"Val_first\": bool(config['preprocess']['Val_first']),\n",
        "    \"Trim_end\": str(config['preprocess']['Trim_end']),\n",
        "    \"Split_Date1\": str(config['preprocess']['Split_Date1']),\n",
        "    \"Split_Date2\": str(config['preprocess']['Split_Date2']),\n",
        "    \"n_day_predict\": config['preprocess']['n_day_predict'],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5536"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"^DJI\"].index.get_loc(\"2022-01-03\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DotCxsDOe38",
        "outputId": "154a76fb-1fb7-4ce2-f927-32849dff679c"
      },
      "outputs": [],
      "source": [
        "#Main.py script\n",
        "#preprocess data\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = preprocess(**preparams)\n",
        "\n",
        "\n",
        "#Dict of Datasets\n",
        "train_data = {}\n",
        "val_data = {}\n",
        "test_data = {}\n",
        "\n",
        "#Dict of batch generaters\n",
        "train_dataloader = {}\n",
        "\n",
        "#Create wholedatasets in dict for each stock\n",
        "#Create batch generator for training\n",
        "\n",
        "\n",
        "X_val = X_val.transpose(0, 3, 1, 2) #TEMP\n",
        "X_test = X_test.transpose(0, 3, 1, 2) #TEMP\n",
        "\n",
        "X_train = X_train.transpose(0, 3, 1, 2) #TEMP\n",
        "for index, y_train_i in y_train.items():\n",
        "  train_data[index] = WholeDataset(X_train, y_train_i)\n",
        "  # train_dataloader[index] = generate_batches(train_data[index], config['train']['batch_size'], config['train']['num_workers']) #TODO: Replace 128 and 0 with .yaml settings\n",
        "  #Train_dataloader moved to training loop, as it needs to be re init every time\n",
        "\n",
        "for index, y_val_i in y_val.items():\n",
        "\n",
        "  val_data[index] = WholeDataset(X_val, y_val_i)\n",
        "\n",
        "for index, y_test_i in y_test.items():\n",
        "  test_data[index] = WholeDataset(X_test, y_test_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kdFnleVyd1AD"
      },
      "outputs": [],
      "source": [
        "class CNNModelOne(nn.Module):\n",
        "    def __init__(self, number_filter, number_of_stocks, seq_len, number_feature, drop, calculated_fc_layer_size):\n",
        "        super(CNNModelOne, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        #self.conv1 = nn.Conv2d(in_channels=number_feature, out_channels=number_filter[0], kernel_size=(1, 1))\n",
        "        self.conv1 = nn.Conv2d(in_channels=82, out_channels=8, kernel_size=(1, 1))\n",
        "        # Layer 2\n",
        "        #self.conv2 = nn.Conv2d(in_channels=number_filter[0], out_channels=number_filter[1], kernel_size=(1, 3))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 5))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Layer 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Flatten and Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(calculated_fc_layer_size, 1)  # Calculate based on output size after last pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        torch.Size([128, 82, 60, 5])\n",
        "        torch.Size([128, 8, 60, 5])\n",
        "        torch.Size([128, 8, 58, 1])\n",
        "        torch.Size([128, 8, 29, 1])\n",
        "        torch.Size([128, 8, 27, 1])\n",
        "        torch.Size([128, 8, 13, 1])\n",
        "        torch.Size([128, 104])\n",
        "        torch.Size([128, 104])\n",
        "        \"\"\"\n",
        "        #print(\"-----------------x-x-xxx--------------\")\n",
        "        #print(x.shape) # torch.Size([128, 82, 60, 5])\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 60, 5])\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 58, 1])\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 29, 1])\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 27, 1])\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 13, 1])\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = self.dropout(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNModelTwo(nn.Module):\n",
        "    def __init__(self, number_filter, number_of_stocks, seq_len, number_feature, drop, calculated_fc_layer_size):\n",
        "        super(CNNModelTwo, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        #self.conv1 = nn.Conv2d(in_channels=number_feature, out_channels=number_filter[0], kernel_size=(1, 1))\n",
        "        self.conv1 = nn.Conv2d(in_channels=82, out_channels=8, kernel_size=(1, 1))\n",
        "        # Layer 2\n",
        "        #self.conv2 = nn.Conv2d(in_channels=number_filter[0], out_channels=number_filter[1], kernel_size=(1, 3))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 5))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Layer 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Flatten and Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "\n",
        "         # Additional Fully Connected Layer\n",
        "        self.fc1 = nn.Linear(calculated_fc_layer_size, 52)  # New intermediate layer with 52 neurons\n",
        "\n",
        "        # Output layer\n",
        "        self.fc2 = nn.Linear(52, 1)  # Output layer after the new FC layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        torch.Size([128, 82, 60, 5])\n",
        "        torch.Size([128, 8, 60, 5])\n",
        "        torch.Size([128, 8, 58, 1])\n",
        "        torch.Size([128, 8, 29, 1])\n",
        "        torch.Size([128, 8, 27, 1])\n",
        "        torch.Size([128, 8, 13, 1])\n",
        "        torch.Size([128, 104])\n",
        "        torch.Size([128, 104])\n",
        "        \"\"\"\n",
        "        #print(\"-----------------x-x-xxx--------------\")\n",
        "        #print(x.shape) # torch.Size([128, 82, 60, 5])\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 60, 5])\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 58, 1])\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 29, 1])\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 27, 1])\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 13, 1])\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = self.dropout(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = F.relu(self.fc1(x))  # Activation for intermediate layer\n",
        "        x = torch.sigmoid(self.fc2(x))  # Final output with sigmoid activation\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KnpvMeGq4bMm"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Train.py script\n",
        "def validate(config, model, dataset):\n",
        "    model.eval()\n",
        "    loss_fcn = torch.nn.BCELoss().to(device)\n",
        "\n",
        "    data_dataloader = generate_batches(dataset, config['train']['batch_size'], config['train']['num_workers'])\n",
        "\n",
        "    loss_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_label in data_dataloader:\n",
        "\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_label = batch_label.to(device)\n",
        "\n",
        "            \n",
        "            batch_logit = model(batch_data).view(-1)\n",
        "\n",
        "            loss = loss_fcn(batch_logit, batch_label)\n",
        "\n",
        "            pred = (batch_logit > 0.5).int()\n",
        "\n",
        "            pred_list.extend(pred.cpu().numpy())\n",
        "            label_list.extend(batch_label.cpu().numpy())\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "        loss_data = np.array(loss_list).mean()\n",
        "        acc = accuracy(pred_list, label_list)\n",
        "        f1 = f1_score(pred_list, label_list, average='macro')\n",
        "\n",
        "    return loss_data, acc, f1,\n",
        "def train(config, train_data, val_dataset, test_dataset, filepath): #Test_dataset SHOULD NOT BE A PARAMETER!!!!!\n",
        "  #Init Model\n",
        "  #model_class = getattr(models, config['model']['type'])\n",
        "  #model = model_class(**config['model']['params'])\n",
        "\n",
        "  ####DEBUG DEBUG DEBUG\n",
        "  model = CNNModelOne(number_filter=[8,8,8], number_of_stocks=5, seq_len=60, number_feature=82, drop=0.1, calculated_fc_layer_size =104)\n",
        "  model = model.to(device)\n",
        "  # print(\"-------Model----------\")\n",
        "  # print(model)\n",
        "  # print(model.conv3.kernel_size)\n",
        "  # print(model.conv3.padding)\n",
        "  # print(\"-------Model----------\")\n",
        "\n",
        "  #Init loss function\n",
        "  #loss_fcn = torch.nn.BCELoss()\n",
        "  #loss_class = getattr(nn, config['loss_function']['type'])\n",
        "  #loss_fcn = loss_class(**config['loss_function']['params']).to(device)\n",
        "  loss_fcn = nn.BCELoss().to(device)\n",
        "\n",
        "\n",
        "  #Init Optimizer\n",
        "  #optimizer_class = getattr(optim, config['optimizer']['type'])\n",
        "  #optimizer = optimizer_class(model.parameters(), **{k: v for k, v in config['optimizer'].items() if k != 'type'})\n",
        "\n",
        "\n",
        "  ###DEBUG DEBUG DEBUG\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Init Scheduler\n",
        "  #scheduler_class = getattr(optim.lr_scheduler, config['scheduler']['type'])\n",
        "  #scheduler = scheduler_class(optimizer, **{k: v for k, v in config['scheduler'].items() if k != 'type'})\n",
        "\n",
        "  ###DEBUG DEBUG DEBUG\n",
        "  #scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True, eps=1e-8)\n",
        "  for epoch in range(config['train']['epoch']):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    #train_dataloader\n",
        "    train_dataloader = generate_batches(train_data, config['train']['batch_size'], config['train']['num_workers'])\n",
        "\n",
        "    for batch_data, batch_label in train_dataloader:\n",
        "      # print(\"-------bd----------\")\n",
        "      # print(batch_data.shape)\n",
        "      # print(\"-------------------\")\n",
        "      batch_data = batch_data.to(device) #\n",
        "      batch_label = batch_label.to(device) #\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      batch_logit = model(batch_data).view(-1)\n",
        "      loss = loss_fcn(batch_logit, batch_label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # print(\"Batch_logit\")\n",
        "      # print(batch_logit)\n",
        "\n",
        "      #Convert to CPU for processing\n",
        "      batch_data = batch_data.cpu()\n",
        "      batch_label = batch_label.cpu()\n",
        "\n",
        "\n",
        "      pred = (batch_logit > 0.5).int()\n",
        "      # print(\"Pred\")\n",
        "      # print(pred)\n",
        "\n",
        "      pred_list.extend(pred.cpu().numpy())\n",
        "      label_list.extend(batch_label.cpu().numpy())\n",
        "\n",
        "      \n",
        "      parameters = list(model.parameters())\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "    loss_data = np.array(loss_list).mean()\n",
        "\n",
        "    train_acc = accuracy(pred_list, label_list)\n",
        "    # print(\"-------acc----------\")\n",
        "    # print(train_acc)\n",
        "    # print(pred_list)\n",
        "    # print(label_list)\n",
        "    # print(\"-------acc----------\")\n",
        "\n",
        "    train_f1 = f1_score(pred_list, label_list, average='macro')\n",
        "\n",
        "    print(\"Epoch {:05d}\\n\"\n",
        "          \"Train: loss: {:.4f} | accuracy: {:.4f} | f-acore: {:.4f}\"\n",
        "          .format(epoch + 1, loss_data, train_acc, train_f1))\n",
        "    #loss_data = float(loss_data.item())\n",
        "\n",
        "    #loss_data = torch.tensor(loss_data)\n",
        "    \n",
        "    #scheduler.step(loss_data) SCHEDULER REMOVE FOR NOW\n",
        "\n",
        "    ###TEMP TEMP\n",
        "    test_loss, test_acc, test_f1 = validate(config, model, test_dataset)\n",
        "    print(\"Test:  loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
        "          .format(test_loss, test_acc, test_f1))\n",
        "\n",
        "    ###TEMP TEMP\n",
        "    \n",
        "    val_loss, val_acc, val_f1 = validate(config, model, val_dataset)\n",
        "    print(\"Validation:  loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
        "          .format(val_loss, val_acc, val_f1))\n",
        "      # choosing best model according to best validation accuracy\n",
        "    best_f1 = 0\n",
        "    if best_f1 < val_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model, filepath)\n",
        "\n",
        "      # else:\n",
        "      #     cur_step += 1\n",
        "      #     if cur_step == config['train']['patience']:\n",
        "      #         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_m91VyEo3Ib",
        "outputId": "5a116a3a-4e07-46fe-a128-76b8c217b718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA GeForce RTX 3070\n",
            "-----------------------------------------------------------------------------------------\n",
            "^DJI\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6919 | accuracy: 0.5369 | f-acore: 0.3649\n",
            "Test:  loss: 0.6913 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6951 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00002\n",
            "Train: loss: 0.6902 | accuracy: 0.5392 | f-acore: 0.3503\n",
            "Test:  loss: 0.6908 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6952 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00003\n",
            "Train: loss: 0.6926 | accuracy: 0.5392 | f-acore: 0.3503\n",
            "Test:  loss: 0.6906 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6951 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00004\n",
            "Train: loss: 0.6872 | accuracy: 0.5374 | f-acore: 0.3504\n",
            "Test:  loss: 0.6911 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6957 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00005\n",
            "Train: loss: 0.6880 | accuracy: 0.5387 | f-acore: 0.3519\n",
            "Test:  loss: 0.6916 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6994 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00006\n",
            "Train: loss: 0.6882 | accuracy: 0.5415 | f-acore: 0.3593\n",
            "Test:  loss: 0.6912 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6984 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00007\n",
            "Train: loss: 0.6881 | accuracy: 0.5456 | f-acore: 0.4191\n",
            "Test:  loss: 0.6933 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7031 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00008\n",
            "Train: loss: 0.6825 | accuracy: 0.5475 | f-acore: 0.4102\n",
            "Test:  loss: 0.6981 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7092 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00009\n",
            "Train: loss: 0.6836 | accuracy: 0.5461 | f-acore: 0.3831\n",
            "Test:  loss: 0.6943 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7041 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00010\n",
            "Train: loss: 0.6863 | accuracy: 0.5442 | f-acore: 0.4105\n",
            "Test:  loss: 0.6947 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7042 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00011\n",
            "Train: loss: 0.6865 | accuracy: 0.5447 | f-acore: 0.4685\n",
            "Test:  loss: 0.6959 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7054 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00012\n",
            "Train: loss: 0.6878 | accuracy: 0.5502 | f-acore: 0.4827\n",
            "Test:  loss: 0.6960 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7083 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00013\n",
            "Train: loss: 0.6824 | accuracy: 0.5507 | f-acore: 0.4777\n",
            "Test:  loss: 0.6938 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7040 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00014\n",
            "Train: loss: 0.6813 | accuracy: 0.5447 | f-acore: 0.4283\n",
            "Test:  loss: 0.7021 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7095 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00015\n",
            "Train: loss: 0.6853 | accuracy: 0.5475 | f-acore: 0.4336\n",
            "Test:  loss: 0.6941 | accuracy: 0.5123 | f1: 0.3624\n",
            "Validation:  loss: 0.6967 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00016\n",
            "Train: loss: 0.6848 | accuracy: 0.5488 | f-acore: 0.4584\n",
            "Test:  loss: 0.6949 | accuracy: 0.4986 | f1: 0.4332\n",
            "Validation:  loss: 0.6936 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00017\n",
            "Train: loss: 0.6850 | accuracy: 0.5580 | f-acore: 0.4768\n",
            "Test:  loss: 0.6963 | accuracy: 0.5096 | f1: 0.4456\n",
            "Validation:  loss: 0.6948 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00018\n",
            "Train: loss: 0.6818 | accuracy: 0.5635 | f-acore: 0.5234\n",
            "Test:  loss: 0.6955 | accuracy: 0.4849 | f1: 0.4846\n",
            "Validation:  loss: 0.6839 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00019\n",
            "Train: loss: 0.6863 | accuracy: 0.5626 | f-acore: 0.5226\n",
            "Test:  loss: 0.6996 | accuracy: 0.5205 | f1: 0.4459\n",
            "Validation:  loss: 0.6933 | accuracy: 0.4762 | f1: 0.3226\n",
            "Epoch 00020\n",
            "Train: loss: 0.6815 | accuracy: 0.5585 | f-acore: 0.4845\n",
            "Test:  loss: 0.7222 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7143 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00021\n",
            "Train: loss: 0.6808 | accuracy: 0.5502 | f-acore: 0.4311\n",
            "Test:  loss: 0.7082 | accuracy: 0.5342 | f1: 0.3586\n",
            "Validation:  loss: 0.6995 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00022\n",
            "Train: loss: 0.6768 | accuracy: 0.5617 | f-acore: 0.5016\n",
            "Test:  loss: 0.7025 | accuracy: 0.4877 | f1: 0.4873\n",
            "Validation:  loss: 0.6780 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00023\n",
            "Train: loss: 0.6889 | accuracy: 0.5548 | f-acore: 0.5078\n",
            "Test:  loss: 0.7096 | accuracy: 0.5288 | f1: 0.5044\n",
            "Validation:  loss: 0.6821 | accuracy: 0.5119 | f1: 0.4856\n",
            "Epoch 00024\n",
            "Train: loss: 0.6781 | accuracy: 0.5644 | f-acore: 0.5314\n",
            "Test:  loss: 0.6969 | accuracy: 0.5178 | f1: 0.5030\n",
            "Validation:  loss: 0.6780 | accuracy: 0.5595 | f1: 0.5450\n",
            "Epoch 00025\n",
            "Train: loss: 0.6750 | accuracy: 0.5543 | f-acore: 0.5251\n",
            "Test:  loss: 0.7099 | accuracy: 0.5260 | f1: 0.3986\n",
            "Validation:  loss: 0.6920 | accuracy: 0.4881 | f1: 0.3806\n",
            "Epoch 00026\n",
            "Train: loss: 0.6859 | accuracy: 0.5562 | f-acore: 0.4729\n",
            "Test:  loss: 0.7201 | accuracy: 0.5342 | f1: 0.4552\n",
            "Validation:  loss: 0.6932 | accuracy: 0.5119 | f1: 0.4349\n",
            "Epoch 00027\n",
            "Train: loss: 0.6792 | accuracy: 0.5681 | f-acore: 0.5334\n",
            "Test:  loss: 0.7108 | accuracy: 0.5479 | f1: 0.4846\n",
            "Validation:  loss: 0.6890 | accuracy: 0.5357 | f1: 0.4625\n",
            "Epoch 00028\n",
            "Train: loss: 0.6771 | accuracy: 0.5608 | f-acore: 0.5065\n",
            "Test:  loss: 0.7193 | accuracy: 0.5397 | f1: 0.3806\n",
            "Validation:  loss: 0.7022 | accuracy: 0.4881 | f1: 0.3280\n",
            "Epoch 00029\n",
            "Train: loss: 0.6767 | accuracy: 0.5635 | f-acore: 0.5037\n",
            "Test:  loss: 0.7146 | accuracy: 0.5288 | f1: 0.4461\n",
            "Validation:  loss: 0.6934 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00030\n",
            "Train: loss: 0.6752 | accuracy: 0.5782 | f-acore: 0.5388\n",
            "Test:  loss: 0.7141 | accuracy: 0.5315 | f1: 0.4768\n",
            "Validation:  loss: 0.6893 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00031\n",
            "Train: loss: 0.6824 | accuracy: 0.5704 | f-acore: 0.5436\n",
            "Test:  loss: 0.7058 | accuracy: 0.4795 | f1: 0.4790\n",
            "Validation:  loss: 0.6790 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00032\n",
            "Train: loss: 0.6733 | accuracy: 0.5828 | f-acore: 0.5625\n",
            "Test:  loss: 0.7067 | accuracy: 0.5068 | f1: 0.4945\n",
            "Validation:  loss: 0.6915 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00033\n",
            "Train: loss: 0.6808 | accuracy: 0.5750 | f-acore: 0.5417\n",
            "Test:  loss: 0.7124 | accuracy: 0.5178 | f1: 0.4977\n",
            "Validation:  loss: 0.7005 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00034\n",
            "Train: loss: 0.6746 | accuracy: 0.5805 | f-acore: 0.5376\n",
            "Test:  loss: 0.7096 | accuracy: 0.4767 | f1: 0.4763\n",
            "Validation:  loss: 0.6837 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00035\n",
            "Train: loss: 0.6720 | accuracy: 0.5695 | f-acore: 0.5512\n",
            "Test:  loss: 0.7136 | accuracy: 0.4986 | f1: 0.4874\n",
            "Validation:  loss: 0.6835 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00036\n",
            "Train: loss: 0.6744 | accuracy: 0.5740 | f-acore: 0.5625\n",
            "Test:  loss: 0.7109 | accuracy: 0.4986 | f1: 0.4817\n",
            "Validation:  loss: 0.6823 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00037\n",
            "Train: loss: 0.6739 | accuracy: 0.5796 | f-acore: 0.5466\n",
            "Test:  loss: 0.7135 | accuracy: 0.5041 | f1: 0.4938\n",
            "Validation:  loss: 0.6846 | accuracy: 0.4762 | f1: 0.4653\n",
            "Epoch 00038\n",
            "Train: loss: 0.6788 | accuracy: 0.5864 | f-acore: 0.5622\n",
            "Test:  loss: 0.7067 | accuracy: 0.4877 | f1: 0.4869\n",
            "Validation:  loss: 0.6778 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00039\n",
            "Train: loss: 0.6790 | accuracy: 0.5901 | f-acore: 0.5444\n",
            "Test:  loss: 0.6998 | accuracy: 0.4904 | f1: 0.4845\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00040\n",
            "Train: loss: 0.6717 | accuracy: 0.5892 | f-acore: 0.5596\n",
            "Test:  loss: 0.7025 | accuracy: 0.5068 | f1: 0.5012\n",
            "Validation:  loss: 0.6790 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00041\n",
            "Train: loss: 0.6686 | accuracy: 0.5832 | f-acore: 0.5640\n",
            "Test:  loss: 0.7157 | accuracy: 0.4904 | f1: 0.4786\n",
            "Validation:  loss: 0.6884 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00042\n",
            "Train: loss: 0.6647 | accuracy: 0.5873 | f-acore: 0.5496\n",
            "Test:  loss: 0.7177 | accuracy: 0.5041 | f1: 0.4903\n",
            "Validation:  loss: 0.6880 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00043\n",
            "Train: loss: 0.6692 | accuracy: 0.5873 | f-acore: 0.5601\n",
            "Test:  loss: 0.7126 | accuracy: 0.4877 | f1: 0.4864\n",
            "Validation:  loss: 0.6825 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00044\n",
            "Train: loss: 0.6708 | accuracy: 0.5846 | f-acore: 0.5646\n",
            "Test:  loss: 0.7207 | accuracy: 0.4986 | f1: 0.4890\n",
            "Validation:  loss: 0.6898 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00045\n",
            "Train: loss: 0.6656 | accuracy: 0.5832 | f-acore: 0.5581\n",
            "Test:  loss: 0.7239 | accuracy: 0.5205 | f1: 0.4849\n",
            "Validation:  loss: 0.7018 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00046\n",
            "Train: loss: 0.6663 | accuracy: 0.5919 | f-acore: 0.5781\n",
            "Test:  loss: 0.7143 | accuracy: 0.5096 | f1: 0.4986\n",
            "Validation:  loss: 0.6922 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00047\n",
            "Train: loss: 0.6600 | accuracy: 0.6002 | f-acore: 0.5808\n",
            "Test:  loss: 0.7212 | accuracy: 0.5041 | f1: 0.4922\n",
            "Validation:  loss: 0.6943 | accuracy: 0.5952 | f1: 0.5593\n",
            "Epoch 00048\n",
            "Train: loss: 0.6639 | accuracy: 0.5860 | f-acore: 0.5727\n",
            "Test:  loss: 0.7145 | accuracy: 0.5041 | f1: 0.4922\n",
            "Validation:  loss: 0.6757 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00049\n",
            "Train: loss: 0.6585 | accuracy: 0.5846 | f-acore: 0.5735\n",
            "Test:  loss: 0.7120 | accuracy: 0.5068 | f1: 0.5041\n",
            "Validation:  loss: 0.6846 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00050\n",
            "Train: loss: 0.6747 | accuracy: 0.5864 | f-acore: 0.5452\n",
            "Test:  loss: 0.7113 | accuracy: 0.5151 | f1: 0.5150\n",
            "Validation:  loss: 0.6822 | accuracy: 0.5595 | f1: 0.5167\n",
            "Epoch 00051\n",
            "Train: loss: 0.6731 | accuracy: 0.5887 | f-acore: 0.5837\n",
            "Test:  loss: 0.7045 | accuracy: 0.4932 | f1: 0.4726\n",
            "Validation:  loss: 0.6816 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00052\n",
            "Train: loss: 0.6681 | accuracy: 0.5851 | f-acore: 0.5728\n",
            "Test:  loss: 0.6974 | accuracy: 0.4877 | f1: 0.4842\n",
            "Validation:  loss: 0.6794 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00053\n",
            "Train: loss: 0.6645 | accuracy: 0.5938 | f-acore: 0.5793\n",
            "Test:  loss: 0.7048 | accuracy: 0.5288 | f1: 0.5227\n",
            "Validation:  loss: 0.6782 | accuracy: 0.4881 | f1: 0.4662\n",
            "Epoch 00054\n",
            "Train: loss: 0.6646 | accuracy: 0.5864 | f-acore: 0.5709\n",
            "Test:  loss: 0.7042 | accuracy: 0.5151 | f1: 0.5145\n",
            "Validation:  loss: 0.6761 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00055\n",
            "Train: loss: 0.6572 | accuracy: 0.5901 | f-acore: 0.5537\n",
            "Test:  loss: 0.7086 | accuracy: 0.5068 | f1: 0.5064\n",
            "Validation:  loss: 0.6776 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00056\n",
            "Train: loss: 0.6669 | accuracy: 0.5938 | f-acore: 0.5554\n",
            "Test:  loss: 0.7063 | accuracy: 0.4959 | f1: 0.4888\n",
            "Validation:  loss: 0.6742 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00057\n",
            "Train: loss: 0.6734 | accuracy: 0.5901 | f-acore: 0.5626\n",
            "Test:  loss: 0.7063 | accuracy: 0.5096 | f1: 0.5075\n",
            "Validation:  loss: 0.6749 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00058\n",
            "Train: loss: 0.6616 | accuracy: 0.6048 | f-acore: 0.5914\n",
            "Test:  loss: 0.6988 | accuracy: 0.5205 | f1: 0.5194\n",
            "Validation:  loss: 0.6767 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00059\n",
            "Train: loss: 0.6541 | accuracy: 0.6071 | f-acore: 0.5814\n",
            "Test:  loss: 0.7024 | accuracy: 0.5260 | f1: 0.5243\n",
            "Validation:  loss: 0.6805 | accuracy: 0.5476 | f1: 0.5143\n",
            "Epoch 00060\n",
            "Train: loss: 0.6630 | accuracy: 0.5961 | f-acore: 0.5482\n",
            "Test:  loss: 0.7088 | accuracy: 0.5260 | f1: 0.5246\n",
            "Validation:  loss: 0.6793 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00061\n",
            "Train: loss: 0.6594 | accuracy: 0.6066 | f-acore: 0.5849\n",
            "Test:  loss: 0.7002 | accuracy: 0.5123 | f1: 0.5096\n",
            "Validation:  loss: 0.6802 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00062\n",
            "Train: loss: 0.6625 | accuracy: 0.6089 | f-acore: 0.5960\n",
            "Test:  loss: 0.7037 | accuracy: 0.5260 | f1: 0.5224\n",
            "Validation:  loss: 0.6829 | accuracy: 0.5595 | f1: 0.5238\n",
            "Epoch 00063\n",
            "Train: loss: 0.6602 | accuracy: 0.6011 | f-acore: 0.5850\n",
            "Test:  loss: 0.7047 | accuracy: 0.5068 | f1: 0.4978\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5476 | f1: 0.5074\n",
            "Epoch 00064\n",
            "Train: loss: 0.6544 | accuracy: 0.6020 | f-acore: 0.5951\n",
            "Test:  loss: 0.7054 | accuracy: 0.5123 | f1: 0.5055\n",
            "Validation:  loss: 0.6860 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00065\n",
            "Train: loss: 0.6535 | accuracy: 0.6080 | f-acore: 0.5980\n",
            "Test:  loss: 0.7076 | accuracy: 0.5260 | f1: 0.5033\n",
            "Validation:  loss: 0.6920 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00066\n",
            "Train: loss: 0.6495 | accuracy: 0.6121 | f-acore: 0.5898\n",
            "Test:  loss: 0.7032 | accuracy: 0.5068 | f1: 0.4978\n",
            "Validation:  loss: 0.6881 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00067\n",
            "Train: loss: 0.6562 | accuracy: 0.6075 | f-acore: 0.5929\n",
            "Test:  loss: 0.7021 | accuracy: 0.5288 | f1: 0.5262\n",
            "Validation:  loss: 0.6815 | accuracy: 0.5476 | f1: 0.5074\n",
            "Epoch 00068\n",
            "Train: loss: 0.6542 | accuracy: 0.6066 | f-acore: 0.5964\n",
            "Test:  loss: 0.7042 | accuracy: 0.5123 | f1: 0.5100\n",
            "Validation:  loss: 0.6803 | accuracy: 0.5119 | f1: 0.4645\n",
            "Epoch 00069\n",
            "Train: loss: 0.6518 | accuracy: 0.6116 | f-acore: 0.5971\n",
            "Test:  loss: 0.7087 | accuracy: 0.5123 | f1: 0.5104\n",
            "Validation:  loss: 0.6703 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00070\n",
            "Train: loss: 0.6548 | accuracy: 0.6199 | f-acore: 0.6121\n",
            "Test:  loss: 0.6948 | accuracy: 0.5260 | f1: 0.5259\n",
            "Validation:  loss: 0.6768 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00071\n",
            "Train: loss: 0.6434 | accuracy: 0.6217 | f-acore: 0.6136\n",
            "Test:  loss: 0.7018 | accuracy: 0.5315 | f1: 0.5315\n",
            "Validation:  loss: 0.6765 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00072\n",
            "Train: loss: 0.6467 | accuracy: 0.6181 | f-acore: 0.5979\n",
            "Test:  loss: 0.6977 | accuracy: 0.5041 | f1: 0.4903\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5000 | f1: 0.4556\n",
            "Epoch 00073\n",
            "Train: loss: 0.6439 | accuracy: 0.6300 | f-acore: 0.6137\n",
            "Test:  loss: 0.6949 | accuracy: 0.5452 | f1: 0.5446\n",
            "Validation:  loss: 0.6732 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00074\n",
            "Train: loss: 0.6434 | accuracy: 0.6249 | f-acore: 0.6164\n",
            "Test:  loss: 0.7055 | accuracy: 0.5233 | f1: 0.5231\n",
            "Validation:  loss: 0.6758 | accuracy: 0.5476 | f1: 0.5143\n",
            "Epoch 00075\n",
            "Train: loss: 0.6431 | accuracy: 0.6204 | f-acore: 0.6088\n",
            "Test:  loss: 0.6983 | accuracy: 0.5452 | f1: 0.5451\n",
            "Validation:  loss: 0.6778 | accuracy: 0.5000 | f1: 0.4556\n",
            "Epoch 00076\n",
            "Train: loss: 0.6444 | accuracy: 0.6227 | f-acore: 0.6022\n",
            "Test:  loss: 0.7048 | accuracy: 0.5205 | f1: 0.5204\n",
            "Validation:  loss: 0.6800 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00077\n",
            "Train: loss: 0.6405 | accuracy: 0.6327 | f-acore: 0.6227\n",
            "Test:  loss: 0.7056 | accuracy: 0.5315 | f1: 0.5279\n",
            "Validation:  loss: 0.6822 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00078\n",
            "Train: loss: 0.6506 | accuracy: 0.6167 | f-acore: 0.5960\n",
            "Test:  loss: 0.7528 | accuracy: 0.5425 | f1: 0.4891\n",
            "Validation:  loss: 0.7129 | accuracy: 0.5119 | f1: 0.4459\n",
            "Epoch 00079\n",
            "Train: loss: 0.6437 | accuracy: 0.6272 | f-acore: 0.6229\n",
            "Test:  loss: 0.7278 | accuracy: 0.5151 | f1: 0.4197\n",
            "Validation:  loss: 0.7151 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00080\n",
            "Train: loss: 0.6376 | accuracy: 0.6231 | f-acore: 0.6141\n",
            "Test:  loss: 0.7031 | accuracy: 0.5315 | f1: 0.5252\n",
            "Validation:  loss: 0.6813 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00081\n",
            "Train: loss: 0.6458 | accuracy: 0.6277 | f-acore: 0.6145\n",
            "Test:  loss: 0.7130 | accuracy: 0.5425 | f1: 0.5369\n",
            "Validation:  loss: 0.6734 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00082\n",
            "Train: loss: 0.6370 | accuracy: 0.6295 | f-acore: 0.6171\n",
            "Test:  loss: 0.7102 | accuracy: 0.5288 | f1: 0.5170\n",
            "Validation:  loss: 0.6815 | accuracy: 0.5238 | f1: 0.4815\n",
            "Epoch 00083\n",
            "Train: loss: 0.6373 | accuracy: 0.6364 | f-acore: 0.6237\n",
            "Test:  loss: 0.7082 | accuracy: 0.5233 | f1: 0.5198\n",
            "Validation:  loss: 0.6747 | accuracy: 0.5952 | f1: 0.5800\n",
            "Epoch 00084\n",
            "Train: loss: 0.6393 | accuracy: 0.6309 | f-acore: 0.6208\n",
            "Test:  loss: 0.7153 | accuracy: 0.5205 | f1: 0.5185\n",
            "Validation:  loss: 0.6723 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00085\n",
            "Train: loss: 0.6313 | accuracy: 0.6268 | f-acore: 0.6163\n",
            "Test:  loss: 0.6910 | accuracy: 0.5370 | f1: 0.5361\n",
            "Validation:  loss: 0.6837 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00086\n",
            "Train: loss: 0.6367 | accuracy: 0.6437 | f-acore: 0.6354\n",
            "Test:  loss: 0.7073 | accuracy: 0.5123 | f1: 0.5115\n",
            "Validation:  loss: 0.6636 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00087\n",
            "Train: loss: 0.6279 | accuracy: 0.6483 | f-acore: 0.6410\n",
            "Test:  loss: 0.7177 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.6697 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00088\n",
            "Train: loss: 0.6335 | accuracy: 0.6488 | f-acore: 0.6321\n",
            "Test:  loss: 0.7130 | accuracy: 0.5151 | f1: 0.5086\n",
            "Validation:  loss: 0.6793 | accuracy: 0.5000 | f1: 0.4556\n",
            "Epoch 00089\n",
            "Train: loss: 0.6339 | accuracy: 0.6428 | f-acore: 0.6360\n",
            "Test:  loss: 0.7090 | accuracy: 0.5288 | f1: 0.5186\n",
            "Validation:  loss: 0.6876 | accuracy: 0.5119 | f1: 0.4557\n",
            "Epoch 00090\n",
            "Train: loss: 0.6370 | accuracy: 0.6451 | f-acore: 0.6407\n",
            "Test:  loss: 0.7245 | accuracy: 0.5233 | f1: 0.5034\n",
            "Validation:  loss: 0.6915 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00091\n",
            "Train: loss: 0.6304 | accuracy: 0.6346 | f-acore: 0.6063\n",
            "Test:  loss: 0.7106 | accuracy: 0.5151 | f1: 0.4987\n",
            "Validation:  loss: 0.6931 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00092\n",
            "Train: loss: 0.6403 | accuracy: 0.6488 | f-acore: 0.6443\n",
            "Test:  loss: 0.7201 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 0.6849 | accuracy: 0.5238 | f1: 0.4734\n",
            "Epoch 00093\n",
            "Train: loss: 0.6344 | accuracy: 0.6419 | f-acore: 0.6196\n",
            "Test:  loss: 0.7185 | accuracy: 0.5096 | f1: 0.5071\n",
            "Validation:  loss: 0.6715 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00094\n",
            "Train: loss: 0.6366 | accuracy: 0.6447 | f-acore: 0.6220\n",
            "Test:  loss: 0.7186 | accuracy: 0.4932 | f1: 0.4850\n",
            "Validation:  loss: 0.6769 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00095\n",
            "Train: loss: 0.6255 | accuracy: 0.6506 | f-acore: 0.6455\n",
            "Test:  loss: 0.7070 | accuracy: 0.5479 | f1: 0.5478\n",
            "Validation:  loss: 0.6705 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00096\n",
            "Train: loss: 0.6300 | accuracy: 0.6511 | f-acore: 0.6446\n",
            "Test:  loss: 0.7070 | accuracy: 0.5288 | f1: 0.5275\n",
            "Validation:  loss: 0.6750 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00097\n",
            "Train: loss: 0.6218 | accuracy: 0.6625 | f-acore: 0.6488\n",
            "Test:  loss: 0.7103 | accuracy: 0.5096 | f1: 0.5089\n",
            "Validation:  loss: 0.6766 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00098\n",
            "Train: loss: 0.6102 | accuracy: 0.6502 | f-acore: 0.6434\n",
            "Test:  loss: 0.7101 | accuracy: 0.5589 | f1: 0.5563\n",
            "Validation:  loss: 0.6713 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00099\n",
            "Train: loss: 0.6199 | accuracy: 0.6538 | f-acore: 0.6458\n",
            "Test:  loss: 0.7144 | accuracy: 0.5260 | f1: 0.5260\n",
            "Validation:  loss: 0.6688 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00100\n",
            "Train: loss: 0.6143 | accuracy: 0.6492 | f-acore: 0.6399\n",
            "Test:  loss: 0.7213 | accuracy: 0.5123 | f1: 0.5123\n",
            "Validation:  loss: 0.6618 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00101\n",
            "Train: loss: 0.6199 | accuracy: 0.6630 | f-acore: 0.6578\n",
            "Test:  loss: 0.7195 | accuracy: 0.5205 | f1: 0.5185\n",
            "Validation:  loss: 0.6713 | accuracy: 0.5714 | f1: 0.5457\n",
            "Epoch 00102\n",
            "Train: loss: 0.6063 | accuracy: 0.6570 | f-acore: 0.6491\n",
            "Test:  loss: 0.7333 | accuracy: 0.5151 | f1: 0.5144\n",
            "Validation:  loss: 0.6647 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00103\n",
            "Train: loss: 0.6180 | accuracy: 0.6529 | f-acore: 0.6504\n",
            "Test:  loss: 0.7416 | accuracy: 0.5014 | f1: 0.5012\n",
            "Validation:  loss: 0.6623 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00104\n",
            "Train: loss: 0.6216 | accuracy: 0.6593 | f-acore: 0.6527\n",
            "Test:  loss: 0.7185 | accuracy: 0.5370 | f1: 0.5369\n",
            "Validation:  loss: 0.6611 | accuracy: 0.6190 | f1: 0.6188\n",
            "Epoch 00105\n",
            "Train: loss: 0.6056 | accuracy: 0.6630 | f-acore: 0.6558\n",
            "Test:  loss: 0.7187 | accuracy: 0.5123 | f1: 0.5067\n",
            "Validation:  loss: 0.6747 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00106\n",
            "Train: loss: 0.6151 | accuracy: 0.6644 | f-acore: 0.6531\n",
            "Test:  loss: 0.7429 | accuracy: 0.5151 | f1: 0.5151\n",
            "Validation:  loss: 0.6817 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00107\n",
            "Train: loss: 0.6290 | accuracy: 0.6653 | f-acore: 0.6596\n",
            "Test:  loss: 0.7365 | accuracy: 0.5288 | f1: 0.5186\n",
            "Validation:  loss: 0.6896 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00108\n",
            "Train: loss: 0.6153 | accuracy: 0.6584 | f-acore: 0.6494\n",
            "Test:  loss: 0.7243 | accuracy: 0.4959 | f1: 0.4912\n",
            "Validation:  loss: 0.6711 | accuracy: 0.5595 | f1: 0.5450\n",
            "Epoch 00109\n",
            "Train: loss: 0.6168 | accuracy: 0.6703 | f-acore: 0.6644\n",
            "Test:  loss: 0.7349 | accuracy: 0.5397 | f1: 0.5332\n",
            "Validation:  loss: 0.6868 | accuracy: 0.5476 | f1: 0.5204\n",
            "Epoch 00110\n",
            "Train: loss: 0.6196 | accuracy: 0.6717 | f-acore: 0.6661\n",
            "Test:  loss: 0.7445 | accuracy: 0.5041 | f1: 0.5007\n",
            "Validation:  loss: 0.6788 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00111\n",
            "Train: loss: 0.6089 | accuracy: 0.6768 | f-acore: 0.6723\n",
            "Test:  loss: 0.7303 | accuracy: 0.5178 | f1: 0.5162\n",
            "Validation:  loss: 0.6808 | accuracy: 0.5714 | f1: 0.5553\n",
            "Epoch 00112\n",
            "Train: loss: 0.6131 | accuracy: 0.6699 | f-acore: 0.6655\n",
            "Test:  loss: 0.7397 | accuracy: 0.4986 | f1: 0.4925\n",
            "Validation:  loss: 0.6814 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00113\n",
            "Train: loss: 0.6002 | accuracy: 0.6593 | f-acore: 0.6530\n",
            "Test:  loss: 0.7480 | accuracy: 0.4877 | f1: 0.4861\n",
            "Validation:  loss: 0.6641 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00114\n",
            "Train: loss: 0.5906 | accuracy: 0.6694 | f-acore: 0.6599\n",
            "Test:  loss: 0.7212 | accuracy: 0.5260 | f1: 0.5260\n",
            "Validation:  loss: 0.6644 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00115\n",
            "Train: loss: 0.5984 | accuracy: 0.6671 | f-acore: 0.6606\n",
            "Test:  loss: 0.7419 | accuracy: 0.5123 | f1: 0.5078\n",
            "Validation:  loss: 0.6781 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00116\n",
            "Train: loss: 0.6006 | accuracy: 0.6749 | f-acore: 0.6694\n",
            "Test:  loss: 0.7382 | accuracy: 0.5178 | f1: 0.5168\n",
            "Validation:  loss: 0.6650 | accuracy: 0.6310 | f1: 0.6267\n",
            "Epoch 00117\n",
            "Train: loss: 0.5941 | accuracy: 0.6868 | f-acore: 0.6814\n",
            "Test:  loss: 0.7374 | accuracy: 0.5233 | f1: 0.5189\n",
            "Validation:  loss: 0.6793 | accuracy: 0.5357 | f1: 0.4981\n",
            "Epoch 00118\n",
            "Train: loss: 0.5845 | accuracy: 0.6777 | f-acore: 0.6702\n",
            "Test:  loss: 0.7378 | accuracy: 0.5233 | f1: 0.5178\n",
            "Validation:  loss: 0.6777 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00119\n",
            "Train: loss: 0.5925 | accuracy: 0.6841 | f-acore: 0.6767\n",
            "Test:  loss: 0.7459 | accuracy: 0.5123 | f1: 0.5067\n",
            "Validation:  loss: 0.6662 | accuracy: 0.5952 | f1: 0.5837\n",
            "Epoch 00120\n",
            "Train: loss: 0.5929 | accuracy: 0.6818 | f-acore: 0.6767\n",
            "Test:  loss: 0.7332 | accuracy: 0.5233 | f1: 0.5223\n",
            "Validation:  loss: 0.6620 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00121\n",
            "Train: loss: 0.6002 | accuracy: 0.6850 | f-acore: 0.6769\n",
            "Test:  loss: 0.7467 | accuracy: 0.5370 | f1: 0.5369\n",
            "Validation:  loss: 0.6607 | accuracy: 0.6071 | f1: 0.6071\n",
            "Epoch 00122\n",
            "Train: loss: 0.6215 | accuracy: 0.6708 | f-acore: 0.6697\n",
            "Test:  loss: 0.7402 | accuracy: 0.5205 | f1: 0.5188\n",
            "Validation:  loss: 0.6741 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00123\n",
            "Train: loss: 0.5853 | accuracy: 0.6836 | f-acore: 0.6788\n",
            "Test:  loss: 0.7586 | accuracy: 0.5233 | f1: 0.5105\n",
            "Validation:  loss: 0.6960 | accuracy: 0.5595 | f1: 0.5302\n",
            "Epoch 00124\n",
            "Train: loss: 0.5839 | accuracy: 0.6836 | f-acore: 0.6744\n",
            "Test:  loss: 0.7535 | accuracy: 0.5233 | f1: 0.5227\n",
            "Validation:  loss: 0.6724 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00125\n",
            "Train: loss: 0.5986 | accuracy: 0.6768 | f-acore: 0.6730\n",
            "Test:  loss: 0.7526 | accuracy: 0.5068 | f1: 0.5037\n",
            "Validation:  loss: 0.6897 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00126\n",
            "Train: loss: 0.5847 | accuracy: 0.6901 | f-acore: 0.6864\n",
            "Test:  loss: 0.7471 | accuracy: 0.5233 | f1: 0.5194\n",
            "Validation:  loss: 0.6817 | accuracy: 0.5476 | f1: 0.5204\n",
            "Epoch 00127\n",
            "Train: loss: 0.5940 | accuracy: 0.6813 | f-acore: 0.6747\n",
            "Test:  loss: 0.7663 | accuracy: 0.5370 | f1: 0.5370\n",
            "Validation:  loss: 0.6637 | accuracy: 0.6190 | f1: 0.6182\n",
            "Epoch 00128\n",
            "Train: loss: 0.5807 | accuracy: 0.6882 | f-acore: 0.6862\n",
            "Test:  loss: 0.7639 | accuracy: 0.5205 | f1: 0.5204\n",
            "Validation:  loss: 0.6578 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00129\n",
            "Train: loss: 0.5891 | accuracy: 0.6823 | f-acore: 0.6789\n",
            "Test:  loss: 0.7533 | accuracy: 0.5452 | f1: 0.5450\n",
            "Validation:  loss: 0.6789 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00130\n",
            "Train: loss: 0.5904 | accuracy: 0.6781 | f-acore: 0.6687\n",
            "Test:  loss: 0.7580 | accuracy: 0.5205 | f1: 0.5205\n",
            "Validation:  loss: 0.6705 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00131\n",
            "Train: loss: 0.5923 | accuracy: 0.6859 | f-acore: 0.6804\n",
            "Test:  loss: 0.7460 | accuracy: 0.5041 | f1: 0.5039\n",
            "Validation:  loss: 0.6771 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00132\n",
            "Train: loss: 0.5946 | accuracy: 0.6905 | f-acore: 0.6830\n",
            "Test:  loss: 0.7570 | accuracy: 0.5205 | f1: 0.5205\n",
            "Validation:  loss: 0.6756 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00133\n",
            "Train: loss: 0.5763 | accuracy: 0.6887 | f-acore: 0.6858\n",
            "Test:  loss: 0.7622 | accuracy: 0.5014 | f1: 0.5011\n",
            "Validation:  loss: 0.6806 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00134\n",
            "Train: loss: 0.5892 | accuracy: 0.6891 | f-acore: 0.6843\n",
            "Test:  loss: 0.7525 | accuracy: 0.5534 | f1: 0.5526\n",
            "Validation:  loss: 0.6881 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00135\n",
            "Train: loss: 0.5881 | accuracy: 0.6933 | f-acore: 0.6886\n",
            "Test:  loss: 0.7577 | accuracy: 0.5425 | f1: 0.5424\n",
            "Validation:  loss: 0.6978 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00136\n",
            "Train: loss: 0.5922 | accuracy: 0.6891 | f-acore: 0.6848\n",
            "Test:  loss: 0.7656 | accuracy: 0.5205 | f1: 0.5203\n",
            "Validation:  loss: 0.6827 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00137\n",
            "Train: loss: 0.5898 | accuracy: 0.6878 | f-acore: 0.6812\n",
            "Test:  loss: 0.7763 | accuracy: 0.4877 | f1: 0.4794\n",
            "Validation:  loss: 0.7144 | accuracy: 0.5833 | f1: 0.5655\n",
            "Epoch 00138\n",
            "Train: loss: 0.5978 | accuracy: 0.6997 | f-acore: 0.6893\n",
            "Test:  loss: 0.7679 | accuracy: 0.5041 | f1: 0.5003\n",
            "Validation:  loss: 0.6882 | accuracy: 0.5833 | f1: 0.5609\n",
            "Epoch 00139\n",
            "Train: loss: 0.5927 | accuracy: 0.6910 | f-acore: 0.6859\n",
            "Test:  loss: 0.7593 | accuracy: 0.5342 | f1: 0.5341\n",
            "Validation:  loss: 0.6577 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00140\n",
            "Train: loss: 0.5772 | accuracy: 0.6951 | f-acore: 0.6895\n",
            "Test:  loss: 0.7415 | accuracy: 0.5288 | f1: 0.5249\n",
            "Validation:  loss: 0.6776 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00141\n",
            "Train: loss: 0.5889 | accuracy: 0.6997 | f-acore: 0.6905\n",
            "Test:  loss: 0.7483 | accuracy: 0.5068 | f1: 0.5017\n",
            "Validation:  loss: 0.6848 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00142\n",
            "Train: loss: 0.5778 | accuracy: 0.6965 | f-acore: 0.6937\n",
            "Test:  loss: 0.7640 | accuracy: 0.5233 | f1: 0.5194\n",
            "Validation:  loss: 0.6889 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00143\n",
            "Train: loss: 0.5717 | accuracy: 0.7006 | f-acore: 0.6948\n",
            "Test:  loss: 0.7686 | accuracy: 0.5342 | f1: 0.5304\n",
            "Validation:  loss: 0.6951 | accuracy: 0.5714 | f1: 0.5333\n",
            "Epoch 00144\n",
            "Train: loss: 0.5732 | accuracy: 0.6891 | f-acore: 0.6828\n",
            "Test:  loss: 0.7649 | accuracy: 0.5479 | f1: 0.5473\n",
            "Validation:  loss: 0.6592 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00145\n",
            "Train: loss: 0.5680 | accuracy: 0.6992 | f-acore: 0.6952\n",
            "Test:  loss: 0.7802 | accuracy: 0.5096 | f1: 0.5036\n",
            "Validation:  loss: 0.6839 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00146\n",
            "Train: loss: 0.5721 | accuracy: 0.6928 | f-acore: 0.6858\n",
            "Test:  loss: 0.7692 | accuracy: 0.5260 | f1: 0.5236\n",
            "Validation:  loss: 0.6697 | accuracy: 0.5714 | f1: 0.5553\n",
            "Epoch 00147\n",
            "Train: loss: 0.5689 | accuracy: 0.7020 | f-acore: 0.6986\n",
            "Test:  loss: 0.7744 | accuracy: 0.5233 | f1: 0.5207\n",
            "Validation:  loss: 0.6870 | accuracy: 0.5476 | f1: 0.5143\n",
            "Epoch 00148\n",
            "Train: loss: 0.5664 | accuracy: 0.7079 | f-acore: 0.7026\n",
            "Test:  loss: 0.7775 | accuracy: 0.5342 | f1: 0.5337\n",
            "Validation:  loss: 0.6829 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00149\n",
            "Train: loss: 0.5830 | accuracy: 0.7006 | f-acore: 0.6963\n",
            "Test:  loss: 0.7633 | accuracy: 0.5452 | f1: 0.5444\n",
            "Validation:  loss: 0.6978 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00150\n",
            "Train: loss: 0.5838 | accuracy: 0.7029 | f-acore: 0.6989\n",
            "Test:  loss: 0.7789 | accuracy: 0.5425 | f1: 0.5420\n",
            "Validation:  loss: 0.6702 | accuracy: 0.5952 | f1: 0.5950\n",
            "Epoch 00151\n",
            "Train: loss: 0.5521 | accuracy: 0.7024 | f-acore: 0.6974\n",
            "Test:  loss: 0.7917 | accuracy: 0.5233 | f1: 0.5225\n",
            "Validation:  loss: 0.7107 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00152\n",
            "Train: loss: 0.5697 | accuracy: 0.7056 | f-acore: 0.6996\n",
            "Test:  loss: 0.8070 | accuracy: 0.5123 | f1: 0.5083\n",
            "Validation:  loss: 0.6957 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00153\n",
            "Train: loss: 0.5647 | accuracy: 0.7047 | f-acore: 0.7001\n",
            "Test:  loss: 0.7959 | accuracy: 0.5288 | f1: 0.5258\n",
            "Validation:  loss: 0.7104 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00154\n",
            "Train: loss: 0.5892 | accuracy: 0.6942 | f-acore: 0.6912\n",
            "Test:  loss: 0.7876 | accuracy: 0.5068 | f1: 0.5037\n",
            "Validation:  loss: 0.6871 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00155\n",
            "Train: loss: 0.5644 | accuracy: 0.7088 | f-acore: 0.7045\n",
            "Test:  loss: 0.7939 | accuracy: 0.5315 | f1: 0.5312\n",
            "Validation:  loss: 0.6814 | accuracy: 0.6071 | f1: 0.5942\n",
            "Epoch 00156\n",
            "Train: loss: 0.5677 | accuracy: 0.7033 | f-acore: 0.6964\n",
            "Test:  loss: 0.8188 | accuracy: 0.5233 | f1: 0.5223\n",
            "Validation:  loss: 0.6910 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00157\n",
            "Train: loss: 0.5528 | accuracy: 0.7144 | f-acore: 0.7131\n",
            "Test:  loss: 0.7955 | accuracy: 0.5233 | f1: 0.5227\n",
            "Validation:  loss: 0.6753 | accuracy: 0.6190 | f1: 0.6111\n",
            "Epoch 00158\n",
            "Train: loss: 0.5564 | accuracy: 0.7029 | f-acore: 0.6995\n",
            "Test:  loss: 0.7957 | accuracy: 0.5315 | f1: 0.5306\n",
            "Validation:  loss: 0.7021 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00159\n",
            "Train: loss: 0.5461 | accuracy: 0.7199 | f-acore: 0.7145\n",
            "Test:  loss: 0.8094 | accuracy: 0.5151 | f1: 0.5139\n",
            "Validation:  loss: 0.6783 | accuracy: 0.5952 | f1: 0.5837\n",
            "Epoch 00160\n",
            "Train: loss: 0.5505 | accuracy: 0.7148 | f-acore: 0.7118\n",
            "Test:  loss: 0.8079 | accuracy: 0.5178 | f1: 0.5172\n",
            "Validation:  loss: 0.6783 | accuracy: 0.6071 | f1: 0.5975\n",
            "Epoch 00161\n",
            "Train: loss: 0.5562 | accuracy: 0.7061 | f-acore: 0.7015\n",
            "Test:  loss: 0.8038 | accuracy: 0.5123 | f1: 0.5100\n",
            "Validation:  loss: 0.6867 | accuracy: 0.5595 | f1: 0.5407\n",
            "Epoch 00162\n",
            "Train: loss: 0.5678 | accuracy: 0.7088 | f-acore: 0.7053\n",
            "Test:  loss: 0.8055 | accuracy: 0.5151 | f1: 0.5130\n",
            "Validation:  loss: 0.7088 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00163\n",
            "Train: loss: 0.5596 | accuracy: 0.7176 | f-acore: 0.7143\n",
            "Test:  loss: 0.7761 | accuracy: 0.5370 | f1: 0.5365\n",
            "Validation:  loss: 0.7069 | accuracy: 0.5238 | f1: 0.5059\n",
            "Epoch 00164\n",
            "Train: loss: 0.5674 | accuracy: 0.7203 | f-acore: 0.7165\n",
            "Test:  loss: 0.8119 | accuracy: 0.5233 | f1: 0.5231\n",
            "Validation:  loss: 0.6903 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00165\n",
            "Train: loss: 0.5624 | accuracy: 0.7024 | f-acore: 0.7009\n",
            "Test:  loss: 0.8231 | accuracy: 0.5233 | f1: 0.5172\n",
            "Validation:  loss: 0.6801 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00166\n",
            "Train: loss: 0.5570 | accuracy: 0.7125 | f-acore: 0.7088\n",
            "Test:  loss: 0.8305 | accuracy: 0.5123 | f1: 0.5123\n",
            "Validation:  loss: 0.6721 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00167\n",
            "Train: loss: 0.5577 | accuracy: 0.7134 | f-acore: 0.7115\n",
            "Test:  loss: 0.8178 | accuracy: 0.5370 | f1: 0.5366\n",
            "Validation:  loss: 0.7100 | accuracy: 0.5714 | f1: 0.5592\n",
            "Epoch 00168\n",
            "Train: loss: 0.5569 | accuracy: 0.7098 | f-acore: 0.7054\n",
            "Test:  loss: 0.8364 | accuracy: 0.5342 | f1: 0.5342\n",
            "Validation:  loss: 0.6704 | accuracy: 0.6190 | f1: 0.6171\n",
            "Epoch 00169\n",
            "Train: loss: 0.5547 | accuracy: 0.7221 | f-acore: 0.7205\n",
            "Test:  loss: 0.8424 | accuracy: 0.5288 | f1: 0.5277\n",
            "Validation:  loss: 0.6944 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00170\n",
            "Train: loss: 0.5617 | accuracy: 0.7070 | f-acore: 0.7051\n",
            "Test:  loss: 0.8031 | accuracy: 0.5233 | f1: 0.5207\n",
            "Validation:  loss: 0.6888 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00171\n",
            "Train: loss: 0.5648 | accuracy: 0.7111 | f-acore: 0.7074\n",
            "Test:  loss: 0.7968 | accuracy: 0.5315 | f1: 0.5301\n",
            "Validation:  loss: 0.7065 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00172\n",
            "Train: loss: 0.5590 | accuracy: 0.6988 | f-acore: 0.6943\n",
            "Test:  loss: 0.8038 | accuracy: 0.5205 | f1: 0.5198\n",
            "Validation:  loss: 0.6841 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00173\n",
            "Train: loss: 0.5551 | accuracy: 0.7162 | f-acore: 0.7134\n",
            "Test:  loss: 0.8261 | accuracy: 0.5178 | f1: 0.5155\n",
            "Validation:  loss: 0.7046 | accuracy: 0.5952 | f1: 0.5837\n",
            "Epoch 00174\n",
            "Train: loss: 0.5483 | accuracy: 0.7180 | f-acore: 0.7146\n",
            "Test:  loss: 0.8104 | accuracy: 0.5123 | f1: 0.5123\n",
            "Validation:  loss: 0.6740 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00175\n",
            "Train: loss: 0.5434 | accuracy: 0.7148 | f-acore: 0.7129\n",
            "Test:  loss: 0.8183 | accuracy: 0.5397 | f1: 0.5397\n",
            "Validation:  loss: 0.6907 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00176\n",
            "Train: loss: 0.5357 | accuracy: 0.7185 | f-acore: 0.7152\n",
            "Test:  loss: 0.8313 | accuracy: 0.5288 | f1: 0.5280\n",
            "Validation:  loss: 0.6931 | accuracy: 0.6310 | f1: 0.6245\n",
            "Epoch 00177\n",
            "Train: loss: 0.5244 | accuracy: 0.7134 | f-acore: 0.7105\n",
            "Test:  loss: 0.8356 | accuracy: 0.5205 | f1: 0.5191\n",
            "Validation:  loss: 0.6884 | accuracy: 0.6190 | f1: 0.6136\n",
            "Epoch 00178\n",
            "Train: loss: 0.5620 | accuracy: 0.7079 | f-acore: 0.7036\n",
            "Test:  loss: 0.8206 | accuracy: 0.5288 | f1: 0.5272\n",
            "Validation:  loss: 0.7043 | accuracy: 0.6190 | f1: 0.6111\n",
            "Epoch 00179\n",
            "Train: loss: 0.5514 | accuracy: 0.7134 | f-acore: 0.7094\n",
            "Test:  loss: 0.7947 | accuracy: 0.5342 | f1: 0.5342\n",
            "Validation:  loss: 0.7180 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00180\n",
            "Train: loss: 0.5441 | accuracy: 0.7322 | f-acore: 0.7290\n",
            "Test:  loss: 0.8145 | accuracy: 0.5178 | f1: 0.5170\n",
            "Validation:  loss: 0.6973 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00181\n",
            "Train: loss: 0.5506 | accuracy: 0.7079 | f-acore: 0.7039\n",
            "Test:  loss: 0.8350 | accuracy: 0.5397 | f1: 0.5393\n",
            "Validation:  loss: 0.7079 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00182\n",
            "Train: loss: 0.5559 | accuracy: 0.7001 | f-acore: 0.6976\n",
            "Test:  loss: 0.8155 | accuracy: 0.5233 | f1: 0.5214\n",
            "Validation:  loss: 0.7767 | accuracy: 0.4881 | f1: 0.4383\n",
            "Epoch 00183\n",
            "Train: loss: 0.5384 | accuracy: 0.7244 | f-acore: 0.7211\n",
            "Test:  loss: 0.8217 | accuracy: 0.5479 | f1: 0.5479\n",
            "Validation:  loss: 0.6913 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00184\n",
            "Train: loss: 0.5445 | accuracy: 0.7130 | f-acore: 0.7095\n",
            "Test:  loss: 0.8510 | accuracy: 0.5260 | f1: 0.5260\n",
            "Validation:  loss: 0.6897 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00185\n",
            "Train: loss: 0.5434 | accuracy: 0.7088 | f-acore: 0.7039\n",
            "Test:  loss: 0.8236 | accuracy: 0.5288 | f1: 0.5287\n",
            "Validation:  loss: 0.7093 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00186\n",
            "Train: loss: 0.5292 | accuracy: 0.7189 | f-acore: 0.7142\n",
            "Test:  loss: 0.8259 | accuracy: 0.5233 | f1: 0.5233\n",
            "Validation:  loss: 0.6911 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00187\n",
            "Train: loss: 0.5638 | accuracy: 0.7203 | f-acore: 0.7171\n",
            "Test:  loss: 0.8550 | accuracy: 0.4986 | f1: 0.4957\n",
            "Validation:  loss: 0.7200 | accuracy: 0.5833 | f1: 0.5609\n",
            "Epoch 00188\n",
            "Train: loss: 0.5536 | accuracy: 0.7240 | f-acore: 0.7201\n",
            "Test:  loss: 0.8341 | accuracy: 0.5096 | f1: 0.5081\n",
            "Validation:  loss: 0.7143 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00189\n",
            "Train: loss: 0.5339 | accuracy: 0.7249 | f-acore: 0.7196\n",
            "Test:  loss: 0.8180 | accuracy: 0.5233 | f1: 0.5232\n",
            "Validation:  loss: 0.6822 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00190\n",
            "Train: loss: 0.5425 | accuracy: 0.7304 | f-acore: 0.7278\n",
            "Test:  loss: 0.8459 | accuracy: 0.5096 | f1: 0.5017\n",
            "Validation:  loss: 0.7501 | accuracy: 0.5476 | f1: 0.5204\n",
            "Epoch 00191\n",
            "Train: loss: 0.5311 | accuracy: 0.7189 | f-acore: 0.7121\n",
            "Test:  loss: 0.8179 | accuracy: 0.5233 | f1: 0.5232\n",
            "Validation:  loss: 0.7197 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00192\n",
            "Train: loss: 0.5406 | accuracy: 0.7276 | f-acore: 0.7250\n",
            "Test:  loss: 0.8498 | accuracy: 0.5315 | f1: 0.5315\n",
            "Validation:  loss: 0.7027 | accuracy: 0.6071 | f1: 0.6026\n",
            "Epoch 00193\n",
            "Train: loss: 0.5511 | accuracy: 0.7304 | f-acore: 0.7294\n",
            "Test:  loss: 0.8460 | accuracy: 0.5342 | f1: 0.5340\n",
            "Validation:  loss: 0.7370 | accuracy: 0.5595 | f1: 0.5450\n",
            "Epoch 00194\n",
            "Train: loss: 0.5248 | accuracy: 0.7322 | f-acore: 0.7288\n",
            "Test:  loss: 0.8288 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 0.6973 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00195\n",
            "Train: loss: 0.5351 | accuracy: 0.7295 | f-acore: 0.7276\n",
            "Test:  loss: 0.8256 | accuracy: 0.5260 | f1: 0.5251\n",
            "Validation:  loss: 0.6959 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00196\n",
            "Train: loss: 0.5364 | accuracy: 0.7254 | f-acore: 0.7215\n",
            "Test:  loss: 0.8205 | accuracy: 0.5260 | f1: 0.5228\n",
            "Validation:  loss: 0.7145 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00197\n",
            "Train: loss: 0.5207 | accuracy: 0.7322 | f-acore: 0.7282\n",
            "Test:  loss: 0.8345 | accuracy: 0.5288 | f1: 0.5280\n",
            "Validation:  loss: 0.6976 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00198\n",
            "Train: loss: 0.5199 | accuracy: 0.7345 | f-acore: 0.7320\n",
            "Test:  loss: 0.8500 | accuracy: 0.5288 | f1: 0.5282\n",
            "Validation:  loss: 0.7131 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00199\n",
            "Train: loss: 0.5288 | accuracy: 0.7382 | f-acore: 0.7358\n",
            "Test:  loss: 0.8694 | accuracy: 0.5342 | f1: 0.5321\n",
            "Validation:  loss: 0.7249 | accuracy: 0.5714 | f1: 0.5592\n",
            "Epoch 00200\n",
            "Train: loss: 0.5373 | accuracy: 0.7231 | f-acore: 0.7186\n",
            "Test:  loss: 0.8719 | accuracy: 0.5123 | f1: 0.5083\n",
            "Validation:  loss: 0.7532 | accuracy: 0.6071 | f1: 0.5904\n",
            "Epoch 00201\n",
            "Train: loss: 0.5231 | accuracy: 0.7336 | f-acore: 0.7297\n",
            "Test:  loss: 0.8565 | accuracy: 0.5151 | f1: 0.5144\n",
            "Validation:  loss: 0.7052 | accuracy: 0.6310 | f1: 0.6219\n",
            "Epoch 00202\n",
            "Train: loss: 0.5170 | accuracy: 0.7318 | f-acore: 0.7291\n",
            "Test:  loss: 0.8640 | accuracy: 0.5260 | f1: 0.5251\n",
            "Validation:  loss: 0.7277 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00203\n",
            "Train: loss: 0.5197 | accuracy: 0.7391 | f-acore: 0.7359\n",
            "Test:  loss: 0.8608 | accuracy: 0.5178 | f1: 0.5159\n",
            "Validation:  loss: 0.7158 | accuracy: 0.6071 | f1: 0.5942\n",
            "Epoch 00204\n",
            "Train: loss: 0.5141 | accuracy: 0.7354 | f-acore: 0.7339\n",
            "Test:  loss: 0.8452 | accuracy: 0.5260 | f1: 0.5258\n",
            "Validation:  loss: 0.6812 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00205\n",
            "Train: loss: 0.5311 | accuracy: 0.7304 | f-acore: 0.7259\n",
            "Test:  loss: 0.8499 | accuracy: 0.5260 | f1: 0.5260\n",
            "Validation:  loss: 0.7014 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00206\n",
            "Train: loss: 0.5169 | accuracy: 0.7469 | f-acore: 0.7444\n",
            "Test:  loss: 0.8594 | accuracy: 0.5205 | f1: 0.5191\n",
            "Validation:  loss: 0.7062 | accuracy: 0.5952 | f1: 0.5868\n",
            "Epoch 00207\n",
            "Train: loss: 0.5321 | accuracy: 0.7267 | f-acore: 0.7236\n",
            "Test:  loss: 0.8367 | accuracy: 0.5233 | f1: 0.5225\n",
            "Validation:  loss: 0.6942 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00208\n",
            "Train: loss: 0.5239 | accuracy: 0.7354 | f-acore: 0.7323\n",
            "Test:  loss: 0.8349 | accuracy: 0.5233 | f1: 0.5220\n",
            "Validation:  loss: 0.6618 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00209\n",
            "Train: loss: 0.5248 | accuracy: 0.7414 | f-acore: 0.7386\n",
            "Test:  loss: 0.8691 | accuracy: 0.5068 | f1: 0.5041\n",
            "Validation:  loss: 0.7059 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00210\n",
            "Train: loss: 0.5240 | accuracy: 0.7240 | f-acore: 0.7203\n",
            "Test:  loss: 0.8495 | accuracy: 0.5315 | f1: 0.5308\n",
            "Validation:  loss: 0.7048 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00211\n",
            "Train: loss: 0.5156 | accuracy: 0.7336 | f-acore: 0.7306\n",
            "Test:  loss: 0.8504 | accuracy: 0.5205 | f1: 0.5204\n",
            "Validation:  loss: 0.6969 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00212\n",
            "Train: loss: 0.5212 | accuracy: 0.7331 | f-acore: 0.7304\n",
            "Test:  loss: 0.8616 | accuracy: 0.5288 | f1: 0.5282\n",
            "Validation:  loss: 0.7021 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00213\n",
            "Train: loss: 0.5256 | accuracy: 0.7341 | f-acore: 0.7315\n",
            "Test:  loss: 0.8543 | accuracy: 0.5288 | f1: 0.5280\n",
            "Validation:  loss: 0.7165 | accuracy: 0.5714 | f1: 0.5625\n",
            "Epoch 00214\n",
            "Train: loss: 0.5215 | accuracy: 0.7565 | f-acore: 0.7539\n",
            "Test:  loss: 0.8712 | accuracy: 0.5096 | f1: 0.5078\n",
            "Validation:  loss: 0.7095 | accuracy: 0.5714 | f1: 0.5553\n",
            "Epoch 00215\n",
            "Train: loss: 0.5154 | accuracy: 0.7350 | f-acore: 0.7336\n",
            "Test:  loss: 0.8724 | accuracy: 0.4986 | f1: 0.4947\n",
            "Validation:  loss: 0.7257 | accuracy: 0.5714 | f1: 0.5553\n",
            "Epoch 00216\n",
            "Train: loss: 0.5130 | accuracy: 0.7419 | f-acore: 0.7388\n",
            "Test:  loss: 0.8548 | accuracy: 0.5233 | f1: 0.5227\n",
            "Validation:  loss: 0.6905 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00217\n",
            "Train: loss: 0.4988 | accuracy: 0.7529 | f-acore: 0.7508\n",
            "Test:  loss: 0.8413 | accuracy: 0.5178 | f1: 0.5172\n",
            "Validation:  loss: 0.6893 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00218\n",
            "Train: loss: 0.5117 | accuracy: 0.7437 | f-acore: 0.7412\n",
            "Test:  loss: 0.8624 | accuracy: 0.5315 | f1: 0.5313\n",
            "Validation:  loss: 0.6999 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00219\n",
            "Train: loss: 0.5153 | accuracy: 0.7419 | f-acore: 0.7387\n",
            "Test:  loss: 0.8636 | accuracy: 0.5260 | f1: 0.5257\n",
            "Validation:  loss: 0.7123 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00220\n",
            "Train: loss: 0.5367 | accuracy: 0.7345 | f-acore: 0.7295\n",
            "Test:  loss: 0.8676 | accuracy: 0.5096 | f1: 0.5081\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00221\n",
            "Train: loss: 0.5256 | accuracy: 0.7231 | f-acore: 0.7225\n",
            "Test:  loss: 0.8090 | accuracy: 0.5205 | f1: 0.5185\n",
            "Validation:  loss: 0.6668 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00222\n",
            "Train: loss: 0.5214 | accuracy: 0.7460 | f-acore: 0.7444\n",
            "Test:  loss: 0.8468 | accuracy: 0.5288 | f1: 0.5287\n",
            "Validation:  loss: 0.7122 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00223\n",
            "Train: loss: 0.5076 | accuracy: 0.7432 | f-acore: 0.7411\n",
            "Test:  loss: 0.8536 | accuracy: 0.5151 | f1: 0.5136\n",
            "Validation:  loss: 0.6988 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00224\n",
            "Train: loss: 0.5160 | accuracy: 0.7359 | f-acore: 0.7334\n",
            "Test:  loss: 0.8451 | accuracy: 0.5151 | f1: 0.5149\n",
            "Validation:  loss: 0.7028 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00225\n",
            "Train: loss: 0.5067 | accuracy: 0.7519 | f-acore: 0.7486\n",
            "Test:  loss: 0.8587 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7199 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00226\n",
            "Train: loss: 0.5244 | accuracy: 0.7478 | f-acore: 0.7469\n",
            "Test:  loss: 0.8811 | accuracy: 0.5260 | f1: 0.5257\n",
            "Validation:  loss: 0.7389 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00227\n",
            "Train: loss: 0.5306 | accuracy: 0.7221 | f-acore: 0.7194\n",
            "Test:  loss: 0.8686 | accuracy: 0.5151 | f1: 0.5144\n",
            "Validation:  loss: 0.7156 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00228\n",
            "Train: loss: 0.5193 | accuracy: 0.7460 | f-acore: 0.7427\n",
            "Test:  loss: 0.8967 | accuracy: 0.5123 | f1: 0.5117\n",
            "Validation:  loss: 0.7114 | accuracy: 0.6071 | f1: 0.6003\n",
            "Epoch 00229\n",
            "Train: loss: 0.5233 | accuracy: 0.7455 | f-acore: 0.7419\n",
            "Test:  loss: 0.8749 | accuracy: 0.5151 | f1: 0.5148\n",
            "Validation:  loss: 0.7264 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00230\n",
            "Train: loss: 0.4999 | accuracy: 0.7368 | f-acore: 0.7328\n",
            "Test:  loss: 0.8666 | accuracy: 0.4986 | f1: 0.4985\n",
            "Validation:  loss: 0.7491 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00231\n",
            "Train: loss: 0.4963 | accuracy: 0.7515 | f-acore: 0.7503\n",
            "Test:  loss: 0.8924 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.7343 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00232\n",
            "Train: loss: 0.5216 | accuracy: 0.7437 | f-acore: 0.7413\n",
            "Test:  loss: 0.8874 | accuracy: 0.4932 | f1: 0.4931\n",
            "Validation:  loss: 0.7143 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00233\n",
            "Train: loss: 0.5357 | accuracy: 0.7409 | f-acore: 0.7394\n",
            "Test:  loss: 0.8827 | accuracy: 0.5123 | f1: 0.5117\n",
            "Validation:  loss: 0.7374 | accuracy: 0.5952 | f1: 0.5868\n",
            "Epoch 00234\n",
            "Train: loss: 0.4950 | accuracy: 0.7497 | f-acore: 0.7470\n",
            "Test:  loss: 0.9064 | accuracy: 0.5096 | f1: 0.5086\n",
            "Validation:  loss: 0.7321 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00235\n",
            "Train: loss: 0.5125 | accuracy: 0.7611 | f-acore: 0.7585\n",
            "Test:  loss: 0.8956 | accuracy: 0.5151 | f1: 0.5149\n",
            "Validation:  loss: 0.7366 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00236\n",
            "Train: loss: 0.4939 | accuracy: 0.7414 | f-acore: 0.7387\n",
            "Test:  loss: 0.8928 | accuracy: 0.4959 | f1: 0.4953\n",
            "Validation:  loss: 0.7094 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00237\n",
            "Train: loss: 0.4793 | accuracy: 0.7694 | f-acore: 0.7674\n",
            "Test:  loss: 0.8703 | accuracy: 0.5096 | f1: 0.5095\n",
            "Validation:  loss: 0.7166 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00238\n",
            "Train: loss: 0.5220 | accuracy: 0.7487 | f-acore: 0.7465\n",
            "Test:  loss: 0.8929 | accuracy: 0.5096 | f1: 0.5091\n",
            "Validation:  loss: 0.7232 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00239\n",
            "Train: loss: 0.5028 | accuracy: 0.7538 | f-acore: 0.7519\n",
            "Test:  loss: 0.8811 | accuracy: 0.5260 | f1: 0.5246\n",
            "Validation:  loss: 0.7144 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00240\n",
            "Train: loss: 0.5065 | accuracy: 0.7442 | f-acore: 0.7425\n",
            "Test:  loss: 0.8837 | accuracy: 0.5233 | f1: 0.5233\n",
            "Validation:  loss: 0.7441 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00241\n",
            "Train: loss: 0.5163 | accuracy: 0.7547 | f-acore: 0.7525\n",
            "Test:  loss: 0.8753 | accuracy: 0.5205 | f1: 0.5196\n",
            "Validation:  loss: 0.7163 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00242\n",
            "Train: loss: 0.4936 | accuracy: 0.7542 | f-acore: 0.7532\n",
            "Test:  loss: 0.8734 | accuracy: 0.5068 | f1: 0.5058\n",
            "Validation:  loss: 0.7294 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00243\n",
            "Train: loss: 0.5057 | accuracy: 0.7510 | f-acore: 0.7479\n",
            "Test:  loss: 0.8715 | accuracy: 0.5151 | f1: 0.5144\n",
            "Validation:  loss: 0.7243 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00244\n",
            "Train: loss: 0.4960 | accuracy: 0.7648 | f-acore: 0.7617\n",
            "Test:  loss: 0.8731 | accuracy: 0.5288 | f1: 0.5287\n",
            "Validation:  loss: 0.7322 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00245\n",
            "Train: loss: 0.4887 | accuracy: 0.7602 | f-acore: 0.7580\n",
            "Test:  loss: 0.8826 | accuracy: 0.5151 | f1: 0.5148\n",
            "Validation:  loss: 0.7536 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00246\n",
            "Train: loss: 0.4905 | accuracy: 0.7552 | f-acore: 0.7524\n",
            "Test:  loss: 0.8787 | accuracy: 0.4849 | f1: 0.4848\n",
            "Validation:  loss: 0.7329 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00247\n",
            "Train: loss: 0.5080 | accuracy: 0.7561 | f-acore: 0.7530\n",
            "Test:  loss: 0.8771 | accuracy: 0.5123 | f1: 0.5117\n",
            "Validation:  loss: 0.7081 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00248\n",
            "Train: loss: 0.5222 | accuracy: 0.7510 | f-acore: 0.7485\n",
            "Test:  loss: 0.8840 | accuracy: 0.5233 | f1: 0.5233\n",
            "Validation:  loss: 0.7431 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00249\n",
            "Train: loss: 0.5017 | accuracy: 0.7464 | f-acore: 0.7421\n",
            "Test:  loss: 0.8469 | accuracy: 0.5151 | f1: 0.5151\n",
            "Validation:  loss: 0.7180 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00250\n",
            "Train: loss: 0.4763 | accuracy: 0.7529 | f-acore: 0.7509\n",
            "Test:  loss: 0.8634 | accuracy: 0.5178 | f1: 0.5176\n",
            "Validation:  loss: 0.7285 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00251\n",
            "Train: loss: 0.4888 | accuracy: 0.7565 | f-acore: 0.7538\n",
            "Test:  loss: 0.8750 | accuracy: 0.4932 | f1: 0.4930\n",
            "Validation:  loss: 0.7215 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00252\n",
            "Train: loss: 0.4906 | accuracy: 0.7703 | f-acore: 0.7687\n",
            "Test:  loss: 0.8835 | accuracy: 0.4986 | f1: 0.4985\n",
            "Validation:  loss: 0.7285 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00253\n",
            "Train: loss: 0.4987 | accuracy: 0.7579 | f-acore: 0.7545\n",
            "Test:  loss: 0.9009 | accuracy: 0.5205 | f1: 0.5205\n",
            "Validation:  loss: 0.7269 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00254\n",
            "Train: loss: 0.4993 | accuracy: 0.7607 | f-acore: 0.7584\n",
            "Test:  loss: 0.8862 | accuracy: 0.4959 | f1: 0.4948\n",
            "Validation:  loss: 0.7097 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00255\n",
            "Train: loss: 0.4971 | accuracy: 0.7662 | f-acore: 0.7644\n",
            "Test:  loss: 0.8630 | accuracy: 0.5041 | f1: 0.5041\n",
            "Validation:  loss: 0.7234 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00256\n",
            "Train: loss: 0.4855 | accuracy: 0.7501 | f-acore: 0.7458\n",
            "Test:  loss: 0.8670 | accuracy: 0.5233 | f1: 0.5233\n",
            "Validation:  loss: 0.7132 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00257\n",
            "Train: loss: 0.4934 | accuracy: 0.7611 | f-acore: 0.7585\n",
            "Test:  loss: 0.8829 | accuracy: 0.4877 | f1: 0.4874\n",
            "Validation:  loss: 0.7017 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00258\n",
            "Train: loss: 0.5061 | accuracy: 0.7510 | f-acore: 0.7486\n",
            "Test:  loss: 0.8742 | accuracy: 0.4932 | f1: 0.4929\n",
            "Validation:  loss: 0.6938 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00259\n",
            "Train: loss: 0.4899 | accuracy: 0.7542 | f-acore: 0.7529\n",
            "Test:  loss: 0.8778 | accuracy: 0.5205 | f1: 0.5202\n",
            "Validation:  loss: 0.7075 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00260\n",
            "Train: loss: 0.4908 | accuracy: 0.7524 | f-acore: 0.7480\n",
            "Test:  loss: 0.8928 | accuracy: 0.5260 | f1: 0.5260\n",
            "Validation:  loss: 0.7417 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00261\n",
            "Train: loss: 0.4981 | accuracy: 0.7639 | f-acore: 0.7618\n",
            "Test:  loss: 0.8776 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 0.7012 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00262\n",
            "Train: loss: 0.4903 | accuracy: 0.7570 | f-acore: 0.7544\n",
            "Test:  loss: 0.8690 | accuracy: 0.5205 | f1: 0.5203\n",
            "Validation:  loss: 0.7245 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00263\n",
            "Train: loss: 0.4635 | accuracy: 0.7579 | f-acore: 0.7560\n",
            "Test:  loss: 0.8802 | accuracy: 0.5151 | f1: 0.5149\n",
            "Validation:  loss: 0.7207 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00264\n",
            "Train: loss: 0.4776 | accuracy: 0.7625 | f-acore: 0.7598\n",
            "Test:  loss: 0.8902 | accuracy: 0.5041 | f1: 0.5040\n",
            "Validation:  loss: 0.7342 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00265\n",
            "Train: loss: 0.4825 | accuracy: 0.7547 | f-acore: 0.7517\n",
            "Test:  loss: 0.8732 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7215 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00266\n",
            "Train: loss: 0.4787 | accuracy: 0.7588 | f-acore: 0.7559\n",
            "Test:  loss: 0.8648 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.6975 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00267\n",
            "Train: loss: 0.4712 | accuracy: 0.7611 | f-acore: 0.7593\n",
            "Test:  loss: 0.9013 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.7316 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00268\n",
            "Train: loss: 0.5180 | accuracy: 0.7542 | f-acore: 0.7508\n",
            "Test:  loss: 0.8864 | accuracy: 0.5123 | f1: 0.5121\n",
            "Validation:  loss: 0.7225 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00269\n",
            "Train: loss: 0.5083 | accuracy: 0.7607 | f-acore: 0.7579\n",
            "Test:  loss: 0.8279 | accuracy: 0.5342 | f1: 0.5342\n",
            "Validation:  loss: 0.7555 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00270\n",
            "Train: loss: 0.4925 | accuracy: 0.7432 | f-acore: 0.7418\n",
            "Test:  loss: 0.8635 | accuracy: 0.5096 | f1: 0.5095\n",
            "Validation:  loss: 0.7425 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00271\n",
            "Train: loss: 0.4889 | accuracy: 0.7602 | f-acore: 0.7578\n",
            "Test:  loss: 0.8602 | accuracy: 0.5151 | f1: 0.5150\n",
            "Validation:  loss: 0.7401 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00272\n",
            "Train: loss: 0.5235 | accuracy: 0.7630 | f-acore: 0.7585\n",
            "Test:  loss: 0.8391 | accuracy: 0.5425 | f1: 0.5423\n",
            "Validation:  loss: 0.7667 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00273\n",
            "Train: loss: 0.4904 | accuracy: 0.7547 | f-acore: 0.7513\n",
            "Test:  loss: 0.8524 | accuracy: 0.5178 | f1: 0.5172\n",
            "Validation:  loss: 0.7554 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00274\n",
            "Train: loss: 0.4692 | accuracy: 0.7680 | f-acore: 0.7650\n",
            "Test:  loss: 0.8922 | accuracy: 0.5096 | f1: 0.5094\n",
            "Validation:  loss: 0.7280 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00275\n",
            "Train: loss: 0.4853 | accuracy: 0.7542 | f-acore: 0.7519\n",
            "Test:  loss: 0.8955 | accuracy: 0.5151 | f1: 0.5141\n",
            "Validation:  loss: 0.7456 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00276\n",
            "Train: loss: 0.4761 | accuracy: 0.7616 | f-acore: 0.7581\n",
            "Test:  loss: 0.8946 | accuracy: 0.5041 | f1: 0.5039\n",
            "Validation:  loss: 0.7203 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00277\n",
            "Train: loss: 0.4809 | accuracy: 0.7657 | f-acore: 0.7638\n",
            "Test:  loss: 0.8723 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7266 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00278\n",
            "Train: loss: 0.4814 | accuracy: 0.7611 | f-acore: 0.7587\n",
            "Test:  loss: 0.8717 | accuracy: 0.5342 | f1: 0.5342\n",
            "Validation:  loss: 0.7581 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00279\n",
            "Train: loss: 0.4746 | accuracy: 0.7717 | f-acore: 0.7701\n",
            "Test:  loss: 0.9008 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.7452 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00280\n",
            "Train: loss: 0.4940 | accuracy: 0.7652 | f-acore: 0.7636\n",
            "Test:  loss: 0.8737 | accuracy: 0.5315 | f1: 0.5313\n",
            "Validation:  loss: 0.7172 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00281\n",
            "Train: loss: 0.4814 | accuracy: 0.7510 | f-acore: 0.7493\n",
            "Test:  loss: 0.8841 | accuracy: 0.5205 | f1: 0.5205\n",
            "Validation:  loss: 0.7391 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00282\n",
            "Train: loss: 0.4741 | accuracy: 0.7721 | f-acore: 0.7699\n",
            "Test:  loss: 0.9235 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.7565 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00283\n",
            "Train: loss: 0.4777 | accuracy: 0.7735 | f-acore: 0.7712\n",
            "Test:  loss: 0.9115 | accuracy: 0.5096 | f1: 0.5091\n",
            "Validation:  loss: 0.7528 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00284\n",
            "Train: loss: 0.4736 | accuracy: 0.7685 | f-acore: 0.7656\n",
            "Test:  loss: 0.9137 | accuracy: 0.5041 | f1: 0.5036\n",
            "Validation:  loss: 0.7297 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00285\n",
            "Train: loss: 0.4898 | accuracy: 0.7634 | f-acore: 0.7606\n",
            "Test:  loss: 0.9088 | accuracy: 0.4986 | f1: 0.4985\n",
            "Validation:  loss: 0.7386 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00286\n",
            "Train: loss: 0.4754 | accuracy: 0.7662 | f-acore: 0.7643\n",
            "Test:  loss: 0.9251 | accuracy: 0.4986 | f1: 0.4986\n",
            "Validation:  loss: 0.7354 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00287\n",
            "Train: loss: 0.4894 | accuracy: 0.7616 | f-acore: 0.7602\n",
            "Test:  loss: 0.9337 | accuracy: 0.5205 | f1: 0.5204\n",
            "Validation:  loss: 0.7746 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00288\n",
            "Train: loss: 0.4782 | accuracy: 0.7671 | f-acore: 0.7645\n",
            "Test:  loss: 0.9096 | accuracy: 0.5014 | f1: 0.5011\n",
            "Validation:  loss: 0.7307 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00289\n",
            "Train: loss: 0.4832 | accuracy: 0.7652 | f-acore: 0.7624\n",
            "Test:  loss: 0.9148 | accuracy: 0.5178 | f1: 0.5170\n",
            "Validation:  loss: 0.7364 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00290\n",
            "Train: loss: 0.4745 | accuracy: 0.7744 | f-acore: 0.7716\n",
            "Test:  loss: 0.9271 | accuracy: 0.5233 | f1: 0.5220\n",
            "Validation:  loss: 0.7230 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00291\n",
            "Train: loss: 0.4913 | accuracy: 0.7547 | f-acore: 0.7533\n",
            "Test:  loss: 0.9484 | accuracy: 0.4986 | f1: 0.4984\n",
            "Validation:  loss: 0.7439 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00292\n",
            "Train: loss: 0.4770 | accuracy: 0.7680 | f-acore: 0.7656\n",
            "Test:  loss: 0.9284 | accuracy: 0.5342 | f1: 0.5342\n",
            "Validation:  loss: 0.7427 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00293\n",
            "Train: loss: 0.4940 | accuracy: 0.7680 | f-acore: 0.7662\n",
            "Test:  loss: 0.9283 | accuracy: 0.5096 | f1: 0.5081\n",
            "Validation:  loss: 0.7262 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00294\n",
            "Train: loss: 0.4702 | accuracy: 0.7634 | f-acore: 0.7610\n",
            "Test:  loss: 0.9141 | accuracy: 0.5068 | f1: 0.5062\n",
            "Validation:  loss: 0.7198 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00295\n",
            "Train: loss: 0.4774 | accuracy: 0.7781 | f-acore: 0.7765\n",
            "Test:  loss: 0.9148 | accuracy: 0.5205 | f1: 0.5204\n",
            "Validation:  loss: 0.7542 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00296\n",
            "Train: loss: 0.4751 | accuracy: 0.7675 | f-acore: 0.7651\n",
            "Test:  loss: 0.9125 | accuracy: 0.5096 | f1: 0.5096\n",
            "Validation:  loss: 0.7386 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00297\n",
            "Train: loss: 0.4867 | accuracy: 0.7570 | f-acore: 0.7558\n",
            "Test:  loss: 0.9222 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.7551 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00298\n",
            "Train: loss: 0.4928 | accuracy: 0.7570 | f-acore: 0.7553\n",
            "Test:  loss: 0.8875 | accuracy: 0.5178 | f1: 0.5162\n",
            "Validation:  loss: 0.7071 | accuracy: 0.6071 | f1: 0.6066\n",
            "Epoch 00299\n",
            "Train: loss: 0.4787 | accuracy: 0.7588 | f-acore: 0.7568\n",
            "Test:  loss: 0.8908 | accuracy: 0.5260 | f1: 0.5259\n",
            "Validation:  loss: 0.7295 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00300\n",
            "Train: loss: 0.4892 | accuracy: 0.7657 | f-acore: 0.7629\n",
            "Test:  loss: 0.9152 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.7648 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00301\n",
            "Train: loss: 0.4905 | accuracy: 0.7657 | f-acore: 0.7634\n",
            "Test:  loss: 0.9095 | accuracy: 0.5041 | f1: 0.5032\n",
            "Validation:  loss: 0.7094 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00302\n",
            "Train: loss: 0.4581 | accuracy: 0.7698 | f-acore: 0.7683\n",
            "Test:  loss: 0.8930 | accuracy: 0.4986 | f1: 0.4981\n",
            "Validation:  loss: 0.7493 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00303\n",
            "Train: loss: 0.4801 | accuracy: 0.7662 | f-acore: 0.7640\n",
            "Test:  loss: 0.9021 | accuracy: 0.5123 | f1: 0.5119\n",
            "Validation:  loss: 0.7519 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00304\n",
            "Train: loss: 0.4486 | accuracy: 0.7717 | f-acore: 0.7705\n",
            "Test:  loss: 0.8913 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.7369 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00305\n",
            "Train: loss: 0.4823 | accuracy: 0.7685 | f-acore: 0.7671\n",
            "Test:  loss: 0.9068 | accuracy: 0.5151 | f1: 0.5141\n",
            "Validation:  loss: 0.7333 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00306\n",
            "Train: loss: 0.4801 | accuracy: 0.7680 | f-acore: 0.7668\n",
            "Test:  loss: 0.9097 | accuracy: 0.5123 | f1: 0.5115\n",
            "Validation:  loss: 0.7226 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00307\n",
            "Train: loss: 0.4640 | accuracy: 0.7712 | f-acore: 0.7699\n",
            "Test:  loss: 0.9047 | accuracy: 0.5014 | f1: 0.5011\n",
            "Validation:  loss: 0.7160 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00308\n",
            "Train: loss: 0.4626 | accuracy: 0.7680 | f-acore: 0.7659\n",
            "Test:  loss: 0.9032 | accuracy: 0.5123 | f1: 0.5110\n",
            "Validation:  loss: 0.7244 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00309\n",
            "Train: loss: 0.4703 | accuracy: 0.7662 | f-acore: 0.7639\n",
            "Test:  loss: 0.9137 | accuracy: 0.5205 | f1: 0.5205\n",
            "Validation:  loss: 0.7368 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00310\n",
            "Train: loss: 0.4721 | accuracy: 0.7694 | f-acore: 0.7663\n",
            "Test:  loss: 0.9118 | accuracy: 0.5233 | f1: 0.5223\n",
            "Validation:  loss: 0.7383 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00311\n",
            "Train: loss: 0.4823 | accuracy: 0.7753 | f-acore: 0.7736\n",
            "Test:  loss: 0.8881 | accuracy: 0.5151 | f1: 0.5149\n",
            "Validation:  loss: 0.7515 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00312\n",
            "Train: loss: 0.4630 | accuracy: 0.7813 | f-acore: 0.7794\n",
            "Test:  loss: 0.8847 | accuracy: 0.5041 | f1: 0.5016\n",
            "Validation:  loss: 0.7121 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00313\n",
            "Train: loss: 0.4502 | accuracy: 0.7758 | f-acore: 0.7749\n",
            "Test:  loss: 0.8958 | accuracy: 0.4932 | f1: 0.4887\n",
            "Validation:  loss: 0.7127 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00314\n",
            "Train: loss: 0.4519 | accuracy: 0.7845 | f-acore: 0.7828\n",
            "Test:  loss: 0.9031 | accuracy: 0.5151 | f1: 0.5141\n",
            "Validation:  loss: 0.7253 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00315\n",
            "Train: loss: 0.4435 | accuracy: 0.7900 | f-acore: 0.7882\n",
            "Test:  loss: 0.9170 | accuracy: 0.5068 | f1: 0.5049\n",
            "Validation:  loss: 0.7389 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00316\n",
            "Train: loss: 0.4914 | accuracy: 0.7758 | f-acore: 0.7743\n",
            "Test:  loss: 0.8913 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7641 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00317\n",
            "Train: loss: 0.4640 | accuracy: 0.7740 | f-acore: 0.7718\n",
            "Test:  loss: 0.8562 | accuracy: 0.5178 | f1: 0.5176\n",
            "Validation:  loss: 0.7437 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00318\n",
            "Train: loss: 0.4821 | accuracy: 0.7790 | f-acore: 0.7772\n",
            "Test:  loss: 0.8784 | accuracy: 0.5315 | f1: 0.5315\n",
            "Validation:  loss: 0.7498 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00319\n",
            "Train: loss: 0.4866 | accuracy: 0.7703 | f-acore: 0.7672\n",
            "Test:  loss: 0.9061 | accuracy: 0.5151 | f1: 0.5149\n",
            "Validation:  loss: 0.7073 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00320\n",
            "Train: loss: 0.4744 | accuracy: 0.7703 | f-acore: 0.7670\n",
            "Test:  loss: 0.8804 | accuracy: 0.5178 | f1: 0.5172\n",
            "Validation:  loss: 0.7266 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00321\n",
            "Train: loss: 0.4646 | accuracy: 0.7675 | f-acore: 0.7645\n",
            "Test:  loss: 0.9061 | accuracy: 0.5233 | f1: 0.5232\n",
            "Validation:  loss: 0.7501 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00322\n",
            "Train: loss: 0.4503 | accuracy: 0.7822 | f-acore: 0.7807\n",
            "Test:  loss: 0.9398 | accuracy: 0.5151 | f1: 0.5148\n",
            "Validation:  loss: 0.7431 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00323\n",
            "Train: loss: 0.4649 | accuracy: 0.7767 | f-acore: 0.7753\n",
            "Test:  loss: 0.9354 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7711 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00324\n",
            "Train: loss: 0.4481 | accuracy: 0.7808 | f-acore: 0.7781\n",
            "Test:  loss: 0.9485 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7392 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00325\n",
            "Train: loss: 0.4787 | accuracy: 0.7804 | f-acore: 0.7772\n",
            "Test:  loss: 0.9382 | accuracy: 0.5014 | f1: 0.4997\n",
            "Validation:  loss: 0.7365 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00326\n",
            "Train: loss: 0.4681 | accuracy: 0.7753 | f-acore: 0.7735\n",
            "Test:  loss: 0.9243 | accuracy: 0.5014 | f1: 0.5009\n",
            "Validation:  loss: 0.7446 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00327\n",
            "Train: loss: 0.4734 | accuracy: 0.7845 | f-acore: 0.7827\n",
            "Test:  loss: 0.9226 | accuracy: 0.5041 | f1: 0.5041\n",
            "Validation:  loss: 0.7704 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00328\n",
            "Train: loss: 0.4745 | accuracy: 0.7648 | f-acore: 0.7628\n",
            "Test:  loss: 0.9278 | accuracy: 0.5288 | f1: 0.5287\n",
            "Validation:  loss: 0.7902 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00329\n",
            "Train: loss: 0.4615 | accuracy: 0.7735 | f-acore: 0.7707\n",
            "Test:  loss: 0.9101 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.7488 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00330\n",
            "Train: loss: 0.4720 | accuracy: 0.7730 | f-acore: 0.7709\n",
            "Test:  loss: 0.9150 | accuracy: 0.5068 | f1: 0.5067\n",
            "Validation:  loss: 0.7555 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00331\n",
            "Train: loss: 0.4541 | accuracy: 0.7909 | f-acore: 0.7888\n",
            "Test:  loss: 0.8957 | accuracy: 0.5288 | f1: 0.5286\n",
            "Validation:  loss: 0.7399 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00332\n",
            "Train: loss: 0.4846 | accuracy: 0.7859 | f-acore: 0.7838\n",
            "Test:  loss: 0.9199 | accuracy: 0.5288 | f1: 0.5283\n",
            "Validation:  loss: 0.7145 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00333\n",
            "Train: loss: 0.4488 | accuracy: 0.7868 | f-acore: 0.7854\n",
            "Test:  loss: 0.8900 | accuracy: 0.5288 | f1: 0.5253\n",
            "Validation:  loss: 0.7005 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00334\n",
            "Train: loss: 0.4553 | accuracy: 0.7790 | f-acore: 0.7776\n",
            "Test:  loss: 0.9324 | accuracy: 0.5315 | f1: 0.5314\n",
            "Validation:  loss: 0.7301 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00335\n",
            "Train: loss: 0.4710 | accuracy: 0.7726 | f-acore: 0.7703\n",
            "Test:  loss: 0.9277 | accuracy: 0.5452 | f1: 0.5452\n",
            "Validation:  loss: 0.7622 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00336\n",
            "Train: loss: 0.4477 | accuracy: 0.7735 | f-acore: 0.7711\n",
            "Test:  loss: 0.9256 | accuracy: 0.5205 | f1: 0.5173\n",
            "Validation:  loss: 0.7293 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00337\n",
            "Train: loss: 0.4667 | accuracy: 0.7785 | f-acore: 0.7761\n",
            "Test:  loss: 0.9121 | accuracy: 0.5205 | f1: 0.5205\n",
            "Validation:  loss: 0.7445 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00338\n",
            "Train: loss: 0.4367 | accuracy: 0.7822 | f-acore: 0.7808\n",
            "Test:  loss: 0.9019 | accuracy: 0.5068 | f1: 0.5065\n",
            "Validation:  loss: 0.7795 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00339\n",
            "Train: loss: 0.4375 | accuracy: 0.7845 | f-acore: 0.7827\n",
            "Test:  loss: 0.9149 | accuracy: 0.5205 | f1: 0.5202\n",
            "Validation:  loss: 0.7697 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00340\n",
            "Train: loss: 0.4776 | accuracy: 0.7882 | f-acore: 0.7861\n",
            "Test:  loss: 0.9431 | accuracy: 0.4986 | f1: 0.4984\n",
            "Validation:  loss: 0.7325 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00341\n",
            "Train: loss: 0.4631 | accuracy: 0.7652 | f-acore: 0.7624\n",
            "Test:  loss: 0.8962 | accuracy: 0.5288 | f1: 0.5286\n",
            "Validation:  loss: 0.7396 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00342\n",
            "Train: loss: 0.4520 | accuracy: 0.7730 | f-acore: 0.7709\n",
            "Test:  loss: 0.9270 | accuracy: 0.5178 | f1: 0.5177\n",
            "Validation:  loss: 0.7234 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00343\n",
            "Train: loss: 0.4590 | accuracy: 0.7675 | f-acore: 0.7650\n",
            "Test:  loss: 0.9204 | accuracy: 0.5205 | f1: 0.5204\n",
            "Validation:  loss: 0.7397 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00344\n",
            "Train: loss: 0.4761 | accuracy: 0.7831 | f-acore: 0.7813\n",
            "Test:  loss: 0.9307 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7536 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00345\n",
            "Train: loss: 0.4578 | accuracy: 0.7891 | f-acore: 0.7867\n",
            "Test:  loss: 0.9464 | accuracy: 0.5014 | f1: 0.5011\n",
            "Validation:  loss: 0.7534 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00346\n",
            "Train: loss: 0.4470 | accuracy: 0.7808 | f-acore: 0.7795\n",
            "Test:  loss: 0.9501 | accuracy: 0.5068 | f1: 0.5041\n",
            "Validation:  loss: 0.7187 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00347\n",
            "Train: loss: 0.4406 | accuracy: 0.7808 | f-acore: 0.7788\n",
            "Test:  loss: 0.9402 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7436 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00348\n",
            "Train: loss: 0.4528 | accuracy: 0.7863 | f-acore: 0.7838\n",
            "Test:  loss: 0.9362 | accuracy: 0.5014 | f1: 0.5007\n",
            "Validation:  loss: 0.7210 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00349\n",
            "Train: loss: 0.4566 | accuracy: 0.7680 | f-acore: 0.7662\n",
            "Test:  loss: 0.9037 | accuracy: 0.4986 | f1: 0.4977\n",
            "Validation:  loss: 0.6901 | accuracy: 0.6190 | f1: 0.6190\n",
            "Epoch 00350\n",
            "Train: loss: 0.4488 | accuracy: 0.7776 | f-acore: 0.7753\n",
            "Test:  loss: 0.9214 | accuracy: 0.5233 | f1: 0.5231\n",
            "Validation:  loss: 0.7233 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00351\n",
            "Train: loss: 0.4469 | accuracy: 0.7863 | f-acore: 0.7849\n",
            "Test:  loss: 0.9568 | accuracy: 0.5096 | f1: 0.5095\n",
            "Validation:  loss: 0.7511 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00352\n",
            "Train: loss: 0.4376 | accuracy: 0.7813 | f-acore: 0.7787\n",
            "Test:  loss: 0.9497 | accuracy: 0.5479 | f1: 0.5476\n",
            "Validation:  loss: 0.7667 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00353\n",
            "Train: loss: 0.4614 | accuracy: 0.8010 | f-acore: 0.7996\n",
            "Test:  loss: 0.9492 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.7694 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00354\n",
            "Train: loss: 0.4908 | accuracy: 0.7685 | f-acore: 0.7651\n",
            "Test:  loss: 0.9182 | accuracy: 0.5342 | f1: 0.5342\n",
            "Validation:  loss: 0.7418 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00355\n",
            "Train: loss: 0.4566 | accuracy: 0.7799 | f-acore: 0.7790\n",
            "Test:  loss: 0.9410 | accuracy: 0.5014 | f1: 0.5013\n",
            "Validation:  loss: 0.7144 | accuracy: 0.6310 | f1: 0.6284\n",
            "Epoch 00356\n",
            "Train: loss: 0.4496 | accuracy: 0.7799 | f-acore: 0.7772\n",
            "Test:  loss: 0.9609 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.7668 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00357\n",
            "Train: loss: 0.4468 | accuracy: 0.7758 | f-acore: 0.7726\n",
            "Test:  loss: 0.9638 | accuracy: 0.5014 | f1: 0.5011\n",
            "Validation:  loss: 0.7461 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00358\n",
            "Train: loss: 0.4654 | accuracy: 0.7799 | f-acore: 0.7774\n",
            "Test:  loss: 0.9479 | accuracy: 0.5041 | f1: 0.5041\n",
            "Validation:  loss: 0.7578 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00359\n",
            "Train: loss: 0.4514 | accuracy: 0.7955 | f-acore: 0.7937\n",
            "Test:  loss: 0.9223 | accuracy: 0.5178 | f1: 0.5177\n",
            "Validation:  loss: 0.7474 | accuracy: 0.6071 | f1: 0.6026\n",
            "Epoch 00360\n",
            "Train: loss: 0.4766 | accuracy: 0.7707 | f-acore: 0.7676\n",
            "Test:  loss: 0.9267 | accuracy: 0.5041 | f1: 0.5039\n",
            "Validation:  loss: 0.7498 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00361\n",
            "Train: loss: 0.4540 | accuracy: 0.7726 | f-acore: 0.7703\n",
            "Test:  loss: 0.9720 | accuracy: 0.5096 | f1: 0.5096\n",
            "Validation:  loss: 0.7286 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00362\n",
            "Train: loss: 0.4613 | accuracy: 0.7808 | f-acore: 0.7793\n",
            "Test:  loss: 0.9376 | accuracy: 0.5260 | f1: 0.5257\n",
            "Validation:  loss: 0.7652 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00363\n",
            "Train: loss: 0.4608 | accuracy: 0.7781 | f-acore: 0.7767\n",
            "Test:  loss: 0.9410 | accuracy: 0.5014 | f1: 0.5007\n",
            "Validation:  loss: 0.7452 | accuracy: 0.6190 | f1: 0.6182\n",
            "Epoch 00364\n",
            "Train: loss: 0.4503 | accuracy: 0.7772 | f-acore: 0.7758\n",
            "Test:  loss: 0.9337 | accuracy: 0.5233 | f1: 0.5232\n",
            "Validation:  loss: 0.7453 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00365\n",
            "Train: loss: 0.4530 | accuracy: 0.7854 | f-acore: 0.7840\n",
            "Test:  loss: 0.9911 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 0.7824 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00366\n",
            "Train: loss: 0.4435 | accuracy: 0.7762 | f-acore: 0.7748\n",
            "Test:  loss: 0.9669 | accuracy: 0.5123 | f1: 0.5120\n",
            "Validation:  loss: 0.7510 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00367\n",
            "Train: loss: 0.4407 | accuracy: 0.7836 | f-acore: 0.7819\n",
            "Test:  loss: 0.9418 | accuracy: 0.5123 | f1: 0.5117\n",
            "Validation:  loss: 0.7422 | accuracy: 0.6190 | f1: 0.6156\n",
            "Epoch 00368\n",
            "Train: loss: 0.4168 | accuracy: 0.7941 | f-acore: 0.7917\n",
            "Test:  loss: 0.9840 | accuracy: 0.4959 | f1: 0.4958\n",
            "Validation:  loss: 0.7359 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00369\n",
            "Train: loss: 0.4388 | accuracy: 0.7873 | f-acore: 0.7857\n",
            "Test:  loss: 0.9598 | accuracy: 0.5068 | f1: 0.5064\n",
            "Validation:  loss: 0.7495 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00370\n",
            "Train: loss: 0.4226 | accuracy: 0.7973 | f-acore: 0.7948\n",
            "Test:  loss: 0.9785 | accuracy: 0.4795 | f1: 0.4777\n",
            "Validation:  loss: 0.7354 | accuracy: 0.6310 | f1: 0.6296\n",
            "Epoch 00371\n",
            "Train: loss: 0.4671 | accuracy: 0.7790 | f-acore: 0.7767\n",
            "Test:  loss: 0.9826 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.7414 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00372\n",
            "Train: loss: 0.4212 | accuracy: 0.7946 | f-acore: 0.7926\n",
            "Test:  loss: 0.9659 | accuracy: 0.4932 | f1: 0.4916\n",
            "Validation:  loss: 0.7542 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00373\n",
            "Train: loss: 0.4266 | accuracy: 0.7868 | f-acore: 0.7852\n",
            "Test:  loss: 0.9788 | accuracy: 0.4959 | f1: 0.4956\n",
            "Validation:  loss: 0.7635 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00374\n",
            "Train: loss: 0.4243 | accuracy: 0.7950 | f-acore: 0.7929\n",
            "Test:  loss: 0.9849 | accuracy: 0.5041 | f1: 0.5040\n",
            "Validation:  loss: 0.7695 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00375\n",
            "Train: loss: 0.4255 | accuracy: 0.7785 | f-acore: 0.7767\n",
            "Test:  loss: 0.9892 | accuracy: 0.5123 | f1: 0.5123\n",
            "Validation:  loss: 0.7615 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00376\n",
            "Train: loss: 0.4434 | accuracy: 0.7923 | f-acore: 0.7901\n",
            "Test:  loss: 0.9567 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7747 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00377\n",
            "Train: loss: 0.4485 | accuracy: 0.7804 | f-acore: 0.7775\n",
            "Test:  loss: 0.9836 | accuracy: 0.4932 | f1: 0.4922\n",
            "Validation:  loss: 0.7492 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00378\n",
            "Train: loss: 0.4506 | accuracy: 0.7863 | f-acore: 0.7845\n",
            "Test:  loss: 0.9389 | accuracy: 0.5068 | f1: 0.5055\n",
            "Validation:  loss: 0.7534 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00379\n",
            "Train: loss: 0.4461 | accuracy: 0.7882 | f-acore: 0.7863\n",
            "Test:  loss: 0.9895 | accuracy: 0.4932 | f1: 0.4922\n",
            "Validation:  loss: 0.7481 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00380\n",
            "Train: loss: 0.4414 | accuracy: 0.7836 | f-acore: 0.7814\n",
            "Test:  loss: 1.0021 | accuracy: 0.4986 | f1: 0.4979\n",
            "Validation:  loss: 0.7678 | accuracy: 0.6310 | f1: 0.6284\n",
            "Epoch 00381\n",
            "Train: loss: 0.4368 | accuracy: 0.7795 | f-acore: 0.7775\n",
            "Test:  loss: 0.9854 | accuracy: 0.4986 | f1: 0.4981\n",
            "Validation:  loss: 0.7472 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00382\n",
            "Train: loss: 0.4548 | accuracy: 0.7818 | f-acore: 0.7801\n",
            "Test:  loss: 1.0223 | accuracy: 0.4822 | f1: 0.4803\n",
            "Validation:  loss: 0.7497 | accuracy: 0.6190 | f1: 0.6171\n",
            "Epoch 00383\n",
            "Train: loss: 0.4514 | accuracy: 0.7877 | f-acore: 0.7854\n",
            "Test:  loss: 0.9911 | accuracy: 0.5260 | f1: 0.5260\n",
            "Validation:  loss: 0.7873 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00384\n",
            "Train: loss: 0.4453 | accuracy: 0.7859 | f-acore: 0.7835\n",
            "Test:  loss: 1.0191 | accuracy: 0.4959 | f1: 0.4945\n",
            "Validation:  loss: 0.7601 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00385\n",
            "Train: loss: 0.4510 | accuracy: 0.7840 | f-acore: 0.7824\n",
            "Test:  loss: 0.9811 | accuracy: 0.5068 | f1: 0.5065\n",
            "Validation:  loss: 0.7804 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00386\n",
            "Train: loss: 0.4424 | accuracy: 0.7960 | f-acore: 0.7938\n",
            "Test:  loss: 0.9812 | accuracy: 0.5178 | f1: 0.5175\n",
            "Validation:  loss: 0.7954 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00387\n",
            "Train: loss: 0.4211 | accuracy: 0.7909 | f-acore: 0.7889\n",
            "Test:  loss: 0.9834 | accuracy: 0.5123 | f1: 0.5123\n",
            "Validation:  loss: 0.7816 | accuracy: 0.6071 | f1: 0.6026\n",
            "Epoch 00388\n",
            "Train: loss: 0.4350 | accuracy: 0.7895 | f-acore: 0.7872\n",
            "Test:  loss: 0.9964 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 0.7519 | accuracy: 0.6190 | f1: 0.6171\n",
            "Epoch 00389\n",
            "Train: loss: 0.4461 | accuracy: 0.7868 | f-acore: 0.7843\n",
            "Test:  loss: 0.9685 | accuracy: 0.5233 | f1: 0.5233\n",
            "Validation:  loss: 0.7665 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00390\n",
            "Train: loss: 0.4555 | accuracy: 0.7978 | f-acore: 0.7966\n",
            "Test:  loss: 0.9721 | accuracy: 0.4877 | f1: 0.4875\n",
            "Validation:  loss: 0.7742 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00391\n",
            "Train: loss: 0.4281 | accuracy: 0.7932 | f-acore: 0.7917\n",
            "Test:  loss: 0.9666 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 0.7351 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00392\n",
            "Train: loss: 0.4234 | accuracy: 0.7973 | f-acore: 0.7950\n",
            "Test:  loss: 1.0315 | accuracy: 0.4932 | f1: 0.4916\n",
            "Validation:  loss: 0.7734 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00393\n",
            "Train: loss: 0.4231 | accuracy: 0.7941 | f-acore: 0.7920\n",
            "Test:  loss: 1.0123 | accuracy: 0.5014 | f1: 0.5003\n",
            "Validation:  loss: 0.7514 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00394\n",
            "Train: loss: 0.4334 | accuracy: 0.7895 | f-acore: 0.7878\n",
            "Test:  loss: 0.9865 | accuracy: 0.4932 | f1: 0.4924\n",
            "Validation:  loss: 0.7445 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00395\n",
            "Train: loss: 0.4164 | accuracy: 0.7937 | f-acore: 0.7916\n",
            "Test:  loss: 0.9809 | accuracy: 0.5014 | f1: 0.5007\n",
            "Validation:  loss: 0.7367 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00396\n",
            "Train: loss: 0.4511 | accuracy: 0.7937 | f-acore: 0.7918\n",
            "Test:  loss: 0.9904 | accuracy: 0.4849 | f1: 0.4832\n",
            "Validation:  loss: 0.7451 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00397\n",
            "Train: loss: 0.4605 | accuracy: 0.7818 | f-acore: 0.7804\n",
            "Test:  loss: 0.9988 | accuracy: 0.5068 | f1: 0.5058\n",
            "Validation:  loss: 0.7401 | accuracy: 0.6310 | f1: 0.6296\n",
            "Epoch 00398\n",
            "Train: loss: 0.4344 | accuracy: 0.7932 | f-acore: 0.7921\n",
            "Test:  loss: 1.0172 | accuracy: 0.5014 | f1: 0.5009\n",
            "Validation:  loss: 0.7660 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00399\n",
            "Train: loss: 0.4620 | accuracy: 0.7836 | f-acore: 0.7811\n",
            "Test:  loss: 0.9804 | accuracy: 0.4959 | f1: 0.4953\n",
            "Validation:  loss: 0.7462 | accuracy: 0.6071 | f1: 0.6044\n",
            "Epoch 00400\n",
            "Train: loss: 0.4524 | accuracy: 0.7822 | f-acore: 0.7803\n",
            "Test:  loss: 1.0016 | accuracy: 0.4986 | f1: 0.4979\n",
            "Validation:  loss: 0.7730 | accuracy: 0.5952 | f1: 0.5915\n",
            "-----------------------------------------------------------------------------------------\n",
            "^GSPC\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6937 | accuracy: 0.5039 | f-acore: 0.4853\n",
            "Test:  loss: 0.6916 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6936 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00002\n",
            "Train: loss: 0.6894 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6911 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6945 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00003\n",
            "Train: loss: 0.6824 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6956 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7014 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00004\n",
            "Train: loss: 0.6950 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6995 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7066 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00005\n",
            "Train: loss: 0.6880 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6916 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6955 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00006\n",
            "Train: loss: 0.6894 | accuracy: 0.5520 | f-acore: 0.3566\n",
            "Test:  loss: 0.6909 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6952 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00007\n",
            "Train: loss: 0.6870 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6912 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6943 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00008\n",
            "Train: loss: 0.6870 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6909 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6949 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00009\n",
            "Train: loss: 0.6884 | accuracy: 0.5520 | f-acore: 0.3557\n",
            "Test:  loss: 0.6913 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6960 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00010\n",
            "Train: loss: 0.6870 | accuracy: 0.5502 | f-acore: 0.3559\n",
            "Test:  loss: 0.6920 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6966 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00011\n",
            "Train: loss: 0.6885 | accuracy: 0.5520 | f-acore: 0.3622\n",
            "Test:  loss: 0.6905 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00012\n",
            "Train: loss: 0.6851 | accuracy: 0.5534 | f-acore: 0.3646\n",
            "Test:  loss: 0.6922 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6976 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00013\n",
            "Train: loss: 0.6812 | accuracy: 0.5530 | f-acore: 0.3697\n",
            "Test:  loss: 0.6936 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6980 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00014\n",
            "Train: loss: 0.6904 | accuracy: 0.5543 | f-acore: 0.3773\n",
            "Test:  loss: 0.6926 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6983 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00015\n",
            "Train: loss: 0.6825 | accuracy: 0.5685 | f-acore: 0.4686\n",
            "Test:  loss: 0.6910 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6945 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00016\n",
            "Train: loss: 0.6872 | accuracy: 0.5557 | f-acore: 0.4350\n",
            "Test:  loss: 0.6914 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6956 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00017\n",
            "Train: loss: 0.6767 | accuracy: 0.5676 | f-acore: 0.4460\n",
            "Test:  loss: 0.6929 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00018\n",
            "Train: loss: 0.6752 | accuracy: 0.5566 | f-acore: 0.4154\n",
            "Test:  loss: 0.7034 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7032 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00019\n",
            "Train: loss: 0.6799 | accuracy: 0.5644 | f-acore: 0.4155\n",
            "Test:  loss: 0.7070 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7035 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00020\n",
            "Train: loss: 0.6804 | accuracy: 0.5722 | f-acore: 0.5228\n",
            "Test:  loss: 0.6974 | accuracy: 0.5123 | f1: 0.4499\n",
            "Validation:  loss: 0.6925 | accuracy: 0.4881 | f1: 0.4712\n",
            "Epoch 00021\n",
            "Train: loss: 0.6770 | accuracy: 0.5681 | f-acore: 0.4811\n",
            "Test:  loss: 0.6998 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.6966 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00022\n",
            "Train: loss: 0.6796 | accuracy: 0.5649 | f-acore: 0.4976\n",
            "Test:  loss: 0.7050 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7012 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00023\n",
            "Train: loss: 0.6713 | accuracy: 0.5704 | f-acore: 0.5047\n",
            "Test:  loss: 0.7124 | accuracy: 0.5233 | f1: 0.3486\n",
            "Validation:  loss: 0.7038 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00024\n",
            "Train: loss: 0.6809 | accuracy: 0.5644 | f-acore: 0.4684\n",
            "Test:  loss: 0.7277 | accuracy: 0.5315 | f1: 0.3470\n",
            "Validation:  loss: 0.7125 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00025\n",
            "Train: loss: 0.6733 | accuracy: 0.5809 | f-acore: 0.5218\n",
            "Test:  loss: 0.6942 | accuracy: 0.5096 | f1: 0.4278\n",
            "Validation:  loss: 0.6939 | accuracy: 0.4881 | f1: 0.4755\n",
            "Epoch 00026\n",
            "Train: loss: 0.6743 | accuracy: 0.5864 | f-acore: 0.5281\n",
            "Test:  loss: 0.6930 | accuracy: 0.5205 | f1: 0.3524\n",
            "Validation:  loss: 0.6953 | accuracy: 0.5000 | f1: 0.3534\n",
            "Epoch 00027\n",
            "Train: loss: 0.6765 | accuracy: 0.5805 | f-acore: 0.5118\n",
            "Test:  loss: 0.6954 | accuracy: 0.5178 | f1: 0.3511\n",
            "Validation:  loss: 0.6948 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00028\n",
            "Train: loss: 0.6748 | accuracy: 0.5786 | f-acore: 0.5061\n",
            "Test:  loss: 0.6935 | accuracy: 0.5205 | f1: 0.3572\n",
            "Validation:  loss: 0.6950 | accuracy: 0.5357 | f1: 0.4081\n",
            "Epoch 00029\n",
            "Train: loss: 0.6663 | accuracy: 0.5933 | f-acore: 0.5293\n",
            "Test:  loss: 0.6918 | accuracy: 0.5342 | f1: 0.3535\n",
            "Validation:  loss: 0.6935 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00030\n",
            "Train: loss: 0.6682 | accuracy: 0.5828 | f-acore: 0.5428\n",
            "Test:  loss: 0.6913 | accuracy: 0.5178 | f1: 0.3822\n",
            "Validation:  loss: 0.6920 | accuracy: 0.5119 | f1: 0.3778\n",
            "Epoch 00031\n",
            "Train: loss: 0.6699 | accuracy: 0.5869 | f-acore: 0.5521\n",
            "Test:  loss: 0.6949 | accuracy: 0.5288 | f1: 0.3751\n",
            "Validation:  loss: 0.6960 | accuracy: 0.5000 | f1: 0.3333\n",
            "Epoch 00032\n",
            "Train: loss: 0.6794 | accuracy: 0.5860 | f-acore: 0.5170\n",
            "Test:  loss: 0.6994 | accuracy: 0.5151 | f1: 0.3592\n",
            "Validation:  loss: 0.6986 | accuracy: 0.5119 | f1: 0.4094\n",
            "Epoch 00033\n",
            "Train: loss: 0.6707 | accuracy: 0.5846 | f-acore: 0.5526\n",
            "Test:  loss: 0.7029 | accuracy: 0.5096 | f1: 0.3566\n",
            "Validation:  loss: 0.6992 | accuracy: 0.5476 | f1: 0.4815\n",
            "Epoch 00034\n",
            "Train: loss: 0.6603 | accuracy: 0.5988 | f-acore: 0.5516\n",
            "Test:  loss: 0.7030 | accuracy: 0.5123 | f1: 0.3752\n",
            "Validation:  loss: 0.6966 | accuracy: 0.5476 | f1: 0.4458\n",
            "Epoch 00035\n",
            "Train: loss: 0.6679 | accuracy: 0.5901 | f-acore: 0.5597\n",
            "Test:  loss: 0.6998 | accuracy: 0.5178 | f1: 0.4049\n",
            "Validation:  loss: 0.6941 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00036\n",
            "Train: loss: 0.6572 | accuracy: 0.5933 | f-acore: 0.5454\n",
            "Test:  loss: 0.7001 | accuracy: 0.5260 | f1: 0.3824\n",
            "Validation:  loss: 0.6973 | accuracy: 0.5238 | f1: 0.3842\n",
            "Epoch 00037\n",
            "Train: loss: 0.6598 | accuracy: 0.5924 | f-acore: 0.5419\n",
            "Test:  loss: 0.7053 | accuracy: 0.5260 | f1: 0.3824\n",
            "Validation:  loss: 0.7022 | accuracy: 0.5238 | f1: 0.4305\n",
            "Epoch 00038\n",
            "Train: loss: 0.6615 | accuracy: 0.5965 | f-acore: 0.5458\n",
            "Test:  loss: 0.7030 | accuracy: 0.5288 | f1: 0.4218\n",
            "Validation:  loss: 0.6987 | accuracy: 0.5357 | f1: 0.4981\n",
            "Epoch 00039\n",
            "Train: loss: 0.6699 | accuracy: 0.6002 | f-acore: 0.5716\n",
            "Test:  loss: 0.6995 | accuracy: 0.5342 | f1: 0.5148\n",
            "Validation:  loss: 0.6924 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00040\n",
            "Train: loss: 0.6690 | accuracy: 0.6057 | f-acore: 0.5828\n",
            "Test:  loss: 0.7005 | accuracy: 0.5233 | f1: 0.4973\n",
            "Validation:  loss: 0.6981 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00041\n",
            "Train: loss: 0.6602 | accuracy: 0.5993 | f-acore: 0.5565\n",
            "Test:  loss: 0.7039 | accuracy: 0.5452 | f1: 0.4869\n",
            "Validation:  loss: 0.6999 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00042\n",
            "Train: loss: 0.6609 | accuracy: 0.6016 | f-acore: 0.5734\n",
            "Test:  loss: 0.7043 | accuracy: 0.5342 | f1: 0.4182\n",
            "Validation:  loss: 0.7012 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00043\n",
            "Train: loss: 0.6500 | accuracy: 0.6039 | f-acore: 0.5783\n",
            "Test:  loss: 0.7383 | accuracy: 0.5342 | f1: 0.3586\n",
            "Validation:  loss: 0.7169 | accuracy: 0.5119 | f1: 0.3593\n",
            "Epoch 00044\n",
            "Train: loss: 0.6680 | accuracy: 0.6130 | f-acore: 0.5684\n",
            "Test:  loss: 0.7314 | accuracy: 0.5315 | f1: 0.3719\n",
            "Validation:  loss: 0.7102 | accuracy: 0.5357 | f1: 0.4081\n",
            "Epoch 00045\n",
            "Train: loss: 0.6631 | accuracy: 0.6084 | f-acore: 0.5712\n",
            "Test:  loss: 0.7202 | accuracy: 0.5260 | f1: 0.3907\n",
            "Validation:  loss: 0.7005 | accuracy: 0.5000 | f1: 0.3875\n",
            "Epoch 00046\n",
            "Train: loss: 0.6539 | accuracy: 0.6061 | f-acore: 0.5762\n",
            "Test:  loss: 0.7003 | accuracy: 0.5342 | f1: 0.4724\n",
            "Validation:  loss: 0.6906 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00047\n",
            "Train: loss: 0.6573 | accuracy: 0.6048 | f-acore: 0.5945\n",
            "Test:  loss: 0.7182 | accuracy: 0.5288 | f1: 0.4488\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00048\n",
            "Train: loss: 0.6602 | accuracy: 0.6006 | f-acore: 0.5530\n",
            "Test:  loss: 0.7137 | accuracy: 0.5342 | f1: 0.4829\n",
            "Validation:  loss: 0.6993 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00049\n",
            "Train: loss: 0.6580 | accuracy: 0.6034 | f-acore: 0.5858\n",
            "Test:  loss: 0.7237 | accuracy: 0.5260 | f1: 0.4572\n",
            "Validation:  loss: 0.7051 | accuracy: 0.5714 | f1: 0.5592\n",
            "Epoch 00050\n",
            "Train: loss: 0.6496 | accuracy: 0.5974 | f-acore: 0.5665\n",
            "Test:  loss: 0.7393 | accuracy: 0.5233 | f1: 0.3632\n",
            "Validation:  loss: 0.7127 | accuracy: 0.5357 | f1: 0.4081\n",
            "Epoch 00051\n",
            "Train: loss: 0.6633 | accuracy: 0.6057 | f-acore: 0.5533\n",
            "Test:  loss: 0.7192 | accuracy: 0.5425 | f1: 0.4553\n",
            "Validation:  loss: 0.7044 | accuracy: 0.5357 | f1: 0.4981\n",
            "Epoch 00052\n",
            "Train: loss: 0.6554 | accuracy: 0.6107 | f-acore: 0.6074\n",
            "Test:  loss: 0.6978 | accuracy: 0.5096 | f1: 0.4680\n",
            "Validation:  loss: 0.6954 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00053\n",
            "Train: loss: 0.6529 | accuracy: 0.6121 | f-acore: 0.5793\n",
            "Test:  loss: 0.7017 | accuracy: 0.5315 | f1: 0.4982\n",
            "Validation:  loss: 0.6925 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00054\n",
            "Train: loss: 0.6550 | accuracy: 0.6126 | f-acore: 0.6077\n",
            "Test:  loss: 0.6965 | accuracy: 0.5096 | f1: 0.4969\n",
            "Validation:  loss: 0.6901 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00055\n",
            "Train: loss: 0.6608 | accuracy: 0.6213 | f-acore: 0.6037\n",
            "Test:  loss: 0.7034 | accuracy: 0.5342 | f1: 0.4701\n",
            "Validation:  loss: 0.6978 | accuracy: 0.5714 | f1: 0.5333\n",
            "Epoch 00056\n",
            "Train: loss: 0.6482 | accuracy: 0.6112 | f-acore: 0.5863\n",
            "Test:  loss: 0.7044 | accuracy: 0.5205 | f1: 0.4782\n",
            "Validation:  loss: 0.6977 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00057\n",
            "Train: loss: 0.6550 | accuracy: 0.6263 | f-acore: 0.6145\n",
            "Test:  loss: 0.7087 | accuracy: 0.5260 | f1: 0.5079\n",
            "Validation:  loss: 0.6970 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00058\n",
            "Train: loss: 0.6477 | accuracy: 0.6194 | f-acore: 0.6077\n",
            "Test:  loss: 0.7051 | accuracy: 0.5205 | f1: 0.4924\n",
            "Validation:  loss: 0.6910 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00059\n",
            "Train: loss: 0.6416 | accuracy: 0.6204 | f-acore: 0.6107\n",
            "Test:  loss: 0.7144 | accuracy: 0.5288 | f1: 0.4345\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5833 | f1: 0.5428\n",
            "Epoch 00060\n",
            "Train: loss: 0.6505 | accuracy: 0.6300 | f-acore: 0.5988\n",
            "Test:  loss: 0.7083 | accuracy: 0.5288 | f1: 0.4748\n",
            "Validation:  loss: 0.6896 | accuracy: 0.5595 | f1: 0.5407\n",
            "Epoch 00061\n",
            "Train: loss: 0.6486 | accuracy: 0.6139 | f-acore: 0.5878\n",
            "Test:  loss: 0.7107 | accuracy: 0.5452 | f1: 0.5284\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00062\n",
            "Train: loss: 0.6485 | accuracy: 0.6194 | f-acore: 0.6064\n",
            "Test:  loss: 0.7153 | accuracy: 0.5068 | f1: 0.4232\n",
            "Validation:  loss: 0.6929 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00063\n",
            "Train: loss: 0.6517 | accuracy: 0.6369 | f-acore: 0.6256\n",
            "Test:  loss: 0.7162 | accuracy: 0.5233 | f1: 0.4552\n",
            "Validation:  loss: 0.6873 | accuracy: 0.6071 | f1: 0.5753\n",
            "Epoch 00064\n",
            "Train: loss: 0.6310 | accuracy: 0.6277 | f-acore: 0.6106\n",
            "Test:  loss: 0.7153 | accuracy: 0.5260 | f1: 0.4748\n",
            "Validation:  loss: 0.6890 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00065\n",
            "Train: loss: 0.6408 | accuracy: 0.6387 | f-acore: 0.6218\n",
            "Test:  loss: 0.7292 | accuracy: 0.5342 | f1: 0.4973\n",
            "Validation:  loss: 0.6935 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00066\n",
            "Train: loss: 0.6464 | accuracy: 0.6213 | f-acore: 0.6161\n",
            "Test:  loss: 0.7175 | accuracy: 0.5123 | f1: 0.4953\n",
            "Validation:  loss: 0.6949 | accuracy: 0.5714 | f1: 0.5625\n",
            "Epoch 00067\n",
            "Train: loss: 0.6462 | accuracy: 0.6272 | f-acore: 0.6037\n",
            "Test:  loss: 0.7076 | accuracy: 0.5479 | f1: 0.5425\n",
            "Validation:  loss: 0.6918 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00068\n",
            "Train: loss: 0.6452 | accuracy: 0.6378 | f-acore: 0.6191\n",
            "Test:  loss: 0.7173 | accuracy: 0.5205 | f1: 0.4667\n",
            "Validation:  loss: 0.6905 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00069\n",
            "Train: loss: 0.6308 | accuracy: 0.6392 | f-acore: 0.6181\n",
            "Test:  loss: 0.7261 | accuracy: 0.5096 | f1: 0.3855\n",
            "Validation:  loss: 0.7043 | accuracy: 0.5595 | f1: 0.5167\n",
            "Epoch 00070\n",
            "Train: loss: 0.6412 | accuracy: 0.6263 | f-acore: 0.5874\n",
            "Test:  loss: 0.7115 | accuracy: 0.5315 | f1: 0.4828\n",
            "Validation:  loss: 0.6956 | accuracy: 0.6190 | f1: 0.6007\n",
            "Epoch 00071\n",
            "Train: loss: 0.6508 | accuracy: 0.6323 | f-acore: 0.6202\n",
            "Test:  loss: 0.7046 | accuracy: 0.5315 | f1: 0.5279\n",
            "Validation:  loss: 0.6983 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00072\n",
            "Train: loss: 0.6461 | accuracy: 0.6369 | f-acore: 0.6203\n",
            "Test:  loss: 0.7053 | accuracy: 0.5425 | f1: 0.5337\n",
            "Validation:  loss: 0.6983 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00073\n",
            "Train: loss: 0.6365 | accuracy: 0.6323 | f-acore: 0.6141\n",
            "Test:  loss: 0.7044 | accuracy: 0.5342 | f1: 0.5114\n",
            "Validation:  loss: 0.6922 | accuracy: 0.5952 | f1: 0.5837\n",
            "Epoch 00074\n",
            "Train: loss: 0.6256 | accuracy: 0.6346 | f-acore: 0.6226\n",
            "Test:  loss: 0.7004 | accuracy: 0.5233 | f1: 0.5114\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00075\n",
            "Train: loss: 0.6269 | accuracy: 0.6529 | f-acore: 0.6418\n",
            "Test:  loss: 0.7255 | accuracy: 0.5260 | f1: 0.4664\n",
            "Validation:  loss: 0.7039 | accuracy: 0.5714 | f1: 0.5260\n",
            "Epoch 00076\n",
            "Train: loss: 0.6388 | accuracy: 0.6369 | f-acore: 0.6134\n",
            "Test:  loss: 0.7173 | accuracy: 0.5425 | f1: 0.4891\n",
            "Validation:  loss: 0.6946 | accuracy: 0.5714 | f1: 0.5457\n",
            "Epoch 00077\n",
            "Train: loss: 0.6398 | accuracy: 0.6451 | f-acore: 0.6315\n",
            "Test:  loss: 0.7127 | accuracy: 0.5397 | f1: 0.5146\n",
            "Validation:  loss: 0.6952 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00078\n",
            "Train: loss: 0.6332 | accuracy: 0.6359 | f-acore: 0.6137\n",
            "Test:  loss: 0.7186 | accuracy: 0.5507 | f1: 0.5180\n",
            "Validation:  loss: 0.7025 | accuracy: 0.5714 | f1: 0.5508\n",
            "Epoch 00079\n",
            "Train: loss: 0.6291 | accuracy: 0.6314 | f-acore: 0.6146\n",
            "Test:  loss: 0.7166 | accuracy: 0.5068 | f1: 0.4710\n",
            "Validation:  loss: 0.6941 | accuracy: 0.5952 | f1: 0.5868\n",
            "Epoch 00080\n",
            "Train: loss: 0.6328 | accuracy: 0.6410 | f-acore: 0.6230\n",
            "Test:  loss: 0.7275 | accuracy: 0.5205 | f1: 0.5141\n",
            "Validation:  loss: 0.7088 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00081\n",
            "Train: loss: 0.6392 | accuracy: 0.6291 | f-acore: 0.6254\n",
            "Test:  loss: 0.7278 | accuracy: 0.5205 | f1: 0.4895\n",
            "Validation:  loss: 0.6990 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00082\n",
            "Train: loss: 0.6438 | accuracy: 0.6511 | f-acore: 0.6382\n",
            "Test:  loss: 0.7342 | accuracy: 0.5370 | f1: 0.4829\n",
            "Validation:  loss: 0.7040 | accuracy: 0.6190 | f1: 0.6007\n",
            "Epoch 00083\n",
            "Train: loss: 0.6279 | accuracy: 0.6543 | f-acore: 0.6438\n",
            "Test:  loss: 0.7585 | accuracy: 0.5233 | f1: 0.3932\n",
            "Validation:  loss: 0.7166 | accuracy: 0.5119 | f1: 0.4094\n",
            "Epoch 00084\n",
            "Train: loss: 0.6302 | accuracy: 0.6470 | f-acore: 0.6289\n",
            "Test:  loss: 0.7527 | accuracy: 0.5123 | f1: 0.3832\n",
            "Validation:  loss: 0.7177 | accuracy: 0.5238 | f1: 0.4305\n",
            "Epoch 00085\n",
            "Train: loss: 0.6223 | accuracy: 0.6566 | f-acore: 0.6377\n",
            "Test:  loss: 0.7272 | accuracy: 0.4959 | f1: 0.4075\n",
            "Validation:  loss: 0.7023 | accuracy: 0.5119 | f1: 0.4557\n",
            "Epoch 00086\n",
            "Train: loss: 0.6196 | accuracy: 0.6520 | f-acore: 0.6436\n",
            "Test:  loss: 0.7247 | accuracy: 0.5178 | f1: 0.4647\n",
            "Validation:  loss: 0.7028 | accuracy: 0.5833 | f1: 0.5556\n",
            "Epoch 00087\n",
            "Train: loss: 0.6280 | accuracy: 0.6460 | f-acore: 0.6373\n",
            "Test:  loss: 0.7406 | accuracy: 0.5260 | f1: 0.4664\n",
            "Validation:  loss: 0.7062 | accuracy: 0.5714 | f1: 0.5333\n",
            "Epoch 00088\n",
            "Train: loss: 0.6158 | accuracy: 0.6428 | f-acore: 0.6299\n",
            "Test:  loss: 0.7270 | accuracy: 0.5205 | f1: 0.4727\n",
            "Validation:  loss: 0.7057 | accuracy: 0.5595 | f1: 0.5407\n",
            "Epoch 00089\n",
            "Train: loss: 0.6234 | accuracy: 0.6483 | f-acore: 0.6410\n",
            "Test:  loss: 0.7356 | accuracy: 0.5123 | f1: 0.4521\n",
            "Validation:  loss: 0.7056 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00090\n",
            "Train: loss: 0.6129 | accuracy: 0.6635 | f-acore: 0.6513\n",
            "Test:  loss: 0.7364 | accuracy: 0.5151 | f1: 0.4722\n",
            "Validation:  loss: 0.6987 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00091\n",
            "Train: loss: 0.6308 | accuracy: 0.6474 | f-acore: 0.6371\n",
            "Test:  loss: 0.7561 | accuracy: 0.5205 | f1: 0.4646\n",
            "Validation:  loss: 0.7178 | accuracy: 0.5833 | f1: 0.5609\n",
            "Epoch 00092\n",
            "Train: loss: 0.6282 | accuracy: 0.6460 | f-acore: 0.6174\n",
            "Test:  loss: 0.7143 | accuracy: 0.4986 | f1: 0.4720\n",
            "Validation:  loss: 0.7089 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00093\n",
            "Train: loss: 0.6348 | accuracy: 0.6447 | f-acore: 0.6431\n",
            "Test:  loss: 0.7209 | accuracy: 0.5288 | f1: 0.5004\n",
            "Validation:  loss: 0.7010 | accuracy: 0.5595 | f1: 0.5487\n",
            "Epoch 00094\n",
            "Train: loss: 0.6054 | accuracy: 0.6644 | f-acore: 0.6545\n",
            "Test:  loss: 0.7113 | accuracy: 0.5068 | f1: 0.4757\n",
            "Validation:  loss: 0.7076 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00095\n",
            "Train: loss: 0.6092 | accuracy: 0.6612 | f-acore: 0.6519\n",
            "Test:  loss: 0.7518 | accuracy: 0.5205 | f1: 0.4580\n",
            "Validation:  loss: 0.7202 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00096\n",
            "Train: loss: 0.6135 | accuracy: 0.6580 | f-acore: 0.6474\n",
            "Test:  loss: 0.7471 | accuracy: 0.5233 | f1: 0.4708\n",
            "Validation:  loss: 0.7167 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00097\n",
            "Train: loss: 0.6282 | accuracy: 0.6492 | f-acore: 0.6398\n",
            "Test:  loss: 0.7316 | accuracy: 0.5096 | f1: 0.4644\n",
            "Validation:  loss: 0.7086 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00098\n",
            "Train: loss: 0.6198 | accuracy: 0.6690 | f-acore: 0.6631\n",
            "Test:  loss: 0.7423 | accuracy: 0.5205 | f1: 0.4895\n",
            "Validation:  loss: 0.7108 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00099\n",
            "Train: loss: 0.6124 | accuracy: 0.6708 | f-acore: 0.6614\n",
            "Test:  loss: 0.7546 | accuracy: 0.5178 | f1: 0.4761\n",
            "Validation:  loss: 0.7160 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00100\n",
            "Train: loss: 0.6162 | accuracy: 0.6616 | f-acore: 0.6483\n",
            "Test:  loss: 0.7643 | accuracy: 0.5205 | f1: 0.4624\n",
            "Validation:  loss: 0.7236 | accuracy: 0.5119 | f1: 0.4794\n",
            "Epoch 00101\n",
            "Train: loss: 0.6175 | accuracy: 0.6630 | f-acore: 0.6494\n",
            "Test:  loss: 0.7459 | accuracy: 0.5151 | f1: 0.4851\n",
            "Validation:  loss: 0.7148 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00102\n",
            "Train: loss: 0.6058 | accuracy: 0.6543 | f-acore: 0.6518\n",
            "Test:  loss: 0.7655 | accuracy: 0.5233 | f1: 0.4766\n",
            "Validation:  loss: 0.7250 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00103\n",
            "Train: loss: 0.6051 | accuracy: 0.6722 | f-acore: 0.6580\n",
            "Test:  loss: 0.7535 | accuracy: 0.5096 | f1: 0.4715\n",
            "Validation:  loss: 0.7196 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00104\n",
            "Train: loss: 0.6028 | accuracy: 0.6685 | f-acore: 0.6596\n",
            "Test:  loss: 0.7577 | accuracy: 0.5205 | f1: 0.4557\n",
            "Validation:  loss: 0.7284 | accuracy: 0.5238 | f1: 0.4734\n",
            "Epoch 00105\n",
            "Train: loss: 0.6052 | accuracy: 0.6768 | f-acore: 0.6617\n",
            "Test:  loss: 0.7466 | accuracy: 0.5123 | f1: 0.4606\n",
            "Validation:  loss: 0.7167 | accuracy: 0.5119 | f1: 0.4856\n",
            "Epoch 00106\n",
            "Train: loss: 0.5967 | accuracy: 0.6772 | f-acore: 0.6702\n",
            "Test:  loss: 0.7448 | accuracy: 0.5096 | f1: 0.4566\n",
            "Validation:  loss: 0.7093 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00107\n",
            "Train: loss: 0.5948 | accuracy: 0.6685 | f-acore: 0.6531\n",
            "Test:  loss: 0.7385 | accuracy: 0.5123 | f1: 0.4769\n",
            "Validation:  loss: 0.7149 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00108\n",
            "Train: loss: 0.5862 | accuracy: 0.6841 | f-acore: 0.6743\n",
            "Test:  loss: 0.7390 | accuracy: 0.5068 | f1: 0.4813\n",
            "Validation:  loss: 0.7163 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00109\n",
            "Train: loss: 0.5966 | accuracy: 0.6859 | f-acore: 0.6806\n",
            "Test:  loss: 0.7337 | accuracy: 0.5068 | f1: 0.4875\n",
            "Validation:  loss: 0.7127 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00110\n",
            "Train: loss: 0.5934 | accuracy: 0.6804 | f-acore: 0.6654\n",
            "Test:  loss: 0.7624 | accuracy: 0.5041 | f1: 0.4621\n",
            "Validation:  loss: 0.7272 | accuracy: 0.4524 | f1: 0.4318\n",
            "Epoch 00111\n",
            "Train: loss: 0.6069 | accuracy: 0.6836 | f-acore: 0.6785\n",
            "Test:  loss: 0.7832 | accuracy: 0.4959 | f1: 0.4445\n",
            "Validation:  loss: 0.7236 | accuracy: 0.5357 | f1: 0.5048\n",
            "Epoch 00112\n",
            "Train: loss: 0.5894 | accuracy: 0.6809 | f-acore: 0.6709\n",
            "Test:  loss: 0.7921 | accuracy: 0.4877 | f1: 0.4385\n",
            "Validation:  loss: 0.7250 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00113\n",
            "Train: loss: 0.6104 | accuracy: 0.6749 | f-acore: 0.6619\n",
            "Test:  loss: 0.7897 | accuracy: 0.5151 | f1: 0.4685\n",
            "Validation:  loss: 0.7267 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00114\n",
            "Train: loss: 0.6121 | accuracy: 0.6873 | f-acore: 0.6824\n",
            "Test:  loss: 0.8116 | accuracy: 0.5041 | f1: 0.4462\n",
            "Validation:  loss: 0.7359 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00115\n",
            "Train: loss: 0.5896 | accuracy: 0.6841 | f-acore: 0.6690\n",
            "Test:  loss: 0.7694 | accuracy: 0.5151 | f1: 0.4704\n",
            "Validation:  loss: 0.7109 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00116\n",
            "Train: loss: 0.6005 | accuracy: 0.6818 | f-acore: 0.6732\n",
            "Test:  loss: 0.7880 | accuracy: 0.5260 | f1: 0.4664\n",
            "Validation:  loss: 0.7288 | accuracy: 0.5119 | f1: 0.4645\n",
            "Epoch 00117\n",
            "Train: loss: 0.6296 | accuracy: 0.6685 | f-acore: 0.6615\n",
            "Test:  loss: 0.7762 | accuracy: 0.5151 | f1: 0.4790\n",
            "Validation:  loss: 0.7275 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00118\n",
            "Train: loss: 0.6063 | accuracy: 0.6832 | f-acore: 0.6712\n",
            "Test:  loss: 0.7465 | accuracy: 0.5123 | f1: 0.4920\n",
            "Validation:  loss: 0.7197 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00119\n",
            "Train: loss: 0.5948 | accuracy: 0.6694 | f-acore: 0.6653\n",
            "Test:  loss: 0.7697 | accuracy: 0.5123 | f1: 0.4815\n",
            "Validation:  loss: 0.7202 | accuracy: 0.5595 | f1: 0.5487\n",
            "Epoch 00120\n",
            "Train: loss: 0.6049 | accuracy: 0.6841 | f-acore: 0.6748\n",
            "Test:  loss: 0.7607 | accuracy: 0.5041 | f1: 0.4720\n",
            "Validation:  loss: 0.7291 | accuracy: 0.5238 | f1: 0.5102\n",
            "Epoch 00121\n",
            "Train: loss: 0.5904 | accuracy: 0.6763 | f-acore: 0.6735\n",
            "Test:  loss: 0.7770 | accuracy: 0.4986 | f1: 0.4543\n",
            "Validation:  loss: 0.7278 | accuracy: 0.4762 | f1: 0.4510\n",
            "Epoch 00122\n",
            "Train: loss: 0.6163 | accuracy: 0.6772 | f-acore: 0.6606\n",
            "Test:  loss: 0.7541 | accuracy: 0.5014 | f1: 0.4698\n",
            "Validation:  loss: 0.7147 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00123\n",
            "Train: loss: 0.5858 | accuracy: 0.6850 | f-acore: 0.6794\n",
            "Test:  loss: 0.7441 | accuracy: 0.5014 | f1: 0.4781\n",
            "Validation:  loss: 0.7249 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00124\n",
            "Train: loss: 0.5943 | accuracy: 0.6997 | f-acore: 0.6949\n",
            "Test:  loss: 0.7740 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.7240 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00125\n",
            "Train: loss: 0.6015 | accuracy: 0.6850 | f-acore: 0.6783\n",
            "Test:  loss: 0.7630 | accuracy: 0.4932 | f1: 0.4405\n",
            "Validation:  loss: 0.7272 | accuracy: 0.5000 | f1: 0.4700\n",
            "Epoch 00126\n",
            "Train: loss: 0.5876 | accuracy: 0.6928 | f-acore: 0.6839\n",
            "Test:  loss: 0.7632 | accuracy: 0.4849 | f1: 0.4404\n",
            "Validation:  loss: 0.7308 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00127\n",
            "Train: loss: 0.5907 | accuracy: 0.6914 | f-acore: 0.6814\n",
            "Test:  loss: 0.7953 | accuracy: 0.5014 | f1: 0.4375\n",
            "Validation:  loss: 0.7391 | accuracy: 0.5000 | f1: 0.4700\n",
            "Epoch 00128\n",
            "Train: loss: 0.5823 | accuracy: 0.6956 | f-acore: 0.6877\n",
            "Test:  loss: 0.7661 | accuracy: 0.5151 | f1: 0.4774\n",
            "Validation:  loss: 0.7241 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00129\n",
            "Train: loss: 0.5971 | accuracy: 0.6942 | f-acore: 0.6841\n",
            "Test:  loss: 0.7619 | accuracy: 0.5096 | f1: 0.4715\n",
            "Validation:  loss: 0.7213 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00130\n",
            "Train: loss: 0.5942 | accuracy: 0.6928 | f-acore: 0.6858\n",
            "Test:  loss: 0.7789 | accuracy: 0.5096 | f1: 0.4698\n",
            "Validation:  loss: 0.7217 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00131\n",
            "Train: loss: 0.5825 | accuracy: 0.6868 | f-acore: 0.6825\n",
            "Test:  loss: 0.7835 | accuracy: 0.4932 | f1: 0.4538\n",
            "Validation:  loss: 0.7334 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00132\n",
            "Train: loss: 0.5693 | accuracy: 0.6974 | f-acore: 0.6870\n",
            "Test:  loss: 0.8039 | accuracy: 0.5205 | f1: 0.4667\n",
            "Validation:  loss: 0.7421 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00133\n",
            "Train: loss: 0.5726 | accuracy: 0.7088 | f-acore: 0.7006\n",
            "Test:  loss: 0.7798 | accuracy: 0.5342 | f1: 0.4905\n",
            "Validation:  loss: 0.7408 | accuracy: 0.5119 | f1: 0.4794\n",
            "Epoch 00134\n",
            "Train: loss: 0.5894 | accuracy: 0.6809 | f-acore: 0.6682\n",
            "Test:  loss: 0.7789 | accuracy: 0.5205 | f1: 0.4833\n",
            "Validation:  loss: 0.7392 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00135\n",
            "Train: loss: 0.5711 | accuracy: 0.6956 | f-acore: 0.6885\n",
            "Test:  loss: 0.7853 | accuracy: 0.5233 | f1: 0.4838\n",
            "Validation:  loss: 0.7392 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00136\n",
            "Train: loss: 0.5840 | accuracy: 0.6832 | f-acore: 0.6731\n",
            "Test:  loss: 0.7665 | accuracy: 0.5260 | f1: 0.4982\n",
            "Validation:  loss: 0.7344 | accuracy: 0.4762 | f1: 0.4565\n",
            "Epoch 00137\n",
            "Train: loss: 0.5783 | accuracy: 0.6956 | f-acore: 0.6874\n",
            "Test:  loss: 0.7737 | accuracy: 0.5151 | f1: 0.4774\n",
            "Validation:  loss: 0.7346 | accuracy: 0.5000 | f1: 0.4700\n",
            "Epoch 00138\n",
            "Train: loss: 0.5761 | accuracy: 0.6974 | f-acore: 0.6920\n",
            "Test:  loss: 0.7495 | accuracy: 0.5205 | f1: 0.4937\n",
            "Validation:  loss: 0.7350 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00139\n",
            "Train: loss: 0.5823 | accuracy: 0.6960 | f-acore: 0.6890\n",
            "Test:  loss: 0.7568 | accuracy: 0.5370 | f1: 0.5070\n",
            "Validation:  loss: 0.7336 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00140\n",
            "Train: loss: 0.5721 | accuracy: 0.7024 | f-acore: 0.6990\n",
            "Test:  loss: 0.7928 | accuracy: 0.5178 | f1: 0.4743\n",
            "Validation:  loss: 0.7535 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00141\n",
            "Train: loss: 0.5709 | accuracy: 0.7038 | f-acore: 0.6959\n",
            "Test:  loss: 0.7755 | accuracy: 0.5205 | f1: 0.4833\n",
            "Validation:  loss: 0.7382 | accuracy: 0.4881 | f1: 0.4605\n",
            "Epoch 00142\n",
            "Train: loss: 0.5620 | accuracy: 0.7102 | f-acore: 0.7065\n",
            "Test:  loss: 0.7801 | accuracy: 0.5178 | f1: 0.4828\n",
            "Validation:  loss: 0.7415 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00143\n",
            "Train: loss: 0.5729 | accuracy: 0.7047 | f-acore: 0.6972\n",
            "Test:  loss: 0.7877 | accuracy: 0.5014 | f1: 0.4600\n",
            "Validation:  loss: 0.7463 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00144\n",
            "Train: loss: 0.5724 | accuracy: 0.7043 | f-acore: 0.7002\n",
            "Test:  loss: 0.8112 | accuracy: 0.5068 | f1: 0.4660\n",
            "Validation:  loss: 0.7506 | accuracy: 0.5000 | f1: 0.4700\n",
            "Epoch 00145\n",
            "Train: loss: 0.5673 | accuracy: 0.7033 | f-acore: 0.6937\n",
            "Test:  loss: 0.7862 | accuracy: 0.5151 | f1: 0.4822\n",
            "Validation:  loss: 0.7473 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00146\n",
            "Train: loss: 0.5604 | accuracy: 0.7102 | f-acore: 0.7033\n",
            "Test:  loss: 0.8010 | accuracy: 0.5151 | f1: 0.4647\n",
            "Validation:  loss: 0.7357 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00147\n",
            "Train: loss: 0.5756 | accuracy: 0.7001 | f-acore: 0.6932\n",
            "Test:  loss: 0.7722 | accuracy: 0.5260 | f1: 0.4892\n",
            "Validation:  loss: 0.7368 | accuracy: 0.5238 | f1: 0.5102\n",
            "Epoch 00148\n",
            "Train: loss: 0.5913 | accuracy: 0.7006 | f-acore: 0.6915\n",
            "Test:  loss: 0.7833 | accuracy: 0.5178 | f1: 0.4706\n",
            "Validation:  loss: 0.7462 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00149\n",
            "Train: loss: 0.5785 | accuracy: 0.6983 | f-acore: 0.6927\n",
            "Test:  loss: 0.7736 | accuracy: 0.5123 | f1: 0.4871\n",
            "Validation:  loss: 0.7335 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00150\n",
            "Train: loss: 0.5756 | accuracy: 0.7006 | f-acore: 0.6943\n",
            "Test:  loss: 0.7619 | accuracy: 0.5123 | f1: 0.4753\n",
            "Validation:  loss: 0.7464 | accuracy: 0.5000 | f1: 0.4812\n",
            "Epoch 00151\n",
            "Train: loss: 0.5611 | accuracy: 0.7061 | f-acore: 0.6972\n",
            "Test:  loss: 0.7911 | accuracy: 0.5288 | f1: 0.4945\n",
            "Validation:  loss: 0.7487 | accuracy: 0.4881 | f1: 0.4712\n",
            "Epoch 00152\n",
            "Train: loss: 0.5692 | accuracy: 0.7043 | f-acore: 0.6965\n",
            "Test:  loss: 0.7855 | accuracy: 0.5205 | f1: 0.4895\n",
            "Validation:  loss: 0.7505 | accuracy: 0.5238 | f1: 0.5102\n",
            "Epoch 00153\n",
            "Train: loss: 0.5771 | accuracy: 0.7079 | f-acore: 0.6996\n",
            "Test:  loss: 0.7900 | accuracy: 0.5205 | f1: 0.4816\n",
            "Validation:  loss: 0.7479 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00154\n",
            "Train: loss: 0.5627 | accuracy: 0.7061 | f-acore: 0.7011\n",
            "Test:  loss: 0.7985 | accuracy: 0.5096 | f1: 0.4731\n",
            "Validation:  loss: 0.7558 | accuracy: 0.4881 | f1: 0.4712\n",
            "Epoch 00155\n",
            "Train: loss: 0.5736 | accuracy: 0.7029 | f-acore: 0.6954\n",
            "Test:  loss: 0.7773 | accuracy: 0.5178 | f1: 0.4902\n",
            "Validation:  loss: 0.7414 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00156\n",
            "Train: loss: 0.5655 | accuracy: 0.7088 | f-acore: 0.6973\n",
            "Test:  loss: 0.7751 | accuracy: 0.5260 | f1: 0.4982\n",
            "Validation:  loss: 0.7343 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00157\n",
            "Train: loss: 0.5529 | accuracy: 0.7125 | f-acore: 0.7041\n",
            "Test:  loss: 0.7853 | accuracy: 0.5041 | f1: 0.4621\n",
            "Validation:  loss: 0.7431 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00158\n",
            "Train: loss: 0.5734 | accuracy: 0.7102 | f-acore: 0.6974\n",
            "Test:  loss: 0.7707 | accuracy: 0.5260 | f1: 0.5090\n",
            "Validation:  loss: 0.7368 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00159\n",
            "Train: loss: 0.5746 | accuracy: 0.7084 | f-acore: 0.7036\n",
            "Test:  loss: 0.7729 | accuracy: 0.5096 | f1: 0.4978\n",
            "Validation:  loss: 0.7360 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00160\n",
            "Train: loss: 0.5522 | accuracy: 0.7125 | f-acore: 0.7098\n",
            "Test:  loss: 0.7772 | accuracy: 0.5123 | f1: 0.4953\n",
            "Validation:  loss: 0.7453 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00161\n",
            "Train: loss: 0.5578 | accuracy: 0.7111 | f-acore: 0.7051\n",
            "Test:  loss: 0.7904 | accuracy: 0.5288 | f1: 0.4880\n",
            "Validation:  loss: 0.7547 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00162\n",
            "Train: loss: 0.5626 | accuracy: 0.7231 | f-acore: 0.7139\n",
            "Test:  loss: 0.7964 | accuracy: 0.5260 | f1: 0.4968\n",
            "Validation:  loss: 0.7374 | accuracy: 0.5238 | f1: 0.5059\n",
            "Epoch 00163\n",
            "Train: loss: 0.5519 | accuracy: 0.7194 | f-acore: 0.7133\n",
            "Test:  loss: 0.8021 | accuracy: 0.5041 | f1: 0.4673\n",
            "Validation:  loss: 0.7528 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00164\n",
            "Train: loss: 0.5424 | accuracy: 0.7221 | f-acore: 0.7143\n",
            "Test:  loss: 0.7956 | accuracy: 0.5123 | f1: 0.4983\n",
            "Validation:  loss: 0.7666 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00165\n",
            "Train: loss: 0.5608 | accuracy: 0.7226 | f-acore: 0.7156\n",
            "Test:  loss: 0.8214 | accuracy: 0.5123 | f1: 0.4830\n",
            "Validation:  loss: 0.7486 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00166\n",
            "Train: loss: 0.5474 | accuracy: 0.7153 | f-acore: 0.7118\n",
            "Test:  loss: 0.8119 | accuracy: 0.5233 | f1: 0.4999\n",
            "Validation:  loss: 0.7439 | accuracy: 0.5714 | f1: 0.5592\n",
            "Epoch 00167\n",
            "Train: loss: 0.5724 | accuracy: 0.7139 | f-acore: 0.7081\n",
            "Test:  loss: 0.7957 | accuracy: 0.5123 | f1: 0.4830\n",
            "Validation:  loss: 0.7458 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00168\n",
            "Train: loss: 0.5621 | accuracy: 0.7102 | f-acore: 0.7044\n",
            "Test:  loss: 0.8055 | accuracy: 0.5123 | f1: 0.4427\n",
            "Validation:  loss: 0.7659 | accuracy: 0.4762 | f1: 0.4207\n",
            "Epoch 00169\n",
            "Train: loss: 0.5509 | accuracy: 0.7258 | f-acore: 0.7189\n",
            "Test:  loss: 0.7536 | accuracy: 0.5068 | f1: 0.4936\n",
            "Validation:  loss: 0.7301 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00170\n",
            "Train: loss: 0.5406 | accuracy: 0.7350 | f-acore: 0.7328\n",
            "Test:  loss: 0.7697 | accuracy: 0.5123 | f1: 0.4953\n",
            "Validation:  loss: 0.7218 | accuracy: 0.5714 | f1: 0.5553\n",
            "Epoch 00171\n",
            "Train: loss: 0.5573 | accuracy: 0.7075 | f-acore: 0.7018\n",
            "Test:  loss: 0.7802 | accuracy: 0.5151 | f1: 0.4893\n",
            "Validation:  loss: 0.7288 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00172\n",
            "Train: loss: 0.5731 | accuracy: 0.7162 | f-acore: 0.7109\n",
            "Test:  loss: 0.7777 | accuracy: 0.5205 | f1: 0.4964\n",
            "Validation:  loss: 0.7338 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00173\n",
            "Train: loss: 0.5745 | accuracy: 0.7079 | f-acore: 0.7039\n",
            "Test:  loss: 0.7938 | accuracy: 0.5288 | f1: 0.5133\n",
            "Validation:  loss: 0.7634 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00174\n",
            "Train: loss: 0.5514 | accuracy: 0.7217 | f-acore: 0.7148\n",
            "Test:  loss: 0.8056 | accuracy: 0.5260 | f1: 0.5154\n",
            "Validation:  loss: 0.7549 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00175\n",
            "Train: loss: 0.5848 | accuracy: 0.7047 | f-acore: 0.6991\n",
            "Test:  loss: 0.7754 | accuracy: 0.5068 | f1: 0.4907\n",
            "Validation:  loss: 0.7518 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00176\n",
            "Train: loss: 0.5530 | accuracy: 0.7267 | f-acore: 0.7220\n",
            "Test:  loss: 0.7769 | accuracy: 0.5151 | f1: 0.4966\n",
            "Validation:  loss: 0.7656 | accuracy: 0.4881 | f1: 0.4755\n",
            "Epoch 00177\n",
            "Train: loss: 0.5389 | accuracy: 0.7249 | f-acore: 0.7196\n",
            "Test:  loss: 0.8077 | accuracy: 0.5014 | f1: 0.4713\n",
            "Validation:  loss: 0.7779 | accuracy: 0.4881 | f1: 0.4712\n",
            "Epoch 00178\n",
            "Train: loss: 0.5588 | accuracy: 0.7125 | f-acore: 0.7027\n",
            "Test:  loss: 0.7975 | accuracy: 0.5342 | f1: 0.5199\n",
            "Validation:  loss: 0.7628 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00179\n",
            "Train: loss: 0.5384 | accuracy: 0.7194 | f-acore: 0.7149\n",
            "Test:  loss: 0.8245 | accuracy: 0.4986 | f1: 0.4630\n",
            "Validation:  loss: 0.7741 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00180\n",
            "Train: loss: 0.5735 | accuracy: 0.7231 | f-acore: 0.7140\n",
            "Test:  loss: 0.8316 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.7766 | accuracy: 0.4762 | f1: 0.4447\n",
            "Epoch 00181\n",
            "Train: loss: 0.5576 | accuracy: 0.7212 | f-acore: 0.7157\n",
            "Test:  loss: 0.8176 | accuracy: 0.5041 | f1: 0.4417\n",
            "Validation:  loss: 0.7733 | accuracy: 0.4643 | f1: 0.4209\n",
            "Epoch 00182\n",
            "Train: loss: 0.5695 | accuracy: 0.7139 | f-acore: 0.7029\n",
            "Test:  loss: 0.8010 | accuracy: 0.4932 | f1: 0.4538\n",
            "Validation:  loss: 0.7580 | accuracy: 0.4881 | f1: 0.4605\n",
            "Epoch 00183\n",
            "Train: loss: 0.5381 | accuracy: 0.7299 | f-acore: 0.7244\n",
            "Test:  loss: 0.7969 | accuracy: 0.4932 | f1: 0.4520\n",
            "Validation:  loss: 0.7665 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00184\n",
            "Train: loss: 0.5397 | accuracy: 0.7304 | f-acore: 0.7236\n",
            "Test:  loss: 0.7888 | accuracy: 0.5151 | f1: 0.4851\n",
            "Validation:  loss: 0.7572 | accuracy: 0.5000 | f1: 0.4812\n",
            "Epoch 00185\n",
            "Train: loss: 0.5373 | accuracy: 0.7299 | f-acore: 0.7238\n",
            "Test:  loss: 0.8051 | accuracy: 0.5068 | f1: 0.4642\n",
            "Validation:  loss: 0.7596 | accuracy: 0.5000 | f1: 0.4700\n",
            "Epoch 00186\n",
            "Train: loss: 0.5313 | accuracy: 0.7286 | f-acore: 0.7224\n",
            "Test:  loss: 0.8026 | accuracy: 0.5123 | f1: 0.4769\n",
            "Validation:  loss: 0.7641 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00187\n",
            "Train: loss: 0.5602 | accuracy: 0.7244 | f-acore: 0.7182\n",
            "Test:  loss: 0.7831 | accuracy: 0.4986 | f1: 0.4677\n",
            "Validation:  loss: 0.7553 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00188\n",
            "Train: loss: 0.5471 | accuracy: 0.7180 | f-acore: 0.7159\n",
            "Test:  loss: 0.7937 | accuracy: 0.4986 | f1: 0.4579\n",
            "Validation:  loss: 0.7379 | accuracy: 0.5476 | f1: 0.5204\n",
            "Epoch 00189\n",
            "Train: loss: 0.5456 | accuracy: 0.7309 | f-acore: 0.7225\n",
            "Test:  loss: 0.7796 | accuracy: 0.5014 | f1: 0.4728\n",
            "Validation:  loss: 0.7397 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00190\n",
            "Train: loss: 0.5753 | accuracy: 0.7171 | f-acore: 0.7146\n",
            "Test:  loss: 0.7962 | accuracy: 0.4877 | f1: 0.4479\n",
            "Validation:  loss: 0.7785 | accuracy: 0.4881 | f1: 0.4712\n",
            "Epoch 00191\n",
            "Train: loss: 0.5414 | accuracy: 0.7185 | f-acore: 0.7120\n",
            "Test:  loss: 0.7738 | accuracy: 0.5397 | f1: 0.5159\n",
            "Validation:  loss: 0.7599 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00192\n",
            "Train: loss: 0.5498 | accuracy: 0.7290 | f-acore: 0.7232\n",
            "Test:  loss: 0.8047 | accuracy: 0.4904 | f1: 0.4385\n",
            "Validation:  loss: 0.7730 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00193\n",
            "Train: loss: 0.5366 | accuracy: 0.7276 | f-acore: 0.7192\n",
            "Test:  loss: 0.7865 | accuracy: 0.4959 | f1: 0.4593\n",
            "Validation:  loss: 0.7676 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00194\n",
            "Train: loss: 0.5492 | accuracy: 0.7231 | f-acore: 0.7154\n",
            "Test:  loss: 0.7845 | accuracy: 0.5205 | f1: 0.4964\n",
            "Validation:  loss: 0.7638 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00195\n",
            "Train: loss: 0.5461 | accuracy: 0.7336 | f-acore: 0.7300\n",
            "Test:  loss: 0.7782 | accuracy: 0.4932 | f1: 0.4619\n",
            "Validation:  loss: 0.7538 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00196\n",
            "Train: loss: 0.5606 | accuracy: 0.7208 | f-acore: 0.7142\n",
            "Test:  loss: 0.7942 | accuracy: 0.5041 | f1: 0.4705\n",
            "Validation:  loss: 0.7675 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00197\n",
            "Train: loss: 0.5595 | accuracy: 0.7263 | f-acore: 0.7221\n",
            "Test:  loss: 0.7772 | accuracy: 0.4740 | f1: 0.4407\n",
            "Validation:  loss: 0.7662 | accuracy: 0.5238 | f1: 0.5059\n",
            "Epoch 00198\n",
            "Train: loss: 0.5281 | accuracy: 0.7396 | f-acore: 0.7347\n",
            "Test:  loss: 0.7985 | accuracy: 0.5096 | f1: 0.4763\n",
            "Validation:  loss: 0.7564 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00199\n",
            "Train: loss: 0.5324 | accuracy: 0.7212 | f-acore: 0.7147\n",
            "Test:  loss: 0.7962 | accuracy: 0.4795 | f1: 0.4465\n",
            "Validation:  loss: 0.7524 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00200\n",
            "Train: loss: 0.5147 | accuracy: 0.7304 | f-acore: 0.7252\n",
            "Test:  loss: 0.8203 | accuracy: 0.4795 | f1: 0.4416\n",
            "Validation:  loss: 0.7601 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00201\n",
            "Train: loss: 0.5311 | accuracy: 0.7244 | f-acore: 0.7186\n",
            "Test:  loss: 0.8059 | accuracy: 0.5068 | f1: 0.4677\n",
            "Validation:  loss: 0.7561 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00202\n",
            "Train: loss: 0.5387 | accuracy: 0.7286 | f-acore: 0.7223\n",
            "Test:  loss: 0.7991 | accuracy: 0.4959 | f1: 0.4523\n",
            "Validation:  loss: 0.7574 | accuracy: 0.5119 | f1: 0.4856\n",
            "Epoch 00203\n",
            "Train: loss: 0.5602 | accuracy: 0.7299 | f-acore: 0.7194\n",
            "Test:  loss: 0.7802 | accuracy: 0.5014 | f1: 0.4635\n",
            "Validation:  loss: 0.7574 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00204\n",
            "Train: loss: 0.5289 | accuracy: 0.7419 | f-acore: 0.7375\n",
            "Test:  loss: 0.7599 | accuracy: 0.5014 | f1: 0.4818\n",
            "Validation:  loss: 0.7474 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00205\n",
            "Train: loss: 0.5447 | accuracy: 0.7258 | f-acore: 0.7160\n",
            "Test:  loss: 0.7643 | accuracy: 0.4986 | f1: 0.4783\n",
            "Validation:  loss: 0.7500 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00206\n",
            "Train: loss: 0.5349 | accuracy: 0.7267 | f-acore: 0.7252\n",
            "Test:  loss: 0.7651 | accuracy: 0.5014 | f1: 0.4683\n",
            "Validation:  loss: 0.7658 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00207\n",
            "Train: loss: 0.5207 | accuracy: 0.7212 | f-acore: 0.7123\n",
            "Test:  loss: 0.7875 | accuracy: 0.5041 | f1: 0.4750\n",
            "Validation:  loss: 0.7572 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00208\n",
            "Train: loss: 0.5403 | accuracy: 0.7391 | f-acore: 0.7344\n",
            "Test:  loss: 0.7896 | accuracy: 0.4932 | f1: 0.4588\n",
            "Validation:  loss: 0.7608 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00209\n",
            "Train: loss: 0.5206 | accuracy: 0.7432 | f-acore: 0.7388\n",
            "Test:  loss: 0.7904 | accuracy: 0.4986 | f1: 0.4662\n",
            "Validation:  loss: 0.7426 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00210\n",
            "Train: loss: 0.5326 | accuracy: 0.7437 | f-acore: 0.7393\n",
            "Test:  loss: 0.8077 | accuracy: 0.4904 | f1: 0.4517\n",
            "Validation:  loss: 0.7641 | accuracy: 0.5238 | f1: 0.5059\n",
            "Epoch 00211\n",
            "Train: loss: 0.5467 | accuracy: 0.7217 | f-acore: 0.7141\n",
            "Test:  loss: 0.8068 | accuracy: 0.4904 | f1: 0.4550\n",
            "Validation:  loss: 0.7781 | accuracy: 0.5000 | f1: 0.4812\n",
            "Epoch 00212\n",
            "Train: loss: 0.5317 | accuracy: 0.7345 | f-acore: 0.7296\n",
            "Test:  loss: 0.7975 | accuracy: 0.5151 | f1: 0.4879\n",
            "Validation:  loss: 0.7888 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00213\n",
            "Train: loss: 0.5225 | accuracy: 0.7515 | f-acore: 0.7461\n",
            "Test:  loss: 0.8102 | accuracy: 0.5068 | f1: 0.4694\n",
            "Validation:  loss: 0.7891 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00214\n",
            "Train: loss: 0.5271 | accuracy: 0.7492 | f-acore: 0.7425\n",
            "Test:  loss: 0.8178 | accuracy: 0.5151 | f1: 0.4822\n",
            "Validation:  loss: 0.7906 | accuracy: 0.5000 | f1: 0.4812\n",
            "Epoch 00215\n",
            "Train: loss: 0.5220 | accuracy: 0.7309 | f-acore: 0.7257\n",
            "Test:  loss: 0.8223 | accuracy: 0.5068 | f1: 0.4742\n",
            "Validation:  loss: 0.7990 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00216\n",
            "Train: loss: 0.5311 | accuracy: 0.7387 | f-acore: 0.7340\n",
            "Test:  loss: 0.8086 | accuracy: 0.5205 | f1: 0.4895\n",
            "Validation:  loss: 0.7952 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00217\n",
            "Train: loss: 0.5075 | accuracy: 0.7409 | f-acore: 0.7335\n",
            "Test:  loss: 0.8110 | accuracy: 0.5096 | f1: 0.4835\n",
            "Validation:  loss: 0.7903 | accuracy: 0.5000 | f1: 0.4857\n",
            "Epoch 00218\n",
            "Train: loss: 0.5262 | accuracy: 0.7400 | f-acore: 0.7347\n",
            "Test:  loss: 0.8028 | accuracy: 0.5041 | f1: 0.4764\n",
            "Validation:  loss: 0.7933 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00219\n",
            "Train: loss: 0.5431 | accuracy: 0.7240 | f-acore: 0.7217\n",
            "Test:  loss: 0.7913 | accuracy: 0.5123 | f1: 0.4844\n",
            "Validation:  loss: 0.7753 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00220\n",
            "Train: loss: 0.5363 | accuracy: 0.7460 | f-acore: 0.7388\n",
            "Test:  loss: 0.8089 | accuracy: 0.4959 | f1: 0.4609\n",
            "Validation:  loss: 0.7774 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00221\n",
            "Train: loss: 0.5325 | accuracy: 0.7331 | f-acore: 0.7299\n",
            "Test:  loss: 0.8260 | accuracy: 0.5014 | f1: 0.4600\n",
            "Validation:  loss: 0.7950 | accuracy: 0.4762 | f1: 0.4510\n",
            "Epoch 00222\n",
            "Train: loss: 0.5294 | accuracy: 0.7345 | f-acore: 0.7266\n",
            "Test:  loss: 0.8069 | accuracy: 0.5014 | f1: 0.4635\n",
            "Validation:  loss: 0.7757 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00223\n",
            "Train: loss: 0.5289 | accuracy: 0.7387 | f-acore: 0.7302\n",
            "Test:  loss: 0.7934 | accuracy: 0.5068 | f1: 0.4886\n",
            "Validation:  loss: 0.7639 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00224\n",
            "Train: loss: 0.5013 | accuracy: 0.7529 | f-acore: 0.7490\n",
            "Test:  loss: 0.8384 | accuracy: 0.5068 | f1: 0.4677\n",
            "Validation:  loss: 0.7784 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00225\n",
            "Train: loss: 0.5018 | accuracy: 0.7446 | f-acore: 0.7388\n",
            "Test:  loss: 0.8195 | accuracy: 0.5041 | f1: 0.4673\n",
            "Validation:  loss: 0.7969 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00226\n",
            "Train: loss: 0.5265 | accuracy: 0.7331 | f-acore: 0.7290\n",
            "Test:  loss: 0.8234 | accuracy: 0.4959 | f1: 0.4559\n",
            "Validation:  loss: 0.7952 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00227\n",
            "Train: loss: 0.5420 | accuracy: 0.7414 | f-acore: 0.7364\n",
            "Test:  loss: 0.8090 | accuracy: 0.4932 | f1: 0.4662\n",
            "Validation:  loss: 0.7909 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00228\n",
            "Train: loss: 0.5104 | accuracy: 0.7455 | f-acore: 0.7434\n",
            "Test:  loss: 0.7968 | accuracy: 0.5068 | f1: 0.4826\n",
            "Validation:  loss: 0.7623 | accuracy: 0.5595 | f1: 0.5450\n",
            "Epoch 00229\n",
            "Train: loss: 0.5024 | accuracy: 0.7460 | f-acore: 0.7430\n",
            "Test:  loss: 0.8103 | accuracy: 0.5096 | f1: 0.4778\n",
            "Validation:  loss: 0.7795 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00230\n",
            "Train: loss: 0.5499 | accuracy: 0.7327 | f-acore: 0.7264\n",
            "Test:  loss: 0.8282 | accuracy: 0.4849 | f1: 0.4440\n",
            "Validation:  loss: 0.7834 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00231\n",
            "Train: loss: 0.5205 | accuracy: 0.7446 | f-acore: 0.7375\n",
            "Test:  loss: 0.8241 | accuracy: 0.5096 | f1: 0.4644\n",
            "Validation:  loss: 0.8023 | accuracy: 0.5119 | f1: 0.4856\n",
            "Epoch 00232\n",
            "Train: loss: 0.5287 | accuracy: 0.7304 | f-acore: 0.7247\n",
            "Test:  loss: 0.8029 | accuracy: 0.4959 | f1: 0.4609\n",
            "Validation:  loss: 0.7828 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00233\n",
            "Train: loss: 0.5188 | accuracy: 0.7446 | f-acore: 0.7396\n",
            "Test:  loss: 0.8166 | accuracy: 0.4849 | f1: 0.4492\n",
            "Validation:  loss: 0.7764 | accuracy: 0.5000 | f1: 0.4857\n",
            "Epoch 00234\n",
            "Train: loss: 0.5334 | accuracy: 0.7501 | f-acore: 0.7453\n",
            "Test:  loss: 0.8100 | accuracy: 0.5014 | f1: 0.4728\n",
            "Validation:  loss: 0.8000 | accuracy: 0.5238 | f1: 0.5102\n",
            "Epoch 00235\n",
            "Train: loss: 0.5036 | accuracy: 0.7437 | f-acore: 0.7371\n",
            "Test:  loss: 0.8281 | accuracy: 0.5014 | f1: 0.4668\n",
            "Validation:  loss: 0.7944 | accuracy: 0.4881 | f1: 0.4755\n",
            "Epoch 00236\n",
            "Train: loss: 0.5113 | accuracy: 0.7625 | f-acore: 0.7581\n",
            "Test:  loss: 0.8176 | accuracy: 0.5123 | f1: 0.4785\n",
            "Validation:  loss: 0.7926 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00237\n",
            "Train: loss: 0.5098 | accuracy: 0.7354 | f-acore: 0.7303\n",
            "Test:  loss: 0.7998 | accuracy: 0.5041 | f1: 0.4829\n",
            "Validation:  loss: 0.7855 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00238\n",
            "Train: loss: 0.5242 | accuracy: 0.7437 | f-acore: 0.7376\n",
            "Test:  loss: 0.8190 | accuracy: 0.4959 | f1: 0.4593\n",
            "Validation:  loss: 0.7884 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00239\n",
            "Train: loss: 0.5134 | accuracy: 0.7460 | f-acore: 0.7437\n",
            "Test:  loss: 0.8395 | accuracy: 0.4986 | f1: 0.4485\n",
            "Validation:  loss: 0.7781 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00240\n",
            "Train: loss: 0.5079 | accuracy: 0.7547 | f-acore: 0.7464\n",
            "Test:  loss: 0.8210 | accuracy: 0.4904 | f1: 0.4482\n",
            "Validation:  loss: 0.7883 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00241\n",
            "Train: loss: 0.4976 | accuracy: 0.7432 | f-acore: 0.7382\n",
            "Test:  loss: 0.8209 | accuracy: 0.5041 | f1: 0.4673\n",
            "Validation:  loss: 0.7911 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00242\n",
            "Train: loss: 0.5308 | accuracy: 0.7533 | f-acore: 0.7475\n",
            "Test:  loss: 0.8142 | accuracy: 0.5014 | f1: 0.4728\n",
            "Validation:  loss: 0.7947 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00243\n",
            "Train: loss: 0.5142 | accuracy: 0.7506 | f-acore: 0.7480\n",
            "Test:  loss: 0.8380 | accuracy: 0.5096 | f1: 0.4698\n",
            "Validation:  loss: 0.8104 | accuracy: 0.5238 | f1: 0.4952\n",
            "Epoch 00244\n",
            "Train: loss: 0.5008 | accuracy: 0.7492 | f-acore: 0.7448\n",
            "Test:  loss: 0.8541 | accuracy: 0.4986 | f1: 0.4485\n",
            "Validation:  loss: 0.8261 | accuracy: 0.5119 | f1: 0.4856\n",
            "Epoch 00245\n",
            "Train: loss: 0.5259 | accuracy: 0.7409 | f-acore: 0.7332\n",
            "Test:  loss: 0.8640 | accuracy: 0.5014 | f1: 0.4485\n",
            "Validation:  loss: 0.8033 | accuracy: 0.5357 | f1: 0.5107\n",
            "Epoch 00246\n",
            "Train: loss: 0.5153 | accuracy: 0.7533 | f-acore: 0.7495\n",
            "Test:  loss: 0.8300 | accuracy: 0.4740 | f1: 0.4357\n",
            "Validation:  loss: 0.7853 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00247\n",
            "Train: loss: 0.4986 | accuracy: 0.7469 | f-acore: 0.7427\n",
            "Test:  loss: 0.8233 | accuracy: 0.4822 | f1: 0.4600\n",
            "Validation:  loss: 0.7941 | accuracy: 0.5595 | f1: 0.5450\n",
            "Epoch 00248\n",
            "Train: loss: 0.4994 | accuracy: 0.7487 | f-acore: 0.7454\n",
            "Test:  loss: 0.8202 | accuracy: 0.4877 | f1: 0.4618\n",
            "Validation:  loss: 0.7958 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00249\n",
            "Train: loss: 0.5052 | accuracy: 0.7529 | f-acore: 0.7492\n",
            "Test:  loss: 0.8658 | accuracy: 0.4849 | f1: 0.4440\n",
            "Validation:  loss: 0.8122 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00250\n",
            "Train: loss: 0.5005 | accuracy: 0.7570 | f-acore: 0.7513\n",
            "Test:  loss: 0.8460 | accuracy: 0.4849 | f1: 0.4508\n",
            "Validation:  loss: 0.8301 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00251\n",
            "Train: loss: 0.4983 | accuracy: 0.7483 | f-acore: 0.7446\n",
            "Test:  loss: 0.8610 | accuracy: 0.4932 | f1: 0.4520\n",
            "Validation:  loss: 0.8194 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00252\n",
            "Train: loss: 0.5009 | accuracy: 0.7497 | f-acore: 0.7431\n",
            "Test:  loss: 0.8438 | accuracy: 0.4822 | f1: 0.4502\n",
            "Validation:  loss: 0.8352 | accuracy: 0.4881 | f1: 0.4755\n",
            "Epoch 00253\n",
            "Train: loss: 0.5121 | accuracy: 0.7515 | f-acore: 0.7468\n",
            "Test:  loss: 0.8604 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.8427 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00254\n",
            "Train: loss: 0.4954 | accuracy: 0.7483 | f-acore: 0.7448\n",
            "Test:  loss: 0.8505 | accuracy: 0.5068 | f1: 0.4710\n",
            "Validation:  loss: 0.8342 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00255\n",
            "Train: loss: 0.5331 | accuracy: 0.7432 | f-acore: 0.7386\n",
            "Test:  loss: 0.8506 | accuracy: 0.5096 | f1: 0.4698\n",
            "Validation:  loss: 0.8180 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00256\n",
            "Train: loss: 0.5063 | accuracy: 0.7552 | f-acore: 0.7510\n",
            "Test:  loss: 0.8449 | accuracy: 0.4849 | f1: 0.4539\n",
            "Validation:  loss: 0.8329 | accuracy: 0.4762 | f1: 0.4612\n",
            "Epoch 00257\n",
            "Train: loss: 0.5087 | accuracy: 0.7524 | f-acore: 0.7457\n",
            "Test:  loss: 0.8302 | accuracy: 0.4959 | f1: 0.4655\n",
            "Validation:  loss: 0.8449 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00258\n",
            "Train: loss: 0.4952 | accuracy: 0.7648 | f-acore: 0.7619\n",
            "Test:  loss: 0.8311 | accuracy: 0.5014 | f1: 0.4698\n",
            "Validation:  loss: 0.8024 | accuracy: 0.5238 | f1: 0.5102\n",
            "Epoch 00259\n",
            "Train: loss: 0.4940 | accuracy: 0.7565 | f-acore: 0.7531\n",
            "Test:  loss: 0.8568 | accuracy: 0.4932 | f1: 0.4571\n",
            "Validation:  loss: 0.8119 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00260\n",
            "Train: loss: 0.5150 | accuracy: 0.7556 | f-acore: 0.7516\n",
            "Test:  loss: 0.8406 | accuracy: 0.4932 | f1: 0.4619\n",
            "Validation:  loss: 0.8548 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00261\n",
            "Train: loss: 0.5064 | accuracy: 0.7575 | f-acore: 0.7545\n",
            "Test:  loss: 0.8378 | accuracy: 0.4932 | f1: 0.4702\n",
            "Validation:  loss: 0.8433 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00262\n",
            "Train: loss: 0.5412 | accuracy: 0.7501 | f-acore: 0.7472\n",
            "Test:  loss: 0.8584 | accuracy: 0.4986 | f1: 0.4720\n",
            "Validation:  loss: 0.8361 | accuracy: 0.4643 | f1: 0.4549\n",
            "Epoch 00263\n",
            "Train: loss: 0.4969 | accuracy: 0.7373 | f-acore: 0.7331\n",
            "Test:  loss: 0.8456 | accuracy: 0.4932 | f1: 0.4726\n",
            "Validation:  loss: 0.8330 | accuracy: 0.5238 | f1: 0.5059\n",
            "Epoch 00264\n",
            "Train: loss: 0.4940 | accuracy: 0.7643 | f-acore: 0.7593\n",
            "Test:  loss: 0.8547 | accuracy: 0.5041 | f1: 0.4689\n",
            "Validation:  loss: 0.8459 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00265\n",
            "Train: loss: 0.4954 | accuracy: 0.7703 | f-acore: 0.7640\n",
            "Test:  loss: 0.8460 | accuracy: 0.5014 | f1: 0.4635\n",
            "Validation:  loss: 0.8846 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00266\n",
            "Train: loss: 0.4960 | accuracy: 0.7662 | f-acore: 0.7610\n",
            "Test:  loss: 0.8741 | accuracy: 0.4767 | f1: 0.4378\n",
            "Validation:  loss: 0.8655 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00267\n",
            "Train: loss: 0.4990 | accuracy: 0.7524 | f-acore: 0.7504\n",
            "Test:  loss: 0.8621 | accuracy: 0.4740 | f1: 0.4407\n",
            "Validation:  loss: 0.8615 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00268\n",
            "Train: loss: 0.5000 | accuracy: 0.7643 | f-acore: 0.7594\n",
            "Test:  loss: 0.8521 | accuracy: 0.4767 | f1: 0.4412\n",
            "Validation:  loss: 0.8428 | accuracy: 0.5000 | f1: 0.4812\n",
            "Epoch 00269\n",
            "Train: loss: 0.5203 | accuracy: 0.7529 | f-acore: 0.7502\n",
            "Test:  loss: 0.8437 | accuracy: 0.4795 | f1: 0.4565\n",
            "Validation:  loss: 0.8345 | accuracy: 0.4881 | f1: 0.4712\n",
            "Epoch 00270\n",
            "Train: loss: 0.5133 | accuracy: 0.7620 | f-acore: 0.7580\n",
            "Test:  loss: 0.8161 | accuracy: 0.5233 | f1: 0.5138\n",
            "Validation:  loss: 0.8748 | accuracy: 0.4643 | f1: 0.4581\n",
            "Epoch 00271\n",
            "Train: loss: 0.5035 | accuracy: 0.7428 | f-acore: 0.7407\n",
            "Test:  loss: 0.8785 | accuracy: 0.5096 | f1: 0.4698\n",
            "Validation:  loss: 0.8736 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00272\n",
            "Train: loss: 0.5027 | accuracy: 0.7611 | f-acore: 0.7565\n",
            "Test:  loss: 0.8770 | accuracy: 0.4877 | f1: 0.4545\n",
            "Validation:  loss: 0.8883 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00273\n",
            "Train: loss: 0.4938 | accuracy: 0.7602 | f-acore: 0.7547\n",
            "Test:  loss: 0.8531 | accuracy: 0.4822 | f1: 0.4420\n",
            "Validation:  loss: 0.8727 | accuracy: 0.4643 | f1: 0.4511\n",
            "Epoch 00274\n",
            "Train: loss: 0.4785 | accuracy: 0.7584 | f-acore: 0.7538\n",
            "Test:  loss: 0.8391 | accuracy: 0.4795 | f1: 0.4465\n",
            "Validation:  loss: 0.8509 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00275\n",
            "Train: loss: 0.5097 | accuracy: 0.7698 | f-acore: 0.7673\n",
            "Test:  loss: 0.8672 | accuracy: 0.4932 | f1: 0.4555\n",
            "Validation:  loss: 0.8706 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00276\n",
            "Train: loss: 0.4806 | accuracy: 0.7611 | f-acore: 0.7569\n",
            "Test:  loss: 0.8398 | accuracy: 0.4849 | f1: 0.4524\n",
            "Validation:  loss: 0.8235 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00277\n",
            "Train: loss: 0.5080 | accuracy: 0.7519 | f-acore: 0.7481\n",
            "Test:  loss: 0.8402 | accuracy: 0.4932 | f1: 0.4603\n",
            "Validation:  loss: 0.8490 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00278\n",
            "Train: loss: 0.5012 | accuracy: 0.7643 | f-acore: 0.7621\n",
            "Test:  loss: 0.8608 | accuracy: 0.4849 | f1: 0.4385\n",
            "Validation:  loss: 0.8532 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00279\n",
            "Train: loss: 0.4909 | accuracy: 0.7694 | f-acore: 0.7655\n",
            "Test:  loss: 0.8516 | accuracy: 0.4986 | f1: 0.4614\n",
            "Validation:  loss: 0.8671 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00280\n",
            "Train: loss: 0.5111 | accuracy: 0.7556 | f-acore: 0.7518\n",
            "Test:  loss: 0.8762 | accuracy: 0.4932 | f1: 0.4538\n",
            "Validation:  loss: 0.8609 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00281\n",
            "Train: loss: 0.5050 | accuracy: 0.7648 | f-acore: 0.7613\n",
            "Test:  loss: 0.8589 | accuracy: 0.4986 | f1: 0.4720\n",
            "Validation:  loss: 0.8793 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00282\n",
            "Train: loss: 0.4954 | accuracy: 0.7515 | f-acore: 0.7478\n",
            "Test:  loss: 0.8977 | accuracy: 0.5014 | f1: 0.4564\n",
            "Validation:  loss: 0.8925 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00283\n",
            "Train: loss: 0.5072 | accuracy: 0.7643 | f-acore: 0.7595\n",
            "Test:  loss: 0.8817 | accuracy: 0.5096 | f1: 0.4715\n",
            "Validation:  loss: 0.8743 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00284\n",
            "Train: loss: 0.4832 | accuracy: 0.7634 | f-acore: 0.7600\n",
            "Test:  loss: 0.8890 | accuracy: 0.4932 | f1: 0.4571\n",
            "Validation:  loss: 0.8451 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00285\n",
            "Train: loss: 0.4796 | accuracy: 0.7694 | f-acore: 0.7653\n",
            "Test:  loss: 0.8583 | accuracy: 0.4932 | f1: 0.4571\n",
            "Validation:  loss: 0.8792 | accuracy: 0.4643 | f1: 0.4581\n",
            "Epoch 00286\n",
            "Train: loss: 0.4949 | accuracy: 0.7662 | f-acore: 0.7602\n",
            "Test:  loss: 0.8620 | accuracy: 0.4932 | f1: 0.4555\n",
            "Validation:  loss: 0.8774 | accuracy: 0.4762 | f1: 0.4714\n",
            "Epoch 00287\n",
            "Train: loss: 0.4813 | accuracy: 0.7698 | f-acore: 0.7646\n",
            "Test:  loss: 0.8469 | accuracy: 0.4959 | f1: 0.4684\n",
            "Validation:  loss: 0.8782 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00288\n",
            "Train: loss: 0.5027 | accuracy: 0.7501 | f-acore: 0.7457\n",
            "Test:  loss: 0.8510 | accuracy: 0.4904 | f1: 0.4566\n",
            "Validation:  loss: 0.8443 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00289\n",
            "Train: loss: 0.4969 | accuracy: 0.7611 | f-acore: 0.7571\n",
            "Test:  loss: 0.8562 | accuracy: 0.4877 | f1: 0.4657\n",
            "Validation:  loss: 0.8738 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00290\n",
            "Train: loss: 0.4926 | accuracy: 0.7639 | f-acore: 0.7608\n",
            "Test:  loss: 0.8865 | accuracy: 0.4932 | f1: 0.4538\n",
            "Validation:  loss: 0.8908 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00291\n",
            "Train: loss: 0.4792 | accuracy: 0.7707 | f-acore: 0.7647\n",
            "Test:  loss: 0.8574 | accuracy: 0.4767 | f1: 0.4444\n",
            "Validation:  loss: 0.9362 | accuracy: 0.4762 | f1: 0.4735\n",
            "Epoch 00292\n",
            "Train: loss: 0.5084 | accuracy: 0.7666 | f-acore: 0.7629\n",
            "Test:  loss: 0.8946 | accuracy: 0.4932 | f1: 0.4502\n",
            "Validation:  loss: 0.8895 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00293\n",
            "Train: loss: 0.4946 | accuracy: 0.7584 | f-acore: 0.7533\n",
            "Test:  loss: 0.8389 | accuracy: 0.4822 | f1: 0.4624\n",
            "Validation:  loss: 0.8665 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00294\n",
            "Train: loss: 0.4936 | accuracy: 0.7712 | f-acore: 0.7667\n",
            "Test:  loss: 0.8581 | accuracy: 0.4877 | f1: 0.4561\n",
            "Validation:  loss: 0.8873 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00295\n",
            "Train: loss: 0.4951 | accuracy: 0.7616 | f-acore: 0.7573\n",
            "Test:  loss: 0.8437 | accuracy: 0.4904 | f1: 0.4626\n",
            "Validation:  loss: 0.8602 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00296\n",
            "Train: loss: 0.4843 | accuracy: 0.7735 | f-acore: 0.7697\n",
            "Test:  loss: 0.8360 | accuracy: 0.4959 | f1: 0.4724\n",
            "Validation:  loss: 0.8764 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00297\n",
            "Train: loss: 0.4928 | accuracy: 0.7652 | f-acore: 0.7613\n",
            "Test:  loss: 0.8415 | accuracy: 0.4795 | f1: 0.4552\n",
            "Validation:  loss: 0.8804 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00298\n",
            "Train: loss: 0.4735 | accuracy: 0.7643 | f-acore: 0.7605\n",
            "Test:  loss: 0.8580 | accuracy: 0.5096 | f1: 0.4808\n",
            "Validation:  loss: 0.9054 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00299\n",
            "Train: loss: 0.4675 | accuracy: 0.7662 | f-acore: 0.7612\n",
            "Test:  loss: 0.8427 | accuracy: 0.5014 | f1: 0.4781\n",
            "Validation:  loss: 0.8676 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00300\n",
            "Train: loss: 0.4970 | accuracy: 0.7735 | f-acore: 0.7697\n",
            "Test:  loss: 0.8631 | accuracy: 0.4877 | f1: 0.4604\n",
            "Validation:  loss: 0.8727 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00301\n",
            "Train: loss: 0.4994 | accuracy: 0.7762 | f-acore: 0.7729\n",
            "Test:  loss: 0.8838 | accuracy: 0.4932 | f1: 0.4538\n",
            "Validation:  loss: 0.8698 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00302\n",
            "Train: loss: 0.4944 | accuracy: 0.7625 | f-acore: 0.7575\n",
            "Test:  loss: 0.8308 | accuracy: 0.4904 | f1: 0.4715\n",
            "Validation:  loss: 0.8868 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00303\n",
            "Train: loss: 0.4721 | accuracy: 0.7620 | f-acore: 0.7577\n",
            "Test:  loss: 0.8502 | accuracy: 0.5041 | f1: 0.4791\n",
            "Validation:  loss: 0.8781 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00304\n",
            "Train: loss: 0.4799 | accuracy: 0.7685 | f-acore: 0.7641\n",
            "Test:  loss: 0.8500 | accuracy: 0.4932 | f1: 0.4771\n",
            "Validation:  loss: 0.8866 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00305\n",
            "Train: loss: 0.4778 | accuracy: 0.7740 | f-acore: 0.7691\n",
            "Test:  loss: 0.8606 | accuracy: 0.4849 | f1: 0.4596\n",
            "Validation:  loss: 0.8839 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00306\n",
            "Train: loss: 0.4735 | accuracy: 0.7634 | f-acore: 0.7598\n",
            "Test:  loss: 0.8544 | accuracy: 0.4932 | f1: 0.4702\n",
            "Validation:  loss: 0.8979 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00307\n",
            "Train: loss: 0.4610 | accuracy: 0.7836 | f-acore: 0.7785\n",
            "Test:  loss: 0.8540 | accuracy: 0.4986 | f1: 0.4733\n",
            "Validation:  loss: 0.8804 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00308\n",
            "Train: loss: 0.4605 | accuracy: 0.7795 | f-acore: 0.7755\n",
            "Test:  loss: 0.8724 | accuracy: 0.4822 | f1: 0.4624\n",
            "Validation:  loss: 0.8785 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00309\n",
            "Train: loss: 0.4497 | accuracy: 0.7767 | f-acore: 0.7728\n",
            "Test:  loss: 0.8739 | accuracy: 0.4795 | f1: 0.4590\n",
            "Validation:  loss: 0.8736 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00310\n",
            "Train: loss: 0.4831 | accuracy: 0.7703 | f-acore: 0.7666\n",
            "Test:  loss: 0.8405 | accuracy: 0.4932 | f1: 0.4818\n",
            "Validation:  loss: 0.8815 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00311\n",
            "Train: loss: 0.4713 | accuracy: 0.7570 | f-acore: 0.7530\n",
            "Test:  loss: 0.8471 | accuracy: 0.4932 | f1: 0.4791\n",
            "Validation:  loss: 0.8821 | accuracy: 0.4762 | f1: 0.4714\n",
            "Epoch 00312\n",
            "Train: loss: 0.4811 | accuracy: 0.7685 | f-acore: 0.7647\n",
            "Test:  loss: 0.8625 | accuracy: 0.4877 | f1: 0.4734\n",
            "Validation:  loss: 0.8842 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00313\n",
            "Train: loss: 0.4790 | accuracy: 0.7643 | f-acore: 0.7609\n",
            "Test:  loss: 0.8604 | accuracy: 0.5123 | f1: 0.4908\n",
            "Validation:  loss: 0.8912 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00314\n",
            "Train: loss: 0.5076 | accuracy: 0.7698 | f-acore: 0.7666\n",
            "Test:  loss: 0.8361 | accuracy: 0.4904 | f1: 0.4692\n",
            "Validation:  loss: 0.8715 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00315\n",
            "Train: loss: 0.4775 | accuracy: 0.7790 | f-acore: 0.7754\n",
            "Test:  loss: 0.8553 | accuracy: 0.4740 | f1: 0.4357\n",
            "Validation:  loss: 0.8646 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00316\n",
            "Train: loss: 0.4708 | accuracy: 0.7657 | f-acore: 0.7618\n",
            "Test:  loss: 0.8904 | accuracy: 0.4932 | f1: 0.4588\n",
            "Validation:  loss: 0.9066 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00317\n",
            "Train: loss: 0.5259 | accuracy: 0.7799 | f-acore: 0.7765\n",
            "Test:  loss: 0.9027 | accuracy: 0.5041 | f1: 0.4689\n",
            "Validation:  loss: 0.8897 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00318\n",
            "Train: loss: 0.4854 | accuracy: 0.7611 | f-acore: 0.7580\n",
            "Test:  loss: 0.8424 | accuracy: 0.4959 | f1: 0.4749\n",
            "Validation:  loss: 0.8818 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00319\n",
            "Train: loss: 0.4706 | accuracy: 0.7717 | f-acore: 0.7688\n",
            "Test:  loss: 0.8383 | accuracy: 0.4959 | f1: 0.4724\n",
            "Validation:  loss: 0.8980 | accuracy: 0.4762 | f1: 0.4735\n",
            "Epoch 00320\n",
            "Train: loss: 0.4646 | accuracy: 0.7685 | f-acore: 0.7655\n",
            "Test:  loss: 0.8644 | accuracy: 0.4904 | f1: 0.4597\n",
            "Validation:  loss: 0.8914 | accuracy: 0.4643 | f1: 0.4549\n",
            "Epoch 00321\n",
            "Train: loss: 0.5054 | accuracy: 0.7735 | f-acore: 0.7706\n",
            "Test:  loss: 0.8618 | accuracy: 0.5096 | f1: 0.4835\n",
            "Validation:  loss: 0.8853 | accuracy: 0.4762 | f1: 0.4714\n",
            "Epoch 00322\n",
            "Train: loss: 0.4762 | accuracy: 0.7611 | f-acore: 0.7572\n",
            "Test:  loss: 0.8313 | accuracy: 0.5014 | f1: 0.4755\n",
            "Validation:  loss: 0.8640 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00323\n",
            "Train: loss: 0.4780 | accuracy: 0.7538 | f-acore: 0.7502\n",
            "Test:  loss: 0.8418 | accuracy: 0.5068 | f1: 0.4757\n",
            "Validation:  loss: 0.8736 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00324\n",
            "Train: loss: 0.4662 | accuracy: 0.7717 | f-acore: 0.7653\n",
            "Test:  loss: 0.8343 | accuracy: 0.5014 | f1: 0.4861\n",
            "Validation:  loss: 0.8840 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00325\n",
            "Train: loss: 0.4677 | accuracy: 0.7740 | f-acore: 0.7708\n",
            "Test:  loss: 0.8738 | accuracy: 0.4986 | f1: 0.4677\n",
            "Validation:  loss: 0.8847 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00326\n",
            "Train: loss: 0.4690 | accuracy: 0.7744 | f-acore: 0.7683\n",
            "Test:  loss: 0.8703 | accuracy: 0.5151 | f1: 0.4879\n",
            "Validation:  loss: 0.8827 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00327\n",
            "Train: loss: 0.4796 | accuracy: 0.7694 | f-acore: 0.7659\n",
            "Test:  loss: 0.8883 | accuracy: 0.4932 | f1: 0.4571\n",
            "Validation:  loss: 0.9121 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00328\n",
            "Train: loss: 0.4654 | accuracy: 0.7730 | f-acore: 0.7679\n",
            "Test:  loss: 0.8926 | accuracy: 0.4822 | f1: 0.4532\n",
            "Validation:  loss: 0.9145 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00329\n",
            "Train: loss: 0.4737 | accuracy: 0.7634 | f-acore: 0.7600\n",
            "Test:  loss: 0.8734 | accuracy: 0.4986 | f1: 0.4783\n",
            "Validation:  loss: 0.9030 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00330\n",
            "Train: loss: 0.4843 | accuracy: 0.7735 | f-acore: 0.7711\n",
            "Test:  loss: 0.8698 | accuracy: 0.5068 | f1: 0.4851\n",
            "Validation:  loss: 0.9092 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00331\n",
            "Train: loss: 0.4536 | accuracy: 0.7822 | f-acore: 0.7774\n",
            "Test:  loss: 0.8657 | accuracy: 0.5123 | f1: 0.4908\n",
            "Validation:  loss: 0.9068 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00332\n",
            "Train: loss: 0.4667 | accuracy: 0.7813 | f-acore: 0.7784\n",
            "Test:  loss: 0.8582 | accuracy: 0.5123 | f1: 0.4964\n",
            "Validation:  loss: 0.8799 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00333\n",
            "Train: loss: 0.4482 | accuracy: 0.7749 | f-acore: 0.7725\n",
            "Test:  loss: 0.8465 | accuracy: 0.5068 | f1: 0.4863\n",
            "Validation:  loss: 0.9065 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00334\n",
            "Train: loss: 0.4522 | accuracy: 0.7707 | f-acore: 0.7663\n",
            "Test:  loss: 0.8660 | accuracy: 0.5014 | f1: 0.4794\n",
            "Validation:  loss: 0.9075 | accuracy: 0.4762 | f1: 0.4735\n",
            "Epoch 00335\n",
            "Train: loss: 0.4529 | accuracy: 0.7941 | f-acore: 0.7910\n",
            "Test:  loss: 0.8718 | accuracy: 0.4959 | f1: 0.4737\n",
            "Validation:  loss: 0.8858 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00336\n",
            "Train: loss: 0.4604 | accuracy: 0.7740 | f-acore: 0.7712\n",
            "Test:  loss: 0.9033 | accuracy: 0.5068 | f1: 0.4710\n",
            "Validation:  loss: 0.8996 | accuracy: 0.5000 | f1: 0.4857\n",
            "Epoch 00337\n",
            "Train: loss: 0.4745 | accuracy: 0.7799 | f-acore: 0.7762\n",
            "Test:  loss: 0.8531 | accuracy: 0.4959 | f1: 0.4724\n",
            "Validation:  loss: 0.9224 | accuracy: 0.4643 | f1: 0.4605\n",
            "Epoch 00338\n",
            "Train: loss: 0.4670 | accuracy: 0.7721 | f-acore: 0.7685\n",
            "Test:  loss: 0.8632 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 0.9230 | accuracy: 0.4524 | f1: 0.4496\n",
            "Epoch 00339\n",
            "Train: loss: 0.4862 | accuracy: 0.7740 | f-acore: 0.7713\n",
            "Test:  loss: 0.8632 | accuracy: 0.5068 | f1: 0.4897\n",
            "Validation:  loss: 0.8926 | accuracy: 0.4762 | f1: 0.4714\n",
            "Epoch 00340\n",
            "Train: loss: 0.4695 | accuracy: 0.7735 | f-acore: 0.7711\n",
            "Test:  loss: 0.8656 | accuracy: 0.4932 | f1: 0.4791\n",
            "Validation:  loss: 0.8865 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00341\n",
            "Train: loss: 0.4554 | accuracy: 0.7818 | f-acore: 0.7794\n",
            "Test:  loss: 0.8529 | accuracy: 0.5123 | f1: 0.4896\n",
            "Validation:  loss: 0.9022 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00342\n",
            "Train: loss: 0.4728 | accuracy: 0.7758 | f-acore: 0.7715\n",
            "Test:  loss: 0.8823 | accuracy: 0.4986 | f1: 0.4806\n",
            "Validation:  loss: 0.9235 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00343\n",
            "Train: loss: 0.4592 | accuracy: 0.7785 | f-acore: 0.7767\n",
            "Test:  loss: 0.9030 | accuracy: 0.4932 | f1: 0.4689\n",
            "Validation:  loss: 0.9366 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00344\n",
            "Train: loss: 0.4926 | accuracy: 0.7781 | f-acore: 0.7735\n",
            "Test:  loss: 0.8611 | accuracy: 0.5041 | f1: 0.4852\n",
            "Validation:  loss: 0.9250 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00345\n",
            "Train: loss: 0.4762 | accuracy: 0.7643 | f-acore: 0.7615\n",
            "Test:  loss: 0.8730 | accuracy: 0.5041 | f1: 0.4791\n",
            "Validation:  loss: 0.9261 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00346\n",
            "Train: loss: 0.4599 | accuracy: 0.7772 | f-acore: 0.7736\n",
            "Test:  loss: 0.8571 | accuracy: 0.5068 | f1: 0.4897\n",
            "Validation:  loss: 0.9261 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00347\n",
            "Train: loss: 0.4789 | accuracy: 0.7818 | f-acore: 0.7785\n",
            "Test:  loss: 0.8520 | accuracy: 0.4932 | f1: 0.4749\n",
            "Validation:  loss: 0.9183 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00348\n",
            "Train: loss: 0.4529 | accuracy: 0.7877 | f-acore: 0.7854\n",
            "Test:  loss: 0.8812 | accuracy: 0.5014 | f1: 0.4794\n",
            "Validation:  loss: 0.9118 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00349\n",
            "Train: loss: 0.4554 | accuracy: 0.7799 | f-acore: 0.7771\n",
            "Test:  loss: 0.8965 | accuracy: 0.4959 | f1: 0.4724\n",
            "Validation:  loss: 0.9035 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00350\n",
            "Train: loss: 0.4611 | accuracy: 0.7744 | f-acore: 0.7708\n",
            "Test:  loss: 0.8855 | accuracy: 0.5123 | f1: 0.4830\n",
            "Validation:  loss: 0.9333 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00351\n",
            "Train: loss: 0.4583 | accuracy: 0.7863 | f-acore: 0.7815\n",
            "Test:  loss: 0.8808 | accuracy: 0.4959 | f1: 0.4698\n",
            "Validation:  loss: 0.9241 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00352\n",
            "Train: loss: 0.4452 | accuracy: 0.7859 | f-acore: 0.7836\n",
            "Test:  loss: 0.9384 | accuracy: 0.4932 | f1: 0.4571\n",
            "Validation:  loss: 0.8877 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00353\n",
            "Train: loss: 0.4553 | accuracy: 0.7840 | f-acore: 0.7804\n",
            "Test:  loss: 0.8928 | accuracy: 0.5014 | f1: 0.4781\n",
            "Validation:  loss: 0.9491 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00354\n",
            "Train: loss: 0.4645 | accuracy: 0.7776 | f-acore: 0.7732\n",
            "Test:  loss: 0.8911 | accuracy: 0.5068 | f1: 0.4863\n",
            "Validation:  loss: 0.9544 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00355\n",
            "Train: loss: 0.4639 | accuracy: 0.7717 | f-acore: 0.7680\n",
            "Test:  loss: 0.9695 | accuracy: 0.4877 | f1: 0.4529\n",
            "Validation:  loss: 0.9817 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00356\n",
            "Train: loss: 0.4524 | accuracy: 0.7886 | f-acore: 0.7861\n",
            "Test:  loss: 0.9256 | accuracy: 0.4904 | f1: 0.4626\n",
            "Validation:  loss: 0.9794 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00357\n",
            "Train: loss: 0.4735 | accuracy: 0.7772 | f-acore: 0.7737\n",
            "Test:  loss: 0.9055 | accuracy: 0.4877 | f1: 0.4657\n",
            "Validation:  loss: 0.9788 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00358\n",
            "Train: loss: 0.4785 | accuracy: 0.7790 | f-acore: 0.7768\n",
            "Test:  loss: 0.8847 | accuracy: 0.5123 | f1: 0.4932\n",
            "Validation:  loss: 0.9362 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00359\n",
            "Train: loss: 0.4592 | accuracy: 0.7740 | f-acore: 0.7698\n",
            "Test:  loss: 0.8741 | accuracy: 0.5068 | f1: 0.4927\n",
            "Validation:  loss: 0.9397 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00360\n",
            "Train: loss: 0.4641 | accuracy: 0.7749 | f-acore: 0.7720\n",
            "Test:  loss: 0.8820 | accuracy: 0.5014 | f1: 0.4840\n",
            "Validation:  loss: 0.9538 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00361\n",
            "Train: loss: 0.4577 | accuracy: 0.7795 | f-acore: 0.7761\n",
            "Test:  loss: 0.9024 | accuracy: 0.4986 | f1: 0.4733\n",
            "Validation:  loss: 0.9149 | accuracy: 0.4643 | f1: 0.4605\n",
            "Epoch 00362\n",
            "Train: loss: 0.4464 | accuracy: 0.7813 | f-acore: 0.7791\n",
            "Test:  loss: 0.8750 | accuracy: 0.5014 | f1: 0.4806\n",
            "Validation:  loss: 0.9571 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00363\n",
            "Train: loss: 0.4542 | accuracy: 0.7799 | f-acore: 0.7762\n",
            "Test:  loss: 0.8963 | accuracy: 0.4959 | f1: 0.4737\n",
            "Validation:  loss: 0.9554 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00364\n",
            "Train: loss: 0.4632 | accuracy: 0.7877 | f-acore: 0.7839\n",
            "Test:  loss: 0.8813 | accuracy: 0.4904 | f1: 0.4737\n",
            "Validation:  loss: 0.9434 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00365\n",
            "Train: loss: 0.4855 | accuracy: 0.7689 | f-acore: 0.7667\n",
            "Test:  loss: 0.9185 | accuracy: 0.5068 | f1: 0.4742\n",
            "Validation:  loss: 0.9456 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00366\n",
            "Train: loss: 0.4479 | accuracy: 0.7730 | f-acore: 0.7675\n",
            "Test:  loss: 0.8727 | accuracy: 0.5178 | f1: 0.4902\n",
            "Validation:  loss: 0.9434 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00367\n",
            "Train: loss: 0.4610 | accuracy: 0.7905 | f-acore: 0.7863\n",
            "Test:  loss: 0.8896 | accuracy: 0.5014 | f1: 0.4829\n",
            "Validation:  loss: 0.9156 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00368\n",
            "Train: loss: 0.4806 | accuracy: 0.7790 | f-acore: 0.7759\n",
            "Test:  loss: 0.8879 | accuracy: 0.5041 | f1: 0.4840\n",
            "Validation:  loss: 0.9511 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00369\n",
            "Train: loss: 0.4495 | accuracy: 0.7836 | f-acore: 0.7791\n",
            "Test:  loss: 0.8767 | accuracy: 0.5096 | f1: 0.4950\n",
            "Validation:  loss: 0.9346 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00370\n",
            "Train: loss: 0.4613 | accuracy: 0.7772 | f-acore: 0.7737\n",
            "Test:  loss: 0.9137 | accuracy: 0.4877 | f1: 0.4604\n",
            "Validation:  loss: 0.9107 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00371\n",
            "Train: loss: 0.4554 | accuracy: 0.7813 | f-acore: 0.7771\n",
            "Test:  loss: 0.8786 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 0.9409 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00372\n",
            "Train: loss: 0.4535 | accuracy: 0.7877 | f-acore: 0.7848\n",
            "Test:  loss: 0.8892 | accuracy: 0.4877 | f1: 0.4692\n",
            "Validation:  loss: 0.8829 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00373\n",
            "Train: loss: 0.4507 | accuracy: 0.7795 | f-acore: 0.7757\n",
            "Test:  loss: 0.8956 | accuracy: 0.4822 | f1: 0.4668\n",
            "Validation:  loss: 0.9296 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00374\n",
            "Train: loss: 0.4406 | accuracy: 0.7891 | f-acore: 0.7850\n",
            "Test:  loss: 0.8916 | accuracy: 0.4795 | f1: 0.4624\n",
            "Validation:  loss: 0.9099 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00375\n",
            "Train: loss: 0.4505 | accuracy: 0.7900 | f-acore: 0.7861\n",
            "Test:  loss: 0.9064 | accuracy: 0.4904 | f1: 0.4654\n",
            "Validation:  loss: 0.9284 | accuracy: 0.4524 | f1: 0.4445\n",
            "Epoch 00376\n",
            "Train: loss: 0.4679 | accuracy: 0.7831 | f-acore: 0.7792\n",
            "Test:  loss: 0.8906 | accuracy: 0.5014 | f1: 0.4829\n",
            "Validation:  loss: 0.9036 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00377\n",
            "Train: loss: 0.4731 | accuracy: 0.7928 | f-acore: 0.7875\n",
            "Test:  loss: 0.8887 | accuracy: 0.5041 | f1: 0.4791\n",
            "Validation:  loss: 0.9225 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00378\n",
            "Train: loss: 0.4386 | accuracy: 0.7808 | f-acore: 0.7770\n",
            "Test:  loss: 0.8899 | accuracy: 0.4986 | f1: 0.4882\n",
            "Validation:  loss: 0.9351 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00379\n",
            "Train: loss: 0.4446 | accuracy: 0.7868 | f-acore: 0.7837\n",
            "Test:  loss: 0.8988 | accuracy: 0.4904 | f1: 0.4748\n",
            "Validation:  loss: 0.9598 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00380\n",
            "Train: loss: 0.4482 | accuracy: 0.7753 | f-acore: 0.7718\n",
            "Test:  loss: 0.9161 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 0.9567 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00381\n",
            "Train: loss: 0.4344 | accuracy: 0.7950 | f-acore: 0.7919\n",
            "Test:  loss: 0.9110 | accuracy: 0.4959 | f1: 0.4783\n",
            "Validation:  loss: 1.0001 | accuracy: 0.4762 | f1: 0.4762\n",
            "Epoch 00382\n",
            "Train: loss: 0.4505 | accuracy: 0.7918 | f-acore: 0.7880\n",
            "Test:  loss: 0.9254 | accuracy: 0.5014 | f1: 0.4755\n",
            "Validation:  loss: 0.9694 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00383\n",
            "Train: loss: 0.4660 | accuracy: 0.7804 | f-acore: 0.7771\n",
            "Test:  loss: 0.8915 | accuracy: 0.5014 | f1: 0.4806\n",
            "Validation:  loss: 0.9596 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00384\n",
            "Train: loss: 0.4518 | accuracy: 0.7854 | f-acore: 0.7809\n",
            "Test:  loss: 0.8844 | accuracy: 0.5068 | f1: 0.4839\n",
            "Validation:  loss: 0.9360 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00385\n",
            "Train: loss: 0.4480 | accuracy: 0.7873 | f-acore: 0.7841\n",
            "Test:  loss: 0.8988 | accuracy: 0.4986 | f1: 0.4795\n",
            "Validation:  loss: 0.8996 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00386\n",
            "Train: loss: 0.4705 | accuracy: 0.7836 | f-acore: 0.7805\n",
            "Test:  loss: 0.9101 | accuracy: 0.4932 | f1: 0.4726\n",
            "Validation:  loss: 0.9353 | accuracy: 0.4762 | f1: 0.4714\n",
            "Epoch 00387\n",
            "Train: loss: 0.4563 | accuracy: 0.7808 | f-acore: 0.7783\n",
            "Test:  loss: 0.9553 | accuracy: 0.4904 | f1: 0.4566\n",
            "Validation:  loss: 0.9675 | accuracy: 0.4643 | f1: 0.4549\n",
            "Epoch 00388\n",
            "Train: loss: 0.4409 | accuracy: 0.7950 | f-acore: 0.7920\n",
            "Test:  loss: 0.9118 | accuracy: 0.4849 | f1: 0.4681\n",
            "Validation:  loss: 0.9774 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00389\n",
            "Train: loss: 0.4534 | accuracy: 0.7790 | f-acore: 0.7760\n",
            "Test:  loss: 0.9083 | accuracy: 0.5014 | f1: 0.4829\n",
            "Validation:  loss: 0.9902 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00390\n",
            "Train: loss: 0.4490 | accuracy: 0.7937 | f-acore: 0.7901\n",
            "Test:  loss: 0.8989 | accuracy: 0.4904 | f1: 0.4767\n",
            "Validation:  loss: 0.9825 | accuracy: 0.4762 | f1: 0.4735\n",
            "Epoch 00391\n",
            "Train: loss: 0.4577 | accuracy: 0.7886 | f-acore: 0.7855\n",
            "Test:  loss: 0.9018 | accuracy: 0.4959 | f1: 0.4804\n",
            "Validation:  loss: 0.9307 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00392\n",
            "Train: loss: 0.4486 | accuracy: 0.7785 | f-acore: 0.7755\n",
            "Test:  loss: 0.9503 | accuracy: 0.4822 | f1: 0.4487\n",
            "Validation:  loss: 0.9127 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00393\n",
            "Train: loss: 0.4724 | accuracy: 0.7822 | f-acore: 0.7776\n",
            "Test:  loss: 0.8826 | accuracy: 0.5014 | f1: 0.4898\n",
            "Validation:  loss: 0.9876 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00394\n",
            "Train: loss: 0.4677 | accuracy: 0.7772 | f-acore: 0.7744\n",
            "Test:  loss: 0.9025 | accuracy: 0.4986 | f1: 0.4898\n",
            "Validation:  loss: 0.9817 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00395\n",
            "Train: loss: 0.4525 | accuracy: 0.7804 | f-acore: 0.7775\n",
            "Test:  loss: 0.8913 | accuracy: 0.4822 | f1: 0.4731\n",
            "Validation:  loss: 1.0217 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00396\n",
            "Train: loss: 0.4486 | accuracy: 0.7850 | f-acore: 0.7804\n",
            "Test:  loss: 0.9245 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 1.0203 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00397\n",
            "Train: loss: 0.4852 | accuracy: 0.7799 | f-acore: 0.7765\n",
            "Test:  loss: 0.9410 | accuracy: 0.5205 | f1: 0.5043\n",
            "Validation:  loss: 1.0113 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00398\n",
            "Train: loss: 0.5054 | accuracy: 0.7662 | f-acore: 0.7635\n",
            "Test:  loss: 0.9238 | accuracy: 0.4986 | f1: 0.4630\n",
            "Validation:  loss: 0.9693 | accuracy: 0.5000 | f1: 0.4812\n",
            "Epoch 00399\n",
            "Train: loss: 0.4505 | accuracy: 0.7740 | f-acore: 0.7694\n",
            "Test:  loss: 0.9136 | accuracy: 0.5123 | f1: 0.4884\n",
            "Validation:  loss: 0.9798 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00400\n",
            "Train: loss: 0.4553 | accuracy: 0.7863 | f-acore: 0.7825\n",
            "Test:  loss: 0.9143 | accuracy: 0.5068 | f1: 0.4800\n",
            "Validation:  loss: 0.9604 | accuracy: 0.5000 | f1: 0.4954\n",
            "-----------------------------------------------------------------------------------------\n",
            "^IXIC\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6894 | accuracy: 0.5438 | f-acore: 0.5101\n",
            "Test:  loss: 0.6905 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6917 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00002\n",
            "Train: loss: 0.6880 | accuracy: 0.5493 | f-acore: 0.3545\n",
            "Test:  loss: 0.7053 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7008 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00003\n",
            "Train: loss: 0.6915 | accuracy: 0.5493 | f-acore: 0.3545\n",
            "Test:  loss: 0.7058 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7003 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00004\n",
            "Train: loss: 0.6899 | accuracy: 0.5493 | f-acore: 0.3545\n",
            "Test:  loss: 0.6936 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6933 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00005\n",
            "Train: loss: 0.6864 | accuracy: 0.5493 | f-acore: 0.3545\n",
            "Test:  loss: 0.6902 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6905 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00006\n",
            "Train: loss: 0.6848 | accuracy: 0.5488 | f-acore: 0.3544\n",
            "Test:  loss: 0.6912 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6912 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00007\n",
            "Train: loss: 0.6857 | accuracy: 0.5493 | f-acore: 0.3545\n",
            "Test:  loss: 0.6958 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6948 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00008\n",
            "Train: loss: 0.6832 | accuracy: 0.5493 | f-acore: 0.3555\n",
            "Test:  loss: 0.6995 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6984 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00009\n",
            "Train: loss: 0.6803 | accuracy: 0.5507 | f-acore: 0.3606\n",
            "Test:  loss: 0.7055 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6999 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00010\n",
            "Train: loss: 0.6863 | accuracy: 0.5507 | f-acore: 0.3660\n",
            "Test:  loss: 0.7056 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7004 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00011\n",
            "Train: loss: 0.6822 | accuracy: 0.5525 | f-acore: 0.4124\n",
            "Test:  loss: 0.7036 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6986 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00012\n",
            "Train: loss: 0.6811 | accuracy: 0.5539 | f-acore: 0.3979\n",
            "Test:  loss: 0.7216 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7092 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00013\n",
            "Train: loss: 0.6815 | accuracy: 0.5520 | f-acore: 0.3812\n",
            "Test:  loss: 0.7198 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7081 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00014\n",
            "Train: loss: 0.6821 | accuracy: 0.5525 | f-acore: 0.3871\n",
            "Test:  loss: 0.7173 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7066 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00015\n",
            "Train: loss: 0.6805 | accuracy: 0.5497 | f-acore: 0.4002\n",
            "Test:  loss: 0.7010 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6960 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00016\n",
            "Train: loss: 0.6765 | accuracy: 0.5516 | f-acore: 0.3975\n",
            "Test:  loss: 0.7138 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7046 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00017\n",
            "Train: loss: 0.6799 | accuracy: 0.5557 | f-acore: 0.4034\n",
            "Test:  loss: 0.7325 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7166 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00018\n",
            "Train: loss: 0.6741 | accuracy: 0.5575 | f-acore: 0.4180\n",
            "Test:  loss: 0.7345 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7179 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00019\n",
            "Train: loss: 0.6829 | accuracy: 0.5626 | f-acore: 0.4144\n",
            "Test:  loss: 0.7146 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7024 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00020\n",
            "Train: loss: 0.6800 | accuracy: 0.5704 | f-acore: 0.4859\n",
            "Test:  loss: 0.7118 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7042 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00021\n",
            "Train: loss: 0.6775 | accuracy: 0.5640 | f-acore: 0.4531\n",
            "Test:  loss: 0.7075 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6991 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00022\n",
            "Train: loss: 0.6859 | accuracy: 0.5594 | f-acore: 0.4316\n",
            "Test:  loss: 0.7130 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7017 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00023\n",
            "Train: loss: 0.6770 | accuracy: 0.5773 | f-acore: 0.5194\n",
            "Test:  loss: 0.6924 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6892 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00024\n",
            "Train: loss: 0.6754 | accuracy: 0.5672 | f-acore: 0.4707\n",
            "Test:  loss: 0.7227 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7066 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00025\n",
            "Train: loss: 0.6744 | accuracy: 0.5649 | f-acore: 0.4467\n",
            "Test:  loss: 0.7452 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7226 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00026\n",
            "Train: loss: 0.6745 | accuracy: 0.5676 | f-acore: 0.4669\n",
            "Test:  loss: 0.7350 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7166 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00027\n",
            "Train: loss: 0.6733 | accuracy: 0.5667 | f-acore: 0.4820\n",
            "Test:  loss: 0.7656 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7303 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00028\n",
            "Train: loss: 0.6765 | accuracy: 0.5736 | f-acore: 0.4868\n",
            "Test:  loss: 0.7178 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7009 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00029\n",
            "Train: loss: 0.6711 | accuracy: 0.5809 | f-acore: 0.5320\n",
            "Test:  loss: 0.6980 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00030\n",
            "Train: loss: 0.6752 | accuracy: 0.5763 | f-acore: 0.5133\n",
            "Test:  loss: 0.7678 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7346 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00031\n",
            "Train: loss: 0.6728 | accuracy: 0.5791 | f-acore: 0.5092\n",
            "Test:  loss: 0.7294 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7116 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00032\n",
            "Train: loss: 0.6794 | accuracy: 0.5855 | f-acore: 0.5274\n",
            "Test:  loss: 0.7280 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7113 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00033\n",
            "Train: loss: 0.6797 | accuracy: 0.5864 | f-acore: 0.5546\n",
            "Test:  loss: 0.7468 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7206 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00034\n",
            "Train: loss: 0.6723 | accuracy: 0.5782 | f-acore: 0.5490\n",
            "Test:  loss: 0.7470 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7201 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00035\n",
            "Train: loss: 0.6666 | accuracy: 0.5805 | f-acore: 0.5118\n",
            "Test:  loss: 0.7335 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7141 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00036\n",
            "Train: loss: 0.6648 | accuracy: 0.5883 | f-acore: 0.5352\n",
            "Test:  loss: 0.7268 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7077 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00037\n",
            "Train: loss: 0.6652 | accuracy: 0.5851 | f-acore: 0.5424\n",
            "Test:  loss: 0.7079 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6974 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00038\n",
            "Train: loss: 0.6790 | accuracy: 0.5777 | f-acore: 0.5172\n",
            "Test:  loss: 0.7167 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7020 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00039\n",
            "Train: loss: 0.6739 | accuracy: 0.5846 | f-acore: 0.5757\n",
            "Test:  loss: 0.7354 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7170 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00040\n",
            "Train: loss: 0.6716 | accuracy: 0.5699 | f-acore: 0.5620\n",
            "Test:  loss: 0.7328 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7115 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00041\n",
            "Train: loss: 0.6697 | accuracy: 0.5722 | f-acore: 0.5268\n",
            "Test:  loss: 0.7397 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7152 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00042\n",
            "Train: loss: 0.6601 | accuracy: 0.5860 | f-acore: 0.5337\n",
            "Test:  loss: 0.7012 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7002 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00043\n",
            "Train: loss: 0.6708 | accuracy: 0.5869 | f-acore: 0.5256\n",
            "Test:  loss: 0.7342 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7110 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00044\n",
            "Train: loss: 0.6620 | accuracy: 0.6052 | f-acore: 0.5698\n",
            "Test:  loss: 0.7538 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7215 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00045\n",
            "Train: loss: 0.6593 | accuracy: 0.5988 | f-acore: 0.5576\n",
            "Test:  loss: 0.7187 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7071 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00046\n",
            "Train: loss: 0.6643 | accuracy: 0.6011 | f-acore: 0.5549\n",
            "Test:  loss: 0.7501 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7223 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00047\n",
            "Train: loss: 0.6628 | accuracy: 0.5892 | f-acore: 0.5643\n",
            "Test:  loss: 0.6980 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.6943 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00048\n",
            "Train: loss: 0.6658 | accuracy: 0.6016 | f-acore: 0.5640\n",
            "Test:  loss: 0.7046 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6943 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00049\n",
            "Train: loss: 0.6631 | accuracy: 0.6121 | f-acore: 0.5972\n",
            "Test:  loss: 0.7061 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.6983 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00050\n",
            "Train: loss: 0.6577 | accuracy: 0.5993 | f-acore: 0.5717\n",
            "Test:  loss: 0.6971 | accuracy: 0.5589 | f1: 0.3852\n",
            "Validation:  loss: 0.6946 | accuracy: 0.5476 | f1: 0.3968\n",
            "Epoch 00051\n",
            "Train: loss: 0.6618 | accuracy: 0.5988 | f-acore: 0.5771\n",
            "Test:  loss: 0.7322 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7086 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00052\n",
            "Train: loss: 0.6603 | accuracy: 0.6080 | f-acore: 0.5816\n",
            "Test:  loss: 0.7315 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7030 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00053\n",
            "Train: loss: 0.6570 | accuracy: 0.5928 | f-acore: 0.5747\n",
            "Test:  loss: 0.7244 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7014 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00054\n",
            "Train: loss: 0.6569 | accuracy: 0.5993 | f-acore: 0.5709\n",
            "Test:  loss: 0.7759 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7288 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00055\n",
            "Train: loss: 0.6547 | accuracy: 0.5951 | f-acore: 0.5775\n",
            "Test:  loss: 0.7619 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7228 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00056\n",
            "Train: loss: 0.6480 | accuracy: 0.6098 | f-acore: 0.5812\n",
            "Test:  loss: 0.7548 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7196 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00057\n",
            "Train: loss: 0.6462 | accuracy: 0.6089 | f-acore: 0.5733\n",
            "Test:  loss: 0.7246 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7069 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00058\n",
            "Train: loss: 0.6494 | accuracy: 0.6080 | f-acore: 0.5952\n",
            "Test:  loss: 0.7437 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7125 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00059\n",
            "Train: loss: 0.6508 | accuracy: 0.6167 | f-acore: 0.5948\n",
            "Test:  loss: 0.7555 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7184 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00060\n",
            "Train: loss: 0.6517 | accuracy: 0.6061 | f-acore: 0.5939\n",
            "Test:  loss: 0.7925 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7351 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00061\n",
            "Train: loss: 0.6541 | accuracy: 0.6194 | f-acore: 0.5977\n",
            "Test:  loss: 0.7193 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.6999 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00062\n",
            "Train: loss: 0.6526 | accuracy: 0.6217 | f-acore: 0.6155\n",
            "Test:  loss: 0.7457 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7157 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00063\n",
            "Train: loss: 0.6415 | accuracy: 0.6190 | f-acore: 0.5945\n",
            "Test:  loss: 0.7759 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7275 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00064\n",
            "Train: loss: 0.6460 | accuracy: 0.6222 | f-acore: 0.6052\n",
            "Test:  loss: 0.7261 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7021 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00065\n",
            "Train: loss: 0.6461 | accuracy: 0.6217 | f-acore: 0.6064\n",
            "Test:  loss: 0.7484 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7123 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00066\n",
            "Train: loss: 0.6538 | accuracy: 0.6208 | f-acore: 0.5846\n",
            "Test:  loss: 0.7058 | accuracy: 0.5699 | f1: 0.4233\n",
            "Validation:  loss: 0.6898 | accuracy: 0.5714 | f1: 0.4286\n",
            "Epoch 00067\n",
            "Train: loss: 0.6507 | accuracy: 0.6245 | f-acore: 0.6188\n",
            "Test:  loss: 0.6933 | accuracy: 0.5315 | f1: 0.4847\n",
            "Validation:  loss: 0.6933 | accuracy: 0.4881 | f1: 0.4188\n",
            "Epoch 00068\n",
            "Train: loss: 0.6452 | accuracy: 0.6222 | f-acore: 0.6102\n",
            "Test:  loss: 0.7110 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7067 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00069\n",
            "Train: loss: 0.6385 | accuracy: 0.6245 | f-acore: 0.6049\n",
            "Test:  loss: 0.7687 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7292 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00070\n",
            "Train: loss: 0.6335 | accuracy: 0.6181 | f-acore: 0.5965\n",
            "Test:  loss: 0.7528 | accuracy: 0.5534 | f1: 0.3618\n",
            "Validation:  loss: 0.7075 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00071\n",
            "Train: loss: 0.6406 | accuracy: 0.6245 | f-acore: 0.6154\n",
            "Test:  loss: 0.7336 | accuracy: 0.5562 | f1: 0.3737\n",
            "Validation:  loss: 0.7004 | accuracy: 0.5476 | f1: 0.3766\n",
            "Epoch 00072\n",
            "Train: loss: 0.6358 | accuracy: 0.6447 | f-acore: 0.6330\n",
            "Test:  loss: 0.7688 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7252 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00073\n",
            "Train: loss: 0.6374 | accuracy: 0.6424 | f-acore: 0.6296\n",
            "Test:  loss: 0.7615 | accuracy: 0.5534 | f1: 0.3826\n",
            "Validation:  loss: 0.7178 | accuracy: 0.5357 | f1: 0.3905\n",
            "Epoch 00074\n",
            "Train: loss: 0.6423 | accuracy: 0.6268 | f-acore: 0.6096\n",
            "Test:  loss: 0.7184 | accuracy: 0.5452 | f1: 0.4756\n",
            "Validation:  loss: 0.6954 | accuracy: 0.5833 | f1: 0.5556\n",
            "Epoch 00075\n",
            "Train: loss: 0.6323 | accuracy: 0.6378 | f-acore: 0.6301\n",
            "Test:  loss: 0.8366 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7601 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00076\n",
            "Train: loss: 0.6306 | accuracy: 0.6437 | f-acore: 0.6348\n",
            "Test:  loss: 0.7699 | accuracy: 0.5562 | f1: 0.3684\n",
            "Validation:  loss: 0.7217 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00077\n",
            "Train: loss: 0.6311 | accuracy: 0.6355 | f-acore: 0.6139\n",
            "Test:  loss: 0.7717 | accuracy: 0.5562 | f1: 0.3737\n",
            "Validation:  loss: 0.7175 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00078\n",
            "Train: loss: 0.6318 | accuracy: 0.6552 | f-acore: 0.6440\n",
            "Test:  loss: 0.7386 | accuracy: 0.5726 | f1: 0.4248\n",
            "Validation:  loss: 0.7018 | accuracy: 0.5476 | f1: 0.4150\n",
            "Epoch 00079\n",
            "Train: loss: 0.6285 | accuracy: 0.6525 | f-acore: 0.6440\n",
            "Test:  loss: 0.7941 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7336 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00080\n",
            "Train: loss: 0.6379 | accuracy: 0.6561 | f-acore: 0.6452\n",
            "Test:  loss: 0.7787 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7216 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00081\n",
            "Train: loss: 0.6386 | accuracy: 0.6414 | f-acore: 0.6349\n",
            "Test:  loss: 0.7375 | accuracy: 0.5616 | f1: 0.4011\n",
            "Validation:  loss: 0.7043 | accuracy: 0.5476 | f1: 0.3968\n",
            "Epoch 00082\n",
            "Train: loss: 0.6417 | accuracy: 0.6419 | f-acore: 0.6374\n",
            "Test:  loss: 0.8747 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7866 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00083\n",
            "Train: loss: 0.6360 | accuracy: 0.6557 | f-acore: 0.6357\n",
            "Test:  loss: 0.7590 | accuracy: 0.5616 | f1: 0.3815\n",
            "Validation:  loss: 0.7162 | accuracy: 0.5357 | f1: 0.3708\n",
            "Epoch 00084\n",
            "Train: loss: 0.6366 | accuracy: 0.6566 | f-acore: 0.6446\n",
            "Test:  loss: 0.7386 | accuracy: 0.5589 | f1: 0.4042\n",
            "Validation:  loss: 0.7041 | accuracy: 0.5238 | f1: 0.3651\n",
            "Epoch 00085\n",
            "Train: loss: 0.6237 | accuracy: 0.6405 | f-acore: 0.6331\n",
            "Test:  loss: 0.6958 | accuracy: 0.5315 | f1: 0.5274\n",
            "Validation:  loss: 0.7061 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00086\n",
            "Train: loss: 0.6266 | accuracy: 0.6419 | f-acore: 0.6342\n",
            "Test:  loss: 0.7055 | accuracy: 0.5425 | f1: 0.4783\n",
            "Validation:  loss: 0.6998 | accuracy: 0.5833 | f1: 0.5428\n",
            "Epoch 00087\n",
            "Train: loss: 0.6235 | accuracy: 0.6552 | f-acore: 0.6438\n",
            "Test:  loss: 0.7536 | accuracy: 0.5726 | f1: 0.4160\n",
            "Validation:  loss: 0.7145 | accuracy: 0.5238 | f1: 0.3842\n",
            "Epoch 00088\n",
            "Train: loss: 0.6208 | accuracy: 0.6589 | f-acore: 0.6435\n",
            "Test:  loss: 0.7233 | accuracy: 0.5562 | f1: 0.4387\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5833 | f1: 0.5353\n",
            "Epoch 00089\n",
            "Train: loss: 0.6139 | accuracy: 0.6584 | f-acore: 0.6497\n",
            "Test:  loss: 0.7635 | accuracy: 0.5671 | f1: 0.4085\n",
            "Validation:  loss: 0.7151 | accuracy: 0.5238 | f1: 0.3842\n",
            "Epoch 00090\n",
            "Train: loss: 0.6219 | accuracy: 0.6534 | f-acore: 0.6406\n",
            "Test:  loss: 0.7928 | accuracy: 0.5534 | f1: 0.3968\n",
            "Validation:  loss: 0.7197 | accuracy: 0.5357 | f1: 0.4239\n",
            "Epoch 00091\n",
            "Train: loss: 0.6209 | accuracy: 0.6520 | f-acore: 0.6410\n",
            "Test:  loss: 0.7309 | accuracy: 0.5315 | f1: 0.4681\n",
            "Validation:  loss: 0.6923 | accuracy: 0.5833 | f1: 0.5496\n",
            "Epoch 00092\n",
            "Train: loss: 0.6349 | accuracy: 0.6506 | f-acore: 0.6452\n",
            "Test:  loss: 0.7709 | accuracy: 0.5671 | f1: 0.4039\n",
            "Validation:  loss: 0.7202 | accuracy: 0.5238 | f1: 0.3651\n",
            "Epoch 00093\n",
            "Train: loss: 0.6131 | accuracy: 0.6566 | f-acore: 0.6471\n",
            "Test:  loss: 0.7600 | accuracy: 0.5699 | f1: 0.4005\n",
            "Validation:  loss: 0.7213 | accuracy: 0.5357 | f1: 0.3708\n",
            "Epoch 00094\n",
            "Train: loss: 0.6123 | accuracy: 0.6713 | f-acore: 0.6585\n",
            "Test:  loss: 0.7809 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7287 | accuracy: 0.5357 | f1: 0.3708\n",
            "Epoch 00095\n",
            "Train: loss: 0.6208 | accuracy: 0.6470 | f-acore: 0.6352\n",
            "Test:  loss: 0.7759 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7310 | accuracy: 0.5357 | f1: 0.3488\n",
            "Epoch 00096\n",
            "Train: loss: 0.6186 | accuracy: 0.6625 | f-acore: 0.6459\n",
            "Test:  loss: 0.7452 | accuracy: 0.5726 | f1: 0.4160\n",
            "Validation:  loss: 0.7115 | accuracy: 0.5357 | f1: 0.3905\n",
            "Epoch 00097\n",
            "Train: loss: 0.6156 | accuracy: 0.6625 | f-acore: 0.6534\n",
            "Test:  loss: 0.8199 | accuracy: 0.5534 | f1: 0.3618\n",
            "Validation:  loss: 0.7534 | accuracy: 0.5357 | f1: 0.3708\n",
            "Epoch 00098\n",
            "Train: loss: 0.6475 | accuracy: 0.6566 | f-acore: 0.6471\n",
            "Test:  loss: 0.7605 | accuracy: 0.5726 | f1: 0.4332\n",
            "Validation:  loss: 0.7149 | accuracy: 0.5595 | f1: 0.4901\n",
            "Epoch 00099\n",
            "Train: loss: 0.6232 | accuracy: 0.6497 | f-acore: 0.6318\n",
            "Test:  loss: 0.7303 | accuracy: 0.5753 | f1: 0.4505\n",
            "Validation:  loss: 0.7025 | accuracy: 0.5595 | f1: 0.4999\n",
            "Epoch 00100\n",
            "Train: loss: 0.6175 | accuracy: 0.6648 | f-acore: 0.6545\n",
            "Test:  loss: 0.7893 | accuracy: 0.5534 | f1: 0.3672\n",
            "Validation:  loss: 0.7325 | accuracy: 0.5476 | f1: 0.3968\n",
            "Epoch 00101\n",
            "Train: loss: 0.6138 | accuracy: 0.6653 | f-acore: 0.6503\n",
            "Test:  loss: 0.7551 | accuracy: 0.5479 | f1: 0.3984\n",
            "Validation:  loss: 0.7114 | accuracy: 0.5357 | f1: 0.4239\n",
            "Epoch 00102\n",
            "Train: loss: 0.6105 | accuracy: 0.6722 | f-acore: 0.6581\n",
            "Test:  loss: 0.7886 | accuracy: 0.5589 | f1: 0.3802\n",
            "Validation:  loss: 0.7281 | accuracy: 0.5357 | f1: 0.4081\n",
            "Epoch 00103\n",
            "Train: loss: 0.6103 | accuracy: 0.6781 | f-acore: 0.6730\n",
            "Test:  loss: 0.7695 | accuracy: 0.5589 | f1: 0.3996\n",
            "Validation:  loss: 0.7178 | accuracy: 0.5476 | f1: 0.4590\n",
            "Epoch 00104\n",
            "Train: loss: 0.6080 | accuracy: 0.6543 | f-acore: 0.6421\n",
            "Test:  loss: 0.7740 | accuracy: 0.5589 | f1: 0.3852\n",
            "Validation:  loss: 0.7237 | accuracy: 0.5238 | f1: 0.4013\n",
            "Epoch 00105\n",
            "Train: loss: 0.6046 | accuracy: 0.6758 | f-acore: 0.6697\n",
            "Test:  loss: 0.8143 | accuracy: 0.5507 | f1: 0.3606\n",
            "Validation:  loss: 0.7416 | accuracy: 0.5357 | f1: 0.3708\n",
            "Epoch 00106\n",
            "Train: loss: 0.6026 | accuracy: 0.6726 | f-acore: 0.6633\n",
            "Test:  loss: 0.8417 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.7553 | accuracy: 0.5476 | f1: 0.3766\n",
            "Epoch 00107\n",
            "Train: loss: 0.5955 | accuracy: 0.6800 | f-acore: 0.6725\n",
            "Test:  loss: 0.7621 | accuracy: 0.5534 | f1: 0.3922\n",
            "Validation:  loss: 0.7199 | accuracy: 0.5357 | f1: 0.4239\n",
            "Epoch 00108\n",
            "Train: loss: 0.6214 | accuracy: 0.6740 | f-acore: 0.6662\n",
            "Test:  loss: 0.7958 | accuracy: 0.5534 | f1: 0.3725\n",
            "Validation:  loss: 0.7375 | accuracy: 0.5357 | f1: 0.3708\n",
            "Epoch 00109\n",
            "Train: loss: 0.6084 | accuracy: 0.6722 | f-acore: 0.6650\n",
            "Test:  loss: 0.8024 | accuracy: 0.5534 | f1: 0.3725\n",
            "Validation:  loss: 0.7397 | accuracy: 0.5238 | f1: 0.3651\n",
            "Epoch 00110\n",
            "Train: loss: 0.5994 | accuracy: 0.6868 | f-acore: 0.6749\n",
            "Test:  loss: 0.8182 | accuracy: 0.5507 | f1: 0.3763\n",
            "Validation:  loss: 0.7425 | accuracy: 0.5238 | f1: 0.4013\n",
            "Epoch 00111\n",
            "Train: loss: 0.5931 | accuracy: 0.6827 | f-acore: 0.6714\n",
            "Test:  loss: 0.7709 | accuracy: 0.5452 | f1: 0.3969\n",
            "Validation:  loss: 0.7236 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00112\n",
            "Train: loss: 0.6095 | accuracy: 0.6676 | f-acore: 0.6604\n",
            "Test:  loss: 0.7349 | accuracy: 0.5507 | f1: 0.4579\n",
            "Validation:  loss: 0.7022 | accuracy: 0.6071 | f1: 0.5690\n",
            "Epoch 00113\n",
            "Train: loss: 0.6114 | accuracy: 0.6690 | f-acore: 0.6594\n",
            "Test:  loss: 0.7574 | accuracy: 0.5534 | f1: 0.4297\n",
            "Validation:  loss: 0.7173 | accuracy: 0.5238 | f1: 0.4305\n",
            "Epoch 00114\n",
            "Train: loss: 0.6026 | accuracy: 0.6703 | f-acore: 0.6664\n",
            "Test:  loss: 0.7829 | accuracy: 0.5507 | f1: 0.4042\n",
            "Validation:  loss: 0.7349 | accuracy: 0.5476 | f1: 0.4312\n",
            "Epoch 00115\n",
            "Train: loss: 0.6100 | accuracy: 0.6763 | f-acore: 0.6670\n",
            "Test:  loss: 0.8533 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.7687 | accuracy: 0.5238 | f1: 0.3842\n",
            "Epoch 00116\n",
            "Train: loss: 0.5985 | accuracy: 0.6868 | f-acore: 0.6782\n",
            "Test:  loss: 0.7562 | accuracy: 0.5397 | f1: 0.4352\n",
            "Validation:  loss: 0.7072 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00117\n",
            "Train: loss: 0.5870 | accuracy: 0.6790 | f-acore: 0.6732\n",
            "Test:  loss: 0.7717 | accuracy: 0.5260 | f1: 0.3907\n",
            "Validation:  loss: 0.7180 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00118\n",
            "Train: loss: 0.6087 | accuracy: 0.6662 | f-acore: 0.6607\n",
            "Test:  loss: 0.8003 | accuracy: 0.5479 | f1: 0.3939\n",
            "Validation:  loss: 0.7352 | accuracy: 0.5238 | f1: 0.4305\n",
            "Epoch 00119\n",
            "Train: loss: 0.6036 | accuracy: 0.6749 | f-acore: 0.6662\n",
            "Test:  loss: 0.7456 | accuracy: 0.5479 | f1: 0.3894\n",
            "Validation:  loss: 0.7077 | accuracy: 0.5595 | f1: 0.4791\n",
            "Epoch 00120\n",
            "Train: loss: 0.6088 | accuracy: 0.6699 | f-acore: 0.6647\n",
            "Test:  loss: 0.7700 | accuracy: 0.5479 | f1: 0.4404\n",
            "Validation:  loss: 0.7179 | accuracy: 0.5476 | f1: 0.5074\n",
            "Epoch 00121\n",
            "Train: loss: 0.6034 | accuracy: 0.6832 | f-acore: 0.6767\n",
            "Test:  loss: 0.7845 | accuracy: 0.5507 | f1: 0.4084\n",
            "Validation:  loss: 0.7323 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00122\n",
            "Train: loss: 0.5910 | accuracy: 0.6836 | f-acore: 0.6717\n",
            "Test:  loss: 0.7782 | accuracy: 0.5644 | f1: 0.4160\n",
            "Validation:  loss: 0.7239 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00123\n",
            "Train: loss: 0.6121 | accuracy: 0.6896 | f-acore: 0.6799\n",
            "Test:  loss: 0.7482 | accuracy: 0.5562 | f1: 0.4554\n",
            "Validation:  loss: 0.7093 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00124\n",
            "Train: loss: 0.5928 | accuracy: 0.6914 | f-acore: 0.6885\n",
            "Test:  loss: 0.8239 | accuracy: 0.5562 | f1: 0.3982\n",
            "Validation:  loss: 0.7507 | accuracy: 0.5357 | f1: 0.4382\n",
            "Epoch 00125\n",
            "Train: loss: 0.5865 | accuracy: 0.6804 | f-acore: 0.6689\n",
            "Test:  loss: 0.8249 | accuracy: 0.5479 | f1: 0.3847\n",
            "Validation:  loss: 0.7488 | accuracy: 0.5595 | f1: 0.4535\n",
            "Epoch 00126\n",
            "Train: loss: 0.5863 | accuracy: 0.6809 | f-acore: 0.6706\n",
            "Test:  loss: 0.8059 | accuracy: 0.5589 | f1: 0.4129\n",
            "Validation:  loss: 0.7339 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00127\n",
            "Train: loss: 0.5982 | accuracy: 0.6823 | f-acore: 0.6742\n",
            "Test:  loss: 0.8103 | accuracy: 0.5589 | f1: 0.4172\n",
            "Validation:  loss: 0.7386 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00128\n",
            "Train: loss: 0.5899 | accuracy: 0.6974 | f-acore: 0.6921\n",
            "Test:  loss: 0.7694 | accuracy: 0.5397 | f1: 0.4385\n",
            "Validation:  loss: 0.7175 | accuracy: 0.5238 | f1: 0.4643\n",
            "Epoch 00129\n",
            "Train: loss: 0.5934 | accuracy: 0.6910 | f-acore: 0.6836\n",
            "Test:  loss: 0.7952 | accuracy: 0.5507 | f1: 0.4455\n",
            "Validation:  loss: 0.7310 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00130\n",
            "Train: loss: 0.5838 | accuracy: 0.6859 | f-acore: 0.6795\n",
            "Test:  loss: 0.8350 | accuracy: 0.5644 | f1: 0.4160\n",
            "Validation:  loss: 0.7498 | accuracy: 0.5357 | f1: 0.4382\n",
            "Epoch 00131\n",
            "Train: loss: 0.6105 | accuracy: 0.6777 | f-acore: 0.6639\n",
            "Test:  loss: 0.8155 | accuracy: 0.5370 | f1: 0.4125\n",
            "Validation:  loss: 0.7460 | accuracy: 0.5476 | f1: 0.4458\n",
            "Epoch 00132\n",
            "Train: loss: 0.5878 | accuracy: 0.6901 | f-acore: 0.6852\n",
            "Test:  loss: 0.8248 | accuracy: 0.5425 | f1: 0.4302\n",
            "Validation:  loss: 0.7532 | accuracy: 0.5357 | f1: 0.4510\n",
            "Epoch 00133\n",
            "Train: loss: 0.5814 | accuracy: 0.6832 | f-acore: 0.6771\n",
            "Test:  loss: 0.8306 | accuracy: 0.5562 | f1: 0.4314\n",
            "Validation:  loss: 0.7439 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00134\n",
            "Train: loss: 0.5957 | accuracy: 0.6978 | f-acore: 0.6898\n",
            "Test:  loss: 0.9107 | accuracy: 0.5479 | f1: 0.3595\n",
            "Validation:  loss: 0.7866 | accuracy: 0.5476 | f1: 0.3968\n",
            "Epoch 00135\n",
            "Train: loss: 0.5819 | accuracy: 0.6933 | f-acore: 0.6882\n",
            "Test:  loss: 0.7926 | accuracy: 0.5562 | f1: 0.4071\n",
            "Validation:  loss: 0.7387 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00136\n",
            "Train: loss: 0.6162 | accuracy: 0.6878 | f-acore: 0.6811\n",
            "Test:  loss: 0.7039 | accuracy: 0.5315 | f1: 0.4884\n",
            "Validation:  loss: 0.7126 | accuracy: 0.4524 | f1: 0.4195\n",
            "Epoch 00137\n",
            "Train: loss: 0.5888 | accuracy: 0.6905 | f-acore: 0.6811\n",
            "Test:  loss: 0.8372 | accuracy: 0.5589 | f1: 0.4086\n",
            "Validation:  loss: 0.7659 | accuracy: 0.5238 | f1: 0.4167\n",
            "Epoch 00138\n",
            "Train: loss: 0.5796 | accuracy: 0.7020 | f-acore: 0.6895\n",
            "Test:  loss: 0.7789 | accuracy: 0.5425 | f1: 0.4402\n",
            "Validation:  loss: 0.7414 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00139\n",
            "Train: loss: 0.5753 | accuracy: 0.7038 | f-acore: 0.6954\n",
            "Test:  loss: 0.8477 | accuracy: 0.5589 | f1: 0.4129\n",
            "Validation:  loss: 0.7664 | accuracy: 0.5238 | f1: 0.4305\n",
            "Epoch 00140\n",
            "Train: loss: 0.5816 | accuracy: 0.6887 | f-acore: 0.6807\n",
            "Test:  loss: 0.7555 | accuracy: 0.5342 | f1: 0.4381\n",
            "Validation:  loss: 0.7316 | accuracy: 0.5000 | f1: 0.4556\n",
            "Epoch 00141\n",
            "Train: loss: 0.5819 | accuracy: 0.6868 | f-acore: 0.6826\n",
            "Test:  loss: 0.8319 | accuracy: 0.5507 | f1: 0.4243\n",
            "Validation:  loss: 0.7558 | accuracy: 0.5357 | f1: 0.4510\n",
            "Epoch 00142\n",
            "Train: loss: 0.5736 | accuracy: 0.7024 | f-acore: 0.6946\n",
            "Test:  loss: 0.7779 | accuracy: 0.5342 | f1: 0.4441\n",
            "Validation:  loss: 0.7303 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00143\n",
            "Train: loss: 0.5715 | accuracy: 0.7020 | f-acore: 0.6979\n",
            "Test:  loss: 0.8436 | accuracy: 0.5616 | f1: 0.4187\n",
            "Validation:  loss: 0.7676 | accuracy: 0.5357 | f1: 0.4625\n",
            "Epoch 00144\n",
            "Train: loss: 0.5737 | accuracy: 0.7029 | f-acore: 0.6947\n",
            "Test:  loss: 0.7505 | accuracy: 0.5370 | f1: 0.4850\n",
            "Validation:  loss: 0.7272 | accuracy: 0.5714 | f1: 0.5508\n",
            "Epoch 00145\n",
            "Train: loss: 0.5659 | accuracy: 0.6905 | f-acore: 0.6844\n",
            "Test:  loss: 0.7898 | accuracy: 0.5151 | f1: 0.4286\n",
            "Validation:  loss: 0.7401 | accuracy: 0.5833 | f1: 0.5496\n",
            "Epoch 00146\n",
            "Train: loss: 0.6073 | accuracy: 0.6983 | f-acore: 0.6926\n",
            "Test:  loss: 0.8092 | accuracy: 0.5452 | f1: 0.4353\n",
            "Validation:  loss: 0.7508 | accuracy: 0.5476 | f1: 0.4997\n",
            "Epoch 00147\n",
            "Train: loss: 0.5780 | accuracy: 0.6845 | f-acore: 0.6761\n",
            "Test:  loss: 0.7709 | accuracy: 0.5370 | f1: 0.4721\n",
            "Validation:  loss: 0.7420 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00148\n",
            "Train: loss: 0.5930 | accuracy: 0.6956 | f-acore: 0.6886\n",
            "Test:  loss: 0.8175 | accuracy: 0.5425 | f1: 0.4370\n",
            "Validation:  loss: 0.7541 | accuracy: 0.5714 | f1: 0.5333\n",
            "Epoch 00149\n",
            "Train: loss: 0.5781 | accuracy: 0.7070 | f-acore: 0.7014\n",
            "Test:  loss: 0.8083 | accuracy: 0.5452 | f1: 0.4353\n",
            "Validation:  loss: 0.7460 | accuracy: 0.5595 | f1: 0.4999\n",
            "Epoch 00150\n",
            "Train: loss: 0.5968 | accuracy: 0.6956 | f-acore: 0.6869\n",
            "Test:  loss: 0.7859 | accuracy: 0.5452 | f1: 0.4420\n",
            "Validation:  loss: 0.7374 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00151\n",
            "Train: loss: 0.5731 | accuracy: 0.6942 | f-acore: 0.6895\n",
            "Test:  loss: 0.6966 | accuracy: 0.5370 | f1: 0.4850\n",
            "Validation:  loss: 0.7110 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00152\n",
            "Train: loss: 0.5754 | accuracy: 0.7006 | f-acore: 0.6934\n",
            "Test:  loss: 0.7597 | accuracy: 0.5507 | f1: 0.4421\n",
            "Validation:  loss: 0.7338 | accuracy: 0.5357 | f1: 0.4906\n",
            "Epoch 00153\n",
            "Train: loss: 0.5762 | accuracy: 0.7020 | f-acore: 0.6974\n",
            "Test:  loss: 0.8278 | accuracy: 0.5589 | f1: 0.4129\n",
            "Validation:  loss: 0.7668 | accuracy: 0.5000 | f1: 0.3713\n",
            "Epoch 00154\n",
            "Train: loss: 0.5801 | accuracy: 0.6901 | f-acore: 0.6862\n",
            "Test:  loss: 0.7974 | accuracy: 0.5589 | f1: 0.4540\n",
            "Validation:  loss: 0.7401 | accuracy: 0.5357 | f1: 0.4906\n",
            "Epoch 00155\n",
            "Train: loss: 0.5858 | accuracy: 0.6997 | f-acore: 0.6950\n",
            "Test:  loss: 0.7595 | accuracy: 0.5507 | f1: 0.4795\n",
            "Validation:  loss: 0.7266 | accuracy: 0.5595 | f1: 0.5358\n",
            "Epoch 00156\n",
            "Train: loss: 0.5609 | accuracy: 0.7047 | f-acore: 0.7017\n",
            "Test:  loss: 0.7994 | accuracy: 0.5452 | f1: 0.4513\n",
            "Validation:  loss: 0.7399 | accuracy: 0.5714 | f1: 0.5457\n",
            "Epoch 00157\n",
            "Train: loss: 0.5583 | accuracy: 0.7130 | f-acore: 0.7083\n",
            "Test:  loss: 0.9047 | accuracy: 0.5616 | f1: 0.4101\n",
            "Validation:  loss: 0.7868 | accuracy: 0.5357 | f1: 0.4510\n",
            "Epoch 00158\n",
            "Train: loss: 0.5440 | accuracy: 0.7111 | f-acore: 0.7030\n",
            "Test:  loss: 0.8246 | accuracy: 0.5315 | f1: 0.4423\n",
            "Validation:  loss: 0.7457 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00159\n",
            "Train: loss: 0.5630 | accuracy: 0.7047 | f-acore: 0.6988\n",
            "Test:  loss: 0.8208 | accuracy: 0.5315 | f1: 0.4300\n",
            "Validation:  loss: 0.7504 | accuracy: 0.5238 | f1: 0.4643\n",
            "Epoch 00160\n",
            "Train: loss: 0.5809 | accuracy: 0.7020 | f-acore: 0.6969\n",
            "Test:  loss: 0.8273 | accuracy: 0.5479 | f1: 0.4404\n",
            "Validation:  loss: 0.7514 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00161\n",
            "Train: loss: 0.5685 | accuracy: 0.7084 | f-acore: 0.7035\n",
            "Test:  loss: 0.8443 | accuracy: 0.5644 | f1: 0.4400\n",
            "Validation:  loss: 0.7673 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00162\n",
            "Train: loss: 0.5584 | accuracy: 0.7084 | f-acore: 0.7016\n",
            "Test:  loss: 0.8153 | accuracy: 0.5479 | f1: 0.4500\n",
            "Validation:  loss: 0.7588 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00163\n",
            "Train: loss: 0.5758 | accuracy: 0.7070 | f-acore: 0.6973\n",
            "Test:  loss: 0.8420 | accuracy: 0.5397 | f1: 0.4352\n",
            "Validation:  loss: 0.7708 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00164\n",
            "Train: loss: 0.5754 | accuracy: 0.7061 | f-acore: 0.7016\n",
            "Test:  loss: 0.8659 | accuracy: 0.5479 | f1: 0.4301\n",
            "Validation:  loss: 0.7905 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00165\n",
            "Train: loss: 0.5580 | accuracy: 0.7066 | f-acore: 0.7033\n",
            "Test:  loss: 0.7840 | accuracy: 0.5068 | f1: 0.4642\n",
            "Validation:  loss: 0.7510 | accuracy: 0.5833 | f1: 0.5655\n",
            "Epoch 00166\n",
            "Train: loss: 0.5548 | accuracy: 0.7033 | f-acore: 0.6963\n",
            "Test:  loss: 0.8616 | accuracy: 0.5534 | f1: 0.4297\n",
            "Validation:  loss: 0.7915 | accuracy: 0.5714 | f1: 0.5260\n",
            "Epoch 00167\n",
            "Train: loss: 0.5590 | accuracy: 0.7148 | f-acore: 0.7115\n",
            "Test:  loss: 0.8456 | accuracy: 0.5425 | f1: 0.4232\n",
            "Validation:  loss: 0.7837 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00168\n",
            "Train: loss: 0.5546 | accuracy: 0.7121 | f-acore: 0.7062\n",
            "Test:  loss: 0.8297 | accuracy: 0.5671 | f1: 0.4454\n",
            "Validation:  loss: 0.7755 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00169\n",
            "Train: loss: 0.5743 | accuracy: 0.7125 | f-acore: 0.7054\n",
            "Test:  loss: 0.8713 | accuracy: 0.5507 | f1: 0.3551\n",
            "Validation:  loss: 0.8031 | accuracy: 0.5119 | f1: 0.3593\n",
            "Epoch 00170\n",
            "Train: loss: 0.5891 | accuracy: 0.7033 | f-acore: 0.6953\n",
            "Test:  loss: 0.7963 | accuracy: 0.5452 | f1: 0.4095\n",
            "Validation:  loss: 0.7685 | accuracy: 0.5238 | f1: 0.4643\n",
            "Epoch 00171\n",
            "Train: loss: 0.5630 | accuracy: 0.7098 | f-acore: 0.7033\n",
            "Test:  loss: 0.8688 | accuracy: 0.5507 | f1: 0.4084\n",
            "Validation:  loss: 0.7766 | accuracy: 0.5357 | f1: 0.4510\n",
            "Epoch 00172\n",
            "Train: loss: 0.5893 | accuracy: 0.7075 | f-acore: 0.6992\n",
            "Test:  loss: 0.8817 | accuracy: 0.5479 | f1: 0.4150\n",
            "Validation:  loss: 0.7844 | accuracy: 0.5595 | f1: 0.4999\n",
            "Epoch 00173\n",
            "Train: loss: 0.5897 | accuracy: 0.7043 | f-acore: 0.7020\n",
            "Test:  loss: 0.7975 | accuracy: 0.5205 | f1: 0.4976\n",
            "Validation:  loss: 0.7339 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00174\n",
            "Train: loss: 0.5803 | accuracy: 0.6969 | f-acore: 0.6943\n",
            "Test:  loss: 0.8049 | accuracy: 0.5096 | f1: 0.4479\n",
            "Validation:  loss: 0.7360 | accuracy: 0.5476 | f1: 0.5204\n",
            "Epoch 00175\n",
            "Train: loss: 0.5579 | accuracy: 0.7194 | f-acore: 0.7159\n",
            "Test:  loss: 0.8790 | accuracy: 0.5644 | f1: 0.4473\n",
            "Validation:  loss: 0.7818 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00176\n",
            "Train: loss: 0.5703 | accuracy: 0.7075 | f-acore: 0.7004\n",
            "Test:  loss: 0.8341 | accuracy: 0.5397 | f1: 0.4506\n",
            "Validation:  loss: 0.7576 | accuracy: 0.5476 | f1: 0.4997\n",
            "Epoch 00177\n",
            "Train: loss: 0.5618 | accuracy: 0.7116 | f-acore: 0.7065\n",
            "Test:  loss: 0.8511 | accuracy: 0.5397 | f1: 0.4352\n",
            "Validation:  loss: 0.7783 | accuracy: 0.5000 | f1: 0.4375\n",
            "Epoch 00178\n",
            "Train: loss: 0.5756 | accuracy: 0.7203 | f-acore: 0.7152\n",
            "Test:  loss: 0.8261 | accuracy: 0.5205 | f1: 0.4533\n",
            "Validation:  loss: 0.7635 | accuracy: 0.5238 | f1: 0.4887\n",
            "Epoch 00179\n",
            "Train: loss: 0.5723 | accuracy: 0.7070 | f-acore: 0.7020\n",
            "Test:  loss: 0.9619 | accuracy: 0.5534 | f1: 0.4057\n",
            "Validation:  loss: 0.8332 | accuracy: 0.5357 | f1: 0.4510\n",
            "Epoch 00180\n",
            "Train: loss: 0.5586 | accuracy: 0.7267 | f-acore: 0.7221\n",
            "Test:  loss: 0.8906 | accuracy: 0.5315 | f1: 0.4235\n",
            "Validation:  loss: 0.7965 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00181\n",
            "Train: loss: 0.5806 | accuracy: 0.7107 | f-acore: 0.7074\n",
            "Test:  loss: 0.8427 | accuracy: 0.5397 | f1: 0.4590\n",
            "Validation:  loss: 0.7758 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00182\n",
            "Train: loss: 0.5678 | accuracy: 0.7056 | f-acore: 0.7033\n",
            "Test:  loss: 0.7811 | accuracy: 0.5068 | f1: 0.4839\n",
            "Validation:  loss: 0.7467 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00183\n",
            "Train: loss: 0.5479 | accuracy: 0.7162 | f-acore: 0.7130\n",
            "Test:  loss: 0.8651 | accuracy: 0.5342 | f1: 0.4498\n",
            "Validation:  loss: 0.7697 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00184\n",
            "Train: loss: 0.5553 | accuracy: 0.7134 | f-acore: 0.7066\n",
            "Test:  loss: 0.8223 | accuracy: 0.5041 | f1: 0.4621\n",
            "Validation:  loss: 0.7526 | accuracy: 0.5595 | f1: 0.5302\n",
            "Epoch 00185\n",
            "Train: loss: 0.5544 | accuracy: 0.7088 | f-acore: 0.7036\n",
            "Test:  loss: 0.8506 | accuracy: 0.5479 | f1: 0.4500\n",
            "Validation:  loss: 0.7734 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00186\n",
            "Train: loss: 0.5652 | accuracy: 0.7162 | f-acore: 0.7064\n",
            "Test:  loss: 0.9025 | accuracy: 0.5397 | f1: 0.4103\n",
            "Validation:  loss: 0.8015 | accuracy: 0.4881 | f1: 0.3947\n",
            "Epoch 00187\n",
            "Train: loss: 0.5389 | accuracy: 0.7254 | f-acore: 0.7193\n",
            "Test:  loss: 0.8877 | accuracy: 0.5616 | f1: 0.4384\n",
            "Validation:  loss: 0.7826 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00188\n",
            "Train: loss: 0.5623 | accuracy: 0.7033 | f-acore: 0.6968\n",
            "Test:  loss: 0.8848 | accuracy: 0.5288 | f1: 0.4345\n",
            "Validation:  loss: 0.7788 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00189\n",
            "Train: loss: 0.5458 | accuracy: 0.7244 | f-acore: 0.7170\n",
            "Test:  loss: 0.9064 | accuracy: 0.5425 | f1: 0.4402\n",
            "Validation:  loss: 0.7911 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00190\n",
            "Train: loss: 0.5459 | accuracy: 0.7166 | f-acore: 0.7109\n",
            "Test:  loss: 0.8360 | accuracy: 0.5425 | f1: 0.4553\n",
            "Validation:  loss: 0.7713 | accuracy: 0.5476 | f1: 0.5306\n",
            "Epoch 00191\n",
            "Train: loss: 0.5568 | accuracy: 0.6974 | f-acore: 0.6934\n",
            "Test:  loss: 0.8133 | accuracy: 0.5370 | f1: 0.4516\n",
            "Validation:  loss: 0.7601 | accuracy: 0.4881 | f1: 0.4188\n",
            "Epoch 00192\n",
            "Train: loss: 0.5593 | accuracy: 0.7217 | f-acore: 0.7117\n",
            "Test:  loss: 0.9628 | accuracy: 0.5397 | f1: 0.4064\n",
            "Validation:  loss: 0.8315 | accuracy: 0.5000 | f1: 0.3875\n",
            "Epoch 00193\n",
            "Train: loss: 0.5378 | accuracy: 0.7111 | f-acore: 0.7063\n",
            "Test:  loss: 0.9592 | accuracy: 0.5479 | f1: 0.4110\n",
            "Validation:  loss: 0.8248 | accuracy: 0.5000 | f1: 0.3875\n",
            "Epoch 00194\n",
            "Train: loss: 0.5469 | accuracy: 0.7203 | f-acore: 0.7130\n",
            "Test:  loss: 0.9533 | accuracy: 0.5342 | f1: 0.4146\n",
            "Validation:  loss: 0.8207 | accuracy: 0.4762 | f1: 0.3736\n",
            "Epoch 00195\n",
            "Train: loss: 0.5648 | accuracy: 0.7276 | f-acore: 0.7232\n",
            "Test:  loss: 0.9287 | accuracy: 0.5507 | f1: 0.4281\n",
            "Validation:  loss: 0.8261 | accuracy: 0.5119 | f1: 0.4349\n",
            "Epoch 00196\n",
            "Train: loss: 0.5641 | accuracy: 0.7208 | f-acore: 0.7145\n",
            "Test:  loss: 0.8910 | accuracy: 0.5452 | f1: 0.4211\n",
            "Validation:  loss: 0.8109 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00197\n",
            "Train: loss: 0.5497 | accuracy: 0.7116 | f-acore: 0.7084\n",
            "Test:  loss: 0.9166 | accuracy: 0.5479 | f1: 0.4264\n",
            "Validation:  loss: 0.8293 | accuracy: 0.4881 | f1: 0.3947\n",
            "Epoch 00198\n",
            "Train: loss: 0.5464 | accuracy: 0.7144 | f-acore: 0.7097\n",
            "Test:  loss: 0.8823 | accuracy: 0.5370 | f1: 0.4302\n",
            "Validation:  loss: 0.7965 | accuracy: 0.5476 | f1: 0.4997\n",
            "Epoch 00199\n",
            "Train: loss: 0.5437 | accuracy: 0.7226 | f-acore: 0.7182\n",
            "Test:  loss: 0.8935 | accuracy: 0.5425 | f1: 0.4302\n",
            "Validation:  loss: 0.7998 | accuracy: 0.5238 | f1: 0.4643\n",
            "Epoch 00200\n",
            "Train: loss: 0.5565 | accuracy: 0.7116 | f-acore: 0.7026\n",
            "Test:  loss: 0.8577 | accuracy: 0.5342 | f1: 0.4441\n",
            "Validation:  loss: 0.7730 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00201\n",
            "Train: loss: 0.5576 | accuracy: 0.7212 | f-acore: 0.7171\n",
            "Test:  loss: 0.8968 | accuracy: 0.5205 | f1: 0.4406\n",
            "Validation:  loss: 0.7986 | accuracy: 0.5595 | f1: 0.5167\n",
            "Epoch 00202\n",
            "Train: loss: 0.5332 | accuracy: 0.7286 | f-acore: 0.7255\n",
            "Test:  loss: 0.8644 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.7893 | accuracy: 0.5595 | f1: 0.5302\n",
            "Epoch 00203\n",
            "Train: loss: 0.5492 | accuracy: 0.7024 | f-acore: 0.6985\n",
            "Test:  loss: 0.9076 | accuracy: 0.5041 | f1: 0.4186\n",
            "Validation:  loss: 0.8008 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00204\n",
            "Train: loss: 0.5910 | accuracy: 0.7144 | f-acore: 0.7096\n",
            "Test:  loss: 0.8794 | accuracy: 0.5260 | f1: 0.4357\n",
            "Validation:  loss: 0.7881 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00205\n",
            "Train: loss: 0.5384 | accuracy: 0.7235 | f-acore: 0.7141\n",
            "Test:  loss: 0.9903 | accuracy: 0.5534 | f1: 0.4141\n",
            "Validation:  loss: 0.8430 | accuracy: 0.5476 | f1: 0.4312\n",
            "Epoch 00206\n",
            "Train: loss: 0.5484 | accuracy: 0.7203 | f-acore: 0.7166\n",
            "Test:  loss: 0.8744 | accuracy: 0.5233 | f1: 0.4340\n",
            "Validation:  loss: 0.7986 | accuracy: 0.5476 | f1: 0.5074\n",
            "Epoch 00207\n",
            "Train: loss: 0.5574 | accuracy: 0.7313 | f-acore: 0.7260\n",
            "Test:  loss: 0.8694 | accuracy: 0.5342 | f1: 0.4285\n",
            "Validation:  loss: 0.7953 | accuracy: 0.5238 | f1: 0.4734\n",
            "Epoch 00208\n",
            "Train: loss: 0.5361 | accuracy: 0.7185 | f-acore: 0.7158\n",
            "Test:  loss: 0.9498 | accuracy: 0.5288 | f1: 0.4149\n",
            "Validation:  loss: 0.8403 | accuracy: 0.4881 | f1: 0.3806\n",
            "Epoch 00209\n",
            "Train: loss: 0.5351 | accuracy: 0.7364 | f-acore: 0.7296\n",
            "Test:  loss: 0.9203 | accuracy: 0.5151 | f1: 0.4227\n",
            "Validation:  loss: 0.8217 | accuracy: 0.5833 | f1: 0.5428\n",
            "Epoch 00210\n",
            "Train: loss: 0.5438 | accuracy: 0.7327 | f-acore: 0.7255\n",
            "Test:  loss: 0.8907 | accuracy: 0.5205 | f1: 0.4433\n",
            "Validation:  loss: 0.7945 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00211\n",
            "Train: loss: 0.5408 | accuracy: 0.7299 | f-acore: 0.7254\n",
            "Test:  loss: 0.9734 | accuracy: 0.5233 | f1: 0.4116\n",
            "Validation:  loss: 0.8303 | accuracy: 0.5476 | f1: 0.4708\n",
            "Epoch 00212\n",
            "Train: loss: 0.5566 | accuracy: 0.7377 | f-acore: 0.7345\n",
            "Test:  loss: 0.8802 | accuracy: 0.5370 | f1: 0.4743\n",
            "Validation:  loss: 0.8004 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00213\n",
            "Train: loss: 0.5710 | accuracy: 0.7309 | f-acore: 0.7258\n",
            "Test:  loss: 0.9120 | accuracy: 0.5178 | f1: 0.4414\n",
            "Validation:  loss: 0.8019 | accuracy: 0.5238 | f1: 0.4734\n",
            "Epoch 00214\n",
            "Train: loss: 0.5563 | accuracy: 0.7199 | f-acore: 0.7179\n",
            "Test:  loss: 0.8308 | accuracy: 0.5096 | f1: 0.4763\n",
            "Validation:  loss: 0.7741 | accuracy: 0.4762 | f1: 0.4612\n",
            "Epoch 00215\n",
            "Train: loss: 0.5415 | accuracy: 0.7322 | f-acore: 0.7266\n",
            "Test:  loss: 0.8154 | accuracy: 0.5068 | f1: 0.4482\n",
            "Validation:  loss: 0.7553 | accuracy: 0.5119 | f1: 0.4958\n",
            "Epoch 00216\n",
            "Train: loss: 0.5282 | accuracy: 0.7364 | f-acore: 0.7331\n",
            "Test:  loss: 0.8949 | accuracy: 0.5068 | f1: 0.4437\n",
            "Validation:  loss: 0.7769 | accuracy: 0.5476 | f1: 0.5074\n",
            "Epoch 00217\n",
            "Train: loss: 0.5196 | accuracy: 0.7286 | f-acore: 0.7234\n",
            "Test:  loss: 0.8744 | accuracy: 0.5288 | f1: 0.4615\n",
            "Validation:  loss: 0.7717 | accuracy: 0.5357 | f1: 0.4906\n",
            "Epoch 00218\n",
            "Train: loss: 0.5263 | accuracy: 0.7345 | f-acore: 0.7299\n",
            "Test:  loss: 0.8882 | accuracy: 0.5260 | f1: 0.4328\n",
            "Validation:  loss: 0.7786 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00219\n",
            "Train: loss: 0.5301 | accuracy: 0.7249 | f-acore: 0.7218\n",
            "Test:  loss: 0.9200 | accuracy: 0.5205 | f1: 0.4262\n",
            "Validation:  loss: 0.8101 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00220\n",
            "Train: loss: 0.5368 | accuracy: 0.7304 | f-acore: 0.7239\n",
            "Test:  loss: 0.9318 | accuracy: 0.5068 | f1: 0.4260\n",
            "Validation:  loss: 0.7983 | accuracy: 0.5714 | f1: 0.5260\n",
            "Epoch 00221\n",
            "Train: loss: 0.5252 | accuracy: 0.7345 | f-acore: 0.7311\n",
            "Test:  loss: 1.0487 | accuracy: 0.5479 | f1: 0.3847\n",
            "Validation:  loss: 0.8630 | accuracy: 0.5238 | f1: 0.4167\n",
            "Epoch 00222\n",
            "Train: loss: 0.5171 | accuracy: 0.7203 | f-acore: 0.7140\n",
            "Test:  loss: 0.9940 | accuracy: 0.5397 | f1: 0.4023\n",
            "Validation:  loss: 0.8448 | accuracy: 0.5119 | f1: 0.4228\n",
            "Epoch 00223\n",
            "Train: loss: 0.5222 | accuracy: 0.7331 | f-acore: 0.7287\n",
            "Test:  loss: 0.9884 | accuracy: 0.5370 | f1: 0.4199\n",
            "Validation:  loss: 0.8407 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00224\n",
            "Train: loss: 0.5229 | accuracy: 0.7350 | f-acore: 0.7315\n",
            "Test:  loss: 0.9641 | accuracy: 0.5370 | f1: 0.4269\n",
            "Validation:  loss: 0.8264 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00225\n",
            "Train: loss: 0.5114 | accuracy: 0.7350 | f-acore: 0.7299\n",
            "Test:  loss: 0.8976 | accuracy: 0.5233 | f1: 0.4368\n",
            "Validation:  loss: 0.8003 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00226\n",
            "Train: loss: 0.5144 | accuracy: 0.7387 | f-acore: 0.7349\n",
            "Test:  loss: 0.9192 | accuracy: 0.5205 | f1: 0.4459\n",
            "Validation:  loss: 0.7989 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00227\n",
            "Train: loss: 0.5275 | accuracy: 0.7304 | f-acore: 0.7257\n",
            "Test:  loss: 0.9200 | accuracy: 0.5288 | f1: 0.4541\n",
            "Validation:  loss: 0.8020 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00228\n",
            "Train: loss: 0.5245 | accuracy: 0.7350 | f-acore: 0.7308\n",
            "Test:  loss: 0.9516 | accuracy: 0.5288 | f1: 0.4345\n",
            "Validation:  loss: 0.8223 | accuracy: 0.5357 | f1: 0.4729\n",
            "Epoch 00229\n",
            "Train: loss: 0.5234 | accuracy: 0.7387 | f-acore: 0.7348\n",
            "Test:  loss: 0.9388 | accuracy: 0.5479 | f1: 0.4370\n",
            "Validation:  loss: 0.8155 | accuracy: 0.5238 | f1: 0.4643\n",
            "Epoch 00230\n",
            "Train: loss: 0.5221 | accuracy: 0.7235 | f-acore: 0.7161\n",
            "Test:  loss: 1.0296 | accuracy: 0.5452 | f1: 0.4248\n",
            "Validation:  loss: 0.8472 | accuracy: 0.5476 | f1: 0.4815\n",
            "Epoch 00231\n",
            "Train: loss: 0.5103 | accuracy: 0.7487 | f-acore: 0.7435\n",
            "Test:  loss: 0.9740 | accuracy: 0.5425 | f1: 0.4495\n",
            "Validation:  loss: 0.8346 | accuracy: 0.5833 | f1: 0.5556\n",
            "Epoch 00232\n",
            "Train: loss: 0.5293 | accuracy: 0.7299 | f-acore: 0.7262\n",
            "Test:  loss: 0.9154 | accuracy: 0.5507 | f1: 0.4637\n",
            "Validation:  loss: 0.8305 | accuracy: 0.5714 | f1: 0.5399\n",
            "Epoch 00233\n",
            "Train: loss: 0.5209 | accuracy: 0.7506 | f-acore: 0.7451\n",
            "Test:  loss: 0.9580 | accuracy: 0.5507 | f1: 0.4243\n",
            "Validation:  loss: 0.8578 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00234\n",
            "Train: loss: 0.5183 | accuracy: 0.7409 | f-acore: 0.7375\n",
            "Test:  loss: 0.9048 | accuracy: 0.5425 | f1: 0.4609\n",
            "Validation:  loss: 0.8251 | accuracy: 0.5595 | f1: 0.5088\n",
            "Epoch 00235\n",
            "Train: loss: 0.5133 | accuracy: 0.7354 | f-acore: 0.7312\n",
            "Test:  loss: 0.9828 | accuracy: 0.5342 | f1: 0.4182\n",
            "Validation:  loss: 0.8539 | accuracy: 0.5357 | f1: 0.4625\n",
            "Epoch 00236\n",
            "Train: loss: 0.5173 | accuracy: 0.7364 | f-acore: 0.7315\n",
            "Test:  loss: 0.9320 | accuracy: 0.5534 | f1: 0.4597\n",
            "Validation:  loss: 0.8304 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00237\n",
            "Train: loss: 0.5164 | accuracy: 0.7396 | f-acore: 0.7357\n",
            "Test:  loss: 1.0383 | accuracy: 0.5479 | f1: 0.4027\n",
            "Validation:  loss: 0.8895 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00238\n",
            "Train: loss: 0.5173 | accuracy: 0.7345 | f-acore: 0.7285\n",
            "Test:  loss: 1.0600 | accuracy: 0.5452 | f1: 0.4012\n",
            "Validation:  loss: 0.8671 | accuracy: 0.5357 | f1: 0.4239\n",
            "Epoch 00239\n",
            "Train: loss: 0.5222 | accuracy: 0.7432 | f-acore: 0.7399\n",
            "Test:  loss: 0.9909 | accuracy: 0.5096 | f1: 0.4383\n",
            "Validation:  loss: 0.8325 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00240\n",
            "Train: loss: 0.5128 | accuracy: 0.7382 | f-acore: 0.7340\n",
            "Test:  loss: 1.0228 | accuracy: 0.5425 | f1: 0.4370\n",
            "Validation:  loss: 0.8663 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00241\n",
            "Train: loss: 0.5008 | accuracy: 0.7400 | f-acore: 0.7352\n",
            "Test:  loss: 1.0338 | accuracy: 0.5397 | f1: 0.4023\n",
            "Validation:  loss: 0.8644 | accuracy: 0.5119 | f1: 0.3944\n",
            "Epoch 00242\n",
            "Train: loss: 0.5294 | accuracy: 0.7446 | f-acore: 0.7391\n",
            "Test:  loss: 0.9321 | accuracy: 0.5397 | f1: 0.4535\n",
            "Validation:  loss: 0.8276 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00243\n",
            "Train: loss: 0.5384 | accuracy: 0.7409 | f-acore: 0.7387\n",
            "Test:  loss: 0.8507 | accuracy: 0.4959 | f1: 0.4761\n",
            "Validation:  loss: 0.7822 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00244\n",
            "Train: loss: 0.5416 | accuracy: 0.7382 | f-acore: 0.7344\n",
            "Test:  loss: 0.9624 | accuracy: 0.5342 | f1: 0.4252\n",
            "Validation:  loss: 0.8275 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00245\n",
            "Train: loss: 0.5228 | accuracy: 0.7267 | f-acore: 0.7237\n",
            "Test:  loss: 0.9915 | accuracy: 0.5370 | f1: 0.4429\n",
            "Validation:  loss: 0.8562 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00246\n",
            "Train: loss: 0.5165 | accuracy: 0.7423 | f-acore: 0.7372\n",
            "Test:  loss: 0.9588 | accuracy: 0.5178 | f1: 0.4414\n",
            "Validation:  loss: 0.8353 | accuracy: 0.5119 | f1: 0.4557\n",
            "Epoch 00247\n",
            "Train: loss: 0.5071 | accuracy: 0.7419 | f-acore: 0.7386\n",
            "Test:  loss: 1.0634 | accuracy: 0.5397 | f1: 0.4141\n",
            "Validation:  loss: 0.8779 | accuracy: 0.5238 | f1: 0.4167\n",
            "Epoch 00248\n",
            "Train: loss: 0.5018 | accuracy: 0.7377 | f-acore: 0.7339\n",
            "Test:  loss: 0.9664 | accuracy: 0.5151 | f1: 0.4369\n",
            "Validation:  loss: 0.8400 | accuracy: 0.5238 | f1: 0.4643\n",
            "Epoch 00249\n",
            "Train: loss: 0.4959 | accuracy: 0.7492 | f-acore: 0.7454\n",
            "Test:  loss: 1.0810 | accuracy: 0.5425 | f1: 0.3911\n",
            "Validation:  loss: 0.9094 | accuracy: 0.5119 | f1: 0.4094\n",
            "Epoch 00250\n",
            "Train: loss: 0.5162 | accuracy: 0.7400 | f-acore: 0.7360\n",
            "Test:  loss: 0.9126 | accuracy: 0.5260 | f1: 0.4547\n",
            "Validation:  loss: 0.8248 | accuracy: 0.5000 | f1: 0.4375\n",
            "Epoch 00251\n",
            "Train: loss: 0.5120 | accuracy: 0.7497 | f-acore: 0.7473\n",
            "Test:  loss: 1.1375 | accuracy: 0.5507 | f1: 0.4042\n",
            "Validation:  loss: 0.9331 | accuracy: 0.5000 | f1: 0.3713\n",
            "Epoch 00252\n",
            "Train: loss: 0.5170 | accuracy: 0.7501 | f-acore: 0.7454\n",
            "Test:  loss: 1.0652 | accuracy: 0.5397 | f1: 0.4215\n",
            "Validation:  loss: 0.9147 | accuracy: 0.5119 | f1: 0.4349\n",
            "Epoch 00253\n",
            "Train: loss: 0.5183 | accuracy: 0.7364 | f-acore: 0.7331\n",
            "Test:  loss: 0.9652 | accuracy: 0.5151 | f1: 0.4421\n",
            "Validation:  loss: 0.8549 | accuracy: 0.5476 | f1: 0.5143\n",
            "Epoch 00254\n",
            "Train: loss: 0.5053 | accuracy: 0.7501 | f-acore: 0.7467\n",
            "Test:  loss: 0.8402 | accuracy: 0.4712 | f1: 0.4555\n",
            "Validation:  loss: 0.8116 | accuracy: 0.4643 | f1: 0.4605\n",
            "Epoch 00255\n",
            "Train: loss: 0.5246 | accuracy: 0.7391 | f-acore: 0.7353\n",
            "Test:  loss: 0.9592 | accuracy: 0.5370 | f1: 0.4598\n",
            "Validation:  loss: 0.8540 | accuracy: 0.4881 | f1: 0.4188\n",
            "Epoch 00256\n",
            "Train: loss: 0.5164 | accuracy: 0.7451 | f-acore: 0.7418\n",
            "Test:  loss: 0.9675 | accuracy: 0.5397 | f1: 0.4385\n",
            "Validation:  loss: 0.8680 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00257\n",
            "Train: loss: 0.4982 | accuracy: 0.7515 | f-acore: 0.7479\n",
            "Test:  loss: 1.0415 | accuracy: 0.5260 | f1: 0.4098\n",
            "Validation:  loss: 0.8993 | accuracy: 0.5357 | f1: 0.4382\n",
            "Epoch 00258\n",
            "Train: loss: 0.4948 | accuracy: 0.7437 | f-acore: 0.7390\n",
            "Test:  loss: 0.9953 | accuracy: 0.5151 | f1: 0.4421\n",
            "Validation:  loss: 0.8680 | accuracy: 0.5000 | f1: 0.4470\n",
            "Epoch 00259\n",
            "Train: loss: 0.5054 | accuracy: 0.7474 | f-acore: 0.7444\n",
            "Test:  loss: 1.1126 | accuracy: 0.5397 | f1: 0.4179\n",
            "Validation:  loss: 0.9284 | accuracy: 0.5119 | f1: 0.4228\n",
            "Epoch 00260\n",
            "Train: loss: 0.5029 | accuracy: 0.7552 | f-acore: 0.7500\n",
            "Test:  loss: 1.0661 | accuracy: 0.5342 | f1: 0.4217\n",
            "Validation:  loss: 0.9078 | accuracy: 0.5000 | f1: 0.3875\n",
            "Epoch 00261\n",
            "Train: loss: 0.5390 | accuracy: 0.7423 | f-acore: 0.7406\n",
            "Test:  loss: 1.0645 | accuracy: 0.5233 | f1: 0.4217\n",
            "Validation:  loss: 0.8827 | accuracy: 0.5476 | f1: 0.4911\n",
            "Epoch 00262\n",
            "Train: loss: 0.5188 | accuracy: 0.7382 | f-acore: 0.7314\n",
            "Test:  loss: 0.9886 | accuracy: 0.5178 | f1: 0.4465\n",
            "Validation:  loss: 0.8630 | accuracy: 0.5119 | f1: 0.4645\n",
            "Epoch 00263\n",
            "Train: loss: 0.5065 | accuracy: 0.7455 | f-acore: 0.7435\n",
            "Test:  loss: 0.9480 | accuracy: 0.5205 | f1: 0.4849\n",
            "Validation:  loss: 0.8386 | accuracy: 0.5238 | f1: 0.5059\n",
            "Epoch 00264\n",
            "Train: loss: 0.5098 | accuracy: 0.7409 | f-acore: 0.7365\n",
            "Test:  loss: 0.9564 | accuracy: 0.5178 | f1: 0.4583\n",
            "Validation:  loss: 0.8555 | accuracy: 0.4881 | f1: 0.4383\n",
            "Epoch 00265\n",
            "Train: loss: 0.5070 | accuracy: 0.7474 | f-acore: 0.7438\n",
            "Test:  loss: 1.0507 | accuracy: 0.5205 | f1: 0.4509\n",
            "Validation:  loss: 0.8957 | accuracy: 0.4762 | f1: 0.4207\n",
            "Epoch 00266\n",
            "Train: loss: 0.5503 | accuracy: 0.7432 | f-acore: 0.7379\n",
            "Test:  loss: 1.0021 | accuracy: 0.5123 | f1: 0.4736\n",
            "Validation:  loss: 0.8483 | accuracy: 0.4643 | f1: 0.4414\n",
            "Epoch 00267\n",
            "Train: loss: 0.5132 | accuracy: 0.7295 | f-acore: 0.7285\n",
            "Test:  loss: 0.9698 | accuracy: 0.5151 | f1: 0.4133\n",
            "Validation:  loss: 0.8611 | accuracy: 0.5000 | f1: 0.3534\n",
            "Epoch 00268\n",
            "Train: loss: 0.5083 | accuracy: 0.7400 | f-acore: 0.7339\n",
            "Test:  loss: 1.0078 | accuracy: 0.5315 | f1: 0.4507\n",
            "Validation:  loss: 0.8693 | accuracy: 0.5000 | f1: 0.4470\n",
            "Epoch 00269\n",
            "Train: loss: 0.4924 | accuracy: 0.7519 | f-acore: 0.7488\n",
            "Test:  loss: 1.0971 | accuracy: 0.5288 | f1: 0.4218\n",
            "Validation:  loss: 0.9174 | accuracy: 0.5357 | f1: 0.4625\n",
            "Epoch 00270\n",
            "Train: loss: 0.5055 | accuracy: 0.7451 | f-acore: 0.7401\n",
            "Test:  loss: 0.9752 | accuracy: 0.4932 | f1: 0.4384\n",
            "Validation:  loss: 0.8557 | accuracy: 0.4762 | f1: 0.4565\n",
            "Epoch 00271\n",
            "Train: loss: 0.4902 | accuracy: 0.7561 | f-acore: 0.7521\n",
            "Test:  loss: 1.1688 | accuracy: 0.5397 | f1: 0.4179\n",
            "Validation:  loss: 0.9403 | accuracy: 0.5119 | f1: 0.3944\n",
            "Epoch 00272\n",
            "Train: loss: 0.5200 | accuracy: 0.7368 | f-acore: 0.7332\n",
            "Test:  loss: 0.9802 | accuracy: 0.5178 | f1: 0.4465\n",
            "Validation:  loss: 0.8592 | accuracy: 0.5000 | f1: 0.4470\n",
            "Epoch 00273\n",
            "Train: loss: 0.5198 | accuracy: 0.7423 | f-acore: 0.7385\n",
            "Test:  loss: 1.0967 | accuracy: 0.5288 | f1: 0.4283\n",
            "Validation:  loss: 0.9200 | accuracy: 0.5119 | f1: 0.3778\n",
            "Epoch 00274\n",
            "Train: loss: 0.5066 | accuracy: 0.7405 | f-acore: 0.7352\n",
            "Test:  loss: 1.1317 | accuracy: 0.5370 | f1: 0.4125\n",
            "Validation:  loss: 0.9436 | accuracy: 0.5238 | f1: 0.4013\n",
            "Epoch 00275\n",
            "Train: loss: 0.4950 | accuracy: 0.7409 | f-acore: 0.7384\n",
            "Test:  loss: 1.1065 | accuracy: 0.5151 | f1: 0.4100\n",
            "Validation:  loss: 0.9218 | accuracy: 0.5119 | f1: 0.4349\n",
            "Epoch 00276\n",
            "Train: loss: 0.5087 | accuracy: 0.7478 | f-acore: 0.7431\n",
            "Test:  loss: 1.0582 | accuracy: 0.5315 | f1: 0.4393\n",
            "Validation:  loss: 0.8997 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00277\n",
            "Train: loss: 0.5045 | accuracy: 0.7469 | f-acore: 0.7440\n",
            "Test:  loss: 0.9480 | accuracy: 0.5123 | f1: 0.4543\n",
            "Validation:  loss: 0.8413 | accuracy: 0.4881 | f1: 0.4383\n",
            "Epoch 00278\n",
            "Train: loss: 0.5016 | accuracy: 0.7570 | f-acore: 0.7528\n",
            "Test:  loss: 1.1032 | accuracy: 0.5315 | f1: 0.4235\n",
            "Validation:  loss: 0.9165 | accuracy: 0.5238 | f1: 0.4305\n",
            "Epoch 00279\n",
            "Train: loss: 0.4945 | accuracy: 0.7570 | f-acore: 0.7523\n",
            "Test:  loss: 1.0011 | accuracy: 0.5178 | f1: 0.4465\n",
            "Validation:  loss: 0.8741 | accuracy: 0.4762 | f1: 0.4207\n",
            "Epoch 00280\n",
            "Train: loss: 0.5277 | accuracy: 0.7442 | f-acore: 0.7402\n",
            "Test:  loss: 1.0509 | accuracy: 0.5233 | f1: 0.4217\n",
            "Validation:  loss: 0.9052 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00281\n",
            "Train: loss: 0.5173 | accuracy: 0.7497 | f-acore: 0.7470\n",
            "Test:  loss: 1.2249 | accuracy: 0.5425 | f1: 0.4079\n",
            "Validation:  loss: 0.9909 | accuracy: 0.5238 | f1: 0.4013\n",
            "Epoch 00282\n",
            "Train: loss: 0.5049 | accuracy: 0.7501 | f-acore: 0.7457\n",
            "Test:  loss: 0.9863 | accuracy: 0.5288 | f1: 0.4405\n",
            "Validation:  loss: 0.8879 | accuracy: 0.4524 | f1: 0.3839\n",
            "Epoch 00283\n",
            "Train: loss: 0.4915 | accuracy: 0.7460 | f-acore: 0.7427\n",
            "Test:  loss: 1.0280 | accuracy: 0.5151 | f1: 0.4342\n",
            "Validation:  loss: 0.9054 | accuracy: 0.4762 | f1: 0.4107\n",
            "Epoch 00284\n",
            "Train: loss: 0.4905 | accuracy: 0.7432 | f-acore: 0.7393\n",
            "Test:  loss: 1.0016 | accuracy: 0.5123 | f1: 0.4239\n",
            "Validation:  loss: 0.8956 | accuracy: 0.4643 | f1: 0.3918\n",
            "Epoch 00285\n",
            "Train: loss: 0.4822 | accuracy: 0.7634 | f-acore: 0.7591\n",
            "Test:  loss: 1.0933 | accuracy: 0.5178 | f1: 0.4332\n",
            "Validation:  loss: 0.9344 | accuracy: 0.5000 | f1: 0.4375\n",
            "Epoch 00286\n",
            "Train: loss: 0.4842 | accuracy: 0.7685 | f-acore: 0.7632\n",
            "Test:  loss: 0.9994 | accuracy: 0.5123 | f1: 0.4586\n",
            "Validation:  loss: 0.8934 | accuracy: 0.4762 | f1: 0.4376\n",
            "Epoch 00287\n",
            "Train: loss: 0.4978 | accuracy: 0.7483 | f-acore: 0.7464\n",
            "Test:  loss: 0.9083 | accuracy: 0.4767 | f1: 0.4579\n",
            "Validation:  loss: 0.8404 | accuracy: 0.4167 | f1: 0.4126\n",
            "Epoch 00288\n",
            "Train: loss: 0.4963 | accuracy: 0.7478 | f-acore: 0.7442\n",
            "Test:  loss: 0.9726 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.8776 | accuracy: 0.4762 | f1: 0.4376\n",
            "Epoch 00289\n",
            "Train: loss: 0.4863 | accuracy: 0.7542 | f-acore: 0.7502\n",
            "Test:  loss: 1.2937 | accuracy: 0.5479 | f1: 0.4150\n",
            "Validation:  loss: 1.0158 | accuracy: 0.5000 | f1: 0.3534\n",
            "Epoch 00290\n",
            "Train: loss: 0.5196 | accuracy: 0.7483 | f-acore: 0.7442\n",
            "Test:  loss: 0.9465 | accuracy: 0.5288 | f1: 0.4913\n",
            "Validation:  loss: 0.8599 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00291\n",
            "Train: loss: 0.4906 | accuracy: 0.7565 | f-acore: 0.7537\n",
            "Test:  loss: 0.9916 | accuracy: 0.5123 | f1: 0.4606\n",
            "Validation:  loss: 0.8735 | accuracy: 0.4762 | f1: 0.4447\n",
            "Epoch 00292\n",
            "Train: loss: 0.4928 | accuracy: 0.7643 | f-acore: 0.7596\n",
            "Test:  loss: 1.0542 | accuracy: 0.5151 | f1: 0.4395\n",
            "Validation:  loss: 0.9070 | accuracy: 0.5119 | f1: 0.4557\n",
            "Epoch 00293\n",
            "Train: loss: 0.4915 | accuracy: 0.7652 | f-acore: 0.7618\n",
            "Test:  loss: 1.2421 | accuracy: 0.5315 | f1: 0.4093\n",
            "Validation:  loss: 0.9885 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00294\n",
            "Train: loss: 0.4931 | accuracy: 0.7437 | f-acore: 0.7395\n",
            "Test:  loss: 0.9525 | accuracy: 0.5096 | f1: 0.4748\n",
            "Validation:  loss: 0.8752 | accuracy: 0.4762 | f1: 0.4565\n",
            "Epoch 00295\n",
            "Train: loss: 0.5195 | accuracy: 0.7565 | f-acore: 0.7513\n",
            "Test:  loss: 1.1157 | accuracy: 0.5370 | f1: 0.4367\n",
            "Validation:  loss: 0.9447 | accuracy: 0.5357 | f1: 0.4625\n",
            "Epoch 00296\n",
            "Train: loss: 0.5042 | accuracy: 0.7538 | f-acore: 0.7519\n",
            "Test:  loss: 1.1136 | accuracy: 0.5397 | f1: 0.4352\n",
            "Validation:  loss: 0.9359 | accuracy: 0.5000 | f1: 0.3875\n",
            "Epoch 00297\n",
            "Train: loss: 0.4803 | accuracy: 0.7616 | f-acore: 0.7590\n",
            "Test:  loss: 1.0908 | accuracy: 0.5260 | f1: 0.4297\n",
            "Validation:  loss: 0.9383 | accuracy: 0.5000 | f1: 0.4151\n",
            "Epoch 00298\n",
            "Train: loss: 0.4911 | accuracy: 0.7597 | f-acore: 0.7563\n",
            "Test:  loss: 1.0538 | accuracy: 0.5260 | f1: 0.4496\n",
            "Validation:  loss: 0.9056 | accuracy: 0.5238 | f1: 0.4734\n",
            "Epoch 00299\n",
            "Train: loss: 0.4988 | accuracy: 0.7533 | f-acore: 0.7479\n",
            "Test:  loss: 0.9203 | accuracy: 0.5370 | f1: 0.4766\n",
            "Validation:  loss: 0.8367 | accuracy: 0.4524 | f1: 0.3944\n",
            "Epoch 00300\n",
            "Train: loss: 0.4938 | accuracy: 0.7662 | f-acore: 0.7643\n",
            "Test:  loss: 1.0807 | accuracy: 0.5178 | f1: 0.4332\n",
            "Validation:  loss: 0.9221 | accuracy: 0.5357 | f1: 0.4822\n",
            "Epoch 00301\n",
            "Train: loss: 0.4915 | accuracy: 0.7630 | f-acore: 0.7591\n",
            "Test:  loss: 1.0302 | accuracy: 0.5178 | f1: 0.4490\n",
            "Validation:  loss: 0.9154 | accuracy: 0.4881 | f1: 0.4383\n",
            "Epoch 00302\n",
            "Train: loss: 0.5012 | accuracy: 0.7602 | f-acore: 0.7574\n",
            "Test:  loss: 1.0445 | accuracy: 0.5233 | f1: 0.4576\n",
            "Validation:  loss: 0.9135 | accuracy: 0.5000 | f1: 0.4556\n",
            "Epoch 00303\n",
            "Train: loss: 0.4939 | accuracy: 0.7561 | f-acore: 0.7529\n",
            "Test:  loss: 1.1681 | accuracy: 0.5260 | f1: 0.4167\n",
            "Validation:  loss: 0.9493 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00304\n",
            "Train: loss: 0.4847 | accuracy: 0.7579 | f-acore: 0.7525\n",
            "Test:  loss: 0.9796 | accuracy: 0.5178 | f1: 0.4245\n",
            "Validation:  loss: 0.8750 | accuracy: 0.4762 | f1: 0.3583\n",
            "Epoch 00305\n",
            "Train: loss: 0.4883 | accuracy: 0.7662 | f-acore: 0.7636\n",
            "Test:  loss: 1.1167 | accuracy: 0.5096 | f1: 0.4305\n",
            "Validation:  loss: 0.9264 | accuracy: 0.4881 | f1: 0.4074\n",
            "Epoch 00306\n",
            "Train: loss: 0.4867 | accuracy: 0.7611 | f-acore: 0.7579\n",
            "Test:  loss: 1.0068 | accuracy: 0.5260 | f1: 0.4619\n",
            "Validation:  loss: 0.8709 | accuracy: 0.5119 | f1: 0.4645\n",
            "Epoch 00307\n",
            "Train: loss: 0.5001 | accuracy: 0.7565 | f-acore: 0.7534\n",
            "Test:  loss: 1.0239 | accuracy: 0.5178 | f1: 0.4687\n",
            "Validation:  loss: 0.8959 | accuracy: 0.4643 | f1: 0.4354\n",
            "Epoch 00308\n",
            "Train: loss: 0.4843 | accuracy: 0.7799 | f-acore: 0.7778\n",
            "Test:  loss: 1.0620 | accuracy: 0.4904 | f1: 0.4463\n",
            "Validation:  loss: 0.9121 | accuracy: 0.4762 | f1: 0.4447\n",
            "Epoch 00309\n",
            "Train: loss: 0.5026 | accuracy: 0.7542 | f-acore: 0.7497\n",
            "Test:  loss: 0.9486 | accuracy: 0.5123 | f1: 0.4719\n",
            "Validation:  loss: 0.8451 | accuracy: 0.4762 | f1: 0.4510\n",
            "Epoch 00310\n",
            "Train: loss: 0.5033 | accuracy: 0.7740 | f-acore: 0.7718\n",
            "Test:  loss: 1.0106 | accuracy: 0.5288 | f1: 0.4768\n",
            "Validation:  loss: 0.8776 | accuracy: 0.5119 | f1: 0.4645\n",
            "Epoch 00311\n",
            "Train: loss: 0.4891 | accuracy: 0.7547 | f-acore: 0.7507\n",
            "Test:  loss: 0.9685 | accuracy: 0.5123 | f1: 0.4753\n",
            "Validation:  loss: 0.8616 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00312\n",
            "Train: loss: 0.4835 | accuracy: 0.7611 | f-acore: 0.7586\n",
            "Test:  loss: 1.1559 | accuracy: 0.5123 | f1: 0.4377\n",
            "Validation:  loss: 0.9468 | accuracy: 0.4762 | f1: 0.3996\n",
            "Epoch 00313\n",
            "Train: loss: 0.4940 | accuracy: 0.7685 | f-acore: 0.7659\n",
            "Test:  loss: 1.1377 | accuracy: 0.5342 | f1: 0.4604\n",
            "Validation:  loss: 0.9410 | accuracy: 0.4881 | f1: 0.3947\n",
            "Epoch 00314\n",
            "Train: loss: 0.4844 | accuracy: 0.7666 | f-acore: 0.7645\n",
            "Test:  loss: 1.1700 | accuracy: 0.5233 | f1: 0.4397\n",
            "Validation:  loss: 0.9593 | accuracy: 0.5238 | f1: 0.4430\n",
            "Epoch 00315\n",
            "Train: loss: 0.5049 | accuracy: 0.7597 | f-acore: 0.7563\n",
            "Test:  loss: 0.9982 | accuracy: 0.4904 | f1: 0.4626\n",
            "Validation:  loss: 0.8829 | accuracy: 0.4524 | f1: 0.4410\n",
            "Epoch 00316\n",
            "Train: loss: 0.5222 | accuracy: 0.7506 | f-acore: 0.7481\n",
            "Test:  loss: 0.9414 | accuracy: 0.5205 | f1: 0.5011\n",
            "Validation:  loss: 0.8844 | accuracy: 0.4405 | f1: 0.4340\n",
            "Epoch 00317\n",
            "Train: loss: 0.4969 | accuracy: 0.7597 | f-acore: 0.7561\n",
            "Test:  loss: 0.8990 | accuracy: 0.4795 | f1: 0.4645\n",
            "Validation:  loss: 0.8345 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00318\n",
            "Train: loss: 0.5128 | accuracy: 0.7593 | f-acore: 0.7553\n",
            "Test:  loss: 0.9955 | accuracy: 0.5123 | f1: 0.4701\n",
            "Validation:  loss: 0.8962 | accuracy: 0.4762 | f1: 0.4612\n",
            "Epoch 00319\n",
            "Train: loss: 0.4940 | accuracy: 0.7497 | f-acore: 0.7460\n",
            "Test:  loss: 0.9428 | accuracy: 0.5260 | f1: 0.4892\n",
            "Validation:  loss: 0.8798 | accuracy: 0.4405 | f1: 0.4340\n",
            "Epoch 00320\n",
            "Train: loss: 0.4886 | accuracy: 0.7657 | f-acore: 0.7621\n",
            "Test:  loss: 1.1032 | accuracy: 0.5123 | f1: 0.4402\n",
            "Validation:  loss: 0.9388 | accuracy: 0.4881 | f1: 0.4291\n",
            "Epoch 00321\n",
            "Train: loss: 0.5000 | accuracy: 0.7579 | f-acore: 0.7554\n",
            "Test:  loss: 1.2160 | accuracy: 0.5288 | f1: 0.4184\n",
            "Validation:  loss: 0.9828 | accuracy: 0.4881 | f1: 0.3806\n",
            "Epoch 00322\n",
            "Train: loss: 0.4924 | accuracy: 0.7575 | f-acore: 0.7545\n",
            "Test:  loss: 1.0721 | accuracy: 0.5014 | f1: 0.4223\n",
            "Validation:  loss: 0.9240 | accuracy: 0.4762 | f1: 0.4107\n",
            "Epoch 00323\n",
            "Train: loss: 0.4980 | accuracy: 0.7529 | f-acore: 0.7466\n",
            "Test:  loss: 1.2123 | accuracy: 0.5452 | f1: 0.4319\n",
            "Validation:  loss: 0.9582 | accuracy: 0.5000 | f1: 0.3534\n",
            "Epoch 00324\n",
            "Train: loss: 0.4810 | accuracy: 0.7538 | f-acore: 0.7519\n",
            "Test:  loss: 1.1194 | accuracy: 0.5178 | f1: 0.4583\n",
            "Validation:  loss: 0.9303 | accuracy: 0.5000 | f1: 0.4470\n",
            "Epoch 00325\n",
            "Train: loss: 0.4824 | accuracy: 0.7607 | f-acore: 0.7548\n",
            "Test:  loss: 1.0068 | accuracy: 0.5233 | f1: 0.4728\n",
            "Validation:  loss: 0.9132 | accuracy: 0.4405 | f1: 0.4103\n",
            "Epoch 00326\n",
            "Train: loss: 0.4613 | accuracy: 0.7685 | f-acore: 0.7664\n",
            "Test:  loss: 1.1961 | accuracy: 0.5260 | f1: 0.4234\n",
            "Validation:  loss: 0.9973 | accuracy: 0.5119 | f1: 0.4349\n",
            "Epoch 00327\n",
            "Train: loss: 0.4721 | accuracy: 0.7474 | f-acore: 0.7424\n",
            "Test:  loss: 1.1921 | accuracy: 0.5233 | f1: 0.4368\n",
            "Validation:  loss: 0.9922 | accuracy: 0.5119 | f1: 0.4459\n",
            "Epoch 00328\n",
            "Train: loss: 0.4788 | accuracy: 0.7721 | f-acore: 0.7700\n",
            "Test:  loss: 1.1247 | accuracy: 0.5123 | f1: 0.4499\n",
            "Validation:  loss: 0.9415 | accuracy: 0.5000 | f1: 0.4375\n",
            "Epoch 00329\n",
            "Train: loss: 0.4895 | accuracy: 0.7657 | f-acore: 0.7630\n",
            "Test:  loss: 1.0752 | accuracy: 0.5151 | f1: 0.4495\n",
            "Validation:  loss: 0.9129 | accuracy: 0.4881 | f1: 0.4188\n",
            "Epoch 00330\n",
            "Train: loss: 0.4862 | accuracy: 0.7694 | f-acore: 0.7683\n",
            "Test:  loss: 0.9776 | accuracy: 0.4712 | f1: 0.4445\n",
            "Validation:  loss: 0.8715 | accuracy: 0.4167 | f1: 0.4065\n",
            "Epoch 00331\n",
            "Train: loss: 0.4832 | accuracy: 0.7685 | f-acore: 0.7627\n",
            "Test:  loss: 1.0334 | accuracy: 0.5178 | f1: 0.4647\n",
            "Validation:  loss: 0.8959 | accuracy: 0.4881 | f1: 0.4605\n",
            "Epoch 00332\n",
            "Train: loss: 0.4585 | accuracy: 0.7721 | f-acore: 0.7700\n",
            "Test:  loss: 1.2320 | accuracy: 0.5178 | f1: 0.4360\n",
            "Validation:  loss: 1.0042 | accuracy: 0.4762 | f1: 0.4107\n",
            "Epoch 00333\n",
            "Train: loss: 0.4678 | accuracy: 0.7685 | f-acore: 0.7638\n",
            "Test:  loss: 0.9937 | accuracy: 0.5096 | f1: 0.4566\n",
            "Validation:  loss: 0.8890 | accuracy: 0.4762 | f1: 0.4510\n",
            "Epoch 00334\n",
            "Train: loss: 0.4674 | accuracy: 0.7698 | f-acore: 0.7668\n",
            "Test:  loss: 1.3435 | accuracy: 0.5397 | f1: 0.4215\n",
            "Validation:  loss: 1.0506 | accuracy: 0.4881 | f1: 0.3649\n",
            "Epoch 00335\n",
            "Train: loss: 0.4728 | accuracy: 0.7749 | f-acore: 0.7712\n",
            "Test:  loss: 1.0260 | accuracy: 0.5178 | f1: 0.4725\n",
            "Validation:  loss: 0.9201 | accuracy: 0.4643 | f1: 0.4286\n",
            "Epoch 00336\n",
            "Train: loss: 0.4839 | accuracy: 0.7707 | f-acore: 0.7675\n",
            "Test:  loss: 1.1766 | accuracy: 0.5370 | f1: 0.4598\n",
            "Validation:  loss: 0.9873 | accuracy: 0.4643 | f1: 0.4026\n",
            "Epoch 00337\n",
            "Train: loss: 0.4981 | accuracy: 0.7483 | f-acore: 0.7441\n",
            "Test:  loss: 0.9618 | accuracy: 0.5425 | f1: 0.4930\n",
            "Validation:  loss: 0.8487 | accuracy: 0.4643 | f1: 0.4122\n",
            "Epoch 00338\n",
            "Train: loss: 0.4790 | accuracy: 0.7652 | f-acore: 0.7618\n",
            "Test:  loss: 1.1444 | accuracy: 0.5151 | f1: 0.4471\n",
            "Validation:  loss: 0.9247 | accuracy: 0.4643 | f1: 0.3798\n",
            "Epoch 00339\n",
            "Train: loss: 0.4801 | accuracy: 0.7767 | f-acore: 0.7726\n",
            "Test:  loss: 1.1864 | accuracy: 0.5123 | f1: 0.4296\n",
            "Validation:  loss: 0.9606 | accuracy: 0.4524 | f1: 0.3451\n",
            "Epoch 00340\n",
            "Train: loss: 0.4650 | accuracy: 0.7712 | f-acore: 0.7683\n",
            "Test:  loss: 1.2831 | accuracy: 0.5315 | f1: 0.4363\n",
            "Validation:  loss: 1.0306 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00341\n",
            "Train: loss: 0.4934 | accuracy: 0.7735 | f-acore: 0.7698\n",
            "Test:  loss: 1.0967 | accuracy: 0.5123 | f1: 0.4499\n",
            "Validation:  loss: 0.9190 | accuracy: 0.4524 | f1: 0.3723\n",
            "Epoch 00342\n",
            "Train: loss: 0.4972 | accuracy: 0.7703 | f-acore: 0.7670\n",
            "Test:  loss: 1.0980 | accuracy: 0.5068 | f1: 0.4525\n",
            "Validation:  loss: 0.9355 | accuracy: 0.4762 | f1: 0.4107\n",
            "Epoch 00343\n",
            "Train: loss: 0.4783 | accuracy: 0.7707 | f-acore: 0.7687\n",
            "Test:  loss: 1.1228 | accuracy: 0.5260 | f1: 0.4167\n",
            "Validation:  loss: 1.0199 | accuracy: 0.4524 | f1: 0.3594\n",
            "Epoch 00344\n",
            "Train: loss: 0.4783 | accuracy: 0.7611 | f-acore: 0.7559\n",
            "Test:  loss: 1.1420 | accuracy: 0.5315 | f1: 0.4268\n",
            "Validation:  loss: 0.9942 | accuracy: 0.4762 | f1: 0.3736\n",
            "Epoch 00345\n",
            "Train: loss: 0.4951 | accuracy: 0.7538 | f-acore: 0.7513\n",
            "Test:  loss: 1.2866 | accuracy: 0.5315 | f1: 0.4130\n",
            "Validation:  loss: 1.0356 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00346\n",
            "Train: loss: 0.4819 | accuracy: 0.7588 | f-acore: 0.7552\n",
            "Test:  loss: 0.9361 | accuracy: 0.4904 | f1: 0.4692\n",
            "Validation:  loss: 0.8597 | accuracy: 0.4048 | f1: 0.3993\n",
            "Epoch 00347\n",
            "Train: loss: 0.4773 | accuracy: 0.7689 | f-acore: 0.7676\n",
            "Test:  loss: 1.1182 | accuracy: 0.5068 | f1: 0.4504\n",
            "Validation:  loss: 0.9450 | accuracy: 0.4405 | f1: 0.3861\n",
            "Epoch 00348\n",
            "Train: loss: 0.4643 | accuracy: 0.7593 | f-acore: 0.7566\n",
            "Test:  loss: 1.0186 | accuracy: 0.4904 | f1: 0.4517\n",
            "Validation:  loss: 0.8948 | accuracy: 0.4643 | f1: 0.4209\n",
            "Epoch 00349\n",
            "Train: loss: 0.4635 | accuracy: 0.7689 | f-acore: 0.7661\n",
            "Test:  loss: 1.2207 | accuracy: 0.5260 | f1: 0.4496\n",
            "Validation:  loss: 0.9814 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00350\n",
            "Train: loss: 0.5061 | accuracy: 0.7685 | f-acore: 0.7648\n",
            "Test:  loss: 1.0010 | accuracy: 0.5205 | f1: 0.4799\n",
            "Validation:  loss: 0.9014 | accuracy: 0.4405 | f1: 0.4032\n",
            "Epoch 00351\n",
            "Train: loss: 0.4924 | accuracy: 0.7630 | f-acore: 0.7612\n",
            "Test:  loss: 1.0530 | accuracy: 0.5096 | f1: 0.4778\n",
            "Validation:  loss: 0.8933 | accuracy: 0.4643 | f1: 0.4414\n",
            "Epoch 00352\n",
            "Train: loss: 0.4674 | accuracy: 0.7758 | f-acore: 0.7731\n",
            "Test:  loss: 1.1138 | accuracy: 0.5260 | f1: 0.4859\n",
            "Validation:  loss: 0.9580 | accuracy: 0.4167 | f1: 0.3975\n",
            "Epoch 00353\n",
            "Train: loss: 0.4753 | accuracy: 0.7726 | f-acore: 0.7700\n",
            "Test:  loss: 1.1518 | accuracy: 0.5288 | f1: 0.4639\n",
            "Validation:  loss: 0.9691 | accuracy: 0.5000 | f1: 0.4269\n",
            "Epoch 00354\n",
            "Train: loss: 0.4759 | accuracy: 0.7648 | f-acore: 0.7599\n",
            "Test:  loss: 0.9765 | accuracy: 0.5068 | f1: 0.4586\n",
            "Validation:  loss: 0.8562 | accuracy: 0.4643 | f1: 0.4286\n",
            "Epoch 00355\n",
            "Train: loss: 0.4724 | accuracy: 0.7639 | f-acore: 0.7614\n",
            "Test:  loss: 1.2090 | accuracy: 0.5233 | f1: 0.4451\n",
            "Validation:  loss: 0.9879 | accuracy: 0.5357 | f1: 0.4510\n",
            "Epoch 00356\n",
            "Train: loss: 0.4792 | accuracy: 0.7652 | f-acore: 0.7617\n",
            "Test:  loss: 1.1119 | accuracy: 0.4959 | f1: 0.4465\n",
            "Validation:  loss: 0.9320 | accuracy: 0.4762 | f1: 0.4376\n",
            "Epoch 00357\n",
            "Train: loss: 0.4841 | accuracy: 0.7703 | f-acore: 0.7678\n",
            "Test:  loss: 1.0274 | accuracy: 0.4740 | f1: 0.4357\n",
            "Validation:  loss: 0.9005 | accuracy: 0.3810 | f1: 0.3633\n",
            "Epoch 00358\n",
            "Train: loss: 0.4652 | accuracy: 0.7625 | f-acore: 0.7601\n",
            "Test:  loss: 1.1698 | accuracy: 0.5315 | f1: 0.4681\n",
            "Validation:  loss: 0.9398 | accuracy: 0.5238 | f1: 0.4542\n",
            "Epoch 00359\n",
            "Train: loss: 0.4619 | accuracy: 0.7799 | f-acore: 0.7771\n",
            "Test:  loss: 1.1793 | accuracy: 0.5233 | f1: 0.4666\n",
            "Validation:  loss: 0.9683 | accuracy: 0.4762 | f1: 0.3996\n",
            "Epoch 00360\n",
            "Train: loss: 0.4608 | accuracy: 0.7698 | f-acore: 0.7678\n",
            "Test:  loss: 1.1271 | accuracy: 0.5370 | f1: 0.4850\n",
            "Validation:  loss: 0.9537 | accuracy: 0.4643 | f1: 0.4026\n",
            "Epoch 00361\n",
            "Train: loss: 0.4545 | accuracy: 0.7818 | f-acore: 0.7783\n",
            "Test:  loss: 1.1884 | accuracy: 0.5288 | f1: 0.4684\n",
            "Validation:  loss: 0.9777 | accuracy: 0.5000 | f1: 0.4375\n",
            "Epoch 00362\n",
            "Train: loss: 0.4635 | accuracy: 0.7818 | f-acore: 0.7791\n",
            "Test:  loss: 1.0631 | accuracy: 0.5315 | f1: 0.4809\n",
            "Validation:  loss: 0.9129 | accuracy: 0.4524 | f1: 0.3839\n",
            "Epoch 00363\n",
            "Train: loss: 0.4584 | accuracy: 0.7744 | f-acore: 0.7713\n",
            "Test:  loss: 1.1321 | accuracy: 0.4932 | f1: 0.4465\n",
            "Validation:  loss: 0.9545 | accuracy: 0.4524 | f1: 0.4037\n",
            "Epoch 00364\n",
            "Train: loss: 0.4682 | accuracy: 0.7744 | f-acore: 0.7717\n",
            "Test:  loss: 1.1814 | accuracy: 0.5288 | f1: 0.4591\n",
            "Validation:  loss: 0.9542 | accuracy: 0.4762 | f1: 0.3873\n",
            "Epoch 00365\n",
            "Train: loss: 0.4398 | accuracy: 0.7877 | f-acore: 0.7841\n",
            "Test:  loss: 1.2153 | accuracy: 0.4986 | f1: 0.4308\n",
            "Validation:  loss: 0.9621 | accuracy: 0.4524 | f1: 0.3594\n",
            "Epoch 00366\n",
            "Train: loss: 0.4679 | accuracy: 0.7932 | f-acore: 0.7912\n",
            "Test:  loss: 1.1407 | accuracy: 0.5315 | f1: 0.4681\n",
            "Validation:  loss: 0.9825 | accuracy: 0.4643 | f1: 0.4026\n",
            "Epoch 00367\n",
            "Train: loss: 0.4712 | accuracy: 0.7740 | f-acore: 0.7718\n",
            "Test:  loss: 1.2996 | accuracy: 0.5425 | f1: 0.4370\n",
            "Validation:  loss: 1.0534 | accuracy: 0.4762 | f1: 0.3583\n",
            "Epoch 00368\n",
            "Train: loss: 0.4468 | accuracy: 0.7758 | f-acore: 0.7724\n",
            "Test:  loss: 1.2375 | accuracy: 0.5178 | f1: 0.4414\n",
            "Validation:  loss: 0.9853 | accuracy: 0.4762 | f1: 0.3736\n",
            "Epoch 00369\n",
            "Train: loss: 0.4656 | accuracy: 0.7689 | f-acore: 0.7646\n",
            "Test:  loss: 1.0657 | accuracy: 0.4986 | f1: 0.4423\n",
            "Validation:  loss: 0.8851 | accuracy: 0.4643 | f1: 0.3918\n",
            "Epoch 00370\n",
            "Train: loss: 0.4759 | accuracy: 0.7859 | f-acore: 0.7829\n",
            "Test:  loss: 1.2276 | accuracy: 0.5342 | f1: 0.4579\n",
            "Validation:  loss: 0.9959 | accuracy: 0.4762 | f1: 0.3873\n",
            "Epoch 00371\n",
            "Train: loss: 0.4793 | accuracy: 0.7620 | f-acore: 0.7602\n",
            "Test:  loss: 1.2307 | accuracy: 0.5205 | f1: 0.4533\n",
            "Validation:  loss: 0.9748 | accuracy: 0.4762 | f1: 0.3873\n",
            "Epoch 00372\n",
            "Train: loss: 0.4702 | accuracy: 0.7749 | f-acore: 0.7715\n",
            "Test:  loss: 1.2996 | accuracy: 0.5288 | f1: 0.4461\n",
            "Validation:  loss: 1.0260 | accuracy: 0.4762 | f1: 0.3736\n",
            "Epoch 00373\n",
            "Train: loss: 0.4459 | accuracy: 0.7767 | f-acore: 0.7725\n",
            "Test:  loss: 0.9917 | accuracy: 0.5342 | f1: 0.4956\n",
            "Validation:  loss: 0.8682 | accuracy: 0.4167 | f1: 0.3852\n",
            "Epoch 00374\n",
            "Train: loss: 0.4782 | accuracy: 0.7813 | f-acore: 0.7789\n",
            "Test:  loss: 1.3161 | accuracy: 0.5425 | f1: 0.4581\n",
            "Validation:  loss: 1.0300 | accuracy: 0.5000 | f1: 0.4020\n",
            "Epoch 00375\n",
            "Train: loss: 0.4987 | accuracy: 0.7652 | f-acore: 0.7586\n",
            "Test:  loss: 0.9968 | accuracy: 0.5260 | f1: 0.4908\n",
            "Validation:  loss: 0.8604 | accuracy: 0.4048 | f1: 0.3690\n",
            "Epoch 00376\n",
            "Train: loss: 0.4799 | accuracy: 0.7584 | f-acore: 0.7570\n",
            "Test:  loss: 0.9920 | accuracy: 0.4822 | f1: 0.4668\n",
            "Validation:  loss: 0.8463 | accuracy: 0.3929 | f1: 0.3886\n",
            "Epoch 00377\n",
            "Train: loss: 0.4630 | accuracy: 0.7721 | f-acore: 0.7684\n",
            "Test:  loss: 1.2840 | accuracy: 0.5041 | f1: 0.4484\n",
            "Validation:  loss: 0.9747 | accuracy: 0.4881 | f1: 0.4383\n",
            "Epoch 00378\n",
            "Train: loss: 0.4630 | accuracy: 0.7804 | f-acore: 0.7778\n",
            "Test:  loss: 1.1626 | accuracy: 0.5315 | f1: 0.4585\n",
            "Validation:  loss: 0.9260 | accuracy: 0.4881 | f1: 0.4074\n",
            "Epoch 00379\n",
            "Train: loss: 0.4805 | accuracy: 0.7836 | f-acore: 0.7799\n",
            "Test:  loss: 1.1876 | accuracy: 0.5205 | f1: 0.4533\n",
            "Validation:  loss: 0.9489 | accuracy: 0.4643 | f1: 0.3918\n",
            "Epoch 00380\n",
            "Train: loss: 0.4635 | accuracy: 0.7840 | f-acore: 0.7808\n",
            "Test:  loss: 1.1972 | accuracy: 0.5041 | f1: 0.4370\n",
            "Validation:  loss: 0.9500 | accuracy: 0.4643 | f1: 0.3798\n",
            "Epoch 00381\n",
            "Train: loss: 0.4629 | accuracy: 0.7652 | f-acore: 0.7621\n",
            "Test:  loss: 1.1274 | accuracy: 0.5041 | f1: 0.4462\n",
            "Validation:  loss: 0.9370 | accuracy: 0.4405 | f1: 0.3951\n",
            "Epoch 00382\n",
            "Train: loss: 0.4713 | accuracy: 0.7762 | f-acore: 0.7740\n",
            "Test:  loss: 1.1281 | accuracy: 0.5096 | f1: 0.4545\n",
            "Validation:  loss: 0.9102 | accuracy: 0.4524 | f1: 0.3944\n",
            "Epoch 00383\n",
            "Train: loss: 0.4546 | accuracy: 0.7749 | f-acore: 0.7708\n",
            "Test:  loss: 1.2866 | accuracy: 0.5233 | f1: 0.4397\n",
            "Validation:  loss: 0.9896 | accuracy: 0.4762 | f1: 0.3736\n",
            "Epoch 00384\n",
            "Train: loss: 0.4564 | accuracy: 0.7845 | f-acore: 0.7817\n",
            "Test:  loss: 1.3071 | accuracy: 0.4986 | f1: 0.4283\n",
            "Validation:  loss: 0.9999 | accuracy: 0.4762 | f1: 0.3873\n",
            "Epoch 00385\n",
            "Train: loss: 0.4616 | accuracy: 0.7836 | f-acore: 0.7811\n",
            "Test:  loss: 1.1476 | accuracy: 0.5205 | f1: 0.4509\n",
            "Validation:  loss: 0.9352 | accuracy: 0.4881 | f1: 0.4188\n",
            "Epoch 00386\n",
            "Train: loss: 0.4815 | accuracy: 0.7689 | f-acore: 0.7678\n",
            "Test:  loss: 1.2401 | accuracy: 0.5205 | f1: 0.4602\n",
            "Validation:  loss: 0.9775 | accuracy: 0.4524 | f1: 0.3944\n",
            "Epoch 00387\n",
            "Train: loss: 0.4751 | accuracy: 0.7497 | f-acore: 0.7454\n",
            "Test:  loss: 0.8641 | accuracy: 0.4932 | f1: 0.4738\n",
            "Validation:  loss: 0.8183 | accuracy: 0.3929 | f1: 0.3858\n",
            "Epoch 00388\n",
            "Train: loss: 0.4831 | accuracy: 0.7671 | f-acore: 0.7640\n",
            "Test:  loss: 1.0552 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.9238 | accuracy: 0.4167 | f1: 0.3495\n",
            "Epoch 00389\n",
            "Train: loss: 0.4566 | accuracy: 0.7662 | f-acore: 0.7619\n",
            "Test:  loss: 1.1837 | accuracy: 0.5425 | f1: 0.4635\n",
            "Validation:  loss: 0.9584 | accuracy: 0.4643 | f1: 0.3517\n",
            "Epoch 00390\n",
            "Train: loss: 0.4537 | accuracy: 0.7960 | f-acore: 0.7934\n",
            "Test:  loss: 1.3036 | accuracy: 0.5260 | f1: 0.4470\n",
            "Validation:  loss: 1.0279 | accuracy: 0.4881 | f1: 0.3806\n",
            "Epoch 00391\n",
            "Train: loss: 0.4565 | accuracy: 0.7785 | f-acore: 0.7760\n",
            "Test:  loss: 1.1802 | accuracy: 0.5041 | f1: 0.4417\n",
            "Validation:  loss: 0.9515 | accuracy: 0.4643 | f1: 0.3918\n",
            "Epoch 00392\n",
            "Train: loss: 0.4658 | accuracy: 0.7762 | f-acore: 0.7724\n",
            "Test:  loss: 1.1283 | accuracy: 0.5041 | f1: 0.4417\n",
            "Validation:  loss: 0.9261 | accuracy: 0.4762 | f1: 0.3873\n",
            "Epoch 00393\n",
            "Train: loss: 0.4625 | accuracy: 0.7909 | f-acore: 0.7883\n",
            "Test:  loss: 1.2114 | accuracy: 0.5370 | f1: 0.4697\n",
            "Validation:  loss: 0.9885 | accuracy: 0.4643 | f1: 0.3918\n",
            "Epoch 00394\n",
            "Train: loss: 0.4701 | accuracy: 0.7822 | f-acore: 0.7795\n",
            "Test:  loss: 1.2138 | accuracy: 0.5205 | f1: 0.4557\n",
            "Validation:  loss: 0.9816 | accuracy: 0.4643 | f1: 0.3798\n",
            "Epoch 00395\n",
            "Train: loss: 0.4462 | accuracy: 0.7772 | f-acore: 0.7737\n",
            "Test:  loss: 1.2428 | accuracy: 0.5014 | f1: 0.4398\n",
            "Validation:  loss: 0.9710 | accuracy: 0.4524 | f1: 0.3839\n",
            "Epoch 00396\n",
            "Train: loss: 0.4539 | accuracy: 0.7850 | f-acore: 0.7826\n",
            "Test:  loss: 1.0723 | accuracy: 0.5178 | f1: 0.4743\n",
            "Validation:  loss: 0.9046 | accuracy: 0.4167 | f1: 0.3694\n",
            "Epoch 00397\n",
            "Train: loss: 0.4578 | accuracy: 0.7694 | f-acore: 0.7674\n",
            "Test:  loss: 1.2052 | accuracy: 0.5205 | f1: 0.4378\n",
            "Validation:  loss: 0.9883 | accuracy: 0.4762 | f1: 0.3873\n",
            "Epoch 00398\n",
            "Train: loss: 0.4504 | accuracy: 0.7822 | f-acore: 0.7770\n",
            "Test:  loss: 1.1113 | accuracy: 0.5123 | f1: 0.4565\n",
            "Validation:  loss: 0.9445 | accuracy: 0.4524 | f1: 0.4037\n",
            "Epoch 00399\n",
            "Train: loss: 0.4425 | accuracy: 0.7717 | f-acore: 0.7681\n",
            "Test:  loss: 1.2330 | accuracy: 0.5342 | f1: 0.4252\n",
            "Validation:  loss: 0.9988 | accuracy: 0.4762 | f1: 0.3583\n",
            "Epoch 00400\n",
            "Train: loss: 0.4564 | accuracy: 0.7740 | f-acore: 0.7707\n",
            "Test:  loss: 1.1070 | accuracy: 0.4959 | f1: 0.4465\n",
            "Validation:  loss: 0.9127 | accuracy: 0.4762 | f1: 0.4296\n",
            "-----------------------------------------------------------------------------------------\n",
            "^NYA\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6928 | accuracy: 0.5241 | f-acore: 0.4191\n",
            "Test:  loss: 0.7092 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.7004 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00002\n",
            "Train: loss: 0.6901 | accuracy: 0.5438 | f-acore: 0.3664\n",
            "Test:  loss: 0.7033 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6945 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00003\n",
            "Train: loss: 0.6891 | accuracy: 0.5410 | f-acore: 0.3529\n",
            "Test:  loss: 0.7083 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6985 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00004\n",
            "Train: loss: 0.6887 | accuracy: 0.5415 | f-acore: 0.3531\n",
            "Test:  loss: 0.7066 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6985 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00005\n",
            "Train: loss: 0.6879 | accuracy: 0.5415 | f-acore: 0.3531\n",
            "Test:  loss: 0.6996 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6947 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00006\n",
            "Train: loss: 0.6902 | accuracy: 0.5415 | f-acore: 0.3531\n",
            "Test:  loss: 0.7083 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6969 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00007\n",
            "Train: loss: 0.6886 | accuracy: 0.5475 | f-acore: 0.3698\n",
            "Test:  loss: 0.7028 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6951 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00008\n",
            "Train: loss: 0.6875 | accuracy: 0.5479 | f-acore: 0.3800\n",
            "Test:  loss: 0.6937 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6913 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00009\n",
            "Train: loss: 0.6883 | accuracy: 0.5484 | f-acore: 0.3753\n",
            "Test:  loss: 0.6954 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6917 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00010\n",
            "Train: loss: 0.6871 | accuracy: 0.5516 | f-acore: 0.4041\n",
            "Test:  loss: 0.6933 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6894 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00011\n",
            "Train: loss: 0.6863 | accuracy: 0.5461 | f-acore: 0.4088\n",
            "Test:  loss: 0.6922 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6901 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00012\n",
            "Train: loss: 0.6809 | accuracy: 0.5520 | f-acore: 0.3900\n",
            "Test:  loss: 0.6950 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6901 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00013\n",
            "Train: loss: 0.6824 | accuracy: 0.5461 | f-acore: 0.3725\n",
            "Test:  loss: 0.6997 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6929 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00014\n",
            "Train: loss: 0.6837 | accuracy: 0.5475 | f-acore: 0.3814\n",
            "Test:  loss: 0.6984 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6926 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00015\n",
            "Train: loss: 0.6842 | accuracy: 0.5520 | f-acore: 0.3970\n",
            "Test:  loss: 0.6945 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6894 | accuracy: 0.5238 | f1: 0.3438\n",
            "Epoch 00016\n",
            "Train: loss: 0.6814 | accuracy: 0.5552 | f-acore: 0.4875\n",
            "Test:  loss: 0.6929 | accuracy: 0.5233 | f1: 0.3536\n",
            "Validation:  loss: 0.6885 | accuracy: 0.5714 | f1: 0.4612\n",
            "Epoch 00017\n",
            "Train: loss: 0.6786 | accuracy: 0.5617 | f-acore: 0.4917\n",
            "Test:  loss: 0.6939 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6880 | accuracy: 0.5595 | f1: 0.4385\n",
            "Epoch 00018\n",
            "Train: loss: 0.6852 | accuracy: 0.5617 | f-acore: 0.4660\n",
            "Test:  loss: 0.6941 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6855 | accuracy: 0.5476 | f1: 0.4312\n",
            "Epoch 00019\n",
            "Train: loss: 0.6781 | accuracy: 0.5621 | f-acore: 0.5009\n",
            "Test:  loss: 0.6945 | accuracy: 0.5260 | f1: 0.3499\n",
            "Validation:  loss: 0.6841 | accuracy: 0.5476 | f1: 0.4458\n",
            "Epoch 00020\n",
            "Train: loss: 0.6770 | accuracy: 0.5667 | f-acore: 0.4834\n",
            "Test:  loss: 0.6970 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6854 | accuracy: 0.5595 | f1: 0.4385\n",
            "Epoch 00021\n",
            "Train: loss: 0.6857 | accuracy: 0.5644 | f-acore: 0.5015\n",
            "Test:  loss: 0.6980 | accuracy: 0.5315 | f1: 0.3623\n",
            "Validation:  loss: 0.6834 | accuracy: 0.5714 | f1: 0.4875\n",
            "Epoch 00022\n",
            "Train: loss: 0.6802 | accuracy: 0.5740 | f-acore: 0.5236\n",
            "Test:  loss: 0.6932 | accuracy: 0.5233 | f1: 0.3435\n",
            "Validation:  loss: 0.6861 | accuracy: 0.5595 | f1: 0.4385\n",
            "Epoch 00023\n",
            "Train: loss: 0.6760 | accuracy: 0.5754 | f-acore: 0.5233\n",
            "Test:  loss: 0.6929 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6848 | accuracy: 0.5595 | f1: 0.4385\n",
            "Epoch 00024\n",
            "Train: loss: 0.6790 | accuracy: 0.5745 | f-acore: 0.5216\n",
            "Test:  loss: 0.7021 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6848 | accuracy: 0.5595 | f1: 0.4385\n",
            "Epoch 00025\n",
            "Train: loss: 0.6779 | accuracy: 0.5727 | f-acore: 0.5041\n",
            "Test:  loss: 0.7058 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6893 | accuracy: 0.5714 | f1: 0.4457\n",
            "Epoch 00026\n",
            "Train: loss: 0.6725 | accuracy: 0.5736 | f-acore: 0.5183\n",
            "Test:  loss: 0.7058 | accuracy: 0.5260 | f1: 0.3447\n",
            "Validation:  loss: 0.6831 | accuracy: 0.5833 | f1: 0.4958\n",
            "Epoch 00027\n",
            "Train: loss: 0.6767 | accuracy: 0.5823 | f-acore: 0.5343\n",
            "Test:  loss: 0.7027 | accuracy: 0.5315 | f1: 0.3853\n",
            "Validation:  loss: 0.6797 | accuracy: 0.5952 | f1: 0.5159\n",
            "Epoch 00028\n",
            "Train: loss: 0.6793 | accuracy: 0.5773 | f-acore: 0.5176\n",
            "Test:  loss: 0.7044 | accuracy: 0.5288 | f1: 0.3751\n",
            "Validation:  loss: 0.6862 | accuracy: 0.5952 | f1: 0.5042\n",
            "Epoch 00029\n",
            "Train: loss: 0.6771 | accuracy: 0.5915 | f-acore: 0.5688\n",
            "Test:  loss: 0.6983 | accuracy: 0.5260 | f1: 0.4133\n",
            "Validation:  loss: 0.6813 | accuracy: 0.5952 | f1: 0.5446\n",
            "Epoch 00030\n",
            "Train: loss: 0.6753 | accuracy: 0.5860 | f-acore: 0.5480\n",
            "Test:  loss: 0.6980 | accuracy: 0.5288 | f1: 0.3611\n",
            "Validation:  loss: 0.6826 | accuracy: 0.6071 | f1: 0.5452\n",
            "Epoch 00031\n",
            "Train: loss: 0.6715 | accuracy: 0.5910 | f-acore: 0.5631\n",
            "Test:  loss: 0.6974 | accuracy: 0.5315 | f1: 0.3672\n",
            "Validation:  loss: 0.6883 | accuracy: 0.6071 | f1: 0.5354\n",
            "Epoch 00032\n",
            "Train: loss: 0.6778 | accuracy: 0.5713 | f-acore: 0.4838\n",
            "Test:  loss: 0.7020 | accuracy: 0.5233 | f1: 0.3536\n",
            "Validation:  loss: 0.6879 | accuracy: 0.6310 | f1: 0.5534\n",
            "Epoch 00033\n",
            "Train: loss: 0.6659 | accuracy: 0.5919 | f-acore: 0.5774\n",
            "Test:  loss: 0.6951 | accuracy: 0.5233 | f1: 0.4785\n",
            "Validation:  loss: 0.6821 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00034\n",
            "Train: loss: 0.6615 | accuracy: 0.5906 | f-acore: 0.5636\n",
            "Test:  loss: 0.7188 | accuracy: 0.5288 | f1: 0.3963\n",
            "Validation:  loss: 0.6826 | accuracy: 0.6190 | f1: 0.5544\n",
            "Epoch 00035\n",
            "Train: loss: 0.6636 | accuracy: 0.5901 | f-acore: 0.5500\n",
            "Test:  loss: 0.7101 | accuracy: 0.5123 | f1: 0.3908\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5833 | f1: 0.5353\n",
            "Epoch 00036\n",
            "Train: loss: 0.6629 | accuracy: 0.5805 | f-acore: 0.5461\n",
            "Test:  loss: 0.7028 | accuracy: 0.5178 | f1: 0.4560\n",
            "Validation:  loss: 0.6814 | accuracy: 0.5714 | f1: 0.5553\n",
            "Epoch 00037\n",
            "Train: loss: 0.6704 | accuracy: 0.5938 | f-acore: 0.5773\n",
            "Test:  loss: 0.7042 | accuracy: 0.5123 | f1: 0.4586\n",
            "Validation:  loss: 0.6813 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00038\n",
            "Train: loss: 0.6671 | accuracy: 0.5947 | f-acore: 0.5791\n",
            "Test:  loss: 0.7146 | accuracy: 0.5288 | f1: 0.3881\n",
            "Validation:  loss: 0.6896 | accuracy: 0.5833 | f1: 0.5176\n",
            "Epoch 00039\n",
            "Train: loss: 0.6739 | accuracy: 0.5965 | f-acore: 0.5529\n",
            "Test:  loss: 0.7088 | accuracy: 0.5315 | f1: 0.3896\n",
            "Validation:  loss: 0.6920 | accuracy: 0.5833 | f1: 0.5176\n",
            "Epoch 00040\n",
            "Train: loss: 0.6649 | accuracy: 0.6020 | f-acore: 0.5914\n",
            "Test:  loss: 0.7071 | accuracy: 0.5288 | f1: 0.4077\n",
            "Validation:  loss: 0.6899 | accuracy: 0.5833 | f1: 0.5176\n",
            "Epoch 00041\n",
            "Train: loss: 0.6547 | accuracy: 0.6011 | f-acore: 0.5770\n",
            "Test:  loss: 0.7095 | accuracy: 0.5178 | f1: 0.3940\n",
            "Validation:  loss: 0.6913 | accuracy: 0.5714 | f1: 0.5179\n",
            "Epoch 00042\n",
            "Train: loss: 0.6715 | accuracy: 0.6057 | f-acore: 0.5753\n",
            "Test:  loss: 0.7134 | accuracy: 0.5288 | f1: 0.3795\n",
            "Validation:  loss: 0.6950 | accuracy: 0.5714 | f1: 0.5088\n",
            "Epoch 00043\n",
            "Train: loss: 0.6628 | accuracy: 0.6116 | f-acore: 0.5917\n",
            "Test:  loss: 0.7085 | accuracy: 0.5397 | f1: 0.3982\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5952 | f1: 0.5265\n",
            "Epoch 00044\n",
            "Train: loss: 0.6633 | accuracy: 0.6116 | f-acore: 0.5910\n",
            "Test:  loss: 0.7078 | accuracy: 0.5288 | f1: 0.3705\n",
            "Validation:  loss: 0.6976 | accuracy: 0.5476 | f1: 0.4590\n",
            "Epoch 00045\n",
            "Train: loss: 0.6601 | accuracy: 0.6061 | f-acore: 0.5939\n",
            "Test:  loss: 0.6993 | accuracy: 0.5260 | f1: 0.4297\n",
            "Validation:  loss: 0.6911 | accuracy: 0.5476 | f1: 0.5258\n",
            "Epoch 00046\n",
            "Train: loss: 0.6556 | accuracy: 0.6144 | f-acore: 0.6050\n",
            "Test:  loss: 0.7052 | accuracy: 0.5315 | f1: 0.4268\n",
            "Validation:  loss: 0.6953 | accuracy: 0.5833 | f1: 0.5353\n",
            "Epoch 00047\n",
            "Train: loss: 0.6516 | accuracy: 0.6034 | f-acore: 0.5601\n",
            "Test:  loss: 0.7155 | accuracy: 0.5397 | f1: 0.4319\n",
            "Validation:  loss: 0.6990 | accuracy: 0.5714 | f1: 0.5179\n",
            "Epoch 00048\n",
            "Train: loss: 0.6617 | accuracy: 0.6061 | f-acore: 0.5911\n",
            "Test:  loss: 0.7111 | accuracy: 0.5096 | f1: 0.4748\n",
            "Validation:  loss: 0.6978 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00049\n",
            "Train: loss: 0.6567 | accuracy: 0.6107 | f-acore: 0.5818\n",
            "Test:  loss: 0.7075 | accuracy: 0.5233 | f1: 0.4871\n",
            "Validation:  loss: 0.7016 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00050\n",
            "Train: loss: 0.6460 | accuracy: 0.6249 | f-acore: 0.6096\n",
            "Test:  loss: 0.7136 | accuracy: 0.5370 | f1: 0.4367\n",
            "Validation:  loss: 0.7055 | accuracy: 0.5238 | f1: 0.4734\n",
            "Epoch 00051\n",
            "Train: loss: 0.6491 | accuracy: 0.6039 | f-acore: 0.5632\n",
            "Test:  loss: 0.7289 | accuracy: 0.5260 | f1: 0.3645\n",
            "Validation:  loss: 0.7170 | accuracy: 0.6190 | f1: 0.5333\n",
            "Epoch 00052\n",
            "Train: loss: 0.6516 | accuracy: 0.6034 | f-acore: 0.5864\n",
            "Test:  loss: 0.7371 | accuracy: 0.5288 | f1: 0.3659\n",
            "Validation:  loss: 0.7316 | accuracy: 0.6310 | f1: 0.5636\n",
            "Epoch 00053\n",
            "Train: loss: 0.6497 | accuracy: 0.6094 | f-acore: 0.5833\n",
            "Test:  loss: 0.7530 | accuracy: 0.5151 | f1: 0.3546\n",
            "Validation:  loss: 0.7276 | accuracy: 0.6190 | f1: 0.5444\n",
            "Epoch 00054\n",
            "Train: loss: 0.6528 | accuracy: 0.6190 | f-acore: 0.5987\n",
            "Test:  loss: 0.7299 | accuracy: 0.5288 | f1: 0.4826\n",
            "Validation:  loss: 0.7153 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00055\n",
            "Train: loss: 0.6515 | accuracy: 0.6162 | f-acore: 0.6146\n",
            "Test:  loss: 0.7217 | accuracy: 0.5397 | f1: 0.4965\n",
            "Validation:  loss: 0.7172 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00056\n",
            "Train: loss: 0.6425 | accuracy: 0.6236 | f-acore: 0.6005\n",
            "Test:  loss: 0.7468 | accuracy: 0.5233 | f1: 0.4116\n",
            "Validation:  loss: 0.7253 | accuracy: 0.5595 | f1: 0.5302\n",
            "Epoch 00057\n",
            "Train: loss: 0.6491 | accuracy: 0.6318 | f-acore: 0.6216\n",
            "Test:  loss: 0.7397 | accuracy: 0.5397 | f1: 0.4477\n",
            "Validation:  loss: 0.7195 | accuracy: 0.5833 | f1: 0.5496\n",
            "Epoch 00058\n",
            "Train: loss: 0.6485 | accuracy: 0.6309 | f-acore: 0.6196\n",
            "Test:  loss: 0.7506 | accuracy: 0.5397 | f1: 0.4477\n",
            "Validation:  loss: 0.7208 | accuracy: 0.5714 | f1: 0.5333\n",
            "Epoch 00059\n",
            "Train: loss: 0.6465 | accuracy: 0.6359 | f-acore: 0.6285\n",
            "Test:  loss: 0.7329 | accuracy: 0.5452 | f1: 0.4970\n",
            "Validation:  loss: 0.7206 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00060\n",
            "Train: loss: 0.6549 | accuracy: 0.6314 | f-acore: 0.6234\n",
            "Test:  loss: 0.7461 | accuracy: 0.5260 | f1: 0.4266\n",
            "Validation:  loss: 0.7247 | accuracy: 0.6071 | f1: 0.5540\n",
            "Epoch 00061\n",
            "Train: loss: 0.6391 | accuracy: 0.6268 | f-acore: 0.6171\n",
            "Test:  loss: 0.7228 | accuracy: 0.5397 | f1: 0.4947\n",
            "Validation:  loss: 0.7181 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00062\n",
            "Train: loss: 0.6346 | accuracy: 0.6387 | f-acore: 0.6288\n",
            "Test:  loss: 0.7354 | accuracy: 0.5370 | f1: 0.4697\n",
            "Validation:  loss: 0.7241 | accuracy: 0.5833 | f1: 0.5609\n",
            "Epoch 00063\n",
            "Train: loss: 0.6393 | accuracy: 0.6332 | f-acore: 0.6114\n",
            "Test:  loss: 0.7626 | accuracy: 0.5260 | f1: 0.4266\n",
            "Validation:  loss: 0.7263 | accuracy: 0.6190 | f1: 0.5787\n",
            "Epoch 00064\n",
            "Train: loss: 0.6270 | accuracy: 0.6465 | f-acore: 0.6318\n",
            "Test:  loss: 0.7372 | accuracy: 0.5507 | f1: 0.4972\n",
            "Validation:  loss: 0.7212 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00065\n",
            "Train: loss: 0.6354 | accuracy: 0.6447 | f-acore: 0.6308\n",
            "Test:  loss: 0.7487 | accuracy: 0.5315 | f1: 0.4828\n",
            "Validation:  loss: 0.7260 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00066\n",
            "Train: loss: 0.6394 | accuracy: 0.6332 | f-acore: 0.6179\n",
            "Test:  loss: 0.7426 | accuracy: 0.5233 | f1: 0.4973\n",
            "Validation:  loss: 0.7386 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00067\n",
            "Train: loss: 0.6306 | accuracy: 0.6497 | f-acore: 0.6459\n",
            "Test:  loss: 0.7590 | accuracy: 0.5151 | f1: 0.4893\n",
            "Validation:  loss: 0.7502 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00068\n",
            "Train: loss: 0.6360 | accuracy: 0.6442 | f-acore: 0.6350\n",
            "Test:  loss: 0.7684 | accuracy: 0.5425 | f1: 0.4911\n",
            "Validation:  loss: 0.7425 | accuracy: 0.5833 | f1: 0.5696\n",
            "Epoch 00069\n",
            "Train: loss: 0.6225 | accuracy: 0.6470 | f-acore: 0.6383\n",
            "Test:  loss: 0.7565 | accuracy: 0.5178 | f1: 0.4941\n",
            "Validation:  loss: 0.7427 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00070\n",
            "Train: loss: 0.6339 | accuracy: 0.6437 | f-acore: 0.6367\n",
            "Test:  loss: 0.7532 | accuracy: 0.5041 | f1: 0.4922\n",
            "Validation:  loss: 0.7463 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00071\n",
            "Train: loss: 0.6384 | accuracy: 0.6488 | f-acore: 0.6445\n",
            "Test:  loss: 0.7560 | accuracy: 0.5068 | f1: 0.4897\n",
            "Validation:  loss: 0.7534 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00072\n",
            "Train: loss: 0.6311 | accuracy: 0.6428 | f-acore: 0.6230\n",
            "Test:  loss: 0.7499 | accuracy: 0.5068 | f1: 0.4917\n",
            "Validation:  loss: 0.7505 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00073\n",
            "Train: loss: 0.6306 | accuracy: 0.6442 | f-acore: 0.6328\n",
            "Test:  loss: 0.7581 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 0.7507 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00074\n",
            "Train: loss: 0.6335 | accuracy: 0.6359 | f-acore: 0.6291\n",
            "Test:  loss: 0.7676 | accuracy: 0.5288 | f1: 0.4930\n",
            "Validation:  loss: 0.7448 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00075\n",
            "Train: loss: 0.6260 | accuracy: 0.6474 | f-acore: 0.6263\n",
            "Test:  loss: 0.7776 | accuracy: 0.5397 | f1: 0.4808\n",
            "Validation:  loss: 0.7569 | accuracy: 0.5833 | f1: 0.5731\n",
            "Epoch 00076\n",
            "Train: loss: 0.6267 | accuracy: 0.6520 | f-acore: 0.6347\n",
            "Test:  loss: 0.7804 | accuracy: 0.5315 | f1: 0.5012\n",
            "Validation:  loss: 0.7680 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00077\n",
            "Train: loss: 0.6308 | accuracy: 0.6401 | f-acore: 0.6387\n",
            "Test:  loss: 0.7669 | accuracy: 0.5260 | f1: 0.5033\n",
            "Validation:  loss: 0.7504 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00078\n",
            "Train: loss: 0.6353 | accuracy: 0.6552 | f-acore: 0.6440\n",
            "Test:  loss: 0.7880 | accuracy: 0.5370 | f1: 0.5010\n",
            "Validation:  loss: 0.7679 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00079\n",
            "Train: loss: 0.6203 | accuracy: 0.6552 | f-acore: 0.6476\n",
            "Test:  loss: 0.7798 | accuracy: 0.5178 | f1: 0.4928\n",
            "Validation:  loss: 0.7656 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00080\n",
            "Train: loss: 0.6167 | accuracy: 0.6584 | f-acore: 0.6499\n",
            "Test:  loss: 0.7694 | accuracy: 0.5123 | f1: 0.4871\n",
            "Validation:  loss: 0.7642 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00081\n",
            "Train: loss: 0.6207 | accuracy: 0.6635 | f-acore: 0.6549\n",
            "Test:  loss: 0.7743 | accuracy: 0.5123 | f1: 0.4857\n",
            "Validation:  loss: 0.7595 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00082\n",
            "Train: loss: 0.6302 | accuracy: 0.6557 | f-acore: 0.6467\n",
            "Test:  loss: 0.7741 | accuracy: 0.5123 | f1: 0.4943\n",
            "Validation:  loss: 0.7646 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00083\n",
            "Train: loss: 0.6350 | accuracy: 0.6657 | f-acore: 0.6611\n",
            "Test:  loss: 0.7969 | accuracy: 0.5397 | f1: 0.4870\n",
            "Validation:  loss: 0.7662 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00084\n",
            "Train: loss: 0.6201 | accuracy: 0.6713 | f-acore: 0.6602\n",
            "Test:  loss: 0.8035 | accuracy: 0.5315 | f1: 0.5026\n",
            "Validation:  loss: 0.7553 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00085\n",
            "Train: loss: 0.6444 | accuracy: 0.6506 | f-acore: 0.6432\n",
            "Test:  loss: 0.8378 | accuracy: 0.5178 | f1: 0.4706\n",
            "Validation:  loss: 0.7813 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00086\n",
            "Train: loss: 0.6319 | accuracy: 0.6456 | f-acore: 0.6318\n",
            "Test:  loss: 0.7943 | accuracy: 0.4986 | f1: 0.4759\n",
            "Validation:  loss: 0.7664 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00087\n",
            "Train: loss: 0.6120 | accuracy: 0.6653 | f-acore: 0.6600\n",
            "Test:  loss: 0.7879 | accuracy: 0.5123 | f1: 0.4953\n",
            "Validation:  loss: 0.7510 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00088\n",
            "Train: loss: 0.6259 | accuracy: 0.6465 | f-acore: 0.6321\n",
            "Test:  loss: 0.7990 | accuracy: 0.5178 | f1: 0.4605\n",
            "Validation:  loss: 0.7808 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00089\n",
            "Train: loss: 0.6268 | accuracy: 0.6653 | f-acore: 0.6602\n",
            "Test:  loss: 0.7869 | accuracy: 0.5178 | f1: 0.4902\n",
            "Validation:  loss: 0.7722 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00090\n",
            "Train: loss: 0.6224 | accuracy: 0.6676 | f-acore: 0.6587\n",
            "Test:  loss: 0.7858 | accuracy: 0.5178 | f1: 0.4778\n",
            "Validation:  loss: 0.7387 | accuracy: 0.5714 | f1: 0.5508\n",
            "Epoch 00091\n",
            "Train: loss: 0.6106 | accuracy: 0.6648 | f-acore: 0.6596\n",
            "Test:  loss: 0.7599 | accuracy: 0.4932 | f1: 0.4857\n",
            "Validation:  loss: 0.7294 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00092\n",
            "Train: loss: 0.6181 | accuracy: 0.6538 | f-acore: 0.6479\n",
            "Test:  loss: 0.7943 | accuracy: 0.4986 | f1: 0.4746\n",
            "Validation:  loss: 0.7670 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00093\n",
            "Train: loss: 0.6071 | accuracy: 0.6635 | f-acore: 0.6534\n",
            "Test:  loss: 0.8156 | accuracy: 0.5096 | f1: 0.4940\n",
            "Validation:  loss: 0.7877 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00094\n",
            "Train: loss: 0.6139 | accuracy: 0.6694 | f-acore: 0.6664\n",
            "Test:  loss: 0.8268 | accuracy: 0.5123 | f1: 0.4974\n",
            "Validation:  loss: 0.7929 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00095\n",
            "Train: loss: 0.6110 | accuracy: 0.6589 | f-acore: 0.6466\n",
            "Test:  loss: 0.8050 | accuracy: 0.5041 | f1: 0.4873\n",
            "Validation:  loss: 0.7677 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00096\n",
            "Train: loss: 0.6178 | accuracy: 0.6580 | f-acore: 0.6462\n",
            "Test:  loss: 0.8008 | accuracy: 0.5123 | f1: 0.5078\n",
            "Validation:  loss: 0.7918 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00097\n",
            "Train: loss: 0.6073 | accuracy: 0.6694 | f-acore: 0.6674\n",
            "Test:  loss: 0.7993 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 0.8076 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00098\n",
            "Train: loss: 0.6115 | accuracy: 0.6625 | f-acore: 0.6592\n",
            "Test:  loss: 0.8125 | accuracy: 0.5068 | f1: 0.4992\n",
            "Validation:  loss: 0.7788 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00099\n",
            "Train: loss: 0.6225 | accuracy: 0.6708 | f-acore: 0.6648\n",
            "Test:  loss: 0.8281 | accuracy: 0.5178 | f1: 0.4988\n",
            "Validation:  loss: 0.7774 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00100\n",
            "Train: loss: 0.6185 | accuracy: 0.6612 | f-acore: 0.6499\n",
            "Test:  loss: 0.8357 | accuracy: 0.5288 | f1: 0.4961\n",
            "Validation:  loss: 0.7474 | accuracy: 0.5952 | f1: 0.5868\n",
            "Epoch 00101\n",
            "Train: loss: 0.6119 | accuracy: 0.6662 | f-acore: 0.6618\n",
            "Test:  loss: 0.8194 | accuracy: 0.5096 | f1: 0.4969\n",
            "Validation:  loss: 0.7627 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00102\n",
            "Train: loss: 0.6158 | accuracy: 0.6653 | f-acore: 0.6577\n",
            "Test:  loss: 0.8281 | accuracy: 0.5123 | f1: 0.4830\n",
            "Validation:  loss: 0.7784 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00103\n",
            "Train: loss: 0.6000 | accuracy: 0.6657 | f-acore: 0.6585\n",
            "Test:  loss: 0.8096 | accuracy: 0.5096 | f1: 0.4960\n",
            "Validation:  loss: 0.7598 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00104\n",
            "Train: loss: 0.6069 | accuracy: 0.6813 | f-acore: 0.6787\n",
            "Test:  loss: 0.7953 | accuracy: 0.5096 | f1: 0.4950\n",
            "Validation:  loss: 0.7707 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00105\n",
            "Train: loss: 0.5990 | accuracy: 0.6749 | f-acore: 0.6694\n",
            "Test:  loss: 0.8141 | accuracy: 0.5151 | f1: 0.4997\n",
            "Validation:  loss: 0.7980 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00106\n",
            "Train: loss: 0.5881 | accuracy: 0.6731 | f-acore: 0.6637\n",
            "Test:  loss: 0.8318 | accuracy: 0.5151 | f1: 0.4966\n",
            "Validation:  loss: 0.7860 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00107\n",
            "Train: loss: 0.5906 | accuracy: 0.6786 | f-acore: 0.6730\n",
            "Test:  loss: 0.8443 | accuracy: 0.5123 | f1: 0.4844\n",
            "Validation:  loss: 0.8106 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00108\n",
            "Train: loss: 0.5757 | accuracy: 0.6956 | f-acore: 0.6929\n",
            "Test:  loss: 0.8513 | accuracy: 0.5151 | f1: 0.4997\n",
            "Validation:  loss: 0.7935 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00109\n",
            "Train: loss: 0.5918 | accuracy: 0.6878 | f-acore: 0.6811\n",
            "Test:  loss: 0.8601 | accuracy: 0.5096 | f1: 0.4848\n",
            "Validation:  loss: 0.8295 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00110\n",
            "Train: loss: 0.6062 | accuracy: 0.6855 | f-acore: 0.6831\n",
            "Test:  loss: 0.8518 | accuracy: 0.5205 | f1: 0.5022\n",
            "Validation:  loss: 0.8012 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00111\n",
            "Train: loss: 0.6090 | accuracy: 0.6809 | f-acore: 0.6739\n",
            "Test:  loss: 0.8111 | accuracy: 0.5178 | f1: 0.4999\n",
            "Validation:  loss: 0.8063 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00112\n",
            "Train: loss: 0.5892 | accuracy: 0.6901 | f-acore: 0.6862\n",
            "Test:  loss: 0.8247 | accuracy: 0.5260 | f1: 0.5119\n",
            "Validation:  loss: 0.7950 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00113\n",
            "Train: loss: 0.5970 | accuracy: 0.6745 | f-acore: 0.6707\n",
            "Test:  loss: 0.8417 | accuracy: 0.5205 | f1: 0.4964\n",
            "Validation:  loss: 0.7938 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00114\n",
            "Train: loss: 0.5795 | accuracy: 0.6928 | f-acore: 0.6882\n",
            "Test:  loss: 0.8385 | accuracy: 0.5151 | f1: 0.5007\n",
            "Validation:  loss: 0.8367 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00115\n",
            "Train: loss: 0.6065 | accuracy: 0.6836 | f-acore: 0.6765\n",
            "Test:  loss: 0.8638 | accuracy: 0.5178 | f1: 0.5058\n",
            "Validation:  loss: 0.8178 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00116\n",
            "Train: loss: 0.5915 | accuracy: 0.6923 | f-acore: 0.6907\n",
            "Test:  loss: 0.8618 | accuracy: 0.5151 | f1: 0.5098\n",
            "Validation:  loss: 0.8247 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00117\n",
            "Train: loss: 0.5906 | accuracy: 0.6864 | f-acore: 0.6826\n",
            "Test:  loss: 0.8991 | accuracy: 0.5123 | f1: 0.4800\n",
            "Validation:  loss: 0.8148 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00118\n",
            "Train: loss: 0.5902 | accuracy: 0.6777 | f-acore: 0.6668\n",
            "Test:  loss: 0.8687 | accuracy: 0.5151 | f1: 0.4806\n",
            "Validation:  loss: 0.7875 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00119\n",
            "Train: loss: 0.5874 | accuracy: 0.6887 | f-acore: 0.6838\n",
            "Test:  loss: 0.8535 | accuracy: 0.5041 | f1: 0.4840\n",
            "Validation:  loss: 0.8243 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00120\n",
            "Train: loss: 0.5916 | accuracy: 0.6804 | f-acore: 0.6757\n",
            "Test:  loss: 0.8731 | accuracy: 0.5151 | f1: 0.4966\n",
            "Validation:  loss: 0.8212 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00121\n",
            "Train: loss: 0.5831 | accuracy: 0.6855 | f-acore: 0.6816\n",
            "Test:  loss: 0.8567 | accuracy: 0.5068 | f1: 0.4999\n",
            "Validation:  loss: 0.8469 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00122\n",
            "Train: loss: 0.5864 | accuracy: 0.6905 | f-acore: 0.6856\n",
            "Test:  loss: 0.8518 | accuracy: 0.5233 | f1: 0.5086\n",
            "Validation:  loss: 0.8150 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00123\n",
            "Train: loss: 0.5903 | accuracy: 0.6781 | f-acore: 0.6702\n",
            "Test:  loss: 0.8447 | accuracy: 0.5233 | f1: 0.4986\n",
            "Validation:  loss: 0.8184 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00124\n",
            "Train: loss: 0.5980 | accuracy: 0.6901 | f-acore: 0.6812\n",
            "Test:  loss: 0.8448 | accuracy: 0.5315 | f1: 0.5202\n",
            "Validation:  loss: 0.8363 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00125\n",
            "Train: loss: 0.5840 | accuracy: 0.6777 | f-acore: 0.6695\n",
            "Test:  loss: 0.8467 | accuracy: 0.5397 | f1: 0.5256\n",
            "Validation:  loss: 0.8368 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00126\n",
            "Train: loss: 0.5834 | accuracy: 0.6942 | f-acore: 0.6900\n",
            "Test:  loss: 0.8682 | accuracy: 0.5123 | f1: 0.5067\n",
            "Validation:  loss: 0.8471 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00127\n",
            "Train: loss: 0.5957 | accuracy: 0.6845 | f-acore: 0.6788\n",
            "Test:  loss: 0.8682 | accuracy: 0.5123 | f1: 0.5018\n",
            "Validation:  loss: 0.8310 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00128\n",
            "Train: loss: 0.5946 | accuracy: 0.6942 | f-acore: 0.6893\n",
            "Test:  loss: 0.8745 | accuracy: 0.4932 | f1: 0.4714\n",
            "Validation:  loss: 0.8105 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00129\n",
            "Train: loss: 0.5777 | accuracy: 0.6878 | f-acore: 0.6810\n",
            "Test:  loss: 0.8847 | accuracy: 0.5123 | f1: 0.4769\n",
            "Validation:  loss: 0.8334 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00130\n",
            "Train: loss: 0.5812 | accuracy: 0.6896 | f-acore: 0.6853\n",
            "Test:  loss: 0.8787 | accuracy: 0.5178 | f1: 0.4966\n",
            "Validation:  loss: 0.8471 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00131\n",
            "Train: loss: 0.5847 | accuracy: 0.6827 | f-acore: 0.6758\n",
            "Test:  loss: 0.8930 | accuracy: 0.5151 | f1: 0.4987\n",
            "Validation:  loss: 0.8404 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00132\n",
            "Train: loss: 0.5770 | accuracy: 0.6896 | f-acore: 0.6878\n",
            "Test:  loss: 0.8912 | accuracy: 0.5096 | f1: 0.5042\n",
            "Validation:  loss: 0.8478 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00133\n",
            "Train: loss: 0.5868 | accuracy: 0.6956 | f-acore: 0.6922\n",
            "Test:  loss: 0.8751 | accuracy: 0.5315 | f1: 0.5166\n",
            "Validation:  loss: 0.8339 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00134\n",
            "Train: loss: 0.5802 | accuracy: 0.6978 | f-acore: 0.6931\n",
            "Test:  loss: 0.8185 | accuracy: 0.5096 | f1: 0.5010\n",
            "Validation:  loss: 0.8062 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00135\n",
            "Train: loss: 0.5933 | accuracy: 0.6891 | f-acore: 0.6865\n",
            "Test:  loss: 0.8436 | accuracy: 0.5178 | f1: 0.4941\n",
            "Validation:  loss: 0.8221 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00136\n",
            "Train: loss: 0.5638 | accuracy: 0.6965 | f-acore: 0.6885\n",
            "Test:  loss: 0.8773 | accuracy: 0.5068 | f1: 0.4800\n",
            "Validation:  loss: 0.8375 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00137\n",
            "Train: loss: 0.5630 | accuracy: 0.6951 | f-acore: 0.6892\n",
            "Test:  loss: 0.8805 | accuracy: 0.5014 | f1: 0.4698\n",
            "Validation:  loss: 0.8467 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00138\n",
            "Train: loss: 0.5862 | accuracy: 0.6969 | f-acore: 0.6905\n",
            "Test:  loss: 0.8748 | accuracy: 0.5096 | f1: 0.4920\n",
            "Validation:  loss: 0.8369 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00139\n",
            "Train: loss: 0.5651 | accuracy: 0.6864 | f-acore: 0.6846\n",
            "Test:  loss: 0.8982 | accuracy: 0.5014 | f1: 0.4889\n",
            "Validation:  loss: 0.8590 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00140\n",
            "Train: loss: 0.5872 | accuracy: 0.7011 | f-acore: 0.6973\n",
            "Test:  loss: 0.8937 | accuracy: 0.5096 | f1: 0.4822\n",
            "Validation:  loss: 0.8653 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00141\n",
            "Train: loss: 0.5839 | accuracy: 0.6960 | f-acore: 0.6879\n",
            "Test:  loss: 0.9097 | accuracy: 0.5151 | f1: 0.4866\n",
            "Validation:  loss: 0.8613 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00142\n",
            "Train: loss: 0.5755 | accuracy: 0.7102 | f-acore: 0.7049\n",
            "Test:  loss: 0.8953 | accuracy: 0.5041 | f1: 0.4938\n",
            "Validation:  loss: 0.8623 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00143\n",
            "Train: loss: 0.5671 | accuracy: 0.7079 | f-acore: 0.7051\n",
            "Test:  loss: 0.9317 | accuracy: 0.4959 | f1: 0.4640\n",
            "Validation:  loss: 0.8708 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00144\n",
            "Train: loss: 0.5795 | accuracy: 0.6965 | f-acore: 0.6872\n",
            "Test:  loss: 0.9081 | accuracy: 0.4877 | f1: 0.4576\n",
            "Validation:  loss: 0.8585 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00145\n",
            "Train: loss: 0.5733 | accuracy: 0.6992 | f-acore: 0.6962\n",
            "Test:  loss: 0.8858 | accuracy: 0.5014 | f1: 0.4898\n",
            "Validation:  loss: 0.8650 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00146\n",
            "Train: loss: 0.5761 | accuracy: 0.6960 | f-acore: 0.6932\n",
            "Test:  loss: 0.9255 | accuracy: 0.5014 | f1: 0.4728\n",
            "Validation:  loss: 0.9058 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00147\n",
            "Train: loss: 0.5756 | accuracy: 0.6919 | f-acore: 0.6844\n",
            "Test:  loss: 0.8996 | accuracy: 0.5151 | f1: 0.4931\n",
            "Validation:  loss: 0.8806 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00148\n",
            "Train: loss: 0.5810 | accuracy: 0.7038 | f-acore: 0.7001\n",
            "Test:  loss: 0.8975 | accuracy: 0.5151 | f1: 0.5025\n",
            "Validation:  loss: 0.8533 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00149\n",
            "Train: loss: 0.5711 | accuracy: 0.6946 | f-acore: 0.6885\n",
            "Test:  loss: 0.9420 | accuracy: 0.5096 | f1: 0.4731\n",
            "Validation:  loss: 0.8874 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00150\n",
            "Train: loss: 0.5838 | accuracy: 0.7001 | f-acore: 0.6952\n",
            "Test:  loss: 0.9281 | accuracy: 0.5068 | f1: 0.4786\n",
            "Validation:  loss: 0.9048 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00151\n",
            "Train: loss: 0.5767 | accuracy: 0.6965 | f-acore: 0.6933\n",
            "Test:  loss: 0.9372 | accuracy: 0.4986 | f1: 0.4692\n",
            "Validation:  loss: 0.9229 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00152\n",
            "Train: loss: 0.5723 | accuracy: 0.7029 | f-acore: 0.6974\n",
            "Test:  loss: 0.9126 | accuracy: 0.5096 | f1: 0.4731\n",
            "Validation:  loss: 0.8754 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00153\n",
            "Train: loss: 0.5555 | accuracy: 0.7056 | f-acore: 0.7000\n",
            "Test:  loss: 0.9174 | accuracy: 0.5123 | f1: 0.4896\n",
            "Validation:  loss: 0.9425 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00154\n",
            "Train: loss: 0.5672 | accuracy: 0.7102 | f-acore: 0.7083\n",
            "Test:  loss: 0.9327 | accuracy: 0.5151 | f1: 0.5103\n",
            "Validation:  loss: 0.9232 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00155\n",
            "Train: loss: 0.5627 | accuracy: 0.7093 | f-acore: 0.7045\n",
            "Test:  loss: 0.9368 | accuracy: 0.5068 | f1: 0.4970\n",
            "Validation:  loss: 0.9399 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00156\n",
            "Train: loss: 0.5999 | accuracy: 0.6983 | f-acore: 0.6971\n",
            "Test:  loss: 0.8837 | accuracy: 0.5041 | f1: 0.5029\n",
            "Validation:  loss: 0.9184 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00157\n",
            "Train: loss: 0.6135 | accuracy: 0.6818 | f-acore: 0.6720\n",
            "Test:  loss: 0.8631 | accuracy: 0.5096 | f1: 0.5017\n",
            "Validation:  loss: 0.8552 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00158\n",
            "Train: loss: 0.5863 | accuracy: 0.6845 | f-acore: 0.6817\n",
            "Test:  loss: 0.8447 | accuracy: 0.5151 | f1: 0.5086\n",
            "Validation:  loss: 0.8781 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00159\n",
            "Train: loss: 0.5809 | accuracy: 0.6937 | f-acore: 0.6920\n",
            "Test:  loss: 0.8839 | accuracy: 0.5041 | f1: 0.4852\n",
            "Validation:  loss: 0.8434 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00160\n",
            "Train: loss: 0.5602 | accuracy: 0.7066 | f-acore: 0.7024\n",
            "Test:  loss: 0.9279 | accuracy: 0.5233 | f1: 0.4973\n",
            "Validation:  loss: 0.8997 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00161\n",
            "Train: loss: 0.5777 | accuracy: 0.7006 | f-acore: 0.6963\n",
            "Test:  loss: 0.9487 | accuracy: 0.5068 | f1: 0.4771\n",
            "Validation:  loss: 0.9071 | accuracy: 0.5952 | f1: 0.5950\n",
            "Epoch 00162\n",
            "Train: loss: 0.5658 | accuracy: 0.6992 | f-acore: 0.6924\n",
            "Test:  loss: 0.9321 | accuracy: 0.5151 | f1: 0.4976\n",
            "Validation:  loss: 0.9089 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00163\n",
            "Train: loss: 0.5570 | accuracy: 0.7111 | f-acore: 0.7069\n",
            "Test:  loss: 0.9270 | accuracy: 0.5205 | f1: 0.5033\n",
            "Validation:  loss: 0.8923 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00164\n",
            "Train: loss: 0.5600 | accuracy: 0.7185 | f-acore: 0.7169\n",
            "Test:  loss: 0.9376 | accuracy: 0.5096 | f1: 0.4940\n",
            "Validation:  loss: 0.9323 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00165\n",
            "Train: loss: 0.5490 | accuracy: 0.7066 | f-acore: 0.6979\n",
            "Test:  loss: 0.9584 | accuracy: 0.5068 | f1: 0.4886\n",
            "Validation:  loss: 0.8957 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00166\n",
            "Train: loss: 0.5626 | accuracy: 0.7125 | f-acore: 0.7089\n",
            "Test:  loss: 0.9252 | accuracy: 0.5178 | f1: 0.5058\n",
            "Validation:  loss: 0.9131 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00167\n",
            "Train: loss: 0.5577 | accuracy: 0.7116 | f-acore: 0.7076\n",
            "Test:  loss: 0.9513 | accuracy: 0.4904 | f1: 0.4667\n",
            "Validation:  loss: 0.8678 | accuracy: 0.5952 | f1: 0.5950\n",
            "Epoch 00168\n",
            "Train: loss: 0.5504 | accuracy: 0.7093 | f-acore: 0.7047\n",
            "Test:  loss: 0.9514 | accuracy: 0.5123 | f1: 0.4932\n",
            "Validation:  loss: 0.8857 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00169\n",
            "Train: loss: 0.5798 | accuracy: 0.7047 | f-acore: 0.6997\n",
            "Test:  loss: 0.9276 | accuracy: 0.5123 | f1: 0.4943\n",
            "Validation:  loss: 0.8778 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00170\n",
            "Train: loss: 0.5592 | accuracy: 0.7047 | f-acore: 0.7018\n",
            "Test:  loss: 0.9579 | accuracy: 0.5151 | f1: 0.4966\n",
            "Validation:  loss: 0.9132 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00171\n",
            "Train: loss: 0.5698 | accuracy: 0.6978 | f-acore: 0.6890\n",
            "Test:  loss: 0.9617 | accuracy: 0.5068 | f1: 0.4771\n",
            "Validation:  loss: 0.9060 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00172\n",
            "Train: loss: 0.5606 | accuracy: 0.7088 | f-acore: 0.7008\n",
            "Test:  loss: 0.9073 | accuracy: 0.5288 | f1: 0.5113\n",
            "Validation:  loss: 0.8591 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00173\n",
            "Train: loss: 0.5610 | accuracy: 0.6937 | f-acore: 0.6922\n",
            "Test:  loss: 0.9133 | accuracy: 0.5151 | f1: 0.5065\n",
            "Validation:  loss: 0.8925 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00174\n",
            "Train: loss: 0.5538 | accuracy: 0.7098 | f-acore: 0.7069\n",
            "Test:  loss: 0.9364 | accuracy: 0.5288 | f1: 0.5123\n",
            "Validation:  loss: 0.9047 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00175\n",
            "Train: loss: 0.5521 | accuracy: 0.7157 | f-acore: 0.7109\n",
            "Test:  loss: 0.9654 | accuracy: 0.5178 | f1: 0.4977\n",
            "Validation:  loss: 0.9118 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00176\n",
            "Train: loss: 0.5536 | accuracy: 0.7107 | f-acore: 0.7066\n",
            "Test:  loss: 0.9898 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 0.9353 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00177\n",
            "Train: loss: 0.5549 | accuracy: 0.7079 | f-acore: 0.7026\n",
            "Test:  loss: 1.0161 | accuracy: 0.5178 | f1: 0.4902\n",
            "Validation:  loss: 0.9515 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00178\n",
            "Train: loss: 0.5699 | accuracy: 0.7134 | f-acore: 0.7090\n",
            "Test:  loss: 0.9505 | accuracy: 0.5260 | f1: 0.5100\n",
            "Validation:  loss: 0.8919 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00179\n",
            "Train: loss: 0.5554 | accuracy: 0.7098 | f-acore: 0.7063\n",
            "Test:  loss: 0.9544 | accuracy: 0.5288 | f1: 0.5123\n",
            "Validation:  loss: 0.8800 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00180\n",
            "Train: loss: 0.5363 | accuracy: 0.7157 | f-acore: 0.7125\n",
            "Test:  loss: 0.9780 | accuracy: 0.5096 | f1: 0.4793\n",
            "Validation:  loss: 0.9215 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00181\n",
            "Train: loss: 0.5787 | accuracy: 0.7121 | f-acore: 0.7090\n",
            "Test:  loss: 0.9685 | accuracy: 0.5096 | f1: 0.4715\n",
            "Validation:  loss: 0.9116 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00182\n",
            "Train: loss: 0.5651 | accuracy: 0.7079 | f-acore: 0.7021\n",
            "Test:  loss: 0.9500 | accuracy: 0.5096 | f1: 0.4861\n",
            "Validation:  loss: 0.9017 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00183\n",
            "Train: loss: 0.5439 | accuracy: 0.7130 | f-acore: 0.7109\n",
            "Test:  loss: 0.9835 | accuracy: 0.5041 | f1: 0.4840\n",
            "Validation:  loss: 0.8959 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00184\n",
            "Train: loss: 0.5509 | accuracy: 0.7217 | f-acore: 0.7169\n",
            "Test:  loss: 0.9992 | accuracy: 0.5041 | f1: 0.4816\n",
            "Validation:  loss: 0.8899 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00185\n",
            "Train: loss: 0.5426 | accuracy: 0.7212 | f-acore: 0.7187\n",
            "Test:  loss: 0.9709 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 0.9091 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00186\n",
            "Train: loss: 0.5688 | accuracy: 0.7125 | f-acore: 0.7080\n",
            "Test:  loss: 0.9956 | accuracy: 0.5178 | f1: 0.4928\n",
            "Validation:  loss: 0.9397 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00187\n",
            "Train: loss: 0.5734 | accuracy: 0.7098 | f-acore: 0.7071\n",
            "Test:  loss: 0.9778 | accuracy: 0.4959 | f1: 0.4711\n",
            "Validation:  loss: 0.9038 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00188\n",
            "Train: loss: 0.5668 | accuracy: 0.7121 | f-acore: 0.7083\n",
            "Test:  loss: 0.9659 | accuracy: 0.5068 | f1: 0.4813\n",
            "Validation:  loss: 0.8902 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00189\n",
            "Train: loss: 0.5571 | accuracy: 0.7116 | f-acore: 0.7069\n",
            "Test:  loss: 1.0208 | accuracy: 0.5096 | f1: 0.4886\n",
            "Validation:  loss: 0.9455 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00190\n",
            "Train: loss: 0.5443 | accuracy: 0.7139 | f-acore: 0.7118\n",
            "Test:  loss: 0.9678 | accuracy: 0.5068 | f1: 0.4886\n",
            "Validation:  loss: 0.9226 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00191\n",
            "Train: loss: 0.5354 | accuracy: 0.7231 | f-acore: 0.7193\n",
            "Test:  loss: 1.0095 | accuracy: 0.5096 | f1: 0.4874\n",
            "Validation:  loss: 0.8964 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00192\n",
            "Train: loss: 0.5399 | accuracy: 0.7327 | f-acore: 0.7272\n",
            "Test:  loss: 1.0014 | accuracy: 0.5096 | f1: 0.4874\n",
            "Validation:  loss: 0.8928 | accuracy: 0.5952 | f1: 0.5950\n",
            "Epoch 00193\n",
            "Train: loss: 0.5443 | accuracy: 0.7226 | f-acore: 0.7203\n",
            "Test:  loss: 0.9836 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 0.9145 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00194\n",
            "Train: loss: 0.5281 | accuracy: 0.7299 | f-acore: 0.7278\n",
            "Test:  loss: 1.0196 | accuracy: 0.5096 | f1: 0.4940\n",
            "Validation:  loss: 0.9100 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00195\n",
            "Train: loss: 0.5379 | accuracy: 0.7189 | f-acore: 0.7160\n",
            "Test:  loss: 1.0037 | accuracy: 0.5096 | f1: 0.4960\n",
            "Validation:  loss: 0.8985 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00196\n",
            "Train: loss: 0.5367 | accuracy: 0.7263 | f-acore: 0.7234\n",
            "Test:  loss: 1.0318 | accuracy: 0.4959 | f1: 0.4842\n",
            "Validation:  loss: 0.9353 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00197\n",
            "Train: loss: 0.5341 | accuracy: 0.7176 | f-acore: 0.7147\n",
            "Test:  loss: 0.9834 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 0.9252 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00198\n",
            "Train: loss: 0.5340 | accuracy: 0.7226 | f-acore: 0.7203\n",
            "Test:  loss: 0.9904 | accuracy: 0.5151 | f1: 0.4954\n",
            "Validation:  loss: 0.9130 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00199\n",
            "Train: loss: 0.5646 | accuracy: 0.7244 | f-acore: 0.7200\n",
            "Test:  loss: 1.0003 | accuracy: 0.5068 | f1: 0.4813\n",
            "Validation:  loss: 0.9451 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00200\n",
            "Train: loss: 0.5441 | accuracy: 0.7075 | f-acore: 0.7056\n",
            "Test:  loss: 0.9699 | accuracy: 0.5068 | f1: 0.4945\n",
            "Validation:  loss: 0.8992 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00201\n",
            "Train: loss: 0.5669 | accuracy: 0.7281 | f-acore: 0.7249\n",
            "Test:  loss: 1.0203 | accuracy: 0.5096 | f1: 0.4861\n",
            "Validation:  loss: 0.9713 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00202\n",
            "Train: loss: 0.5729 | accuracy: 0.7047 | f-acore: 0.6974\n",
            "Test:  loss: 0.9713 | accuracy: 0.5205 | f1: 0.5022\n",
            "Validation:  loss: 0.8961 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00203\n",
            "Train: loss: 0.5568 | accuracy: 0.7079 | f-acore: 0.7055\n",
            "Test:  loss: 0.9667 | accuracy: 0.5151 | f1: 0.4931\n",
            "Validation:  loss: 0.9176 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00204\n",
            "Train: loss: 0.5559 | accuracy: 0.7139 | f-acore: 0.7106\n",
            "Test:  loss: 1.0040 | accuracy: 0.4932 | f1: 0.4648\n",
            "Validation:  loss: 0.9169 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00205\n",
            "Train: loss: 0.5347 | accuracy: 0.7130 | f-acore: 0.7090\n",
            "Test:  loss: 1.0674 | accuracy: 0.5014 | f1: 0.4525\n",
            "Validation:  loss: 0.9631 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00206\n",
            "Train: loss: 0.5546 | accuracy: 0.7166 | f-acore: 0.7117\n",
            "Test:  loss: 1.0263 | accuracy: 0.5178 | f1: 0.4915\n",
            "Validation:  loss: 0.9243 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00207\n",
            "Train: loss: 0.5519 | accuracy: 0.7322 | f-acore: 0.7265\n",
            "Test:  loss: 1.0229 | accuracy: 0.5096 | f1: 0.4848\n",
            "Validation:  loss: 0.9460 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00208\n",
            "Train: loss: 0.5332 | accuracy: 0.7309 | f-acore: 0.7288\n",
            "Test:  loss: 1.0221 | accuracy: 0.4932 | f1: 0.4809\n",
            "Validation:  loss: 0.9432 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00209\n",
            "Train: loss: 0.5295 | accuracy: 0.7254 | f-acore: 0.7230\n",
            "Test:  loss: 1.0336 | accuracy: 0.5068 | f1: 0.4875\n",
            "Validation:  loss: 0.9320 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00210\n",
            "Train: loss: 0.5385 | accuracy: 0.7166 | f-acore: 0.7113\n",
            "Test:  loss: 1.0441 | accuracy: 0.5096 | f1: 0.4848\n",
            "Validation:  loss: 0.9652 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00211\n",
            "Train: loss: 0.5554 | accuracy: 0.7157 | f-acore: 0.7127\n",
            "Test:  loss: 1.0016 | accuracy: 0.5178 | f1: 0.5058\n",
            "Validation:  loss: 0.9344 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00212\n",
            "Train: loss: 0.5596 | accuracy: 0.7180 | f-acore: 0.7165\n",
            "Test:  loss: 0.9707 | accuracy: 0.5068 | f1: 0.4985\n",
            "Validation:  loss: 0.8987 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00213\n",
            "Train: loss: 0.5425 | accuracy: 0.7276 | f-acore: 0.7243\n",
            "Test:  loss: 1.0014 | accuracy: 0.5068 | f1: 0.4851\n",
            "Validation:  loss: 0.9441 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00214\n",
            "Train: loss: 0.5426 | accuracy: 0.7263 | f-acore: 0.7232\n",
            "Test:  loss: 0.9649 | accuracy: 0.5342 | f1: 0.5137\n",
            "Validation:  loss: 0.9451 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00215\n",
            "Train: loss: 0.5424 | accuracy: 0.7276 | f-acore: 0.7250\n",
            "Test:  loss: 1.0083 | accuracy: 0.5178 | f1: 0.4812\n",
            "Validation:  loss: 0.9541 | accuracy: 0.6071 | f1: 0.6066\n",
            "Epoch 00216\n",
            "Train: loss: 0.5383 | accuracy: 0.7276 | f-acore: 0.7243\n",
            "Test:  loss: 0.9811 | accuracy: 0.5178 | f1: 0.4828\n",
            "Validation:  loss: 0.9533 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00217\n",
            "Train: loss: 0.5524 | accuracy: 0.7322 | f-acore: 0.7302\n",
            "Test:  loss: 0.9870 | accuracy: 0.5151 | f1: 0.4976\n",
            "Validation:  loss: 0.9472 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00218\n",
            "Train: loss: 0.5306 | accuracy: 0.7336 | f-acore: 0.7326\n",
            "Test:  loss: 1.0178 | accuracy: 0.5068 | f1: 0.4875\n",
            "Validation:  loss: 0.9575 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00219\n",
            "Train: loss: 0.5438 | accuracy: 0.7263 | f-acore: 0.7229\n",
            "Test:  loss: 1.1002 | accuracy: 0.5041 | f1: 0.4735\n",
            "Validation:  loss: 0.9920 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00220\n",
            "Train: loss: 0.5363 | accuracy: 0.7217 | f-acore: 0.7190\n",
            "Test:  loss: 1.0957 | accuracy: 0.5014 | f1: 0.4794\n",
            "Validation:  loss: 0.9814 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00221\n",
            "Train: loss: 0.5357 | accuracy: 0.7221 | f-acore: 0.7175\n",
            "Test:  loss: 1.0499 | accuracy: 0.4959 | f1: 0.4670\n",
            "Validation:  loss: 0.9531 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00222\n",
            "Train: loss: 0.5411 | accuracy: 0.7235 | f-acore: 0.7217\n",
            "Test:  loss: 1.0439 | accuracy: 0.4877 | f1: 0.4681\n",
            "Validation:  loss: 0.9640 | accuracy: 0.5952 | f1: 0.5950\n",
            "Epoch 00223\n",
            "Train: loss: 0.5494 | accuracy: 0.7276 | f-acore: 0.7236\n",
            "Test:  loss: 1.0242 | accuracy: 0.5068 | f1: 0.4851\n",
            "Validation:  loss: 0.9483 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00224\n",
            "Train: loss: 0.5576 | accuracy: 0.7318 | f-acore: 0.7302\n",
            "Test:  loss: 0.9730 | accuracy: 0.5370 | f1: 0.5232\n",
            "Validation:  loss: 0.9698 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00225\n",
            "Train: loss: 0.5219 | accuracy: 0.7299 | f-acore: 0.7257\n",
            "Test:  loss: 1.0232 | accuracy: 0.5123 | f1: 0.4857\n",
            "Validation:  loss: 0.9623 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00226\n",
            "Train: loss: 0.5300 | accuracy: 0.7322 | f-acore: 0.7288\n",
            "Test:  loss: 1.0058 | accuracy: 0.5123 | f1: 0.4983\n",
            "Validation:  loss: 0.9487 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00227\n",
            "Train: loss: 0.5203 | accuracy: 0.7281 | f-acore: 0.7257\n",
            "Test:  loss: 1.0021 | accuracy: 0.5123 | f1: 0.4932\n",
            "Validation:  loss: 0.9379 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00228\n",
            "Train: loss: 0.5379 | accuracy: 0.7208 | f-acore: 0.7183\n",
            "Test:  loss: 1.0022 | accuracy: 0.5096 | f1: 0.4920\n",
            "Validation:  loss: 0.9533 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00229\n",
            "Train: loss: 0.5419 | accuracy: 0.7295 | f-acore: 0.7257\n",
            "Test:  loss: 1.0124 | accuracy: 0.5123 | f1: 0.4871\n",
            "Validation:  loss: 0.9832 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00230\n",
            "Train: loss: 0.5318 | accuracy: 0.7318 | f-acore: 0.7268\n",
            "Test:  loss: 1.0533 | accuracy: 0.5178 | f1: 0.5030\n",
            "Validation:  loss: 0.9839 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00231\n",
            "Train: loss: 0.5568 | accuracy: 0.7235 | f-acore: 0.7190\n",
            "Test:  loss: 1.0108 | accuracy: 0.4986 | f1: 0.4827\n",
            "Validation:  loss: 0.9631 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00232\n",
            "Train: loss: 0.5410 | accuracy: 0.7364 | f-acore: 0.7311\n",
            "Test:  loss: 1.0119 | accuracy: 0.5205 | f1: 0.5033\n",
            "Validation:  loss: 0.9885 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00233\n",
            "Train: loss: 0.5389 | accuracy: 0.7221 | f-acore: 0.7193\n",
            "Test:  loss: 1.0362 | accuracy: 0.5041 | f1: 0.4938\n",
            "Validation:  loss: 1.0231 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00234\n",
            "Train: loss: 0.5492 | accuracy: 0.7313 | f-acore: 0.7290\n",
            "Test:  loss: 0.9887 | accuracy: 0.5205 | f1: 0.5098\n",
            "Validation:  loss: 0.9322 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00235\n",
            "Train: loss: 0.5398 | accuracy: 0.7254 | f-acore: 0.7224\n",
            "Test:  loss: 0.9701 | accuracy: 0.5151 | f1: 0.5079\n",
            "Validation:  loss: 0.9706 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00236\n",
            "Train: loss: 0.5272 | accuracy: 0.7368 | f-acore: 0.7342\n",
            "Test:  loss: 1.0022 | accuracy: 0.5068 | f1: 0.5017\n",
            "Validation:  loss: 1.0109 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00237\n",
            "Train: loss: 0.5327 | accuracy: 0.7405 | f-acore: 0.7379\n",
            "Test:  loss: 1.0252 | accuracy: 0.4959 | f1: 0.4859\n",
            "Validation:  loss: 0.9547 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00238\n",
            "Train: loss: 0.5425 | accuracy: 0.7290 | f-acore: 0.7256\n",
            "Test:  loss: 1.0136 | accuracy: 0.5123 | f1: 0.4974\n",
            "Validation:  loss: 0.9257 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00239\n",
            "Train: loss: 0.5251 | accuracy: 0.7409 | f-acore: 0.7370\n",
            "Test:  loss: 0.9552 | accuracy: 0.5288 | f1: 0.5178\n",
            "Validation:  loss: 0.9633 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00240\n",
            "Train: loss: 0.5331 | accuracy: 0.7322 | f-acore: 0.7301\n",
            "Test:  loss: 0.9962 | accuracy: 0.5068 | f1: 0.5005\n",
            "Validation:  loss: 0.9941 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00241\n",
            "Train: loss: 0.5408 | accuracy: 0.7286 | f-acore: 0.7248\n",
            "Test:  loss: 1.0266 | accuracy: 0.5178 | f1: 0.5020\n",
            "Validation:  loss: 0.9887 | accuracy: 0.5952 | f1: 0.5950\n",
            "Epoch 00242\n",
            "Train: loss: 0.5059 | accuracy: 0.7373 | f-acore: 0.7323\n",
            "Test:  loss: 1.0243 | accuracy: 0.5041 | f1: 0.4922\n",
            "Validation:  loss: 1.0030 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00243\n",
            "Train: loss: 0.5343 | accuracy: 0.7341 | f-acore: 0.7298\n",
            "Test:  loss: 1.0167 | accuracy: 0.5123 | f1: 0.5010\n",
            "Validation:  loss: 0.9926 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00244\n",
            "Train: loss: 0.5471 | accuracy: 0.7281 | f-acore: 0.7245\n",
            "Test:  loss: 0.9930 | accuracy: 0.5151 | f1: 0.5050\n",
            "Validation:  loss: 0.9289 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00245\n",
            "Train: loss: 0.5610 | accuracy: 0.7221 | f-acore: 0.7152\n",
            "Test:  loss: 0.9975 | accuracy: 0.5096 | f1: 0.4930\n",
            "Validation:  loss: 0.9026 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00246\n",
            "Train: loss: 0.5218 | accuracy: 0.7281 | f-acore: 0.7242\n",
            "Test:  loss: 0.9998 | accuracy: 0.5041 | f1: 0.4922\n",
            "Validation:  loss: 0.9589 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00247\n",
            "Train: loss: 0.5170 | accuracy: 0.7331 | f-acore: 0.7299\n",
            "Test:  loss: 1.0488 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 0.9861 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00248\n",
            "Train: loss: 0.5301 | accuracy: 0.7221 | f-acore: 0.7181\n",
            "Test:  loss: 1.0517 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 0.9969 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00249\n",
            "Train: loss: 0.5425 | accuracy: 0.7272 | f-acore: 0.7237\n",
            "Test:  loss: 1.0199 | accuracy: 0.5096 | f1: 0.4994\n",
            "Validation:  loss: 0.9481 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00250\n",
            "Train: loss: 0.5298 | accuracy: 0.7244 | f-acore: 0.7225\n",
            "Test:  loss: 1.0397 | accuracy: 0.5096 | f1: 0.5010\n",
            "Validation:  loss: 1.0093 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00251\n",
            "Train: loss: 0.5084 | accuracy: 0.7428 | f-acore: 0.7411\n",
            "Test:  loss: 1.0199 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 0.9774 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00252\n",
            "Train: loss: 0.5264 | accuracy: 0.7414 | f-acore: 0.7392\n",
            "Test:  loss: 1.0656 | accuracy: 0.4932 | f1: 0.4850\n",
            "Validation:  loss: 1.0420 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00253\n",
            "Train: loss: 0.5393 | accuracy: 0.7377 | f-acore: 0.7361\n",
            "Test:  loss: 1.0527 | accuracy: 0.4822 | f1: 0.4777\n",
            "Validation:  loss: 1.0293 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00254\n",
            "Train: loss: 0.5312 | accuracy: 0.7318 | f-acore: 0.7283\n",
            "Test:  loss: 1.0613 | accuracy: 0.4986 | f1: 0.4827\n",
            "Validation:  loss: 0.9950 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00255\n",
            "Train: loss: 0.5549 | accuracy: 0.7313 | f-acore: 0.7288\n",
            "Test:  loss: 1.0952 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 1.0049 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00256\n",
            "Train: loss: 0.5304 | accuracy: 0.7304 | f-acore: 0.7277\n",
            "Test:  loss: 1.0620 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 0.9868 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00257\n",
            "Train: loss: 0.5225 | accuracy: 0.7276 | f-acore: 0.7241\n",
            "Test:  loss: 1.0515 | accuracy: 0.4822 | f1: 0.4752\n",
            "Validation:  loss: 1.0146 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00258\n",
            "Train: loss: 0.5264 | accuracy: 0.7419 | f-acore: 0.7395\n",
            "Test:  loss: 1.1156 | accuracy: 0.4877 | f1: 0.4787\n",
            "Validation:  loss: 1.0220 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00259\n",
            "Train: loss: 0.5250 | accuracy: 0.7345 | f-acore: 0.7308\n",
            "Test:  loss: 1.0949 | accuracy: 0.4959 | f1: 0.4842\n",
            "Validation:  loss: 1.0211 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00260\n",
            "Train: loss: 0.5163 | accuracy: 0.7405 | f-acore: 0.7383\n",
            "Test:  loss: 1.0908 | accuracy: 0.4986 | f1: 0.4847\n",
            "Validation:  loss: 1.0034 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00261\n",
            "Train: loss: 0.5127 | accuracy: 0.7350 | f-acore: 0.7308\n",
            "Test:  loss: 1.1144 | accuracy: 0.4904 | f1: 0.4726\n",
            "Validation:  loss: 0.9797 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00262\n",
            "Train: loss: 0.5037 | accuracy: 0.7446 | f-acore: 0.7410\n",
            "Test:  loss: 1.1285 | accuracy: 0.4932 | f1: 0.4791\n",
            "Validation:  loss: 1.0224 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00263\n",
            "Train: loss: 0.5057 | accuracy: 0.7487 | f-acore: 0.7453\n",
            "Test:  loss: 1.0798 | accuracy: 0.5068 | f1: 0.4917\n",
            "Validation:  loss: 0.9914 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00264\n",
            "Train: loss: 0.5103 | accuracy: 0.7387 | f-acore: 0.7366\n",
            "Test:  loss: 1.0648 | accuracy: 0.5041 | f1: 0.4968\n",
            "Validation:  loss: 0.9680 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00265\n",
            "Train: loss: 0.5242 | accuracy: 0.7281 | f-acore: 0.7253\n",
            "Test:  loss: 1.1150 | accuracy: 0.4959 | f1: 0.4859\n",
            "Validation:  loss: 1.0160 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00266\n",
            "Train: loss: 0.5263 | accuracy: 0.7428 | f-acore: 0.7402\n",
            "Test:  loss: 1.1023 | accuracy: 0.4904 | f1: 0.4811\n",
            "Validation:  loss: 1.0332 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00267\n",
            "Train: loss: 0.5511 | accuracy: 0.7391 | f-acore: 0.7373\n",
            "Test:  loss: 1.0508 | accuracy: 0.4959 | f1: 0.4894\n",
            "Validation:  loss: 1.0101 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00268\n",
            "Train: loss: 0.5283 | accuracy: 0.7331 | f-acore: 0.7315\n",
            "Test:  loss: 1.0366 | accuracy: 0.4986 | f1: 0.4925\n",
            "Validation:  loss: 1.0335 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00269\n",
            "Train: loss: 0.5301 | accuracy: 0.7474 | f-acore: 0.7462\n",
            "Test:  loss: 1.0665 | accuracy: 0.4932 | f1: 0.4818\n",
            "Validation:  loss: 1.0146 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00270\n",
            "Train: loss: 0.5087 | accuracy: 0.7474 | f-acore: 0.7442\n",
            "Test:  loss: 1.0594 | accuracy: 0.5233 | f1: 0.5086\n",
            "Validation:  loss: 0.9683 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00271\n",
            "Train: loss: 0.5235 | accuracy: 0.7364 | f-acore: 0.7326\n",
            "Test:  loss: 1.0865 | accuracy: 0.5151 | f1: 0.4966\n",
            "Validation:  loss: 1.0058 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00272\n",
            "Train: loss: 0.5055 | accuracy: 0.7492 | f-acore: 0.7453\n",
            "Test:  loss: 1.1078 | accuracy: 0.5041 | f1: 0.4852\n",
            "Validation:  loss: 1.0016 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00273\n",
            "Train: loss: 0.5196 | accuracy: 0.7478 | f-acore: 0.7451\n",
            "Test:  loss: 1.1244 | accuracy: 0.4904 | f1: 0.4803\n",
            "Validation:  loss: 1.0446 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00274\n",
            "Train: loss: 0.5082 | accuracy: 0.7341 | f-acore: 0.7318\n",
            "Test:  loss: 1.1031 | accuracy: 0.5068 | f1: 0.4945\n",
            "Validation:  loss: 1.0426 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00275\n",
            "Train: loss: 0.5123 | accuracy: 0.7524 | f-acore: 0.7500\n",
            "Test:  loss: 1.1339 | accuracy: 0.5233 | f1: 0.5056\n",
            "Validation:  loss: 1.0770 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00276\n",
            "Train: loss: 0.5218 | accuracy: 0.7382 | f-acore: 0.7365\n",
            "Test:  loss: 1.1209 | accuracy: 0.5233 | f1: 0.5034\n",
            "Validation:  loss: 1.0838 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00277\n",
            "Train: loss: 0.5173 | accuracy: 0.7432 | f-acore: 0.7393\n",
            "Test:  loss: 1.1564 | accuracy: 0.5123 | f1: 0.4871\n",
            "Validation:  loss: 1.0827 | accuracy: 0.4524 | f1: 0.4511\n",
            "Epoch 00278\n",
            "Train: loss: 0.5139 | accuracy: 0.7368 | f-acore: 0.7301\n",
            "Test:  loss: 1.1085 | accuracy: 0.5123 | f1: 0.4964\n",
            "Validation:  loss: 1.0296 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00279\n",
            "Train: loss: 0.5007 | accuracy: 0.7483 | f-acore: 0.7457\n",
            "Test:  loss: 1.1401 | accuracy: 0.5014 | f1: 0.4880\n",
            "Validation:  loss: 1.1107 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00280\n",
            "Train: loss: 0.5118 | accuracy: 0.7455 | f-acore: 0.7427\n",
            "Test:  loss: 1.0986 | accuracy: 0.5151 | f1: 0.4893\n",
            "Validation:  loss: 1.0413 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00281\n",
            "Train: loss: 0.5248 | accuracy: 0.7409 | f-acore: 0.7382\n",
            "Test:  loss: 1.0978 | accuracy: 0.5068 | f1: 0.4851\n",
            "Validation:  loss: 1.0210 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00282\n",
            "Train: loss: 0.5009 | accuracy: 0.7387 | f-acore: 0.7355\n",
            "Test:  loss: 1.1184 | accuracy: 0.5068 | f1: 0.4786\n",
            "Validation:  loss: 1.0417 | accuracy: 0.4643 | f1: 0.4642\n",
            "Epoch 00283\n",
            "Train: loss: 0.5148 | accuracy: 0.7515 | f-acore: 0.7495\n",
            "Test:  loss: 1.1387 | accuracy: 0.5151 | f1: 0.4919\n",
            "Validation:  loss: 1.0647 | accuracy: 0.4762 | f1: 0.4762\n",
            "Epoch 00284\n",
            "Train: loss: 0.4948 | accuracy: 0.7538 | f-acore: 0.7507\n",
            "Test:  loss: 1.1678 | accuracy: 0.5041 | f1: 0.4764\n",
            "Validation:  loss: 1.0624 | accuracy: 0.4643 | f1: 0.4605\n",
            "Epoch 00285\n",
            "Train: loss: 0.4965 | accuracy: 0.7474 | f-acore: 0.7433\n",
            "Test:  loss: 1.2045 | accuracy: 0.5014 | f1: 0.4713\n",
            "Validation:  loss: 1.0767 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00286\n",
            "Train: loss: 0.5071 | accuracy: 0.7331 | f-acore: 0.7288\n",
            "Test:  loss: 1.0959 | accuracy: 0.5151 | f1: 0.4954\n",
            "Validation:  loss: 1.0132 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00287\n",
            "Train: loss: 0.5096 | accuracy: 0.7497 | f-acore: 0.7461\n",
            "Test:  loss: 1.1422 | accuracy: 0.5096 | f1: 0.4808\n",
            "Validation:  loss: 1.0734 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00288\n",
            "Train: loss: 0.4919 | accuracy: 0.7451 | f-acore: 0.7417\n",
            "Test:  loss: 1.1656 | accuracy: 0.5041 | f1: 0.4816\n",
            "Validation:  loss: 1.0922 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00289\n",
            "Train: loss: 0.5017 | accuracy: 0.7611 | f-acore: 0.7584\n",
            "Test:  loss: 1.1098 | accuracy: 0.5205 | f1: 0.4976\n",
            "Validation:  loss: 1.0474 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00290\n",
            "Train: loss: 0.5245 | accuracy: 0.7547 | f-acore: 0.7514\n",
            "Test:  loss: 1.1642 | accuracy: 0.5068 | f1: 0.4813\n",
            "Validation:  loss: 1.0872 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00291\n",
            "Train: loss: 0.5130 | accuracy: 0.7547 | f-acore: 0.7524\n",
            "Test:  loss: 1.1475 | accuracy: 0.5068 | f1: 0.4886\n",
            "Validation:  loss: 1.0463 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00292\n",
            "Train: loss: 0.5045 | accuracy: 0.7428 | f-acore: 0.7379\n",
            "Test:  loss: 1.1176 | accuracy: 0.5178 | f1: 0.4915\n",
            "Validation:  loss: 1.0168 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00293\n",
            "Train: loss: 0.5051 | accuracy: 0.7474 | f-acore: 0.7444\n",
            "Test:  loss: 1.0888 | accuracy: 0.5068 | f1: 0.4962\n",
            "Validation:  loss: 1.0301 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00294\n",
            "Train: loss: 0.5018 | accuracy: 0.7428 | f-acore: 0.7409\n",
            "Test:  loss: 1.1319 | accuracy: 0.5123 | f1: 0.4920\n",
            "Validation:  loss: 1.0749 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00295\n",
            "Train: loss: 0.5236 | accuracy: 0.7423 | f-acore: 0.7393\n",
            "Test:  loss: 1.1105 | accuracy: 0.5260 | f1: 0.5079\n",
            "Validation:  loss: 1.0617 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00296\n",
            "Train: loss: 0.5049 | accuracy: 0.7492 | f-acore: 0.7468\n",
            "Test:  loss: 1.0711 | accuracy: 0.5205 | f1: 0.5053\n",
            "Validation:  loss: 1.0269 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00297\n",
            "Train: loss: 0.5123 | accuracy: 0.7474 | f-acore: 0.7439\n",
            "Test:  loss: 1.0962 | accuracy: 0.4986 | f1: 0.4733\n",
            "Validation:  loss: 1.0441 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00298\n",
            "Train: loss: 0.5058 | accuracy: 0.7442 | f-acore: 0.7400\n",
            "Test:  loss: 1.0772 | accuracy: 0.5041 | f1: 0.4804\n",
            "Validation:  loss: 1.0116 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00299\n",
            "Train: loss: 0.5195 | accuracy: 0.7657 | f-acore: 0.7631\n",
            "Test:  loss: 1.0561 | accuracy: 0.5342 | f1: 0.5199\n",
            "Validation:  loss: 1.0137 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00300\n",
            "Train: loss: 0.5141 | accuracy: 0.7524 | f-acore: 0.7508\n",
            "Test:  loss: 1.0878 | accuracy: 0.5397 | f1: 0.5216\n",
            "Validation:  loss: 1.0262 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00301\n",
            "Train: loss: 0.5178 | accuracy: 0.7497 | f-acore: 0.7463\n",
            "Test:  loss: 1.1210 | accuracy: 0.5233 | f1: 0.4986\n",
            "Validation:  loss: 1.0199 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00302\n",
            "Train: loss: 0.4982 | accuracy: 0.7487 | f-acore: 0.7467\n",
            "Test:  loss: 1.0012 | accuracy: 0.5288 | f1: 0.4990\n",
            "Validation:  loss: 0.9728 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00303\n",
            "Train: loss: 0.5148 | accuracy: 0.7400 | f-acore: 0.7367\n",
            "Test:  loss: 1.0750 | accuracy: 0.5205 | f1: 0.5011\n",
            "Validation:  loss: 1.0165 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00304\n",
            "Train: loss: 0.4798 | accuracy: 0.7607 | f-acore: 0.7583\n",
            "Test:  loss: 1.1336 | accuracy: 0.5151 | f1: 0.4976\n",
            "Validation:  loss: 1.0328 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00305\n",
            "Train: loss: 0.4967 | accuracy: 0.7487 | f-acore: 0.7469\n",
            "Test:  loss: 1.0804 | accuracy: 0.5260 | f1: 0.5100\n",
            "Validation:  loss: 1.0224 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00306\n",
            "Train: loss: 0.5282 | accuracy: 0.7542 | f-acore: 0.7530\n",
            "Test:  loss: 1.0624 | accuracy: 0.5123 | f1: 0.5018\n",
            "Validation:  loss: 1.0337 | accuracy: 0.4762 | f1: 0.4735\n",
            "Epoch 00307\n",
            "Train: loss: 0.5204 | accuracy: 0.7428 | f-acore: 0.7377\n",
            "Test:  loss: 1.1535 | accuracy: 0.5233 | f1: 0.4999\n",
            "Validation:  loss: 1.0871 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00308\n",
            "Train: loss: 0.5039 | accuracy: 0.7451 | f-acore: 0.7411\n",
            "Test:  loss: 1.1180 | accuracy: 0.4986 | f1: 0.4856\n",
            "Validation:  loss: 1.0827 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00309\n",
            "Train: loss: 0.4932 | accuracy: 0.7570 | f-acore: 0.7548\n",
            "Test:  loss: 1.1396 | accuracy: 0.5096 | f1: 0.4950\n",
            "Validation:  loss: 1.0813 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00310\n",
            "Train: loss: 0.4911 | accuracy: 0.7492 | f-acore: 0.7466\n",
            "Test:  loss: 1.1532 | accuracy: 0.5123 | f1: 0.4983\n",
            "Validation:  loss: 1.0936 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00311\n",
            "Train: loss: 0.4902 | accuracy: 0.7552 | f-acore: 0.7534\n",
            "Test:  loss: 1.1736 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 1.1071 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00312\n",
            "Train: loss: 0.4874 | accuracy: 0.7533 | f-acore: 0.7507\n",
            "Test:  loss: 1.1915 | accuracy: 0.4959 | f1: 0.4772\n",
            "Validation:  loss: 1.0931 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00313\n",
            "Train: loss: 0.5070 | accuracy: 0.7409 | f-acore: 0.7383\n",
            "Test:  loss: 1.1821 | accuracy: 0.5014 | f1: 0.4850\n",
            "Validation:  loss: 1.1032 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00314\n",
            "Train: loss: 0.4876 | accuracy: 0.7602 | f-acore: 0.7579\n",
            "Test:  loss: 1.1489 | accuracy: 0.5151 | f1: 0.4976\n",
            "Validation:  loss: 1.0814 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00315\n",
            "Train: loss: 0.5000 | accuracy: 0.7602 | f-acore: 0.7568\n",
            "Test:  loss: 1.1699 | accuracy: 0.4932 | f1: 0.4738\n",
            "Validation:  loss: 1.1233 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00316\n",
            "Train: loss: 0.5033 | accuracy: 0.7561 | f-acore: 0.7533\n",
            "Test:  loss: 1.1695 | accuracy: 0.5014 | f1: 0.4818\n",
            "Validation:  loss: 1.1110 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00317\n",
            "Train: loss: 0.4918 | accuracy: 0.7639 | f-acore: 0.7625\n",
            "Test:  loss: 1.1877 | accuracy: 0.4959 | f1: 0.4804\n",
            "Validation:  loss: 1.1001 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00318\n",
            "Train: loss: 0.5039 | accuracy: 0.7529 | f-acore: 0.7500\n",
            "Test:  loss: 1.2047 | accuracy: 0.5014 | f1: 0.4769\n",
            "Validation:  loss: 1.0868 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00319\n",
            "Train: loss: 0.5011 | accuracy: 0.7524 | f-acore: 0.7501\n",
            "Test:  loss: 1.1492 | accuracy: 0.5123 | f1: 0.4983\n",
            "Validation:  loss: 1.0950 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00320\n",
            "Train: loss: 0.5096 | accuracy: 0.7382 | f-acore: 0.7365\n",
            "Test:  loss: 1.1264 | accuracy: 0.5068 | f1: 0.4927\n",
            "Validation:  loss: 1.0789 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00321\n",
            "Train: loss: 0.4908 | accuracy: 0.7442 | f-acore: 0.7411\n",
            "Test:  loss: 1.1687 | accuracy: 0.5096 | f1: 0.4897\n",
            "Validation:  loss: 1.0980 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00322\n",
            "Train: loss: 0.5024 | accuracy: 0.7607 | f-acore: 0.7586\n",
            "Test:  loss: 1.1844 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 1.0935 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00323\n",
            "Train: loss: 0.5000 | accuracy: 0.7561 | f-acore: 0.7534\n",
            "Test:  loss: 1.1889 | accuracy: 0.4986 | f1: 0.4847\n",
            "Validation:  loss: 1.1033 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00324\n",
            "Train: loss: 0.4812 | accuracy: 0.7515 | f-acore: 0.7494\n",
            "Test:  loss: 1.1456 | accuracy: 0.5123 | f1: 0.4964\n",
            "Validation:  loss: 1.0716 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00325\n",
            "Train: loss: 0.5049 | accuracy: 0.7501 | f-acore: 0.7479\n",
            "Test:  loss: 1.1833 | accuracy: 0.5014 | f1: 0.4818\n",
            "Validation:  loss: 1.1039 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00326\n",
            "Train: loss: 0.4877 | accuracy: 0.7607 | f-acore: 0.7584\n",
            "Test:  loss: 1.1832 | accuracy: 0.5178 | f1: 0.5020\n",
            "Validation:  loss: 1.1133 | accuracy: 0.4643 | f1: 0.4624\n",
            "Epoch 00327\n",
            "Train: loss: 0.4913 | accuracy: 0.7533 | f-acore: 0.7507\n",
            "Test:  loss: 1.1758 | accuracy: 0.5014 | f1: 0.4806\n",
            "Validation:  loss: 1.1022 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00328\n",
            "Train: loss: 0.4889 | accuracy: 0.7497 | f-acore: 0.7466\n",
            "Test:  loss: 1.1812 | accuracy: 0.5233 | f1: 0.4999\n",
            "Validation:  loss: 1.0752 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00329\n",
            "Train: loss: 0.4725 | accuracy: 0.7639 | f-acore: 0.7619\n",
            "Test:  loss: 1.1448 | accuracy: 0.5041 | f1: 0.4816\n",
            "Validation:  loss: 1.0557 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00330\n",
            "Train: loss: 0.5036 | accuracy: 0.7648 | f-acore: 0.7621\n",
            "Test:  loss: 1.1771 | accuracy: 0.5068 | f1: 0.4863\n",
            "Validation:  loss: 1.0773 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00331\n",
            "Train: loss: 0.5009 | accuracy: 0.7579 | f-acore: 0.7557\n",
            "Test:  loss: 1.1386 | accuracy: 0.4932 | f1: 0.4749\n",
            "Validation:  loss: 1.0517 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00332\n",
            "Train: loss: 0.4996 | accuracy: 0.7556 | f-acore: 0.7518\n",
            "Test:  loss: 1.1970 | accuracy: 0.5178 | f1: 0.4941\n",
            "Validation:  loss: 1.1205 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00333\n",
            "Train: loss: 0.4909 | accuracy: 0.7519 | f-acore: 0.7489\n",
            "Test:  loss: 1.1003 | accuracy: 0.5123 | f1: 0.4943\n",
            "Validation:  loss: 1.0556 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00334\n",
            "Train: loss: 0.5183 | accuracy: 0.7524 | f-acore: 0.7500\n",
            "Test:  loss: 1.0916 | accuracy: 0.5288 | f1: 0.5133\n",
            "Validation:  loss: 1.0259 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00335\n",
            "Train: loss: 0.4982 | accuracy: 0.7597 | f-acore: 0.7564\n",
            "Test:  loss: 1.1828 | accuracy: 0.5178 | f1: 0.4966\n",
            "Validation:  loss: 1.0849 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00336\n",
            "Train: loss: 0.4936 | accuracy: 0.7538 | f-acore: 0.7507\n",
            "Test:  loss: 1.1489 | accuracy: 0.5041 | f1: 0.4873\n",
            "Validation:  loss: 1.0603 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00337\n",
            "Train: loss: 0.5168 | accuracy: 0.7533 | f-acore: 0.7495\n",
            "Test:  loss: 1.0719 | accuracy: 0.5233 | f1: 0.5122\n",
            "Validation:  loss: 1.0425 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00338\n",
            "Train: loss: 0.4746 | accuracy: 0.7533 | f-acore: 0.7519\n",
            "Test:  loss: 1.1351 | accuracy: 0.5014 | f1: 0.4870\n",
            "Validation:  loss: 1.0806 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00339\n",
            "Train: loss: 0.4871 | accuracy: 0.7515 | f-acore: 0.7493\n",
            "Test:  loss: 1.1651 | accuracy: 0.5041 | f1: 0.4884\n",
            "Validation:  loss: 1.0937 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00340\n",
            "Train: loss: 0.5016 | accuracy: 0.7611 | f-acore: 0.7577\n",
            "Test:  loss: 1.1888 | accuracy: 0.5151 | f1: 0.4976\n",
            "Validation:  loss: 1.1191 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00341\n",
            "Train: loss: 0.4715 | accuracy: 0.7662 | f-acore: 0.7642\n",
            "Test:  loss: 1.1654 | accuracy: 0.5068 | f1: 0.4936\n",
            "Validation:  loss: 1.1246 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00342\n",
            "Train: loss: 0.4858 | accuracy: 0.7584 | f-acore: 0.7561\n",
            "Test:  loss: 1.2383 | accuracy: 0.4959 | f1: 0.4794\n",
            "Validation:  loss: 1.1452 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00343\n",
            "Train: loss: 0.5100 | accuracy: 0.7570 | f-acore: 0.7552\n",
            "Test:  loss: 1.1466 | accuracy: 0.5068 | f1: 0.4936\n",
            "Validation:  loss: 1.0884 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00344\n",
            "Train: loss: 0.4927 | accuracy: 0.7616 | f-acore: 0.7583\n",
            "Test:  loss: 1.1390 | accuracy: 0.5178 | f1: 0.4941\n",
            "Validation:  loss: 1.0431 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00345\n",
            "Train: loss: 0.4889 | accuracy: 0.7639 | f-acore: 0.7609\n",
            "Test:  loss: 1.1611 | accuracy: 0.5151 | f1: 0.5007\n",
            "Validation:  loss: 1.0799 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00346\n",
            "Train: loss: 0.4882 | accuracy: 0.7630 | f-acore: 0.7602\n",
            "Test:  loss: 1.1711 | accuracy: 0.5205 | f1: 0.5033\n",
            "Validation:  loss: 1.1053 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00347\n",
            "Train: loss: 0.5064 | accuracy: 0.7565 | f-acore: 0.7550\n",
            "Test:  loss: 1.1577 | accuracy: 0.5123 | f1: 0.5034\n",
            "Validation:  loss: 1.1252 | accuracy: 0.4643 | f1: 0.4624\n",
            "Epoch 00348\n",
            "Train: loss: 0.5216 | accuracy: 0.7620 | f-acore: 0.7603\n",
            "Test:  loss: 1.1058 | accuracy: 0.4959 | f1: 0.4874\n",
            "Validation:  loss: 1.0602 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00349\n",
            "Train: loss: 0.5028 | accuracy: 0.7588 | f-acore: 0.7545\n",
            "Test:  loss: 1.1531 | accuracy: 0.5041 | f1: 0.4778\n",
            "Validation:  loss: 1.0737 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00350\n",
            "Train: loss: 0.4928 | accuracy: 0.7547 | f-acore: 0.7511\n",
            "Test:  loss: 1.0534 | accuracy: 0.4849 | f1: 0.4821\n",
            "Validation:  loss: 1.0584 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00351\n",
            "Train: loss: 0.4876 | accuracy: 0.7533 | f-acore: 0.7521\n",
            "Test:  loss: 1.2009 | accuracy: 0.4849 | f1: 0.4755\n",
            "Validation:  loss: 1.1412 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00352\n",
            "Train: loss: 0.4746 | accuracy: 0.7666 | f-acore: 0.7640\n",
            "Test:  loss: 1.2520 | accuracy: 0.5068 | f1: 0.4907\n",
            "Validation:  loss: 1.1877 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00353\n",
            "Train: loss: 0.4789 | accuracy: 0.7584 | f-acore: 0.7565\n",
            "Test:  loss: 1.2407 | accuracy: 0.4959 | f1: 0.4772\n",
            "Validation:  loss: 1.1859 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00354\n",
            "Train: loss: 0.4727 | accuracy: 0.7602 | f-acore: 0.7573\n",
            "Test:  loss: 1.1746 | accuracy: 0.4986 | f1: 0.4837\n",
            "Validation:  loss: 1.1293 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00355\n",
            "Train: loss: 0.4646 | accuracy: 0.7579 | f-acore: 0.7557\n",
            "Test:  loss: 1.1922 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 1.1588 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00356\n",
            "Train: loss: 0.4814 | accuracy: 0.7575 | f-acore: 0.7548\n",
            "Test:  loss: 1.1686 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 1.1405 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00357\n",
            "Train: loss: 0.4681 | accuracy: 0.7634 | f-acore: 0.7605\n",
            "Test:  loss: 1.1870 | accuracy: 0.5151 | f1: 0.4997\n",
            "Validation:  loss: 1.1423 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00358\n",
            "Train: loss: 0.4719 | accuracy: 0.7662 | f-acore: 0.7637\n",
            "Test:  loss: 1.2373 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 1.2019 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00359\n",
            "Train: loss: 0.4946 | accuracy: 0.7593 | f-acore: 0.7575\n",
            "Test:  loss: 1.2416 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 1.1986 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00360\n",
            "Train: loss: 0.5037 | accuracy: 0.7767 | f-acore: 0.7742\n",
            "Test:  loss: 1.1794 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 1.1437 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00361\n",
            "Train: loss: 0.4924 | accuracy: 0.7538 | f-acore: 0.7488\n",
            "Test:  loss: 1.1353 | accuracy: 0.5288 | f1: 0.5123\n",
            "Validation:  loss: 1.1326 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00362\n",
            "Train: loss: 0.5040 | accuracy: 0.7547 | f-acore: 0.7516\n",
            "Test:  loss: 1.1645 | accuracy: 0.5205 | f1: 0.5106\n",
            "Validation:  loss: 1.1618 | accuracy: 0.4524 | f1: 0.4511\n",
            "Epoch 00363\n",
            "Train: loss: 0.4843 | accuracy: 0.7515 | f-acore: 0.7488\n",
            "Test:  loss: 1.1815 | accuracy: 0.5151 | f1: 0.5007\n",
            "Validation:  loss: 1.1562 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00364\n",
            "Train: loss: 0.4800 | accuracy: 0.7529 | f-acore: 0.7505\n",
            "Test:  loss: 1.1570 | accuracy: 0.5233 | f1: 0.5122\n",
            "Validation:  loss: 1.0947 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00365\n",
            "Train: loss: 0.4796 | accuracy: 0.7735 | f-acore: 0.7716\n",
            "Test:  loss: 1.1855 | accuracy: 0.5260 | f1: 0.5119\n",
            "Validation:  loss: 1.1633 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00366\n",
            "Train: loss: 0.4918 | accuracy: 0.7698 | f-acore: 0.7684\n",
            "Test:  loss: 1.1906 | accuracy: 0.5288 | f1: 0.5123\n",
            "Validation:  loss: 1.1569 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00367\n",
            "Train: loss: 0.5169 | accuracy: 0.7570 | f-acore: 0.7542\n",
            "Test:  loss: 1.2001 | accuracy: 0.5123 | f1: 0.4932\n",
            "Validation:  loss: 1.1351 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00368\n",
            "Train: loss: 0.4875 | accuracy: 0.7487 | f-acore: 0.7459\n",
            "Test:  loss: 1.0643 | accuracy: 0.5288 | f1: 0.5143\n",
            "Validation:  loss: 1.0157 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00369\n",
            "Train: loss: 0.4926 | accuracy: 0.7611 | f-acore: 0.7581\n",
            "Test:  loss: 1.1081 | accuracy: 0.5205 | f1: 0.5081\n",
            "Validation:  loss: 1.0640 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00370\n",
            "Train: loss: 0.4979 | accuracy: 0.7519 | f-acore: 0.7492\n",
            "Test:  loss: 1.2235 | accuracy: 0.5041 | f1: 0.4863\n",
            "Validation:  loss: 1.1921 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00371\n",
            "Train: loss: 0.4903 | accuracy: 0.7643 | f-acore: 0.7631\n",
            "Test:  loss: 1.1443 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 1.1501 | accuracy: 0.4524 | f1: 0.4511\n",
            "Epoch 00372\n",
            "Train: loss: 0.4898 | accuracy: 0.7460 | f-acore: 0.7441\n",
            "Test:  loss: 1.1299 | accuracy: 0.5041 | f1: 0.4987\n",
            "Validation:  loss: 1.0928 | accuracy: 0.4524 | f1: 0.4496\n",
            "Epoch 00373\n",
            "Train: loss: 0.4772 | accuracy: 0.7575 | f-acore: 0.7555\n",
            "Test:  loss: 1.1502 | accuracy: 0.4986 | f1: 0.4874\n",
            "Validation:  loss: 1.0993 | accuracy: 0.4643 | f1: 0.4636\n",
            "Epoch 00374\n",
            "Train: loss: 0.4789 | accuracy: 0.7611 | f-acore: 0.7588\n",
            "Test:  loss: 1.1916 | accuracy: 0.5068 | f1: 0.4970\n",
            "Validation:  loss: 1.1326 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00375\n",
            "Train: loss: 0.4868 | accuracy: 0.7497 | f-acore: 0.7468\n",
            "Test:  loss: 1.1902 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 1.1263 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00376\n",
            "Train: loss: 0.4906 | accuracy: 0.7685 | f-acore: 0.7664\n",
            "Test:  loss: 1.1798 | accuracy: 0.5068 | f1: 0.4985\n",
            "Validation:  loss: 1.1363 | accuracy: 0.4762 | f1: 0.4750\n",
            "Epoch 00377\n",
            "Train: loss: 0.4599 | accuracy: 0.7648 | f-acore: 0.7637\n",
            "Test:  loss: 1.2116 | accuracy: 0.4986 | f1: 0.4890\n",
            "Validation:  loss: 1.1519 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00378\n",
            "Train: loss: 0.4681 | accuracy: 0.7712 | f-acore: 0.7695\n",
            "Test:  loss: 1.1669 | accuracy: 0.5178 | f1: 0.5082\n",
            "Validation:  loss: 1.1329 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00379\n",
            "Train: loss: 0.4616 | accuracy: 0.7685 | f-acore: 0.7656\n",
            "Test:  loss: 1.2524 | accuracy: 0.5178 | f1: 0.5010\n",
            "Validation:  loss: 1.2045 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00380\n",
            "Train: loss: 0.4670 | accuracy: 0.7662 | f-acore: 0.7642\n",
            "Test:  loss: 1.2658 | accuracy: 0.5068 | f1: 0.4962\n",
            "Validation:  loss: 1.2161 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00381\n",
            "Train: loss: 0.4980 | accuracy: 0.7588 | f-acore: 0.7555\n",
            "Test:  loss: 1.1695 | accuracy: 0.5260 | f1: 0.5110\n",
            "Validation:  loss: 1.1073 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00382\n",
            "Train: loss: 0.4723 | accuracy: 0.7717 | f-acore: 0.7699\n",
            "Test:  loss: 1.0643 | accuracy: 0.5260 | f1: 0.5162\n",
            "Validation:  loss: 0.9975 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00383\n",
            "Train: loss: 0.4867 | accuracy: 0.7565 | f-acore: 0.7538\n",
            "Test:  loss: 1.1127 | accuracy: 0.5233 | f1: 0.5034\n",
            "Validation:  loss: 1.0208 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00384\n",
            "Train: loss: 0.4680 | accuracy: 0.7602 | f-acore: 0.7580\n",
            "Test:  loss: 1.1102 | accuracy: 0.5507 | f1: 0.5410\n",
            "Validation:  loss: 1.0795 | accuracy: 0.5238 | f1: 0.5227\n",
            "Epoch 00385\n",
            "Train: loss: 0.4734 | accuracy: 0.7721 | f-acore: 0.7692\n",
            "Test:  loss: 1.1235 | accuracy: 0.5260 | f1: 0.5090\n",
            "Validation:  loss: 1.0432 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00386\n",
            "Train: loss: 0.4872 | accuracy: 0.7744 | f-acore: 0.7713\n",
            "Test:  loss: 1.1339 | accuracy: 0.5288 | f1: 0.5143\n",
            "Validation:  loss: 1.0900 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00387\n",
            "Train: loss: 0.4593 | accuracy: 0.7717 | f-acore: 0.7696\n",
            "Test:  loss: 1.1119 | accuracy: 0.5315 | f1: 0.5218\n",
            "Validation:  loss: 1.0585 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00388\n",
            "Train: loss: 0.4501 | accuracy: 0.7845 | f-acore: 0.7826\n",
            "Test:  loss: 1.1588 | accuracy: 0.5233 | f1: 0.5067\n",
            "Validation:  loss: 1.0993 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00389\n",
            "Train: loss: 0.4820 | accuracy: 0.7685 | f-acore: 0.7664\n",
            "Test:  loss: 1.1781 | accuracy: 0.5233 | f1: 0.5067\n",
            "Validation:  loss: 1.1160 | accuracy: 0.5000 | f1: 0.5000\n",
            "Epoch 00390\n",
            "Train: loss: 0.4763 | accuracy: 0.7657 | f-acore: 0.7632\n",
            "Test:  loss: 1.1541 | accuracy: 0.5233 | f1: 0.5114\n",
            "Validation:  loss: 1.1126 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00391\n",
            "Train: loss: 0.4833 | accuracy: 0.7556 | f-acore: 0.7525\n",
            "Test:  loss: 1.1869 | accuracy: 0.5178 | f1: 0.5020\n",
            "Validation:  loss: 1.1237 | accuracy: 0.4881 | f1: 0.4880\n",
            "Epoch 00392\n",
            "Train: loss: 0.4987 | accuracy: 0.7584 | f-acore: 0.7567\n",
            "Test:  loss: 1.1766 | accuracy: 0.5205 | f1: 0.5063\n",
            "Validation:  loss: 1.1122 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00393\n",
            "Train: loss: 0.5098 | accuracy: 0.7584 | f-acore: 0.7555\n",
            "Test:  loss: 1.1374 | accuracy: 0.5233 | f1: 0.5130\n",
            "Validation:  loss: 1.1213 | accuracy: 0.5238 | f1: 0.5238\n",
            "Epoch 00394\n",
            "Train: loss: 0.4962 | accuracy: 0.7657 | f-acore: 0.7638\n",
            "Test:  loss: 1.1783 | accuracy: 0.5260 | f1: 0.5110\n",
            "Validation:  loss: 1.1758 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00395\n",
            "Train: loss: 0.4583 | accuracy: 0.7602 | f-acore: 0.7580\n",
            "Test:  loss: 1.2547 | accuracy: 0.5178 | f1: 0.4999\n",
            "Validation:  loss: 1.1978 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00396\n",
            "Train: loss: 0.4503 | accuracy: 0.7703 | f-acore: 0.7680\n",
            "Test:  loss: 1.2332 | accuracy: 0.5288 | f1: 0.5133\n",
            "Validation:  loss: 1.1907 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00397\n",
            "Train: loss: 0.4563 | accuracy: 0.7772 | f-acore: 0.7746\n",
            "Test:  loss: 1.2296 | accuracy: 0.5233 | f1: 0.5105\n",
            "Validation:  loss: 1.2060 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00398\n",
            "Train: loss: 0.4780 | accuracy: 0.7790 | f-acore: 0.7769\n",
            "Test:  loss: 1.2050 | accuracy: 0.5288 | f1: 0.5143\n",
            "Validation:  loss: 1.1818 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00399\n",
            "Train: loss: 0.4848 | accuracy: 0.7616 | f-acore: 0.7592\n",
            "Test:  loss: 1.0970 | accuracy: 0.4904 | f1: 0.4737\n",
            "Validation:  loss: 1.1236 | accuracy: 0.4762 | f1: 0.4759\n",
            "Epoch 00400\n",
            "Train: loss: 0.4658 | accuracy: 0.7776 | f-acore: 0.7747\n",
            "Test:  loss: 1.1534 | accuracy: 0.5370 | f1: 0.5213\n",
            "Validation:  loss: 1.1445 | accuracy: 0.4881 | f1: 0.4880\n",
            "-----------------------------------------------------------------------------------------\n",
            "^RUT\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6981 | accuracy: 0.4681 | f-acore: 0.3189\n",
            "Test:  loss: 0.6945 | accuracy: 0.4795 | f1: 0.3241\n",
            "Validation:  loss: 0.6953 | accuracy: 0.4524 | f1: 0.3115\n",
            "Epoch 00002\n",
            "Train: loss: 0.6942 | accuracy: 0.4828 | f-acore: 0.3909\n",
            "Test:  loss: 0.6946 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6882 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00003\n",
            "Train: loss: 0.6912 | accuracy: 0.5351 | f-acore: 0.4178\n",
            "Test:  loss: 0.7116 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6933 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00004\n",
            "Train: loss: 0.6879 | accuracy: 0.5323 | f-acore: 0.3518\n",
            "Test:  loss: 0.6966 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6880 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00005\n",
            "Train: loss: 0.6890 | accuracy: 0.5323 | f-acore: 0.3509\n",
            "Test:  loss: 0.6999 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6891 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00006\n",
            "Train: loss: 0.6896 | accuracy: 0.5332 | f-acore: 0.3522\n",
            "Test:  loss: 0.7033 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6886 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00007\n",
            "Train: loss: 0.6917 | accuracy: 0.5319 | f-acore: 0.3533\n",
            "Test:  loss: 0.6935 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00008\n",
            "Train: loss: 0.6881 | accuracy: 0.5410 | f-acore: 0.4099\n",
            "Test:  loss: 0.6925 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6881 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00009\n",
            "Train: loss: 0.6879 | accuracy: 0.5424 | f-acore: 0.4054\n",
            "Test:  loss: 0.6948 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00010\n",
            "Train: loss: 0.6873 | accuracy: 0.5351 | f-acore: 0.3649\n",
            "Test:  loss: 0.6942 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00011\n",
            "Train: loss: 0.6879 | accuracy: 0.5360 | f-acore: 0.3871\n",
            "Test:  loss: 0.6957 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6869 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00012\n",
            "Train: loss: 0.6879 | accuracy: 0.5346 | f-acore: 0.3819\n",
            "Test:  loss: 0.6952 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6855 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00013\n",
            "Train: loss: 0.6898 | accuracy: 0.5378 | f-acore: 0.3931\n",
            "Test:  loss: 0.6941 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6852 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00014\n",
            "Train: loss: 0.6873 | accuracy: 0.5401 | f-acore: 0.5163\n",
            "Test:  loss: 0.6925 | accuracy: 0.5151 | f1: 0.3498\n",
            "Validation:  loss: 0.6857 | accuracy: 0.5714 | f1: 0.4094\n",
            "Epoch 00015\n",
            "Train: loss: 0.6897 | accuracy: 0.5571 | f-acore: 0.4831\n",
            "Test:  loss: 0.6986 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6818 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00016\n",
            "Train: loss: 0.6857 | accuracy: 0.5557 | f-acore: 0.5003\n",
            "Test:  loss: 0.6938 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6784 | accuracy: 0.5833 | f1: 0.4530\n",
            "Epoch 00017\n",
            "Train: loss: 0.6864 | accuracy: 0.5415 | f-acore: 0.4234\n",
            "Test:  loss: 0.6935 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6774 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00018\n",
            "Train: loss: 0.6848 | accuracy: 0.5438 | f-acore: 0.4272\n",
            "Test:  loss: 0.6990 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6766 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00019\n",
            "Train: loss: 0.6828 | accuracy: 0.5598 | f-acore: 0.4754\n",
            "Test:  loss: 0.6989 | accuracy: 0.5151 | f1: 0.3450\n",
            "Validation:  loss: 0.6734 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00020\n",
            "Train: loss: 0.6889 | accuracy: 0.5452 | f-acore: 0.5025\n",
            "Test:  loss: 0.6961 | accuracy: 0.5233 | f1: 0.3892\n",
            "Validation:  loss: 0.6705 | accuracy: 0.5476 | f1: 0.4590\n",
            "Epoch 00021\n",
            "Train: loss: 0.6845 | accuracy: 0.5557 | f-acore: 0.4753\n",
            "Test:  loss: 0.6975 | accuracy: 0.5205 | f1: 0.3423\n",
            "Validation:  loss: 0.6761 | accuracy: 0.5476 | f1: 0.3538\n",
            "Epoch 00022\n",
            "Train: loss: 0.6804 | accuracy: 0.5580 | f-acore: 0.5193\n",
            "Test:  loss: 0.6936 | accuracy: 0.5041 | f1: 0.4214\n",
            "Validation:  loss: 0.6754 | accuracy: 0.5952 | f1: 0.5524\n",
            "Epoch 00023\n",
            "Train: loss: 0.6861 | accuracy: 0.5617 | f-acore: 0.5555\n",
            "Test:  loss: 0.6937 | accuracy: 0.5096 | f1: 0.4358\n",
            "Validation:  loss: 0.6735 | accuracy: 0.5952 | f1: 0.5593\n",
            "Epoch 00024\n",
            "Train: loss: 0.6779 | accuracy: 0.5699 | f-acore: 0.5276\n",
            "Test:  loss: 0.6947 | accuracy: 0.5041 | f1: 0.4214\n",
            "Validation:  loss: 0.6717 | accuracy: 0.5833 | f1: 0.5428\n",
            "Epoch 00025\n",
            "Train: loss: 0.6776 | accuracy: 0.5713 | f-acore: 0.5497\n",
            "Test:  loss: 0.6963 | accuracy: 0.5123 | f1: 0.4475\n",
            "Validation:  loss: 0.6728 | accuracy: 0.5952 | f1: 0.5593\n",
            "Epoch 00026\n",
            "Train: loss: 0.6811 | accuracy: 0.5608 | f-acore: 0.5406\n",
            "Test:  loss: 0.6939 | accuracy: 0.5151 | f1: 0.4685\n",
            "Validation:  loss: 0.6726 | accuracy: 0.5833 | f1: 0.5609\n",
            "Epoch 00027\n",
            "Train: loss: 0.6813 | accuracy: 0.5713 | f-acore: 0.5362\n",
            "Test:  loss: 0.6941 | accuracy: 0.5068 | f1: 0.5033\n",
            "Validation:  loss: 0.6749 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00028\n",
            "Train: loss: 0.6767 | accuracy: 0.5791 | f-acore: 0.5560\n",
            "Test:  loss: 0.7053 | accuracy: 0.5123 | f1: 0.3981\n",
            "Validation:  loss: 0.6683 | accuracy: 0.6190 | f1: 0.5714\n",
            "Epoch 00029\n",
            "Train: loss: 0.6731 | accuracy: 0.5708 | f-acore: 0.5461\n",
            "Test:  loss: 0.7060 | accuracy: 0.5068 | f1: 0.3840\n",
            "Validation:  loss: 0.6700 | accuracy: 0.6071 | f1: 0.5452\n",
            "Epoch 00030\n",
            "Train: loss: 0.6799 | accuracy: 0.5713 | f-acore: 0.5175\n",
            "Test:  loss: 0.6974 | accuracy: 0.5178 | f1: 0.5116\n",
            "Validation:  loss: 0.6839 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00031\n",
            "Train: loss: 0.6776 | accuracy: 0.5800 | f-acore: 0.5779\n",
            "Test:  loss: 0.7042 | accuracy: 0.5178 | f1: 0.3862\n",
            "Validation:  loss: 0.6709 | accuracy: 0.5833 | f1: 0.4688\n",
            "Epoch 00032\n",
            "Train: loss: 0.6798 | accuracy: 0.5750 | f-acore: 0.5614\n",
            "Test:  loss: 0.6966 | accuracy: 0.5205 | f1: 0.4231\n",
            "Validation:  loss: 0.6713 | accuracy: 0.6190 | f1: 0.5634\n",
            "Epoch 00033\n",
            "Train: loss: 0.6776 | accuracy: 0.5667 | f-acore: 0.5649\n",
            "Test:  loss: 0.6927 | accuracy: 0.5178 | f1: 0.4725\n",
            "Validation:  loss: 0.6730 | accuracy: 0.6190 | f1: 0.5852\n",
            "Epoch 00034\n",
            "Train: loss: 0.6767 | accuracy: 0.5823 | f-acore: 0.5410\n",
            "Test:  loss: 0.6945 | accuracy: 0.5068 | f1: 0.4389\n",
            "Validation:  loss: 0.6721 | accuracy: 0.5952 | f1: 0.5593\n",
            "Epoch 00035\n",
            "Train: loss: 0.6797 | accuracy: 0.5928 | f-acore: 0.5780\n",
            "Test:  loss: 0.6971 | accuracy: 0.5123 | f1: 0.4402\n",
            "Validation:  loss: 0.6740 | accuracy: 0.5952 | f1: 0.5524\n",
            "Epoch 00036\n",
            "Train: loss: 0.6738 | accuracy: 0.5855 | f-acore: 0.5706\n",
            "Test:  loss: 0.6961 | accuracy: 0.5123 | f1: 0.4884\n",
            "Validation:  loss: 0.6674 | accuracy: 0.6190 | f1: 0.6007\n",
            "Epoch 00037\n",
            "Train: loss: 0.6684 | accuracy: 0.5906 | f-acore: 0.5811\n",
            "Test:  loss: 0.6956 | accuracy: 0.5205 | f1: 0.5098\n",
            "Validation:  loss: 0.6745 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00038\n",
            "Train: loss: 0.6696 | accuracy: 0.5846 | f-acore: 0.5707\n",
            "Test:  loss: 0.6949 | accuracy: 0.5288 | f1: 0.5178\n",
            "Validation:  loss: 0.6702 | accuracy: 0.5952 | f1: 0.5800\n",
            "Epoch 00039\n",
            "Train: loss: 0.6795 | accuracy: 0.5818 | f-acore: 0.5415\n",
            "Test:  loss: 0.6990 | accuracy: 0.5096 | f1: 0.4221\n",
            "Validation:  loss: 0.6675 | accuracy: 0.5952 | f1: 0.5524\n",
            "Epoch 00040\n",
            "Train: loss: 0.6740 | accuracy: 0.5832 | f-acore: 0.5811\n",
            "Test:  loss: 0.6944 | accuracy: 0.5425 | f1: 0.5363\n",
            "Validation:  loss: 0.6718 | accuracy: 0.5714 | f1: 0.5625\n",
            "Epoch 00041\n",
            "Train: loss: 0.6778 | accuracy: 0.5818 | f-acore: 0.5773\n",
            "Test:  loss: 0.6943 | accuracy: 0.5534 | f1: 0.5485\n",
            "Validation:  loss: 0.6760 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00042\n",
            "Train: loss: 0.6747 | accuracy: 0.5951 | f-acore: 0.5776\n",
            "Test:  loss: 0.6933 | accuracy: 0.5370 | f1: 0.5250\n",
            "Validation:  loss: 0.6772 | accuracy: 0.5595 | f1: 0.5167\n",
            "Epoch 00043\n",
            "Train: loss: 0.6702 | accuracy: 0.5924 | f-acore: 0.5871\n",
            "Test:  loss: 0.6969 | accuracy: 0.5288 | f1: 0.5277\n",
            "Validation:  loss: 0.6790 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00044\n",
            "Train: loss: 0.6744 | accuracy: 0.5974 | f-acore: 0.5878\n",
            "Test:  loss: 0.7022 | accuracy: 0.5096 | f1: 0.4663\n",
            "Validation:  loss: 0.6737 | accuracy: 0.6190 | f1: 0.5852\n",
            "Epoch 00045\n",
            "Train: loss: 0.6623 | accuracy: 0.6039 | f-acore: 0.5944\n",
            "Test:  loss: 0.6999 | accuracy: 0.5425 | f1: 0.5414\n",
            "Validation:  loss: 0.6752 | accuracy: 0.6429 | f1: 0.6427\n",
            "Epoch 00046\n",
            "Train: loss: 0.6629 | accuracy: 0.6025 | f-acore: 0.5952\n",
            "Test:  loss: 0.6997 | accuracy: 0.5288 | f1: 0.5113\n",
            "Validation:  loss: 0.6655 | accuracy: 0.6071 | f1: 0.5904\n",
            "Epoch 00047\n",
            "Train: loss: 0.6683 | accuracy: 0.5906 | f-acore: 0.5745\n",
            "Test:  loss: 0.6999 | accuracy: 0.5370 | f1: 0.5368\n",
            "Validation:  loss: 0.6802 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00048\n",
            "Train: loss: 0.6718 | accuracy: 0.5988 | f-acore: 0.5787\n",
            "Test:  loss: 0.6985 | accuracy: 0.5342 | f1: 0.5170\n",
            "Validation:  loss: 0.6770 | accuracy: 0.6667 | f1: 0.6597\n",
            "Epoch 00049\n",
            "Train: loss: 0.6647 | accuracy: 0.5979 | f-acore: 0.5837\n",
            "Test:  loss: 0.6979 | accuracy: 0.5260 | f1: 0.5184\n",
            "Validation:  loss: 0.6701 | accuracy: 0.6190 | f1: 0.6171\n",
            "Epoch 00050\n",
            "Train: loss: 0.6575 | accuracy: 0.5983 | f-acore: 0.5823\n",
            "Test:  loss: 0.6986 | accuracy: 0.5233 | f1: 0.5214\n",
            "Validation:  loss: 0.6800 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00051\n",
            "Train: loss: 0.6719 | accuracy: 0.6002 | f-acore: 0.5783\n",
            "Test:  loss: 0.7053 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.6814 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00052\n",
            "Train: loss: 0.6646 | accuracy: 0.5933 | f-acore: 0.5896\n",
            "Test:  loss: 0.6995 | accuracy: 0.5233 | f1: 0.5189\n",
            "Validation:  loss: 0.6807 | accuracy: 0.6310 | f1: 0.6296\n",
            "Epoch 00053\n",
            "Train: loss: 0.6576 | accuracy: 0.6130 | f-acore: 0.6003\n",
            "Test:  loss: 0.7016 | accuracy: 0.5205 | f1: 0.5135\n",
            "Validation:  loss: 0.6724 | accuracy: 0.5833 | f1: 0.5761\n",
            "Epoch 00054\n",
            "Train: loss: 0.6612 | accuracy: 0.5983 | f-acore: 0.5771\n",
            "Test:  loss: 0.7032 | accuracy: 0.5151 | f1: 0.5136\n",
            "Validation:  loss: 0.6770 | accuracy: 0.6429 | f1: 0.6427\n",
            "Epoch 00055\n",
            "Train: loss: 0.6647 | accuracy: 0.5997 | f-acore: 0.5985\n",
            "Test:  loss: 0.7001 | accuracy: 0.5151 | f1: 0.5151\n",
            "Validation:  loss: 0.6778 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00056\n",
            "Train: loss: 0.6648 | accuracy: 0.6029 | f-acore: 0.5903\n",
            "Test:  loss: 0.7013 | accuracy: 0.5014 | f1: 0.4967\n",
            "Validation:  loss: 0.6811 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00057\n",
            "Train: loss: 0.6512 | accuracy: 0.6126 | f-acore: 0.6048\n",
            "Test:  loss: 0.6967 | accuracy: 0.5233 | f1: 0.5145\n",
            "Validation:  loss: 0.6715 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00058\n",
            "Train: loss: 0.6680 | accuracy: 0.6071 | f-acore: 0.5865\n",
            "Test:  loss: 0.6984 | accuracy: 0.5260 | f1: 0.5214\n",
            "Validation:  loss: 0.6720 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00059\n",
            "Train: loss: 0.6535 | accuracy: 0.6057 | f-acore: 0.6007\n",
            "Test:  loss: 0.7038 | accuracy: 0.4877 | f1: 0.4424\n",
            "Validation:  loss: 0.6585 | accuracy: 0.6071 | f1: 0.5942\n",
            "Epoch 00060\n",
            "Train: loss: 0.6560 | accuracy: 0.6084 | f-acore: 0.5989\n",
            "Test:  loss: 0.7118 | accuracy: 0.5205 | f1: 0.5185\n",
            "Validation:  loss: 0.6873 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00061\n",
            "Train: loss: 0.6689 | accuracy: 0.6061 | f-acore: 0.6060\n",
            "Test:  loss: 0.7020 | accuracy: 0.5425 | f1: 0.5411\n",
            "Validation:  loss: 0.6737 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00062\n",
            "Train: loss: 0.6553 | accuracy: 0.6121 | f-acore: 0.5912\n",
            "Test:  loss: 0.6991 | accuracy: 0.5425 | f1: 0.5414\n",
            "Validation:  loss: 0.6698 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00063\n",
            "Train: loss: 0.6618 | accuracy: 0.6061 | f-acore: 0.5878\n",
            "Test:  loss: 0.7049 | accuracy: 0.5452 | f1: 0.5449\n",
            "Validation:  loss: 0.6689 | accuracy: 0.6071 | f1: 0.6071\n",
            "Epoch 00064\n",
            "Train: loss: 0.6616 | accuracy: 0.6277 | f-acore: 0.6162\n",
            "Test:  loss: 0.7091 | accuracy: 0.5151 | f1: 0.5098\n",
            "Validation:  loss: 0.6777 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00065\n",
            "Train: loss: 0.6544 | accuracy: 0.6249 | f-acore: 0.6219\n",
            "Test:  loss: 0.6985 | accuracy: 0.5370 | f1: 0.5370\n",
            "Validation:  loss: 0.6729 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00066\n",
            "Train: loss: 0.6486 | accuracy: 0.6181 | f-acore: 0.6069\n",
            "Test:  loss: 0.7051 | accuracy: 0.5096 | f1: 0.5081\n",
            "Validation:  loss: 0.6716 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00067\n",
            "Train: loss: 0.6523 | accuracy: 0.6204 | f-acore: 0.6081\n",
            "Test:  loss: 0.7138 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00068\n",
            "Train: loss: 0.6580 | accuracy: 0.5970 | f-acore: 0.5951\n",
            "Test:  loss: 0.6989 | accuracy: 0.5288 | f1: 0.5269\n",
            "Validation:  loss: 0.6734 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00069\n",
            "Train: loss: 0.6576 | accuracy: 0.6222 | f-acore: 0.6124\n",
            "Test:  loss: 0.7060 | accuracy: 0.5452 | f1: 0.5450\n",
            "Validation:  loss: 0.6829 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00070\n",
            "Train: loss: 0.6501 | accuracy: 0.6158 | f-acore: 0.6135\n",
            "Test:  loss: 0.7129 | accuracy: 0.5096 | f1: 0.5089\n",
            "Validation:  loss: 0.6809 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00071\n",
            "Train: loss: 0.6569 | accuracy: 0.6171 | f-acore: 0.6162\n",
            "Test:  loss: 0.7085 | accuracy: 0.5205 | f1: 0.5177\n",
            "Validation:  loss: 0.6678 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00072\n",
            "Train: loss: 0.6551 | accuracy: 0.6240 | f-acore: 0.6090\n",
            "Test:  loss: 0.7059 | accuracy: 0.5233 | f1: 0.4932\n",
            "Validation:  loss: 0.6679 | accuracy: 0.5952 | f1: 0.5894\n",
            "Epoch 00073\n",
            "Train: loss: 0.6428 | accuracy: 0.6300 | f-acore: 0.6234\n",
            "Test:  loss: 0.7069 | accuracy: 0.5260 | f1: 0.5119\n",
            "Validation:  loss: 0.6644 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00074\n",
            "Train: loss: 0.6593 | accuracy: 0.6144 | f-acore: 0.6078\n",
            "Test:  loss: 0.7096 | accuracy: 0.5260 | f1: 0.5253\n",
            "Validation:  loss: 0.6690 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00075\n",
            "Train: loss: 0.6505 | accuracy: 0.6240 | f-acore: 0.6220\n",
            "Test:  loss: 0.7109 | accuracy: 0.5151 | f1: 0.5133\n",
            "Validation:  loss: 0.6793 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00076\n",
            "Train: loss: 0.6500 | accuracy: 0.6300 | f-acore: 0.6264\n",
            "Test:  loss: 0.7210 | accuracy: 0.5233 | f1: 0.5178\n",
            "Validation:  loss: 0.6742 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00077\n",
            "Train: loss: 0.6405 | accuracy: 0.6213 | f-acore: 0.6117\n",
            "Test:  loss: 0.7121 | accuracy: 0.5260 | f1: 0.5259\n",
            "Validation:  loss: 0.6668 | accuracy: 0.5952 | f1: 0.5932\n",
            "Epoch 00078\n",
            "Train: loss: 0.6450 | accuracy: 0.6249 | f-acore: 0.6165\n",
            "Test:  loss: 0.7129 | accuracy: 0.5014 | f1: 0.5000\n",
            "Validation:  loss: 0.6671 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00079\n",
            "Train: loss: 0.6444 | accuracy: 0.6318 | f-acore: 0.6261\n",
            "Test:  loss: 0.7095 | accuracy: 0.5151 | f1: 0.5126\n",
            "Validation:  loss: 0.6697 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00080\n",
            "Train: loss: 0.6308 | accuracy: 0.6263 | f-acore: 0.6203\n",
            "Test:  loss: 0.7134 | accuracy: 0.5315 | f1: 0.5295\n",
            "Validation:  loss: 0.6759 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00081\n",
            "Train: loss: 0.6382 | accuracy: 0.6346 | f-acore: 0.6305\n",
            "Test:  loss: 0.7180 | accuracy: 0.5288 | f1: 0.5102\n",
            "Validation:  loss: 0.6544 | accuracy: 0.6667 | f1: 0.6636\n",
            "Epoch 00082\n",
            "Train: loss: 0.6415 | accuracy: 0.6341 | f-acore: 0.6258\n",
            "Test:  loss: 0.7232 | accuracy: 0.4986 | f1: 0.4874\n",
            "Validation:  loss: 0.6883 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00083\n",
            "Train: loss: 0.6460 | accuracy: 0.6318 | f-acore: 0.6183\n",
            "Test:  loss: 0.7155 | accuracy: 0.5205 | f1: 0.5173\n",
            "Validation:  loss: 0.6820 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00084\n",
            "Train: loss: 0.6468 | accuracy: 0.6387 | f-acore: 0.6292\n",
            "Test:  loss: 0.7200 | accuracy: 0.5233 | f1: 0.5207\n",
            "Validation:  loss: 0.6863 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00085\n",
            "Train: loss: 0.6333 | accuracy: 0.6401 | f-acore: 0.6371\n",
            "Test:  loss: 0.7100 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.6815 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00086\n",
            "Train: loss: 0.6329 | accuracy: 0.6378 | f-acore: 0.6276\n",
            "Test:  loss: 0.7203 | accuracy: 0.5205 | f1: 0.5194\n",
            "Validation:  loss: 0.6717 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00087\n",
            "Train: loss: 0.6454 | accuracy: 0.6327 | f-acore: 0.6182\n",
            "Test:  loss: 0.7075 | accuracy: 0.5288 | f1: 0.5288\n",
            "Validation:  loss: 0.6694 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00088\n",
            "Train: loss: 0.6471 | accuracy: 0.6364 | f-acore: 0.6346\n",
            "Test:  loss: 0.7053 | accuracy: 0.5397 | f1: 0.5194\n",
            "Validation:  loss: 0.6550 | accuracy: 0.5952 | f1: 0.5915\n",
            "Epoch 00089\n",
            "Train: loss: 0.6498 | accuracy: 0.6291 | f-acore: 0.6175\n",
            "Test:  loss: 0.7047 | accuracy: 0.5315 | f1: 0.5258\n",
            "Validation:  loss: 0.6694 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00090\n",
            "Train: loss: 0.6424 | accuracy: 0.6382 | f-acore: 0.6348\n",
            "Test:  loss: 0.7097 | accuracy: 0.5096 | f1: 0.4978\n",
            "Validation:  loss: 0.7078 | accuracy: 0.4762 | f1: 0.4296\n",
            "Epoch 00091\n",
            "Train: loss: 0.6474 | accuracy: 0.6428 | f-acore: 0.6347\n",
            "Test:  loss: 0.7036 | accuracy: 0.5233 | f1: 0.5227\n",
            "Validation:  loss: 0.6763 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00092\n",
            "Train: loss: 0.6362 | accuracy: 0.6456 | f-acore: 0.6336\n",
            "Test:  loss: 0.7040 | accuracy: 0.5260 | f1: 0.4768\n",
            "Validation:  loss: 0.6572 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00093\n",
            "Train: loss: 0.6458 | accuracy: 0.6424 | f-acore: 0.6417\n",
            "Test:  loss: 0.7013 | accuracy: 0.5288 | f1: 0.5091\n",
            "Validation:  loss: 0.6674 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00094\n",
            "Train: loss: 0.6341 | accuracy: 0.6437 | f-acore: 0.6414\n",
            "Test:  loss: 0.7054 | accuracy: 0.5315 | f1: 0.5194\n",
            "Validation:  loss: 0.6564 | accuracy: 0.6190 | f1: 0.6111\n",
            "Epoch 00095\n",
            "Train: loss: 0.6336 | accuracy: 0.6382 | f-acore: 0.6237\n",
            "Test:  loss: 0.7128 | accuracy: 0.5151 | f1: 0.5133\n",
            "Validation:  loss: 0.6692 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00096\n",
            "Train: loss: 0.6239 | accuracy: 0.6410 | f-acore: 0.6377\n",
            "Test:  loss: 0.7185 | accuracy: 0.4959 | f1: 0.4935\n",
            "Validation:  loss: 0.6784 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00097\n",
            "Train: loss: 0.6361 | accuracy: 0.6525 | f-acore: 0.6435\n",
            "Test:  loss: 0.7145 | accuracy: 0.5178 | f1: 0.5177\n",
            "Validation:  loss: 0.6656 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00098\n",
            "Train: loss: 0.6282 | accuracy: 0.6401 | f-acore: 0.6328\n",
            "Test:  loss: 0.7059 | accuracy: 0.4986 | f1: 0.4974\n",
            "Validation:  loss: 0.6923 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00099\n",
            "Train: loss: 0.6205 | accuracy: 0.6465 | f-acore: 0.6438\n",
            "Test:  loss: 0.7084 | accuracy: 0.4986 | f1: 0.4986\n",
            "Validation:  loss: 0.6786 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00100\n",
            "Train: loss: 0.6289 | accuracy: 0.6401 | f-acore: 0.6365\n",
            "Test:  loss: 0.7178 | accuracy: 0.4849 | f1: 0.4843\n",
            "Validation:  loss: 0.6802 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00101\n",
            "Train: loss: 0.6118 | accuracy: 0.6511 | f-acore: 0.6414\n",
            "Test:  loss: 0.7193 | accuracy: 0.5014 | f1: 0.4997\n",
            "Validation:  loss: 0.6932 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00102\n",
            "Train: loss: 0.6195 | accuracy: 0.6520 | f-acore: 0.6484\n",
            "Test:  loss: 0.7188 | accuracy: 0.5233 | f1: 0.5207\n",
            "Validation:  loss: 0.6732 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00103\n",
            "Train: loss: 0.6103 | accuracy: 0.6520 | f-acore: 0.6410\n",
            "Test:  loss: 0.7251 | accuracy: 0.5178 | f1: 0.5175\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00104\n",
            "Train: loss: 0.6305 | accuracy: 0.6492 | f-acore: 0.6441\n",
            "Test:  loss: 0.7195 | accuracy: 0.5068 | f1: 0.5065\n",
            "Validation:  loss: 0.6757 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00105\n",
            "Train: loss: 0.6225 | accuracy: 0.6525 | f-acore: 0.6495\n",
            "Test:  loss: 0.7134 | accuracy: 0.5288 | f1: 0.5287\n",
            "Validation:  loss: 0.6726 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00106\n",
            "Train: loss: 0.6092 | accuracy: 0.6525 | f-acore: 0.6470\n",
            "Test:  loss: 0.7238 | accuracy: 0.4986 | f1: 0.4865\n",
            "Validation:  loss: 0.7016 | accuracy: 0.5119 | f1: 0.4856\n",
            "Epoch 00107\n",
            "Train: loss: 0.6253 | accuracy: 0.6456 | f-acore: 0.6406\n",
            "Test:  loss: 0.7194 | accuracy: 0.5205 | f1: 0.5173\n",
            "Validation:  loss: 0.6773 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00108\n",
            "Train: loss: 0.6236 | accuracy: 0.6424 | f-acore: 0.6341\n",
            "Test:  loss: 0.7288 | accuracy: 0.4986 | f1: 0.4986\n",
            "Validation:  loss: 0.6755 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00109\n",
            "Train: loss: 0.6176 | accuracy: 0.6552 | f-acore: 0.6528\n",
            "Test:  loss: 0.7346 | accuracy: 0.5096 | f1: 0.5091\n",
            "Validation:  loss: 0.6713 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00110\n",
            "Train: loss: 0.6122 | accuracy: 0.6625 | f-acore: 0.6594\n",
            "Test:  loss: 0.7219 | accuracy: 0.5096 | f1: 0.5036\n",
            "Validation:  loss: 0.6691 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00111\n",
            "Train: loss: 0.6193 | accuracy: 0.6433 | f-acore: 0.6318\n",
            "Test:  loss: 0.7280 | accuracy: 0.4877 | f1: 0.4424\n",
            "Validation:  loss: 0.6522 | accuracy: 0.5952 | f1: 0.5800\n",
            "Epoch 00112\n",
            "Train: loss: 0.6237 | accuracy: 0.6488 | f-acore: 0.6469\n",
            "Test:  loss: 0.7224 | accuracy: 0.4986 | f1: 0.4979\n",
            "Validation:  loss: 0.6987 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00113\n",
            "Train: loss: 0.6284 | accuracy: 0.6529 | f-acore: 0.6505\n",
            "Test:  loss: 0.7262 | accuracy: 0.4959 | f1: 0.4948\n",
            "Validation:  loss: 0.6858 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00114\n",
            "Train: loss: 0.6231 | accuracy: 0.6635 | f-acore: 0.6583\n",
            "Test:  loss: 0.7126 | accuracy: 0.5151 | f1: 0.5147\n",
            "Validation:  loss: 0.6752 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00115\n",
            "Train: loss: 0.6267 | accuracy: 0.6515 | f-acore: 0.6467\n",
            "Test:  loss: 0.7229 | accuracy: 0.5096 | f1: 0.4778\n",
            "Validation:  loss: 0.6713 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00116\n",
            "Train: loss: 0.6014 | accuracy: 0.6754 | f-acore: 0.6697\n",
            "Test:  loss: 0.7150 | accuracy: 0.5123 | f1: 0.5119\n",
            "Validation:  loss: 0.6807 | accuracy: 0.6071 | f1: 0.6057\n",
            "Epoch 00117\n",
            "Train: loss: 0.6109 | accuracy: 0.6602 | f-acore: 0.6538\n",
            "Test:  loss: 0.7336 | accuracy: 0.5123 | f1: 0.4815\n",
            "Validation:  loss: 0.6565 | accuracy: 0.5952 | f1: 0.5868\n",
            "Epoch 00118\n",
            "Train: loss: 0.6178 | accuracy: 0.6502 | f-acore: 0.6431\n",
            "Test:  loss: 0.7258 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 0.6788 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00119\n",
            "Train: loss: 0.6173 | accuracy: 0.6676 | f-acore: 0.6655\n",
            "Test:  loss: 0.7384 | accuracy: 0.4849 | f1: 0.4817\n",
            "Validation:  loss: 0.6956 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00120\n",
            "Train: loss: 0.6113 | accuracy: 0.6657 | f-acore: 0.6557\n",
            "Test:  loss: 0.7388 | accuracy: 0.4986 | f1: 0.4952\n",
            "Validation:  loss: 0.7115 | accuracy: 0.5238 | f1: 0.5009\n",
            "Epoch 00121\n",
            "Train: loss: 0.6179 | accuracy: 0.6602 | f-acore: 0.6550\n",
            "Test:  loss: 0.7440 | accuracy: 0.5233 | f1: 0.5166\n",
            "Validation:  loss: 0.7043 | accuracy: 0.5357 | f1: 0.5204\n",
            "Epoch 00122\n",
            "Train: loss: 0.6205 | accuracy: 0.6612 | f-acore: 0.6564\n",
            "Test:  loss: 0.7341 | accuracy: 0.5014 | f1: 0.5014\n",
            "Validation:  loss: 0.6960 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00123\n",
            "Train: loss: 0.6218 | accuracy: 0.6690 | f-acore: 0.6624\n",
            "Test:  loss: 0.7320 | accuracy: 0.5014 | f1: 0.4990\n",
            "Validation:  loss: 0.6733 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00124\n",
            "Train: loss: 0.6016 | accuracy: 0.6703 | f-acore: 0.6645\n",
            "Test:  loss: 0.7183 | accuracy: 0.4932 | f1: 0.4835\n",
            "Validation:  loss: 0.6659 | accuracy: 0.5952 | f1: 0.5943\n",
            "Epoch 00125\n",
            "Train: loss: 0.6055 | accuracy: 0.6781 | f-acore: 0.6707\n",
            "Test:  loss: 0.7300 | accuracy: 0.5068 | f1: 0.5064\n",
            "Validation:  loss: 0.6940 | accuracy: 0.5119 | f1: 0.4911\n",
            "Epoch 00126\n",
            "Train: loss: 0.5993 | accuracy: 0.6694 | f-acore: 0.6637\n",
            "Test:  loss: 0.7285 | accuracy: 0.4959 | f1: 0.4894\n",
            "Validation:  loss: 0.6669 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00127\n",
            "Train: loss: 0.5991 | accuracy: 0.6781 | f-acore: 0.6735\n",
            "Test:  loss: 0.7311 | accuracy: 0.4959 | f1: 0.4948\n",
            "Validation:  loss: 0.6937 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00128\n",
            "Train: loss: 0.6098 | accuracy: 0.6589 | f-acore: 0.6566\n",
            "Test:  loss: 0.7384 | accuracy: 0.4959 | f1: 0.4833\n",
            "Validation:  loss: 0.6658 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00129\n",
            "Train: loss: 0.5983 | accuracy: 0.6690 | f-acore: 0.6649\n",
            "Test:  loss: 0.7312 | accuracy: 0.4986 | f1: 0.4965\n",
            "Validation:  loss: 0.6944 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00130\n",
            "Train: loss: 0.5974 | accuracy: 0.6745 | f-acore: 0.6696\n",
            "Test:  loss: 0.7403 | accuracy: 0.4986 | f1: 0.4937\n",
            "Validation:  loss: 0.6808 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00131\n",
            "Train: loss: 0.6006 | accuracy: 0.6699 | f-acore: 0.6632\n",
            "Test:  loss: 0.7425 | accuracy: 0.5041 | f1: 0.4981\n",
            "Validation:  loss: 0.6845 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00132\n",
            "Train: loss: 0.5971 | accuracy: 0.6749 | f-acore: 0.6686\n",
            "Test:  loss: 0.7338 | accuracy: 0.5123 | f1: 0.5048\n",
            "Validation:  loss: 0.6869 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00133\n",
            "Train: loss: 0.6175 | accuracy: 0.6612 | f-acore: 0.6524\n",
            "Test:  loss: 0.7311 | accuracy: 0.4986 | f1: 0.4977\n",
            "Validation:  loss: 0.7015 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00134\n",
            "Train: loss: 0.6037 | accuracy: 0.6657 | f-acore: 0.6611\n",
            "Test:  loss: 0.7340 | accuracy: 0.5260 | f1: 0.5255\n",
            "Validation:  loss: 0.7064 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00135\n",
            "Train: loss: 0.6029 | accuracy: 0.6653 | f-acore: 0.6612\n",
            "Test:  loss: 0.7393 | accuracy: 0.5096 | f1: 0.5030\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00136\n",
            "Train: loss: 0.6059 | accuracy: 0.6804 | f-acore: 0.6781\n",
            "Test:  loss: 0.7484 | accuracy: 0.5096 | f1: 0.4763\n",
            "Validation:  loss: 0.6726 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00137\n",
            "Train: loss: 0.6094 | accuracy: 0.6745 | f-acore: 0.6655\n",
            "Test:  loss: 0.7305 | accuracy: 0.5096 | f1: 0.5094\n",
            "Validation:  loss: 0.7387 | accuracy: 0.4643 | f1: 0.4354\n",
            "Epoch 00138\n",
            "Train: loss: 0.6077 | accuracy: 0.6703 | f-acore: 0.6657\n",
            "Test:  loss: 0.7354 | accuracy: 0.5123 | f1: 0.5119\n",
            "Validation:  loss: 0.7031 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00139\n",
            "Train: loss: 0.5958 | accuracy: 0.6859 | f-acore: 0.6817\n",
            "Test:  loss: 0.7479 | accuracy: 0.5041 | f1: 0.5029\n",
            "Validation:  loss: 0.7033 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00140\n",
            "Train: loss: 0.6025 | accuracy: 0.6703 | f-acore: 0.6619\n",
            "Test:  loss: 0.7589 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7426 | accuracy: 0.5595 | f1: 0.5238\n",
            "Epoch 00141\n",
            "Train: loss: 0.5880 | accuracy: 0.6891 | f-acore: 0.6845\n",
            "Test:  loss: 0.7530 | accuracy: 0.4932 | f1: 0.4809\n",
            "Validation:  loss: 0.6863 | accuracy: 0.5952 | f1: 0.5952\n",
            "Epoch 00142\n",
            "Train: loss: 0.5932 | accuracy: 0.6749 | f-acore: 0.6716\n",
            "Test:  loss: 0.7464 | accuracy: 0.5178 | f1: 0.5178\n",
            "Validation:  loss: 0.7071 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00143\n",
            "Train: loss: 0.5784 | accuracy: 0.6832 | f-acore: 0.6734\n",
            "Test:  loss: 0.7535 | accuracy: 0.5123 | f1: 0.5117\n",
            "Validation:  loss: 0.7194 | accuracy: 0.5357 | f1: 0.5159\n",
            "Epoch 00144\n",
            "Train: loss: 0.6025 | accuracy: 0.6873 | f-acore: 0.6846\n",
            "Test:  loss: 0.7411 | accuracy: 0.5096 | f1: 0.5089\n",
            "Validation:  loss: 0.6957 | accuracy: 0.5714 | f1: 0.5625\n",
            "Epoch 00145\n",
            "Train: loss: 0.5840 | accuracy: 0.6832 | f-acore: 0.6816\n",
            "Test:  loss: 0.7468 | accuracy: 0.5041 | f1: 0.5041\n",
            "Validation:  loss: 0.7111 | accuracy: 0.5595 | f1: 0.5450\n",
            "Epoch 00146\n",
            "Train: loss: 0.5874 | accuracy: 0.6850 | f-acore: 0.6820\n",
            "Test:  loss: 0.7476 | accuracy: 0.4904 | f1: 0.4899\n",
            "Validation:  loss: 0.7031 | accuracy: 0.5595 | f1: 0.5487\n",
            "Epoch 00147\n",
            "Train: loss: 0.5857 | accuracy: 0.6891 | f-acore: 0.6845\n",
            "Test:  loss: 0.7576 | accuracy: 0.4904 | f1: 0.4903\n",
            "Validation:  loss: 0.7038 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00148\n",
            "Train: loss: 0.5943 | accuracy: 0.6841 | f-acore: 0.6825\n",
            "Test:  loss: 0.7500 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.6853 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00149\n",
            "Train: loss: 0.6090 | accuracy: 0.6786 | f-acore: 0.6701\n",
            "Test:  loss: 0.7388 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 0.7103 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00150\n",
            "Train: loss: 0.5955 | accuracy: 0.6832 | f-acore: 0.6809\n",
            "Test:  loss: 0.7461 | accuracy: 0.5041 | f1: 0.5037\n",
            "Validation:  loss: 0.7060 | accuracy: 0.5714 | f1: 0.5675\n",
            "Epoch 00151\n",
            "Train: loss: 0.5930 | accuracy: 0.6827 | f-acore: 0.6784\n",
            "Test:  loss: 0.7566 | accuracy: 0.4822 | f1: 0.4809\n",
            "Validation:  loss: 0.7054 | accuracy: 0.5714 | f1: 0.5714\n",
            "Epoch 00152\n",
            "Train: loss: 0.5955 | accuracy: 0.6800 | f-acore: 0.6753\n",
            "Test:  loss: 0.7531 | accuracy: 0.5178 | f1: 0.5110\n",
            "Validation:  loss: 0.7084 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00153\n",
            "Train: loss: 0.5980 | accuracy: 0.6992 | f-acore: 0.6969\n",
            "Test:  loss: 0.7589 | accuracy: 0.4904 | f1: 0.4899\n",
            "Validation:  loss: 0.6920 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00154\n",
            "Train: loss: 0.5922 | accuracy: 0.6786 | f-acore: 0.6707\n",
            "Test:  loss: 0.7724 | accuracy: 0.4932 | f1: 0.4771\n",
            "Validation:  loss: 0.6803 | accuracy: 0.6310 | f1: 0.6305\n",
            "Epoch 00155\n",
            "Train: loss: 0.5773 | accuracy: 0.6864 | f-acore: 0.6819\n",
            "Test:  loss: 0.7681 | accuracy: 0.5123 | f1: 0.5048\n",
            "Validation:  loss: 0.6815 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00156\n",
            "Train: loss: 0.5930 | accuracy: 0.6923 | f-acore: 0.6861\n",
            "Test:  loss: 0.7630 | accuracy: 0.4959 | f1: 0.4959\n",
            "Validation:  loss: 0.7141 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00157\n",
            "Train: loss: 0.5921 | accuracy: 0.6845 | f-acore: 0.6808\n",
            "Test:  loss: 0.7649 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 0.6940 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00158\n",
            "Train: loss: 0.6009 | accuracy: 0.6914 | f-acore: 0.6849\n",
            "Test:  loss: 0.7468 | accuracy: 0.4877 | f1: 0.4867\n",
            "Validation:  loss: 0.6981 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00159\n",
            "Train: loss: 0.5766 | accuracy: 0.6781 | f-acore: 0.6746\n",
            "Test:  loss: 0.7593 | accuracy: 0.5260 | f1: 0.5162\n",
            "Validation:  loss: 0.7187 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00160\n",
            "Train: loss: 0.5865 | accuracy: 0.6859 | f-acore: 0.6787\n",
            "Test:  loss: 0.7559 | accuracy: 0.4822 | f1: 0.4821\n",
            "Validation:  loss: 0.7306 | accuracy: 0.5714 | f1: 0.5625\n",
            "Epoch 00161\n",
            "Train: loss: 0.5787 | accuracy: 0.6809 | f-acore: 0.6780\n",
            "Test:  loss: 0.7704 | accuracy: 0.4767 | f1: 0.4765\n",
            "Validation:  loss: 0.7138 | accuracy: 0.6190 | f1: 0.6111\n",
            "Epoch 00162\n",
            "Train: loss: 0.5794 | accuracy: 0.6983 | f-acore: 0.6946\n",
            "Test:  loss: 0.7649 | accuracy: 0.4986 | f1: 0.4925\n",
            "Validation:  loss: 0.7097 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00163\n",
            "Train: loss: 0.5800 | accuracy: 0.6946 | f-acore: 0.6936\n",
            "Test:  loss: 0.7680 | accuracy: 0.4986 | f1: 0.4931\n",
            "Validation:  loss: 0.6839 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00164\n",
            "Train: loss: 0.5712 | accuracy: 0.6878 | f-acore: 0.6799\n",
            "Test:  loss: 0.7651 | accuracy: 0.5041 | f1: 0.5037\n",
            "Validation:  loss: 0.7100 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00165\n",
            "Train: loss: 0.5576 | accuracy: 0.6951 | f-acore: 0.6930\n",
            "Test:  loss: 0.7561 | accuracy: 0.4986 | f1: 0.4961\n",
            "Validation:  loss: 0.6966 | accuracy: 0.5595 | f1: 0.5595\n",
            "Epoch 00166\n",
            "Train: loss: 0.5747 | accuracy: 0.6997 | f-acore: 0.6953\n",
            "Test:  loss: 0.7788 | accuracy: 0.4959 | f1: 0.4956\n",
            "Validation:  loss: 0.7175 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00167\n",
            "Train: loss: 0.5791 | accuracy: 0.6992 | f-acore: 0.6957\n",
            "Test:  loss: 0.7637 | accuracy: 0.5096 | f1: 0.5058\n",
            "Validation:  loss: 0.7094 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00168\n",
            "Train: loss: 0.5523 | accuracy: 0.6983 | f-acore: 0.6946\n",
            "Test:  loss: 0.7805 | accuracy: 0.4959 | f1: 0.4942\n",
            "Validation:  loss: 0.7092 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00169\n",
            "Train: loss: 0.5644 | accuracy: 0.7052 | f-acore: 0.7018\n",
            "Test:  loss: 0.7781 | accuracy: 0.4767 | f1: 0.4740\n",
            "Validation:  loss: 0.7095 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00170\n",
            "Train: loss: 0.5734 | accuracy: 0.6983 | f-acore: 0.6951\n",
            "Test:  loss: 0.7859 | accuracy: 0.4904 | f1: 0.4862\n",
            "Validation:  loss: 0.7019 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00171\n",
            "Train: loss: 0.5746 | accuracy: 0.7001 | f-acore: 0.6972\n",
            "Test:  loss: 0.7818 | accuracy: 0.4877 | f1: 0.4874\n",
            "Validation:  loss: 0.7310 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00172\n",
            "Train: loss: 0.5704 | accuracy: 0.6928 | f-acore: 0.6838\n",
            "Test:  loss: 0.7927 | accuracy: 0.4877 | f1: 0.4832\n",
            "Validation:  loss: 0.7775 | accuracy: 0.4881 | f1: 0.4605\n",
            "Epoch 00173\n",
            "Train: loss: 0.5596 | accuracy: 0.6983 | f-acore: 0.6961\n",
            "Test:  loss: 0.7884 | accuracy: 0.4904 | f1: 0.4839\n",
            "Validation:  loss: 0.6921 | accuracy: 0.5833 | f1: 0.5828\n",
            "Epoch 00174\n",
            "Train: loss: 0.5641 | accuracy: 0.6992 | f-acore: 0.6930\n",
            "Test:  loss: 0.8047 | accuracy: 0.4712 | f1: 0.4712\n",
            "Validation:  loss: 0.7355 | accuracy: 0.5952 | f1: 0.5758\n",
            "Epoch 00175\n",
            "Train: loss: 0.5708 | accuracy: 0.6937 | f-acore: 0.6933\n",
            "Test:  loss: 0.7947 | accuracy: 0.4712 | f1: 0.4696\n",
            "Validation:  loss: 0.7077 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00176\n",
            "Train: loss: 0.5725 | accuracy: 0.7024 | f-acore: 0.6962\n",
            "Test:  loss: 0.7779 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 0.7341 | accuracy: 0.5595 | f1: 0.5487\n",
            "Epoch 00177\n",
            "Train: loss: 0.5515 | accuracy: 0.7079 | f-acore: 0.7021\n",
            "Test:  loss: 0.7835 | accuracy: 0.5014 | f1: 0.4994\n",
            "Validation:  loss: 0.7251 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00178\n",
            "Train: loss: 0.5697 | accuracy: 0.6956 | f-acore: 0.6908\n",
            "Test:  loss: 0.7789 | accuracy: 0.4904 | f1: 0.4839\n",
            "Validation:  loss: 0.7302 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00179\n",
            "Train: loss: 0.5533 | accuracy: 0.7107 | f-acore: 0.7084\n",
            "Test:  loss: 0.7901 | accuracy: 0.4904 | f1: 0.4851\n",
            "Validation:  loss: 0.7079 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00180\n",
            "Train: loss: 0.5682 | accuracy: 0.7070 | f-acore: 0.7024\n",
            "Test:  loss: 0.7927 | accuracy: 0.4740 | f1: 0.4737\n",
            "Validation:  loss: 0.7333 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00181\n",
            "Train: loss: 0.5918 | accuracy: 0.7088 | f-acore: 0.7064\n",
            "Test:  loss: 0.7935 | accuracy: 0.4904 | f1: 0.4899\n",
            "Validation:  loss: 0.7688 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00182\n",
            "Train: loss: 0.5744 | accuracy: 0.6836 | f-acore: 0.6755\n",
            "Test:  loss: 0.7949 | accuracy: 0.5041 | f1: 0.5032\n",
            "Validation:  loss: 0.7948 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00183\n",
            "Train: loss: 0.5760 | accuracy: 0.6951 | f-acore: 0.6907\n",
            "Test:  loss: 0.8118 | accuracy: 0.4685 | f1: 0.4684\n",
            "Validation:  loss: 0.7495 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00184\n",
            "Train: loss: 0.5757 | accuracy: 0.7240 | f-acore: 0.7225\n",
            "Test:  loss: 0.7943 | accuracy: 0.4959 | f1: 0.4912\n",
            "Validation:  loss: 0.7253 | accuracy: 0.5833 | f1: 0.5833\n",
            "Epoch 00185\n",
            "Train: loss: 0.5594 | accuracy: 0.7066 | f-acore: 0.7001\n",
            "Test:  loss: 0.7719 | accuracy: 0.5342 | f1: 0.5114\n",
            "Validation:  loss: 0.7305 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00186\n",
            "Train: loss: 0.5684 | accuracy: 0.7061 | f-acore: 0.7020\n",
            "Test:  loss: 0.7615 | accuracy: 0.5014 | f1: 0.4967\n",
            "Validation:  loss: 0.7032 | accuracy: 0.5714 | f1: 0.5712\n",
            "Epoch 00187\n",
            "Train: loss: 0.5597 | accuracy: 0.7020 | f-acore: 0.6963\n",
            "Test:  loss: 0.7744 | accuracy: 0.4849 | f1: 0.4807\n",
            "Validation:  loss: 0.7379 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00188\n",
            "Train: loss: 0.5482 | accuracy: 0.7176 | f-acore: 0.7158\n",
            "Test:  loss: 0.7840 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 0.7143 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00189\n",
            "Train: loss: 0.5512 | accuracy: 0.7088 | f-acore: 0.7033\n",
            "Test:  loss: 0.7959 | accuracy: 0.5014 | f1: 0.4950\n",
            "Validation:  loss: 0.7295 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00190\n",
            "Train: loss: 0.5487 | accuracy: 0.7244 | f-acore: 0.7218\n",
            "Test:  loss: 0.7946 | accuracy: 0.4877 | f1: 0.4869\n",
            "Validation:  loss: 0.7671 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00191\n",
            "Train: loss: 0.5549 | accuracy: 0.7088 | f-acore: 0.7061\n",
            "Test:  loss: 0.8062 | accuracy: 0.4959 | f1: 0.4901\n",
            "Validation:  loss: 0.7605 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00192\n",
            "Train: loss: 0.5518 | accuracy: 0.7102 | f-acore: 0.7075\n",
            "Test:  loss: 0.8075 | accuracy: 0.5014 | f1: 0.5012\n",
            "Validation:  loss: 0.7747 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00193\n",
            "Train: loss: 0.5633 | accuracy: 0.7130 | f-acore: 0.7106\n",
            "Test:  loss: 0.7923 | accuracy: 0.5014 | f1: 0.5000\n",
            "Validation:  loss: 0.7400 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00194\n",
            "Train: loss: 0.5718 | accuracy: 0.7107 | f-acore: 0.7060\n",
            "Test:  loss: 0.7883 | accuracy: 0.5123 | f1: 0.5088\n",
            "Validation:  loss: 0.7461 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00195\n",
            "Train: loss: 0.5550 | accuracy: 0.7043 | f-acore: 0.7018\n",
            "Test:  loss: 0.7882 | accuracy: 0.4986 | f1: 0.4974\n",
            "Validation:  loss: 0.7733 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00196\n",
            "Train: loss: 0.5447 | accuracy: 0.7180 | f-acore: 0.7140\n",
            "Test:  loss: 0.8025 | accuracy: 0.4740 | f1: 0.4691\n",
            "Validation:  loss: 0.7361 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00197\n",
            "Train: loss: 0.5630 | accuracy: 0.7084 | f-acore: 0.7047\n",
            "Test:  loss: 0.8167 | accuracy: 0.4904 | f1: 0.4902\n",
            "Validation:  loss: 0.7521 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00198\n",
            "Train: loss: 0.5450 | accuracy: 0.7121 | f-acore: 0.7096\n",
            "Test:  loss: 0.8031 | accuracy: 0.4904 | f1: 0.4902\n",
            "Validation:  loss: 0.7608 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00199\n",
            "Train: loss: 0.5491 | accuracy: 0.7189 | f-acore: 0.7129\n",
            "Test:  loss: 0.8200 | accuracy: 0.5014 | f1: 0.5013\n",
            "Validation:  loss: 0.7958 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00200\n",
            "Train: loss: 0.5479 | accuracy: 0.7153 | f-acore: 0.7149\n",
            "Test:  loss: 0.8161 | accuracy: 0.4877 | f1: 0.4864\n",
            "Validation:  loss: 0.7516 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00201\n",
            "Train: loss: 0.5651 | accuracy: 0.7121 | f-acore: 0.7066\n",
            "Test:  loss: 0.8174 | accuracy: 0.4767 | f1: 0.4736\n",
            "Validation:  loss: 0.7665 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00202\n",
            "Train: loss: 0.5513 | accuracy: 0.7189 | f-acore: 0.7183\n",
            "Test:  loss: 0.8194 | accuracy: 0.4822 | f1: 0.4812\n",
            "Validation:  loss: 0.7706 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00203\n",
            "Train: loss: 0.5334 | accuracy: 0.7313 | f-acore: 0.7276\n",
            "Test:  loss: 0.8325 | accuracy: 0.4932 | f1: 0.4926\n",
            "Validation:  loss: 0.8046 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00204\n",
            "Train: loss: 0.5373 | accuracy: 0.7199 | f-acore: 0.7182\n",
            "Test:  loss: 0.8231 | accuracy: 0.4986 | f1: 0.4979\n",
            "Validation:  loss: 0.7914 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00205\n",
            "Train: loss: 0.5274 | accuracy: 0.7199 | f-acore: 0.7158\n",
            "Test:  loss: 0.8239 | accuracy: 0.4822 | f1: 0.4816\n",
            "Validation:  loss: 0.7856 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00206\n",
            "Train: loss: 0.5269 | accuracy: 0.7199 | f-acore: 0.7158\n",
            "Test:  loss: 0.8350 | accuracy: 0.5014 | f1: 0.5012\n",
            "Validation:  loss: 0.8436 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00207\n",
            "Train: loss: 0.5408 | accuracy: 0.7144 | f-acore: 0.7113\n",
            "Test:  loss: 0.8296 | accuracy: 0.5014 | f1: 0.5014\n",
            "Validation:  loss: 0.7942 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00208\n",
            "Train: loss: 0.5531 | accuracy: 0.7157 | f-acore: 0.7123\n",
            "Test:  loss: 0.8444 | accuracy: 0.4932 | f1: 0.4929\n",
            "Validation:  loss: 0.7944 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00209\n",
            "Train: loss: 0.5400 | accuracy: 0.7231 | f-acore: 0.7200\n",
            "Test:  loss: 0.8278 | accuracy: 0.4849 | f1: 0.4845\n",
            "Validation:  loss: 0.7998 | accuracy: 0.4643 | f1: 0.4624\n",
            "Epoch 00210\n",
            "Train: loss: 0.5274 | accuracy: 0.7318 | f-acore: 0.7283\n",
            "Test:  loss: 0.8263 | accuracy: 0.4959 | f1: 0.4958\n",
            "Validation:  loss: 0.8341 | accuracy: 0.4643 | f1: 0.4549\n",
            "Epoch 00211\n",
            "Train: loss: 0.5467 | accuracy: 0.7240 | f-acore: 0.7223\n",
            "Test:  loss: 0.8374 | accuracy: 0.4877 | f1: 0.4821\n",
            "Validation:  loss: 0.7702 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00212\n",
            "Train: loss: 0.5250 | accuracy: 0.7254 | f-acore: 0.7230\n",
            "Test:  loss: 0.8520 | accuracy: 0.4904 | f1: 0.4904\n",
            "Validation:  loss: 0.8156 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00213\n",
            "Train: loss: 0.5455 | accuracy: 0.7405 | f-acore: 0.7373\n",
            "Test:  loss: 0.8457 | accuracy: 0.4904 | f1: 0.4904\n",
            "Validation:  loss: 0.8142 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00214\n",
            "Train: loss: 0.5241 | accuracy: 0.7240 | f-acore: 0.7204\n",
            "Test:  loss: 0.8410 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 0.8010 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00215\n",
            "Train: loss: 0.5285 | accuracy: 0.7387 | f-acore: 0.7370\n",
            "Test:  loss: 0.8436 | accuracy: 0.4740 | f1: 0.4696\n",
            "Validation:  loss: 0.7601 | accuracy: 0.5119 | f1: 0.5113\n",
            "Epoch 00216\n",
            "Train: loss: 0.5316 | accuracy: 0.7341 | f-acore: 0.7308\n",
            "Test:  loss: 0.8426 | accuracy: 0.5014 | f1: 0.5014\n",
            "Validation:  loss: 0.8138 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00217\n",
            "Train: loss: 0.5391 | accuracy: 0.7359 | f-acore: 0.7316\n",
            "Test:  loss: 0.8495 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 0.8496 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00218\n",
            "Train: loss: 0.5285 | accuracy: 0.7400 | f-acore: 0.7395\n",
            "Test:  loss: 0.8403 | accuracy: 0.4849 | f1: 0.4817\n",
            "Validation:  loss: 0.7996 | accuracy: 0.5000 | f1: 0.4997\n",
            "Epoch 00219\n",
            "Train: loss: 0.5315 | accuracy: 0.7286 | f-acore: 0.7234\n",
            "Test:  loss: 0.8535 | accuracy: 0.4932 | f1: 0.4930\n",
            "Validation:  loss: 0.8863 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00220\n",
            "Train: loss: 0.5446 | accuracy: 0.7396 | f-acore: 0.7373\n",
            "Test:  loss: 0.8490 | accuracy: 0.4932 | f1: 0.4909\n",
            "Validation:  loss: 0.8302 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00221\n",
            "Train: loss: 0.5339 | accuracy: 0.7359 | f-acore: 0.7324\n",
            "Test:  loss: 0.8489 | accuracy: 0.4932 | f1: 0.4863\n",
            "Validation:  loss: 0.8187 | accuracy: 0.5357 | f1: 0.5356\n",
            "Epoch 00222\n",
            "Train: loss: 0.5349 | accuracy: 0.7295 | f-acore: 0.7266\n",
            "Test:  loss: 0.8511 | accuracy: 0.4685 | f1: 0.4603\n",
            "Validation:  loss: 0.8200 | accuracy: 0.4881 | f1: 0.4863\n",
            "Epoch 00223\n",
            "Train: loss: 0.5372 | accuracy: 0.7272 | f-acore: 0.7255\n",
            "Test:  loss: 0.8661 | accuracy: 0.4986 | f1: 0.4985\n",
            "Validation:  loss: 0.8606 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00224\n",
            "Train: loss: 0.5269 | accuracy: 0.7354 | f-acore: 0.7331\n",
            "Test:  loss: 0.8634 | accuracy: 0.4959 | f1: 0.4948\n",
            "Validation:  loss: 0.8391 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00225\n",
            "Train: loss: 0.5170 | accuracy: 0.7327 | f-acore: 0.7312\n",
            "Test:  loss: 0.8580 | accuracy: 0.4932 | f1: 0.4882\n",
            "Validation:  loss: 0.8244 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00226\n",
            "Train: loss: 0.5321 | accuracy: 0.7350 | f-acore: 0.7306\n",
            "Test:  loss: 0.8722 | accuracy: 0.4959 | f1: 0.4939\n",
            "Validation:  loss: 0.8957 | accuracy: 0.5000 | f1: 0.4759\n",
            "Epoch 00227\n",
            "Train: loss: 0.5262 | accuracy: 0.7396 | f-acore: 0.7382\n",
            "Test:  loss: 0.8724 | accuracy: 0.4740 | f1: 0.4685\n",
            "Validation:  loss: 0.8224 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00228\n",
            "Train: loss: 0.5249 | accuracy: 0.7244 | f-acore: 0.7201\n",
            "Test:  loss: 0.8609 | accuracy: 0.4932 | f1: 0.4928\n",
            "Validation:  loss: 0.8855 | accuracy: 0.5000 | f1: 0.4954\n",
            "Epoch 00229\n",
            "Train: loss: 0.5278 | accuracy: 0.7281 | f-acore: 0.7254\n",
            "Test:  loss: 0.8621 | accuracy: 0.4904 | f1: 0.4867\n",
            "Validation:  loss: 0.8412 | accuracy: 0.5476 | f1: 0.5466\n",
            "Epoch 00230\n",
            "Train: loss: 0.5088 | accuracy: 0.7405 | f-acore: 0.7372\n",
            "Test:  loss: 0.8805 | accuracy: 0.4877 | f1: 0.4858\n",
            "Validation:  loss: 0.8592 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00231\n",
            "Train: loss: 0.5114 | accuracy: 0.7519 | f-acore: 0.7494\n",
            "Test:  loss: 0.8801 | accuracy: 0.5041 | f1: 0.5036\n",
            "Validation:  loss: 0.8900 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00232\n",
            "Train: loss: 0.5420 | accuracy: 0.7396 | f-acore: 0.7365\n",
            "Test:  loss: 0.8787 | accuracy: 0.4932 | f1: 0.4928\n",
            "Validation:  loss: 0.8731 | accuracy: 0.5714 | f1: 0.5625\n",
            "Epoch 00233\n",
            "Train: loss: 0.5448 | accuracy: 0.7254 | f-acore: 0.7233\n",
            "Test:  loss: 0.8823 | accuracy: 0.4740 | f1: 0.4696\n",
            "Validation:  loss: 0.8172 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00234\n",
            "Train: loss: 0.5161 | accuracy: 0.7364 | f-acore: 0.7326\n",
            "Test:  loss: 0.8940 | accuracy: 0.4822 | f1: 0.4796\n",
            "Validation:  loss: 0.9715 | accuracy: 0.4881 | f1: 0.4662\n",
            "Epoch 00235\n",
            "Train: loss: 0.5257 | accuracy: 0.7387 | f-acore: 0.7370\n",
            "Test:  loss: 0.8658 | accuracy: 0.4904 | f1: 0.4867\n",
            "Validation:  loss: 0.8526 | accuracy: 0.5000 | f1: 0.4974\n",
            "Epoch 00236\n",
            "Train: loss: 0.5125 | accuracy: 0.7593 | f-acore: 0.7572\n",
            "Test:  loss: 0.8727 | accuracy: 0.4822 | f1: 0.4821\n",
            "Validation:  loss: 0.9488 | accuracy: 0.4524 | f1: 0.4367\n",
            "Epoch 00237\n",
            "Train: loss: 0.5151 | accuracy: 0.7451 | f-acore: 0.7428\n",
            "Test:  loss: 0.8785 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 0.8937 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00238\n",
            "Train: loss: 0.5260 | accuracy: 0.7469 | f-acore: 0.7440\n",
            "Test:  loss: 0.8695 | accuracy: 0.4795 | f1: 0.4766\n",
            "Validation:  loss: 0.8417 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00239\n",
            "Train: loss: 0.5276 | accuracy: 0.7428 | f-acore: 0.7403\n",
            "Test:  loss: 0.8576 | accuracy: 0.4877 | f1: 0.4832\n",
            "Validation:  loss: 0.8349 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00240\n",
            "Train: loss: 0.5094 | accuracy: 0.7345 | f-acore: 0.7297\n",
            "Test:  loss: 0.9021 | accuracy: 0.4877 | f1: 0.4871\n",
            "Validation:  loss: 0.9227 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00241\n",
            "Train: loss: 0.5152 | accuracy: 0.7423 | f-acore: 0.7404\n",
            "Test:  loss: 0.8932 | accuracy: 0.4740 | f1: 0.4706\n",
            "Validation:  loss: 0.8498 | accuracy: 0.4881 | f1: 0.4874\n",
            "Epoch 00242\n",
            "Train: loss: 0.5283 | accuracy: 0.7451 | f-acore: 0.7429\n",
            "Test:  loss: 0.8941 | accuracy: 0.4904 | f1: 0.4901\n",
            "Validation:  loss: 0.8785 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00243\n",
            "Train: loss: 0.5455 | accuracy: 0.7432 | f-acore: 0.7411\n",
            "Test:  loss: 0.8873 | accuracy: 0.4959 | f1: 0.4953\n",
            "Validation:  loss: 0.8379 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00244\n",
            "Train: loss: 0.5012 | accuracy: 0.7387 | f-acore: 0.7335\n",
            "Test:  loss: 0.9170 | accuracy: 0.4795 | f1: 0.4793\n",
            "Validation:  loss: 0.8365 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00245\n",
            "Train: loss: 0.4935 | accuracy: 0.7538 | f-acore: 0.7507\n",
            "Test:  loss: 0.9207 | accuracy: 0.4658 | f1: 0.4655\n",
            "Validation:  loss: 0.8526 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00246\n",
            "Train: loss: 0.5136 | accuracy: 0.7455 | f-acore: 0.7444\n",
            "Test:  loss: 0.8974 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 0.8381 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00247\n",
            "Train: loss: 0.5198 | accuracy: 0.7547 | f-acore: 0.7520\n",
            "Test:  loss: 0.9101 | accuracy: 0.4877 | f1: 0.4867\n",
            "Validation:  loss: 0.8849 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00248\n",
            "Train: loss: 0.4951 | accuracy: 0.7492 | f-acore: 0.7469\n",
            "Test:  loss: 0.9063 | accuracy: 0.4849 | f1: 0.4848\n",
            "Validation:  loss: 0.9185 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00249\n",
            "Train: loss: 0.5119 | accuracy: 0.7442 | f-acore: 0.7418\n",
            "Test:  loss: 0.9175 | accuracy: 0.4822 | f1: 0.4796\n",
            "Validation:  loss: 0.8315 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00250\n",
            "Train: loss: 0.5006 | accuracy: 0.7469 | f-acore: 0.7439\n",
            "Test:  loss: 0.9292 | accuracy: 0.4986 | f1: 0.4985\n",
            "Validation:  loss: 0.9137 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00251\n",
            "Train: loss: 0.5013 | accuracy: 0.7597 | f-acore: 0.7587\n",
            "Test:  loss: 0.9110 | accuracy: 0.5014 | f1: 0.5012\n",
            "Validation:  loss: 0.8836 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00252\n",
            "Train: loss: 0.5073 | accuracy: 0.7602 | f-acore: 0.7579\n",
            "Test:  loss: 0.9244 | accuracy: 0.5068 | f1: 0.5064\n",
            "Validation:  loss: 0.9061 | accuracy: 0.5000 | f1: 0.4928\n",
            "Epoch 00253\n",
            "Train: loss: 0.5255 | accuracy: 0.7538 | f-acore: 0.7511\n",
            "Test:  loss: 0.9216 | accuracy: 0.4822 | f1: 0.4821\n",
            "Validation:  loss: 0.8916 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00254\n",
            "Train: loss: 0.5202 | accuracy: 0.7428 | f-acore: 0.7419\n",
            "Test:  loss: 0.9044 | accuracy: 0.4986 | f1: 0.4986\n",
            "Validation:  loss: 0.8867 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00255\n",
            "Train: loss: 0.5222 | accuracy: 0.7419 | f-acore: 0.7399\n",
            "Test:  loss: 0.8904 | accuracy: 0.4822 | f1: 0.4814\n",
            "Validation:  loss: 0.9259 | accuracy: 0.5595 | f1: 0.5487\n",
            "Epoch 00256\n",
            "Train: loss: 0.5003 | accuracy: 0.7432 | f-acore: 0.7412\n",
            "Test:  loss: 0.9115 | accuracy: 0.5014 | f1: 0.5003\n",
            "Validation:  loss: 0.9380 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00257\n",
            "Train: loss: 0.4999 | accuracy: 0.7474 | f-acore: 0.7450\n",
            "Test:  loss: 0.9519 | accuracy: 0.4877 | f1: 0.4877\n",
            "Validation:  loss: 0.9209 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00258\n",
            "Train: loss: 0.5028 | accuracy: 0.7442 | f-acore: 0.7394\n",
            "Test:  loss: 0.9332 | accuracy: 0.4658 | f1: 0.4658\n",
            "Validation:  loss: 0.8871 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00259\n",
            "Train: loss: 0.4931 | accuracy: 0.7579 | f-acore: 0.7557\n",
            "Test:  loss: 0.9279 | accuracy: 0.4822 | f1: 0.4809\n",
            "Validation:  loss: 0.8624 | accuracy: 0.5000 | f1: 0.4989\n",
            "Epoch 00260\n",
            "Train: loss: 0.4964 | accuracy: 0.7542 | f-acore: 0.7517\n",
            "Test:  loss: 0.9277 | accuracy: 0.4877 | f1: 0.4877\n",
            "Validation:  loss: 0.8865 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00261\n",
            "Train: loss: 0.5034 | accuracy: 0.7478 | f-acore: 0.7445\n",
            "Test:  loss: 0.9440 | accuracy: 0.4986 | f1: 0.4977\n",
            "Validation:  loss: 0.8530 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00262\n",
            "Train: loss: 0.5136 | accuracy: 0.7483 | f-acore: 0.7441\n",
            "Test:  loss: 0.9373 | accuracy: 0.4767 | f1: 0.4763\n",
            "Validation:  loss: 0.9041 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00263\n",
            "Train: loss: 0.5007 | accuracy: 0.7616 | f-acore: 0.7607\n",
            "Test:  loss: 0.9566 | accuracy: 0.4685 | f1: 0.4682\n",
            "Validation:  loss: 0.9048 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00264\n",
            "Train: loss: 0.5244 | accuracy: 0.7409 | f-acore: 0.7369\n",
            "Test:  loss: 0.9151 | accuracy: 0.4822 | f1: 0.4821\n",
            "Validation:  loss: 0.8647 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00265\n",
            "Train: loss: 0.5141 | accuracy: 0.7506 | f-acore: 0.7504\n",
            "Test:  loss: 0.9472 | accuracy: 0.4795 | f1: 0.4780\n",
            "Validation:  loss: 0.8770 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00266\n",
            "Train: loss: 0.5122 | accuracy: 0.7492 | f-acore: 0.7460\n",
            "Test:  loss: 0.9461 | accuracy: 0.4822 | f1: 0.4819\n",
            "Validation:  loss: 0.9461 | accuracy: 0.4881 | f1: 0.4792\n",
            "Epoch 00267\n",
            "Train: loss: 0.5114 | accuracy: 0.7483 | f-acore: 0.7470\n",
            "Test:  loss: 0.9316 | accuracy: 0.4685 | f1: 0.4685\n",
            "Validation:  loss: 0.9607 | accuracy: 0.4762 | f1: 0.4687\n",
            "Epoch 00268\n",
            "Train: loss: 0.5121 | accuracy: 0.7409 | f-acore: 0.7380\n",
            "Test:  loss: 0.9432 | accuracy: 0.4849 | f1: 0.4848\n",
            "Validation:  loss: 0.9783 | accuracy: 0.5714 | f1: 0.5692\n",
            "Epoch 00269\n",
            "Train: loss: 0.5156 | accuracy: 0.7501 | f-acore: 0.7482\n",
            "Test:  loss: 0.9281 | accuracy: 0.4849 | f1: 0.4847\n",
            "Validation:  loss: 0.8765 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00270\n",
            "Train: loss: 0.5051 | accuracy: 0.7575 | f-acore: 0.7540\n",
            "Test:  loss: 0.9541 | accuracy: 0.5014 | f1: 0.5007\n",
            "Validation:  loss: 0.8968 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00271\n",
            "Train: loss: 0.4808 | accuracy: 0.7547 | f-acore: 0.7523\n",
            "Test:  loss: 0.9886 | accuracy: 0.4932 | f1: 0.4919\n",
            "Validation:  loss: 0.9312 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00272\n",
            "Train: loss: 0.5019 | accuracy: 0.7556 | f-acore: 0.7539\n",
            "Test:  loss: 0.9575 | accuracy: 0.5151 | f1: 0.5148\n",
            "Validation:  loss: 0.8695 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00273\n",
            "Train: loss: 0.5140 | accuracy: 0.7584 | f-acore: 0.7556\n",
            "Test:  loss: 0.9639 | accuracy: 0.5041 | f1: 0.5036\n",
            "Validation:  loss: 0.9375 | accuracy: 0.5595 | f1: 0.5487\n",
            "Epoch 00274\n",
            "Train: loss: 0.5017 | accuracy: 0.7570 | f-acore: 0.7541\n",
            "Test:  loss: 0.9430 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 0.8736 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00275\n",
            "Train: loss: 0.4955 | accuracy: 0.7533 | f-acore: 0.7505\n",
            "Test:  loss: 0.9796 | accuracy: 0.4767 | f1: 0.4748\n",
            "Validation:  loss: 0.9431 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00276\n",
            "Train: loss: 0.5085 | accuracy: 0.7515 | f-acore: 0.7506\n",
            "Test:  loss: 0.9650 | accuracy: 0.4822 | f1: 0.4822\n",
            "Validation:  loss: 0.8816 | accuracy: 0.5833 | f1: 0.5819\n",
            "Epoch 00277\n",
            "Train: loss: 0.5051 | accuracy: 0.7446 | f-acore: 0.7392\n",
            "Test:  loss: 0.9586 | accuracy: 0.4603 | f1: 0.4600\n",
            "Validation:  loss: 0.9263 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00278\n",
            "Train: loss: 0.4809 | accuracy: 0.7616 | f-acore: 0.7611\n",
            "Test:  loss: 0.9873 | accuracy: 0.4740 | f1: 0.4740\n",
            "Validation:  loss: 0.9097 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00279\n",
            "Train: loss: 0.5028 | accuracy: 0.7556 | f-acore: 0.7527\n",
            "Test:  loss: 0.9809 | accuracy: 0.4877 | f1: 0.4874\n",
            "Validation:  loss: 0.9006 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00280\n",
            "Train: loss: 0.5017 | accuracy: 0.7538 | f-acore: 0.7533\n",
            "Test:  loss: 0.9705 | accuracy: 0.4658 | f1: 0.4650\n",
            "Validation:  loss: 0.8811 | accuracy: 0.5357 | f1: 0.5351\n",
            "Epoch 00281\n",
            "Train: loss: 0.4993 | accuracy: 0.7519 | f-acore: 0.7479\n",
            "Test:  loss: 0.9944 | accuracy: 0.4740 | f1: 0.4733\n",
            "Validation:  loss: 0.8896 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00282\n",
            "Train: loss: 0.4979 | accuracy: 0.7602 | f-acore: 0.7579\n",
            "Test:  loss: 0.9519 | accuracy: 0.4630 | f1: 0.4627\n",
            "Validation:  loss: 0.8220 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00283\n",
            "Train: loss: 0.4865 | accuracy: 0.7602 | f-acore: 0.7581\n",
            "Test:  loss: 0.9560 | accuracy: 0.4877 | f1: 0.4871\n",
            "Validation:  loss: 0.8156 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00284\n",
            "Train: loss: 0.4957 | accuracy: 0.7588 | f-acore: 0.7564\n",
            "Test:  loss: 0.9663 | accuracy: 0.4959 | f1: 0.4957\n",
            "Validation:  loss: 0.9225 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00285\n",
            "Train: loss: 0.5183 | accuracy: 0.7685 | f-acore: 0.7668\n",
            "Test:  loss: 0.9571 | accuracy: 0.4877 | f1: 0.4877\n",
            "Validation:  loss: 0.9088 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00286\n",
            "Train: loss: 0.4933 | accuracy: 0.7460 | f-acore: 0.7412\n",
            "Test:  loss: 0.9406 | accuracy: 0.4904 | f1: 0.4890\n",
            "Validation:  loss: 0.8316 | accuracy: 0.5119 | f1: 0.5118\n",
            "Epoch 00287\n",
            "Train: loss: 0.4925 | accuracy: 0.7556 | f-acore: 0.7537\n",
            "Test:  loss: 0.9849 | accuracy: 0.4877 | f1: 0.4869\n",
            "Validation:  loss: 0.8567 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00288\n",
            "Train: loss: 0.4944 | accuracy: 0.7542 | f-acore: 0.7530\n",
            "Test:  loss: 0.9815 | accuracy: 0.4685 | f1: 0.4685\n",
            "Validation:  loss: 0.8655 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00289\n",
            "Train: loss: 0.5041 | accuracy: 0.7593 | f-acore: 0.7568\n",
            "Test:  loss: 0.9706 | accuracy: 0.4877 | f1: 0.4876\n",
            "Validation:  loss: 0.8738 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00290\n",
            "Train: loss: 0.5171 | accuracy: 0.7487 | f-acore: 0.7473\n",
            "Test:  loss: 0.9828 | accuracy: 0.4630 | f1: 0.4627\n",
            "Validation:  loss: 0.9214 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00291\n",
            "Train: loss: 0.5316 | accuracy: 0.7478 | f-acore: 0.7474\n",
            "Test:  loss: 0.9667 | accuracy: 0.4877 | f1: 0.4873\n",
            "Validation:  loss: 0.8929 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00292\n",
            "Train: loss: 0.4938 | accuracy: 0.7570 | f-acore: 0.7551\n",
            "Test:  loss: 0.9663 | accuracy: 0.4822 | f1: 0.4803\n",
            "Validation:  loss: 0.8523 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00293\n",
            "Train: loss: 0.4796 | accuracy: 0.7607 | f-acore: 0.7580\n",
            "Test:  loss: 0.9601 | accuracy: 0.4740 | f1: 0.4735\n",
            "Validation:  loss: 0.9060 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00294\n",
            "Train: loss: 0.4821 | accuracy: 0.7634 | f-acore: 0.7620\n",
            "Test:  loss: 1.0118 | accuracy: 0.4932 | f1: 0.4919\n",
            "Validation:  loss: 0.9492 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00295\n",
            "Train: loss: 0.4955 | accuracy: 0.7611 | f-acore: 0.7572\n",
            "Test:  loss: 1.0050 | accuracy: 0.4767 | f1: 0.4744\n",
            "Validation:  loss: 0.9572 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00296\n",
            "Train: loss: 0.4840 | accuracy: 0.7630 | f-acore: 0.7623\n",
            "Test:  loss: 0.9743 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 0.9035 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00297\n",
            "Train: loss: 0.4764 | accuracy: 0.7707 | f-acore: 0.7677\n",
            "Test:  loss: 0.9916 | accuracy: 0.4932 | f1: 0.4922\n",
            "Validation:  loss: 0.9293 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00298\n",
            "Train: loss: 0.4761 | accuracy: 0.7652 | f-acore: 0.7632\n",
            "Test:  loss: 1.0117 | accuracy: 0.4795 | f1: 0.4761\n",
            "Validation:  loss: 0.9712 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00299\n",
            "Train: loss: 0.4791 | accuracy: 0.7634 | f-acore: 0.7613\n",
            "Test:  loss: 1.0008 | accuracy: 0.4904 | f1: 0.4890\n",
            "Validation:  loss: 0.9227 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00300\n",
            "Train: loss: 0.5004 | accuracy: 0.7675 | f-acore: 0.7661\n",
            "Test:  loss: 1.0083 | accuracy: 0.4904 | f1: 0.4899\n",
            "Validation:  loss: 0.9083 | accuracy: 0.5357 | f1: 0.5243\n",
            "Epoch 00301\n",
            "Train: loss: 0.4827 | accuracy: 0.7561 | f-acore: 0.7551\n",
            "Test:  loss: 0.9628 | accuracy: 0.4904 | f1: 0.4902\n",
            "Validation:  loss: 0.8928 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00302\n",
            "Train: loss: 0.4880 | accuracy: 0.7703 | f-acore: 0.7683\n",
            "Test:  loss: 1.0060 | accuracy: 0.4712 | f1: 0.4693\n",
            "Validation:  loss: 0.9895 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00303\n",
            "Train: loss: 0.4683 | accuracy: 0.7611 | f-acore: 0.7605\n",
            "Test:  loss: 1.0323 | accuracy: 0.4795 | f1: 0.4791\n",
            "Validation:  loss: 0.9562 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00304\n",
            "Train: loss: 0.4630 | accuracy: 0.7707 | f-acore: 0.7682\n",
            "Test:  loss: 1.0004 | accuracy: 0.4849 | f1: 0.4849\n",
            "Validation:  loss: 0.9263 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00305\n",
            "Train: loss: 0.4833 | accuracy: 0.7579 | f-acore: 0.7566\n",
            "Test:  loss: 0.9987 | accuracy: 0.4822 | f1: 0.4819\n",
            "Validation:  loss: 0.8973 | accuracy: 0.5833 | f1: 0.5804\n",
            "Epoch 00306\n",
            "Train: loss: 0.4843 | accuracy: 0.7698 | f-acore: 0.7672\n",
            "Test:  loss: 1.0403 | accuracy: 0.4932 | f1: 0.4909\n",
            "Validation:  loss: 1.0386 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00307\n",
            "Train: loss: 0.4758 | accuracy: 0.7758 | f-acore: 0.7727\n",
            "Test:  loss: 1.0244 | accuracy: 0.4849 | f1: 0.4848\n",
            "Validation:  loss: 0.9300 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00308\n",
            "Train: loss: 0.4773 | accuracy: 0.7630 | f-acore: 0.7612\n",
            "Test:  loss: 1.0095 | accuracy: 0.4548 | f1: 0.4468\n",
            "Validation:  loss: 0.8511 | accuracy: 0.5476 | f1: 0.5476\n",
            "Epoch 00309\n",
            "Train: loss: 0.4627 | accuracy: 0.7721 | f-acore: 0.7701\n",
            "Test:  loss: 0.9847 | accuracy: 0.4740 | f1: 0.4738\n",
            "Validation:  loss: 0.9186 | accuracy: 0.5476 | f1: 0.5435\n",
            "Epoch 00310\n",
            "Train: loss: 0.4782 | accuracy: 0.7671 | f-acore: 0.7659\n",
            "Test:  loss: 0.9898 | accuracy: 0.4685 | f1: 0.4678\n",
            "Validation:  loss: 0.9120 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00311\n",
            "Train: loss: 0.4785 | accuracy: 0.7643 | f-acore: 0.7628\n",
            "Test:  loss: 1.0251 | accuracy: 0.4685 | f1: 0.4680\n",
            "Validation:  loss: 0.9187 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00312\n",
            "Train: loss: 0.4830 | accuracy: 0.7648 | f-acore: 0.7625\n",
            "Test:  loss: 1.0030 | accuracy: 0.4712 | f1: 0.4710\n",
            "Validation:  loss: 0.8691 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00313\n",
            "Train: loss: 0.4738 | accuracy: 0.7685 | f-acore: 0.7664\n",
            "Test:  loss: 1.0561 | accuracy: 0.4877 | f1: 0.4861\n",
            "Validation:  loss: 0.9626 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00314\n",
            "Train: loss: 0.4683 | accuracy: 0.7643 | f-acore: 0.7637\n",
            "Test:  loss: 1.0137 | accuracy: 0.4767 | f1: 0.4759\n",
            "Validation:  loss: 0.9376 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00315\n",
            "Train: loss: 0.5095 | accuracy: 0.7740 | f-acore: 0.7712\n",
            "Test:  loss: 1.0554 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 1.0405 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00316\n",
            "Train: loss: 0.4792 | accuracy: 0.7703 | f-acore: 0.7683\n",
            "Test:  loss: 1.0430 | accuracy: 0.4795 | f1: 0.4777\n",
            "Validation:  loss: 1.0523 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00317\n",
            "Train: loss: 0.4895 | accuracy: 0.7607 | f-acore: 0.7587\n",
            "Test:  loss: 1.0271 | accuracy: 0.4740 | f1: 0.4733\n",
            "Validation:  loss: 0.9460 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00318\n",
            "Train: loss: 0.4619 | accuracy: 0.7675 | f-acore: 0.7665\n",
            "Test:  loss: 1.0336 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.9675 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00319\n",
            "Train: loss: 0.4673 | accuracy: 0.7689 | f-acore: 0.7666\n",
            "Test:  loss: 1.0210 | accuracy: 0.4986 | f1: 0.4979\n",
            "Validation:  loss: 0.9402 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00320\n",
            "Train: loss: 0.4583 | accuracy: 0.7804 | f-acore: 0.7782\n",
            "Test:  loss: 1.0145 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 0.9574 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00321\n",
            "Train: loss: 0.4883 | accuracy: 0.7625 | f-acore: 0.7612\n",
            "Test:  loss: 1.0336 | accuracy: 0.4932 | f1: 0.4931\n",
            "Validation:  loss: 0.9856 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00322\n",
            "Train: loss: 0.4788 | accuracy: 0.7538 | f-acore: 0.7517\n",
            "Test:  loss: 1.0119 | accuracy: 0.4959 | f1: 0.4945\n",
            "Validation:  loss: 0.9168 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00323\n",
            "Train: loss: 0.4821 | accuracy: 0.7657 | f-acore: 0.7635\n",
            "Test:  loss: 1.0112 | accuracy: 0.4658 | f1: 0.4645\n",
            "Validation:  loss: 0.9360 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00324\n",
            "Train: loss: 0.4783 | accuracy: 0.7680 | f-acore: 0.7653\n",
            "Test:  loss: 0.9790 | accuracy: 0.4767 | f1: 0.4744\n",
            "Validation:  loss: 0.8354 | accuracy: 0.5476 | f1: 0.5474\n",
            "Epoch 00325\n",
            "Train: loss: 0.4572 | accuracy: 0.7740 | f-acore: 0.7719\n",
            "Test:  loss: 1.0100 | accuracy: 0.5151 | f1: 0.5151\n",
            "Validation:  loss: 0.9318 | accuracy: 0.5833 | f1: 0.5785\n",
            "Epoch 00326\n",
            "Train: loss: 0.4948 | accuracy: 0.7776 | f-acore: 0.7765\n",
            "Test:  loss: 1.0122 | accuracy: 0.4959 | f1: 0.4954\n",
            "Validation:  loss: 0.9213 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00327\n",
            "Train: loss: 0.5020 | accuracy: 0.7675 | f-acore: 0.7663\n",
            "Test:  loss: 1.0199 | accuracy: 0.4904 | f1: 0.4901\n",
            "Validation:  loss: 0.8868 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00328\n",
            "Train: loss: 0.5022 | accuracy: 0.7726 | f-acore: 0.7697\n",
            "Test:  loss: 1.0433 | accuracy: 0.5014 | f1: 0.5007\n",
            "Validation:  loss: 0.9429 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00329\n",
            "Train: loss: 0.4641 | accuracy: 0.7785 | f-acore: 0.7773\n",
            "Test:  loss: 1.0227 | accuracy: 0.4795 | f1: 0.4786\n",
            "Validation:  loss: 0.9681 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00330\n",
            "Train: loss: 0.4899 | accuracy: 0.7721 | f-acore: 0.7693\n",
            "Test:  loss: 1.0137 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 0.8386 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00331\n",
            "Train: loss: 0.5049 | accuracy: 0.7630 | f-acore: 0.7607\n",
            "Test:  loss: 1.0039 | accuracy: 0.4740 | f1: 0.4739\n",
            "Validation:  loss: 0.8221 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00332\n",
            "Train: loss: 0.4938 | accuracy: 0.7565 | f-acore: 0.7555\n",
            "Test:  loss: 0.9884 | accuracy: 0.4795 | f1: 0.4793\n",
            "Validation:  loss: 0.9309 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00333\n",
            "Train: loss: 0.4798 | accuracy: 0.7529 | f-acore: 0.7520\n",
            "Test:  loss: 1.0427 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 0.8647 | accuracy: 0.5119 | f1: 0.5085\n",
            "Epoch 00334\n",
            "Train: loss: 0.5027 | accuracy: 0.7639 | f-acore: 0.7607\n",
            "Test:  loss: 1.0371 | accuracy: 0.4849 | f1: 0.4848\n",
            "Validation:  loss: 0.9352 | accuracy: 0.5595 | f1: 0.5518\n",
            "Epoch 00335\n",
            "Train: loss: 0.4762 | accuracy: 0.7620 | f-acore: 0.7585\n",
            "Test:  loss: 1.0013 | accuracy: 0.4822 | f1: 0.4821\n",
            "Validation:  loss: 1.0040 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00336\n",
            "Train: loss: 0.4603 | accuracy: 0.7639 | f-acore: 0.7624\n",
            "Test:  loss: 1.0069 | accuracy: 0.5096 | f1: 0.5086\n",
            "Validation:  loss: 0.9164 | accuracy: 0.5595 | f1: 0.5590\n",
            "Epoch 00337\n",
            "Train: loss: 0.4784 | accuracy: 0.7717 | f-acore: 0.7711\n",
            "Test:  loss: 1.0221 | accuracy: 0.4822 | f1: 0.4799\n",
            "Validation:  loss: 0.8832 | accuracy: 0.5238 | f1: 0.5235\n",
            "Epoch 00338\n",
            "Train: loss: 0.4656 | accuracy: 0.7625 | f-acore: 0.7593\n",
            "Test:  loss: 1.0739 | accuracy: 0.4849 | f1: 0.4829\n",
            "Validation:  loss: 1.0551 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00339\n",
            "Train: loss: 0.4648 | accuracy: 0.7685 | f-acore: 0.7671\n",
            "Test:  loss: 1.0289 | accuracy: 0.4959 | f1: 0.4948\n",
            "Validation:  loss: 0.9502 | accuracy: 0.5714 | f1: 0.5705\n",
            "Epoch 00340\n",
            "Train: loss: 0.4555 | accuracy: 0.7854 | f-acore: 0.7844\n",
            "Test:  loss: 1.0471 | accuracy: 0.5041 | f1: 0.5039\n",
            "Validation:  loss: 0.9664 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00341\n",
            "Train: loss: 0.4630 | accuracy: 0.7767 | f-acore: 0.7750\n",
            "Test:  loss: 1.0785 | accuracy: 0.4740 | f1: 0.4733\n",
            "Validation:  loss: 1.0051 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00342\n",
            "Train: loss: 0.4626 | accuracy: 0.7781 | f-acore: 0.7769\n",
            "Test:  loss: 1.0690 | accuracy: 0.4904 | f1: 0.4901\n",
            "Validation:  loss: 0.9804 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00343\n",
            "Train: loss: 0.4749 | accuracy: 0.7652 | f-acore: 0.7632\n",
            "Test:  loss: 1.0525 | accuracy: 0.4740 | f1: 0.4737\n",
            "Validation:  loss: 0.9280 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00344\n",
            "Train: loss: 0.4607 | accuracy: 0.7854 | f-acore: 0.7845\n",
            "Test:  loss: 1.0784 | accuracy: 0.4932 | f1: 0.4932\n",
            "Validation:  loss: 0.9716 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00345\n",
            "Train: loss: 0.4824 | accuracy: 0.7689 | f-acore: 0.7677\n",
            "Test:  loss: 1.0839 | accuracy: 0.4603 | f1: 0.4600\n",
            "Validation:  loss: 0.9280 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00346\n",
            "Train: loss: 0.4695 | accuracy: 0.7785 | f-acore: 0.7772\n",
            "Test:  loss: 1.0729 | accuracy: 0.4603 | f1: 0.4603\n",
            "Validation:  loss: 0.9690 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00347\n",
            "Train: loss: 0.4786 | accuracy: 0.7666 | f-acore: 0.7651\n",
            "Test:  loss: 1.0875 | accuracy: 0.4795 | f1: 0.4786\n",
            "Validation:  loss: 0.9887 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00348\n",
            "Train: loss: 0.4643 | accuracy: 0.7639 | f-acore: 0.7611\n",
            "Test:  loss: 1.0792 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 1.0029 | accuracy: 0.5595 | f1: 0.5580\n",
            "Epoch 00349\n",
            "Train: loss: 0.4682 | accuracy: 0.7730 | f-acore: 0.7704\n",
            "Test:  loss: 1.0652 | accuracy: 0.4986 | f1: 0.4983\n",
            "Validation:  loss: 1.0484 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00350\n",
            "Train: loss: 0.4557 | accuracy: 0.7744 | f-acore: 0.7733\n",
            "Test:  loss: 1.0707 | accuracy: 0.4877 | f1: 0.4858\n",
            "Validation:  loss: 1.0419 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00351\n",
            "Train: loss: 0.4547 | accuracy: 0.7795 | f-acore: 0.7770\n",
            "Test:  loss: 1.0832 | accuracy: 0.4767 | f1: 0.4759\n",
            "Validation:  loss: 1.0097 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00352\n",
            "Train: loss: 0.4637 | accuracy: 0.7781 | f-acore: 0.7765\n",
            "Test:  loss: 1.1400 | accuracy: 0.4904 | f1: 0.4880\n",
            "Validation:  loss: 1.0837 | accuracy: 0.5000 | f1: 0.4857\n",
            "Epoch 00353\n",
            "Train: loss: 0.4381 | accuracy: 0.7909 | f-acore: 0.7896\n",
            "Test:  loss: 1.1149 | accuracy: 0.4877 | f1: 0.4867\n",
            "Validation:  loss: 1.0568 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00354\n",
            "Train: loss: 0.4551 | accuracy: 0.7707 | f-acore: 0.7691\n",
            "Test:  loss: 1.0971 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 0.9349 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00355\n",
            "Train: loss: 0.4449 | accuracy: 0.7804 | f-acore: 0.7788\n",
            "Test:  loss: 1.1242 | accuracy: 0.4822 | f1: 0.4803\n",
            "Validation:  loss: 1.0378 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00356\n",
            "Train: loss: 0.4730 | accuracy: 0.7753 | f-acore: 0.7737\n",
            "Test:  loss: 1.1231 | accuracy: 0.4767 | f1: 0.4744\n",
            "Validation:  loss: 1.0696 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00357\n",
            "Train: loss: 0.4586 | accuracy: 0.7831 | f-acore: 0.7813\n",
            "Test:  loss: 1.0649 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 1.0109 | accuracy: 0.5476 | f1: 0.5453\n",
            "Epoch 00358\n",
            "Train: loss: 0.4508 | accuracy: 0.7744 | f-acore: 0.7731\n",
            "Test:  loss: 1.1152 | accuracy: 0.4795 | f1: 0.4790\n",
            "Validation:  loss: 1.0821 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00359\n",
            "Train: loss: 0.4561 | accuracy: 0.7772 | f-acore: 0.7759\n",
            "Test:  loss: 1.1143 | accuracy: 0.4795 | f1: 0.4788\n",
            "Validation:  loss: 1.0576 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00360\n",
            "Train: loss: 0.4456 | accuracy: 0.7808 | f-acore: 0.7795\n",
            "Test:  loss: 1.1168 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 1.0738 | accuracy: 0.5238 | f1: 0.5139\n",
            "Epoch 00361\n",
            "Train: loss: 0.4549 | accuracy: 0.7790 | f-acore: 0.7762\n",
            "Test:  loss: 1.0956 | accuracy: 0.4877 | f1: 0.4871\n",
            "Validation:  loss: 1.0103 | accuracy: 0.5476 | f1: 0.5347\n",
            "Epoch 00362\n",
            "Train: loss: 0.4414 | accuracy: 0.7859 | f-acore: 0.7845\n",
            "Test:  loss: 1.0963 | accuracy: 0.4767 | f1: 0.4759\n",
            "Validation:  loss: 0.9363 | accuracy: 0.5238 | f1: 0.5214\n",
            "Epoch 00363\n",
            "Train: loss: 0.4640 | accuracy: 0.7840 | f-acore: 0.7822\n",
            "Test:  loss: 1.1204 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 1.0369 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00364\n",
            "Train: loss: 0.4544 | accuracy: 0.7918 | f-acore: 0.7902\n",
            "Test:  loss: 1.1345 | accuracy: 0.4795 | f1: 0.4786\n",
            "Validation:  loss: 1.1763 | accuracy: 0.4762 | f1: 0.4612\n",
            "Epoch 00365\n",
            "Train: loss: 0.5083 | accuracy: 0.7799 | f-acore: 0.7791\n",
            "Test:  loss: 1.1013 | accuracy: 0.4712 | f1: 0.4708\n",
            "Validation:  loss: 0.9829 | accuracy: 0.4881 | f1: 0.4822\n",
            "Epoch 00366\n",
            "Train: loss: 0.4617 | accuracy: 0.7808 | f-acore: 0.7778\n",
            "Test:  loss: 1.0994 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 1.0447 | accuracy: 0.5238 | f1: 0.5102\n",
            "Epoch 00367\n",
            "Train: loss: 0.4752 | accuracy: 0.7675 | f-acore: 0.7671\n",
            "Test:  loss: 1.0777 | accuracy: 0.4932 | f1: 0.4931\n",
            "Validation:  loss: 1.1316 | accuracy: 0.5000 | f1: 0.4896\n",
            "Epoch 00368\n",
            "Train: loss: 0.4608 | accuracy: 0.7781 | f-acore: 0.7750\n",
            "Test:  loss: 1.1014 | accuracy: 0.4822 | f1: 0.4822\n",
            "Validation:  loss: 1.0836 | accuracy: 0.4643 | f1: 0.4581\n",
            "Epoch 00369\n",
            "Train: loss: 0.4453 | accuracy: 0.7891 | f-acore: 0.7871\n",
            "Test:  loss: 1.1158 | accuracy: 0.4849 | f1: 0.4838\n",
            "Validation:  loss: 1.0605 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00370\n",
            "Train: loss: 0.4442 | accuracy: 0.7795 | f-acore: 0.7780\n",
            "Test:  loss: 1.0947 | accuracy: 0.4904 | f1: 0.4904\n",
            "Validation:  loss: 1.0200 | accuracy: 0.5238 | f1: 0.5170\n",
            "Epoch 00371\n",
            "Train: loss: 0.4437 | accuracy: 0.7905 | f-acore: 0.7899\n",
            "Test:  loss: 1.1253 | accuracy: 0.4822 | f1: 0.4819\n",
            "Validation:  loss: 0.9844 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00372\n",
            "Train: loss: 0.4841 | accuracy: 0.7886 | f-acore: 0.7872\n",
            "Test:  loss: 1.1202 | accuracy: 0.4959 | f1: 0.4953\n",
            "Validation:  loss: 1.0397 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00373\n",
            "Train: loss: 0.4543 | accuracy: 0.7850 | f-acore: 0.7833\n",
            "Test:  loss: 1.0411 | accuracy: 0.4740 | f1: 0.4731\n",
            "Validation:  loss: 1.0396 | accuracy: 0.4881 | f1: 0.4845\n",
            "Epoch 00374\n",
            "Train: loss: 0.4526 | accuracy: 0.7859 | f-acore: 0.7850\n",
            "Test:  loss: 1.1265 | accuracy: 0.4849 | f1: 0.4843\n",
            "Validation:  loss: 1.1025 | accuracy: 0.4881 | f1: 0.4755\n",
            "Epoch 00375\n",
            "Train: loss: 0.4366 | accuracy: 0.7863 | f-acore: 0.7848\n",
            "Test:  loss: 1.1148 | accuracy: 0.4959 | f1: 0.4935\n",
            "Validation:  loss: 1.1323 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00376\n",
            "Train: loss: 0.4641 | accuracy: 0.7877 | f-acore: 0.7863\n",
            "Test:  loss: 1.1048 | accuracy: 0.4959 | f1: 0.4959\n",
            "Validation:  loss: 1.0250 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00377\n",
            "Train: loss: 0.4478 | accuracy: 0.7854 | f-acore: 0.7851\n",
            "Test:  loss: 1.1083 | accuracy: 0.4904 | f1: 0.4901\n",
            "Validation:  loss: 1.0742 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00378\n",
            "Train: loss: 0.4498 | accuracy: 0.7740 | f-acore: 0.7723\n",
            "Test:  loss: 1.0999 | accuracy: 0.4904 | f1: 0.4904\n",
            "Validation:  loss: 1.0585 | accuracy: 0.5119 | f1: 0.5062\n",
            "Epoch 00379\n",
            "Train: loss: 0.4391 | accuracy: 0.7831 | f-acore: 0.7815\n",
            "Test:  loss: 1.0797 | accuracy: 0.4849 | f1: 0.4849\n",
            "Validation:  loss: 1.0355 | accuracy: 0.5357 | f1: 0.5276\n",
            "Epoch 00380\n",
            "Train: loss: 0.4647 | accuracy: 0.7822 | f-acore: 0.7809\n",
            "Test:  loss: 1.1138 | accuracy: 0.4986 | f1: 0.4977\n",
            "Validation:  loss: 1.1199 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00381\n",
            "Train: loss: 0.4547 | accuracy: 0.7753 | f-acore: 0.7744\n",
            "Test:  loss: 1.1219 | accuracy: 0.5014 | f1: 0.5014\n",
            "Validation:  loss: 1.0406 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00382\n",
            "Train: loss: 0.4269 | accuracy: 0.7960 | f-acore: 0.7936\n",
            "Test:  loss: 1.1368 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 1.0444 | accuracy: 0.5595 | f1: 0.5544\n",
            "Epoch 00383\n",
            "Train: loss: 0.4464 | accuracy: 0.7813 | f-acore: 0.7796\n",
            "Test:  loss: 1.1274 | accuracy: 0.4740 | f1: 0.4728\n",
            "Validation:  loss: 1.0967 | accuracy: 0.5476 | f1: 0.5382\n",
            "Epoch 00384\n",
            "Train: loss: 0.4450 | accuracy: 0.7863 | f-acore: 0.7848\n",
            "Test:  loss: 1.1228 | accuracy: 0.4712 | f1: 0.4711\n",
            "Validation:  loss: 1.0570 | accuracy: 0.5119 | f1: 0.5034\n",
            "Epoch 00385\n",
            "Train: loss: 0.4335 | accuracy: 0.7877 | f-acore: 0.7866\n",
            "Test:  loss: 1.1089 | accuracy: 0.4740 | f1: 0.4738\n",
            "Validation:  loss: 1.0263 | accuracy: 0.5238 | f1: 0.5195\n",
            "Epoch 00386\n",
            "Train: loss: 0.4531 | accuracy: 0.7909 | f-acore: 0.7893\n",
            "Test:  loss: 1.1243 | accuracy: 0.4712 | f1: 0.4712\n",
            "Validation:  loss: 1.0413 | accuracy: 0.5714 | f1: 0.5653\n",
            "Epoch 00387\n",
            "Train: loss: 0.4563 | accuracy: 0.7772 | f-acore: 0.7768\n",
            "Test:  loss: 1.1507 | accuracy: 0.4932 | f1: 0.4928\n",
            "Validation:  loss: 1.0893 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00388\n",
            "Train: loss: 0.4554 | accuracy: 0.7818 | f-acore: 0.7796\n",
            "Test:  loss: 1.1666 | accuracy: 0.4740 | f1: 0.4731\n",
            "Validation:  loss: 1.0063 | accuracy: 0.5119 | f1: 0.5102\n",
            "Epoch 00389\n",
            "Train: loss: 0.4650 | accuracy: 0.7836 | f-acore: 0.7817\n",
            "Test:  loss: 1.1578 | accuracy: 0.4904 | f1: 0.4904\n",
            "Validation:  loss: 1.0742 | accuracy: 0.5595 | f1: 0.5564\n",
            "Epoch 00390\n",
            "Train: loss: 0.4616 | accuracy: 0.7845 | f-acore: 0.7836\n",
            "Test:  loss: 1.1368 | accuracy: 0.4959 | f1: 0.4959\n",
            "Validation:  loss: 1.0987 | accuracy: 0.5476 | f1: 0.5411\n",
            "Epoch 00391\n",
            "Train: loss: 0.4876 | accuracy: 0.7762 | f-acore: 0.7750\n",
            "Test:  loss: 1.1443 | accuracy: 0.4932 | f1: 0.4931\n",
            "Validation:  loss: 1.0763 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00392\n",
            "Train: loss: 0.4773 | accuracy: 0.7680 | f-acore: 0.7667\n",
            "Test:  loss: 1.1341 | accuracy: 0.4493 | f1: 0.4487\n",
            "Validation:  loss: 1.1053 | accuracy: 0.5357 | f1: 0.5303\n",
            "Epoch 00393\n",
            "Train: loss: 0.4564 | accuracy: 0.7785 | f-acore: 0.7771\n",
            "Test:  loss: 1.1000 | accuracy: 0.5014 | f1: 0.5009\n",
            "Validation:  loss: 1.1057 | accuracy: 0.5357 | f1: 0.5341\n",
            "Epoch 00394\n",
            "Train: loss: 0.4587 | accuracy: 0.7776 | f-acore: 0.7764\n",
            "Test:  loss: 1.0802 | accuracy: 0.5041 | f1: 0.5029\n",
            "Validation:  loss: 1.1014 | accuracy: 0.5357 | f1: 0.5325\n",
            "Epoch 00395\n",
            "Train: loss: 0.4598 | accuracy: 0.7813 | f-acore: 0.7789\n",
            "Test:  loss: 1.1172 | accuracy: 0.4986 | f1: 0.4965\n",
            "Validation:  loss: 0.9816 | accuracy: 0.6190 | f1: 0.6182\n",
            "Epoch 00396\n",
            "Train: loss: 0.4564 | accuracy: 0.7758 | f-acore: 0.7721\n",
            "Test:  loss: 1.1444 | accuracy: 0.4767 | f1: 0.4751\n",
            "Validation:  loss: 1.1646 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00397\n",
            "Train: loss: 0.4456 | accuracy: 0.7918 | f-acore: 0.7906\n",
            "Test:  loss: 1.1516 | accuracy: 0.4767 | f1: 0.4757\n",
            "Validation:  loss: 1.1748 | accuracy: 0.5119 | f1: 0.4999\n",
            "Epoch 00398\n",
            "Train: loss: 0.4498 | accuracy: 0.7868 | f-acore: 0.7851\n",
            "Test:  loss: 1.2158 | accuracy: 0.4767 | f1: 0.4748\n",
            "Validation:  loss: 1.2421 | accuracy: 0.4881 | f1: 0.4755\n",
            "Epoch 00399\n",
            "Train: loss: 0.4540 | accuracy: 0.7941 | f-acore: 0.7931\n",
            "Test:  loss: 1.1394 | accuracy: 0.4767 | f1: 0.4761\n",
            "Validation:  loss: 1.0961 | accuracy: 0.5000 | f1: 0.4857\n",
            "Epoch 00400\n",
            "Train: loss: 0.4421 | accuracy: 0.7850 | f-acore: 0.7837\n",
            "Test:  loss: 1.1663 | accuracy: 0.4658 | f1: 0.4654\n",
            "Validation:  loss: 1.1474 | accuracy: 0.5000 | f1: 0.4928\n"
          ]
        }
      ],
      "source": [
        "#Main.py script\n",
        "#Training loop\n",
        "import models #TODO: Put this at top of imports\n",
        "\n",
        "#Set up GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU instead.\")\n",
        "\n",
        "gen_num = 1 #TODO: Define this in the Config file\n",
        "for iteration in range(gen_num):\n",
        "\n",
        "\n",
        "  for index, _ in y_train.items():\n",
        "    #Get Model output path\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    print(index)\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    model_path = next_file(config['model']['type'] + index[1:], join(\"./Results/\", os.path.basename(config_path)))\n",
        "    # for b, a, in train_dataloader[index]:\n",
        "    #   print(\"opppppppppppppppppppppppppppppppppppppppppppppppppppppppp\")\n",
        "    train(config, train_data[index], val_data[index], test_data[index], model_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
