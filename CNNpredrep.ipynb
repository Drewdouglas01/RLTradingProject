{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rtHVti8i9NV4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Tuple, Any\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import accuracy_score as accuracy, f1_score\n",
        "from sklearn.preprocessing import scale\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib2 import Path\n",
        "from os.path import join\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Der8STJzGL-r"
      },
      "source": [
        "**Pre-Processing Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iTTWDMy5ILXX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import scale\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#IMPORT FROM dataset.py CNNpred-pytorch\n",
        "class WholeDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, target):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.target.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #print(\"Accessing data at index\", idx, \"with shape:\", self.data[idx].shape)\n",
        "        return self.data[idx], self.target[idx]\n",
        "\n",
        "#IMPORT FROM dataset.py CNNpred-pytorch\n",
        "def generate_batches(dataset, #ONLY GENERATES TWO BATCHES\n",
        "                     batch_size,\n",
        "                     shuffle=True,\n",
        "                     drop_last=False,\n",
        "                     device=\"cpu\",\n",
        "                     n_workers=0):\n",
        "    dataloader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last=drop_last,\n",
        "                            num_workers=n_workers,\n",
        "                            pin_memory=False)\n",
        "\n",
        "    for data, labels in dataloader:\n",
        "        #data = torch.unsqueeze(data, 1).float()\n",
        "        data = data.float()\n",
        "        labels = labels.float()\n",
        "        yield data.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "#Personally I think this should be applied to the data before it is split into\n",
        "#train, test, and val, but following CNNpred code, the test set losses seq_len\n",
        "#points with this method\n",
        "def create_windows(X, y, seq_len):\n",
        "  series = []\n",
        "  target = []\n",
        "  for i in range(len(X) - seq_len + 1):\n",
        "    series.append(X[i: i + seq_len])\n",
        "    target.append(y[i + seq_len - 1])\n",
        "\n",
        "  return np.array(series), np.array(target)\n",
        "\n",
        "\n",
        "def scale_X(X_train, X_val, X_test):\n",
        "  # Shapes of the arrays\n",
        "  num_samples_train, seq_length, num_stocks, num_features = X_train.shape\n",
        "  num_samples_val = X_val.shape[0]\n",
        "  num_samples_test = X_test.shape[0]\n",
        "\n",
        "  # Initialize a scaler for each feature\n",
        "  scalers = [StandardScaler() for _ in range(num_features)]\n",
        "\n",
        "  # Scale training data and prepare to scale validation and test data\n",
        "  X_train_scaled = np.empty_like(X_train)\n",
        "  X_val_scaled = np.empty_like(X_val)\n",
        "  X_test_scaled = np.empty_like(X_test)\n",
        "\n",
        "  # Scale each feature\n",
        "  for i in range(num_features):\n",
        "      # Extract the feature across all training data\n",
        "      feature_data_train = X_train[:, :, :, i].reshape(num_samples_train, seq_length * num_stocks)\n",
        "      \n",
        "      # Fit and transform training data\n",
        "      scalers[i].fit(feature_data_train)  # Fit only on training data\n",
        "      scaled_feature_data_train = scalers[i].transform(feature_data_train)\n",
        "      \n",
        "      # Transform validation data\n",
        "      feature_data_val = X_val[:, :, :, i].reshape(num_samples_val, seq_length * num_stocks)\n",
        "      scaled_feature_data_val = scalers[i].transform(feature_data_val)\n",
        "      \n",
        "      # Transform test data\n",
        "      feature_data_test = X_test[:, :, :, i].reshape(num_samples_test, seq_length * num_stocks)\n",
        "      scaled_feature_data_test = scalers[i].transform(feature_data_test)\n",
        "      \n",
        "      # Reshape scaled data back and store it in the correct position\n",
        "      X_train_scaled[:, :, :, i] = scaled_feature_data_train.reshape(num_samples_train, seq_length, num_stocks)\n",
        "      X_val_scaled[:, :, :, i] = scaled_feature_data_val.reshape(num_samples_val, seq_length, num_stocks)\n",
        "      X_test_scaled[:, :, :, i] = scaled_feature_data_test.reshape(num_samples_test, seq_length, num_stocks)\n",
        "\n",
        "  return X_train_scaled, X_val_scaled, X_test_scaled\n",
        "  # Now X_train_scaled, X_val_scaled, and X_test_scaled contain the appropriately scaled data\n",
        "\n",
        "\n",
        "def preprocess(data: dict,\n",
        "               seq_len: int,\n",
        "               Val_first: bool,\n",
        "               Trim_end: str,\n",
        "               Split_Date1: str,\n",
        "               Split_Date2: str,\n",
        "               n_day_predict: int = 1,) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "\n",
        "\n",
        "  X_all = []\n",
        "  y_all = {}\n",
        "\n",
        "  for index, df in data.items():\n",
        "\n",
        "    #Ensure it is sorted\n",
        "    df = df.sort_index()\n",
        "\n",
        "    #Get y\n",
        "    y_i = (df['close'][n_day_predict:] / df['close'][:-n_day_predict].values).astype(int)\n",
        "    y_i = y_i[:-n_day_predict]\n",
        "\n",
        "\n",
        "    #touch up data\n",
        "    X_i = df.fillna(0)\n",
        "    X_i = X_i[:-n_day_predict]\n",
        "    X_i = X_i[n_day_predict:]\n",
        "\n",
        "    X_all.append(X_i) \n",
        "    y_all[index] = y_i\n",
        "\n",
        "    #Get Trim index\n",
        "    Trim_index   = df.index.get_loc(Trim_end)\n",
        "    Split_index1 = df.index.get_loc(Split_Date1)\n",
        "    Split_index2 = df.index.get_loc(Split_Date2)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "  y = {}\n",
        "    \n",
        "  for index, df in data.items():\n",
        "    X, y[index] = create_windows(np.transpose(np.array(X_all), (1, 0, 2)), np.array(y_all[index]).flatten(), seq_len)\n",
        "  \n",
        "  y_train = {}\n",
        "\n",
        "  y_test = {}\n",
        "\n",
        "  y_val = {}\n",
        "\n",
        "  TESTAMOUNT = 365 #THIS IS HARD CODED AS ****, the 30 is HARD CODED\n",
        "  if Val_first: #Puts the validation first\n",
        "     X_val = X[Trim_index:Split_index1]\n",
        "     X_train = X[Split_index1:Split_index2]\n",
        "     X_test = X[Split_index2:Split_index2+TESTAMOUNT]\n",
        "     for index, _ in data.items():\n",
        "        y_val[index]   = y[index][Trim_index:Split_index1]\n",
        "        y_train[index] = y[index][Split_index1:Split_index2]\n",
        "        y_test[index]  = y[index][Split_index2:Split_index2+TESTAMOUNT] \n",
        "  else:\n",
        "    X_train = X[Trim_index:Split_index1]\n",
        "    X_val = X[Split_index1:Split_index2]\n",
        "    X_test = X[Split_index2:Split_index2+TESTAMOUNT]\n",
        "    for index, _ in data.items():\n",
        "      y_train[index]   = y[index][Trim_index:Split_index1]\n",
        "      y_val[index] = y[index][Split_index1:Split_index2]\n",
        "      y_test[index]  = y[index][Split_index2:Split_index2+TESTAMOUNT]\n",
        "  \n",
        "\n",
        "  #Scaling\n",
        "  X_train, X_val, X_test = scale_X(X_train, X_val, X_test)\n",
        "  \n",
        "\n",
        "  return X_train, y_train, X_test, y_test, X_val, y_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCiFDpaiT6Gj"
      },
      "source": [
        "**Utility Functions** Might combine with preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Urt_zmA6A1i1"
      },
      "outputs": [],
      "source": [
        "#Use for deriving next model filename\n",
        "def next_file(file, path):\n",
        "  #Ensure dicectory exists\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "\n",
        "  #Get root and extension\n",
        "  filename, ext = os.path.splitext(file)\n",
        "\n",
        "  #Get list of files\n",
        "  files = os.listdir(path)\n",
        "  num = []\n",
        "  for file in files:\n",
        "    if file.startswith(filename):\n",
        "      num.append(int(re.findall(r'\\d+', file.split('-')[-1])[0]))\n",
        "\n",
        "  #Find next iteration number\n",
        "  file_iteration_number = max(num) + 1 if len(num) else 1\n",
        "  return join(path, filename + \"-\" + str(file_iteration_number) + ext)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KoOV7hsvU22"
      },
      "source": [
        "**Engine Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzAp2PS4lsPF",
        "outputId": "e3f2deb9-8bca-412e-a0b1-ac6e77acfd13"
      },
      "outputs": [],
      "source": [
        "#Main.py script\n",
        "#Define Model and preprocessing params\n",
        "config_path = \"./Configs/year5_CNNpred.yaml\" #TODO: Define config file, this will be done in command line\n",
        "with open(config_path, \"r\") as file:\n",
        "  config = yaml.safe_load(file)\n",
        "\n",
        "with open(config['preprocess']['dataset_path'], 'rb') as file:\n",
        "  data = pickle.load(file)\n",
        "\n",
        "\n",
        "preparams = {\n",
        "    \"data\": data,\n",
        "    \"seq_len\": config['preprocess']['seq_len'],\n",
        "    \"Val_first\": bool(config['preprocess']['Val_first']),\n",
        "    \"Trim_end\": str(config['preprocess']['Trim_end']),\n",
        "    \"Split_Date1\": str(config['preprocess']['Split_Date1']),\n",
        "    \"Split_Date2\": str(config['preprocess']['Split_Date2']),\n",
        "    \"n_day_predict\": config['preprocess']['n_day_predict'],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5536"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"^DJI\"].index.get_loc(\"2022-01-03\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DotCxsDOe38",
        "outputId": "154a76fb-1fb7-4ce2-f927-32849dff679c"
      },
      "outputs": [],
      "source": [
        "#Main.py script\n",
        "#preprocess data\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = preprocess(**preparams)\n",
        "\n",
        "\n",
        "#Dict of Datasets\n",
        "train_data = {}\n",
        "val_data = {}\n",
        "test_data = {}\n",
        "\n",
        "#Dict of batch generaters\n",
        "train_dataloader = {}\n",
        "\n",
        "#Create wholedatasets in dict for each stock\n",
        "#Create batch generator for training\n",
        "\n",
        "\n",
        "X_val = X_val.transpose(0, 3, 1, 2) #TEMP\n",
        "X_test = X_test.transpose(0, 3, 1, 2) #TEMP\n",
        "\n",
        "X_train = X_train.transpose(0, 3, 1, 2) #TEMP\n",
        "for index, y_train_i in y_train.items():\n",
        "  train_data[index] = WholeDataset(X_train, y_train_i)\n",
        "  # train_dataloader[index] = generate_batches(train_data[index], config['train']['batch_size'], config['train']['num_workers']) #TODO: Replace 128 and 0 with .yaml settings\n",
        "  #Train_dataloader moved to training loop, as it needs to be re init every time\n",
        "\n",
        "for index, y_val_i in y_val.items():\n",
        "\n",
        "  val_data[index] = WholeDataset(X_val, y_val_i)\n",
        "\n",
        "for index, y_test_i in y_test.items():\n",
        "  test_data[index] = WholeDataset(X_test, y_test_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kdFnleVyd1AD"
      },
      "outputs": [],
      "source": [
        "class CNNModelOne(nn.Module):\n",
        "    def __init__(self, number_filter, number_of_stocks, seq_len, number_feature, drop, calculated_fc_layer_size):\n",
        "        super(CNNModelOne, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        #self.conv1 = nn.Conv2d(in_channels=number_feature, out_channels=number_filter[0], kernel_size=(1, 1))\n",
        "        self.conv1 = nn.Conv2d(in_channels=82, out_channels=8, kernel_size=(1, 1))\n",
        "        # Layer 2\n",
        "        #self.conv2 = nn.Conv2d(in_channels=number_filter[0], out_channels=number_filter[1], kernel_size=(1, 3))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 5))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Layer 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Flatten and Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "\n",
        "        # Output layer\n",
        "        self.fc = nn.Linear(calculated_fc_layer_size, 1)  # Calculate based on output size after last pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        torch.Size([128, 82, 60, 5])\n",
        "        torch.Size([128, 8, 60, 5])\n",
        "        torch.Size([128, 8, 58, 1])\n",
        "        torch.Size([128, 8, 29, 1])\n",
        "        torch.Size([128, 8, 27, 1])\n",
        "        torch.Size([128, 8, 13, 1])\n",
        "        torch.Size([128, 104])\n",
        "        torch.Size([128, 104])\n",
        "        \"\"\"\n",
        "        #print(\"-----------------x-x-xxx--------------\")\n",
        "        #print(x.shape) # torch.Size([128, 82, 60, 5])\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 60, 5])\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 58, 1])\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 29, 1])\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 27, 1])\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 13, 1])\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = self.dropout(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNNModelTwo(nn.Module):\n",
        "    def __init__(self, number_filter, number_of_stocks, seq_len, number_feature, drop, calculated_fc_layer_size):\n",
        "        super(CNNModelTwo, self).__init__()\n",
        "\n",
        "        # Layer 1\n",
        "        #self.conv1 = nn.Conv2d(in_channels=number_feature, out_channels=number_filter[0], kernel_size=(1, 1))\n",
        "        self.conv1 = nn.Conv2d(in_channels=82, out_channels=8, kernel_size=(1, 1))\n",
        "        # Layer 2\n",
        "        #self.conv2 = nn.Conv2d(in_channels=number_filter[0], out_channels=number_filter[1], kernel_size=(1, 3))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 5))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Layer 3\n",
        "        self.conv3 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3, 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
        "\n",
        "        # Flatten and Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "\n",
        "         # Additional Fully Connected Layer\n",
        "        self.fc1 = nn.Linear(calculated_fc_layer_size, 52)  # New intermediate layer with 52 neurons\n",
        "\n",
        "        # Output layer\n",
        "        self.fc2 = nn.Linear(52, 1)  # Output layer after the new FC layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        torch.Size([128, 82, 60, 5])\n",
        "        torch.Size([128, 8, 60, 5])\n",
        "        torch.Size([128, 8, 58, 1])\n",
        "        torch.Size([128, 8, 29, 1])\n",
        "        torch.Size([128, 8, 27, 1])\n",
        "        torch.Size([128, 8, 13, 1])\n",
        "        torch.Size([128, 104])\n",
        "        torch.Size([128, 104])\n",
        "        \"\"\"\n",
        "        #print(\"-----------------x-x-xxx--------------\")\n",
        "        #print(x.shape) # torch.Size([128, 82, 60, 5])\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 60, 5])\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 58, 1])\n",
        "        x = self.pool1(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 29, 1])\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x.shape) # torch.Size([128, 8, 27, 1])\n",
        "        x = self.pool2(x)\n",
        "        #print(x.shape) # torch.Size([128, 8, 13, 1])\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = self.dropout(x)\n",
        "        #print(x.shape) # torch.Size([128, 104])\n",
        "        x = F.relu(self.fc1(x))  # Activation for intermediate layer\n",
        "        x = torch.sigmoid(self.fc2(x))  # Final output with sigmoid activation\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KnpvMeGq4bMm"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Train.py script\n",
        "def validate(config, model, dataset):\n",
        "    model.eval()\n",
        "    loss_fcn = torch.nn.BCELoss().to(device)\n",
        "\n",
        "    data_dataloader = generate_batches(dataset, config['train']['batch_size'], config['train']['num_workers'])\n",
        "\n",
        "    loss_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch_data, batch_label in data_dataloader:\n",
        "\n",
        "            batch_data = batch_data.to(device)\n",
        "            batch_label = batch_label.to(device)\n",
        "\n",
        "            \n",
        "            batch_logit = model(batch_data).view(-1)\n",
        "\n",
        "            loss = loss_fcn(batch_logit, batch_label)\n",
        "\n",
        "            pred = (batch_logit > 0.5).int()\n",
        "\n",
        "            pred_list.extend(pred.cpu().numpy())\n",
        "            label_list.extend(batch_label.cpu().numpy())\n",
        "\n",
        "            loss_list.append(loss.item())\n",
        "\n",
        "        loss_data = np.array(loss_list).mean()\n",
        "        acc = accuracy(pred_list, label_list)\n",
        "        f1 = f1_score(pred_list, label_list, average='macro')\n",
        "\n",
        "    return loss_data, acc, f1,\n",
        "def train(config, train_data, val_dataset, test_dataset, filepath): #Test_dataset SHOULD NOT BE A PARAMETER!!!!!\n",
        "  #Init Model\n",
        "  #model_class = getattr(models, config['model']['type'])\n",
        "  #model = model_class(**config['model']['params'])\n",
        "\n",
        "  ####DEBUG DEBUG DEBUG\n",
        "  model = CNNModelOne(number_filter=[8,8,8], number_of_stocks=5, seq_len=60, number_feature=82, drop=0.1, calculated_fc_layer_size =104)\n",
        "  model = model.to(device)\n",
        "  # print(\"-------Model----------\")\n",
        "  # print(model)\n",
        "  # print(model.conv3.kernel_size)\n",
        "  # print(model.conv3.padding)\n",
        "  # print(\"-------Model----------\")\n",
        "\n",
        "  #Init loss function\n",
        "  #loss_fcn = torch.nn.BCELoss()\n",
        "  #loss_class = getattr(nn, config['loss_function']['type'])\n",
        "  #loss_fcn = loss_class(**config['loss_function']['params']).to(device)\n",
        "  loss_fcn = nn.BCELoss().to(device)\n",
        "\n",
        "\n",
        "  #Init Optimizer\n",
        "  #optimizer_class = getattr(optim, config['optimizer']['type'])\n",
        "  #optimizer = optimizer_class(model.parameters(), **{k: v for k, v in config['optimizer'].items() if k != 'type'})\n",
        "\n",
        "\n",
        "  ###DEBUG DEBUG DEBUG\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Init Scheduler\n",
        "  #scheduler_class = getattr(optim.lr_scheduler, config['scheduler']['type'])\n",
        "  #scheduler = scheduler_class(optimizer, **{k: v for k, v in config['scheduler'].items() if k != 'type'})\n",
        "\n",
        "  ###DEBUG DEBUG DEBUG\n",
        "  #scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True, eps=1e-8)\n",
        "  for epoch in range(config['train']['epoch']):\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "    #train_dataloader\n",
        "    train_dataloader = generate_batches(train_data, config['train']['batch_size'], config['train']['num_workers'])\n",
        "\n",
        "    for batch_data, batch_label in train_dataloader:\n",
        "      # print(\"-------bd----------\")\n",
        "      # print(batch_data.shape)\n",
        "      # print(\"-------------------\")\n",
        "      batch_data = batch_data.to(device) #\n",
        "      batch_label = batch_label.to(device) #\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      batch_logit = model(batch_data).view(-1)\n",
        "      loss = loss_fcn(batch_logit, batch_label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      # print(\"Batch_logit\")\n",
        "      # print(batch_logit)\n",
        "\n",
        "      #Convert to CPU for processing\n",
        "      batch_data = batch_data.cpu()\n",
        "      batch_label = batch_label.cpu()\n",
        "\n",
        "\n",
        "      pred = (batch_logit > 0.5).int()\n",
        "      # print(\"Pred\")\n",
        "      # print(pred)\n",
        "\n",
        "      pred_list.extend(pred.cpu().numpy())\n",
        "      label_list.extend(batch_label.cpu().numpy())\n",
        "\n",
        "      \n",
        "      parameters = list(model.parameters())\n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "    loss_data = np.array(loss_list).mean()\n",
        "\n",
        "    train_acc = accuracy(pred_list, label_list)\n",
        "    # print(\"-------acc----------\")\n",
        "    # print(train_acc)\n",
        "    # print(pred_list)\n",
        "    # print(label_list)\n",
        "    # print(\"-------acc----------\")\n",
        "\n",
        "    train_f1 = f1_score(pred_list, label_list, average='macro')\n",
        "\n",
        "    print(\"Epoch {:05d}\\n\"\n",
        "          \"Train: loss: {:.4f} | accuracy: {:.4f} | f-acore: {:.4f}\"\n",
        "          .format(epoch + 1, loss_data, train_acc, train_f1))\n",
        "    #loss_data = float(loss_data.item())\n",
        "\n",
        "    #loss_data = torch.tensor(loss_data)\n",
        "    \n",
        "    #scheduler.step(loss_data) SCHEDULER REMOVE FOR NOW\n",
        "\n",
        "    ###TEMP TEMP\n",
        "    test_loss, test_acc, test_f1 = validate(config, model, test_dataset)\n",
        "    print(\"Test:  loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
        "          .format(test_loss, test_acc, test_f1))\n",
        "\n",
        "    ###TEMP TEMP\n",
        "    \n",
        "    val_loss, val_acc, val_f1 = validate(config, model, val_dataset)\n",
        "    print(\"Validation:  loss: {:.4f} | accuracy: {:.4f} | f1: {:.4f}\"\n",
        "          .format(val_loss, val_acc, val_f1))\n",
        "      # choosing best model according to best validation accuracy\n",
        "    best_f1 = 0\n",
        "    if best_f1 < val_f1:\n",
        "        best_f1 = val_f1\n",
        "        torch.save(model, filepath)\n",
        "\n",
        "      # else:\n",
        "      #     cur_step += 1\n",
        "      #     if cur_step == config['train']['patience']:\n",
        "      #         break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_m91VyEo3Ib",
        "outputId": "5a116a3a-4e07-46fe-a128-76b8c217b718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using GPU: NVIDIA GeForce RTX 3070\n",
            "-----------------------------------------------------------------------------------------\n",
            "^DJI\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6906 | accuracy: 0.5330 | f-acore: 0.3477\n",
            "Test:  loss: 0.6879 | accuracy: 0.5562 | f1: 0.3574\n",
            "Validation:  loss: 0.6815 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00002\n",
            "Train: loss: 0.6913 | accuracy: 0.5316 | f-acore: 0.3480\n",
            "Test:  loss: 0.6949 | accuracy: 0.4630 | f1: 0.4496\n",
            "Validation:  loss: 0.6877 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00003\n",
            "Train: loss: 0.6914 | accuracy: 0.5330 | f-acore: 0.3727\n",
            "Test:  loss: 0.6961 | accuracy: 0.4521 | f1: 0.4329\n",
            "Validation:  loss: 0.6873 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00004\n",
            "Train: loss: 0.6885 | accuracy: 0.5348 | f-acore: 0.3736\n",
            "Test:  loss: 0.6906 | accuracy: 0.5562 | f1: 0.3574\n",
            "Validation:  loss: 0.6814 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00005\n",
            "Train: loss: 0.6905 | accuracy: 0.5334 | f-acore: 0.3798\n",
            "Test:  loss: 0.6932 | accuracy: 0.4904 | f1: 0.4275\n",
            "Validation:  loss: 0.6829 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00006\n",
            "Train: loss: 0.6914 | accuracy: 0.5417 | f-acore: 0.4399\n",
            "Test:  loss: 0.7048 | accuracy: 0.4521 | f1: 0.3652\n",
            "Validation:  loss: 0.6924 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00007\n",
            "Train: loss: 0.6887 | accuracy: 0.5426 | f-acore: 0.4612\n",
            "Test:  loss: 0.7028 | accuracy: 0.4438 | f1: 0.3905\n",
            "Validation:  loss: 0.6909 | accuracy: 0.5432 | f1: 0.4706\n",
            "Epoch 00008\n",
            "Train: loss: 0.6879 | accuracy: 0.5371 | f-acore: 0.3941\n",
            "Test:  loss: 0.7004 | accuracy: 0.4438 | f1: 0.4078\n",
            "Validation:  loss: 0.6890 | accuracy: 0.6049 | f1: 0.4499\n",
            "Epoch 00009\n",
            "Train: loss: 0.6893 | accuracy: 0.5375 | f-acore: 0.3871\n",
            "Test:  loss: 0.7000 | accuracy: 0.4384 | f1: 0.4053\n",
            "Validation:  loss: 0.6877 | accuracy: 0.5802 | f1: 0.3929\n",
            "Epoch 00010\n",
            "Train: loss: 0.6859 | accuracy: 0.5444 | f-acore: 0.4339\n",
            "Test:  loss: 0.7089 | accuracy: 0.4548 | f1: 0.3669\n",
            "Validation:  loss: 0.6950 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00011\n",
            "Train: loss: 0.6838 | accuracy: 0.5408 | f-acore: 0.4621\n",
            "Test:  loss: 0.7090 | accuracy: 0.4329 | f1: 0.3785\n",
            "Validation:  loss: 0.6931 | accuracy: 0.5062 | f1: 0.4834\n",
            "Epoch 00012\n",
            "Train: loss: 0.6891 | accuracy: 0.5453 | f-acore: 0.4175\n",
            "Test:  loss: 0.7260 | accuracy: 0.4521 | f1: 0.3494\n",
            "Validation:  loss: 0.7008 | accuracy: 0.4074 | f1: 0.3864\n",
            "Epoch 00013\n",
            "Train: loss: 0.6845 | accuracy: 0.5604 | f-acore: 0.5163\n",
            "Test:  loss: 0.7275 | accuracy: 0.4438 | f1: 0.3074\n",
            "Validation:  loss: 0.7011 | accuracy: 0.4444 | f1: 0.4002\n",
            "Epoch 00014\n",
            "Train: loss: 0.6815 | accuracy: 0.5568 | f-acore: 0.5044\n",
            "Test:  loss: 0.7131 | accuracy: 0.4329 | f1: 0.3806\n",
            "Validation:  loss: 0.6939 | accuracy: 0.4938 | f1: 0.4675\n",
            "Epoch 00015\n",
            "Train: loss: 0.6875 | accuracy: 0.5508 | f-acore: 0.4373\n",
            "Test:  loss: 0.7384 | accuracy: 0.4438 | f1: 0.3686\n",
            "Validation:  loss: 0.7031 | accuracy: 0.4321 | f1: 0.4250\n",
            "Epoch 00016\n",
            "Train: loss: 0.6818 | accuracy: 0.5641 | f-acore: 0.5605\n",
            "Test:  loss: 0.7210 | accuracy: 0.4411 | f1: 0.3585\n",
            "Validation:  loss: 0.6870 | accuracy: 0.6173 | f1: 0.6055\n",
            "Epoch 00017\n",
            "Train: loss: 0.6841 | accuracy: 0.5554 | f-acore: 0.4508\n",
            "Test:  loss: 0.6990 | accuracy: 0.4356 | f1: 0.4356\n",
            "Validation:  loss: 0.6744 | accuracy: 0.6049 | f1: 0.4286\n",
            "Epoch 00018\n",
            "Train: loss: 0.6790 | accuracy: 0.5554 | f-acore: 0.4718\n",
            "Test:  loss: 0.7156 | accuracy: 0.4247 | f1: 0.3727\n",
            "Validation:  loss: 0.6907 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00019\n",
            "Train: loss: 0.6808 | accuracy: 0.5678 | f-acore: 0.5141\n",
            "Test:  loss: 0.7263 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.6895 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00020\n",
            "Train: loss: 0.6798 | accuracy: 0.5705 | f-acore: 0.5540\n",
            "Test:  loss: 0.7338 | accuracy: 0.4301 | f1: 0.3743\n",
            "Validation:  loss: 0.6907 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00021\n",
            "Train: loss: 0.6798 | accuracy: 0.5687 | f-acore: 0.4946\n",
            "Test:  loss: 0.7228 | accuracy: 0.4411 | f1: 0.4023\n",
            "Validation:  loss: 0.6941 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00022\n",
            "Train: loss: 0.6821 | accuracy: 0.5765 | f-acore: 0.5541\n",
            "Test:  loss: 0.7602 | accuracy: 0.4438 | f1: 0.3658\n",
            "Validation:  loss: 0.7200 | accuracy: 0.4321 | f1: 0.4119\n",
            "Epoch 00023\n",
            "Train: loss: 0.6741 | accuracy: 0.5833 | f-acore: 0.5520\n",
            "Test:  loss: 0.7301 | accuracy: 0.4164 | f1: 0.3900\n",
            "Validation:  loss: 0.6819 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00024\n",
            "Train: loss: 0.6780 | accuracy: 0.5728 | f-acore: 0.5209\n",
            "Test:  loss: 0.7670 | accuracy: 0.4274 | f1: 0.3631\n",
            "Validation:  loss: 0.7055 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00025\n",
            "Train: loss: 0.6789 | accuracy: 0.5760 | f-acore: 0.5668\n",
            "Test:  loss: 0.7607 | accuracy: 0.4329 | f1: 0.3806\n",
            "Validation:  loss: 0.6941 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00026\n",
            "Train: loss: 0.6729 | accuracy: 0.5806 | f-acore: 0.5401\n",
            "Test:  loss: 0.7598 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7049 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00027\n",
            "Train: loss: 0.6699 | accuracy: 0.5820 | f-acore: 0.5655\n",
            "Test:  loss: 0.7834 | accuracy: 0.4329 | f1: 0.3641\n",
            "Validation:  loss: 0.7143 | accuracy: 0.4198 | f1: 0.4140\n",
            "Epoch 00028\n",
            "Train: loss: 0.6762 | accuracy: 0.5719 | f-acore: 0.5416\n",
            "Test:  loss: 0.8014 | accuracy: 0.4274 | f1: 0.3631\n",
            "Validation:  loss: 0.7095 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00029\n",
            "Train: loss: 0.6742 | accuracy: 0.5755 | f-acore: 0.5721\n",
            "Test:  loss: 0.7808 | accuracy: 0.4411 | f1: 0.3668\n",
            "Validation:  loss: 0.7048 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00030\n",
            "Train: loss: 0.6696 | accuracy: 0.5824 | f-acore: 0.5461\n",
            "Test:  loss: 0.7866 | accuracy: 0.4411 | f1: 0.3695\n",
            "Validation:  loss: 0.7151 | accuracy: 0.4198 | f1: 0.4198\n",
            "Epoch 00031\n",
            "Train: loss: 0.6769 | accuracy: 0.5884 | f-acore: 0.5655\n",
            "Test:  loss: 0.7926 | accuracy: 0.4329 | f1: 0.3615\n",
            "Validation:  loss: 0.7082 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00032\n",
            "Train: loss: 0.6719 | accuracy: 0.5865 | f-acore: 0.5715\n",
            "Test:  loss: 0.7970 | accuracy: 0.4356 | f1: 0.3685\n",
            "Validation:  loss: 0.7166 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00033\n",
            "Train: loss: 0.6735 | accuracy: 0.5797 | f-acore: 0.5621\n",
            "Test:  loss: 0.7685 | accuracy: 0.4301 | f1: 0.3743\n",
            "Validation:  loss: 0.6988 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00034\n",
            "Train: loss: 0.6713 | accuracy: 0.5820 | f-acore: 0.5489\n",
            "Test:  loss: 0.8131 | accuracy: 0.4438 | f1: 0.3789\n",
            "Validation:  loss: 0.7170 | accuracy: 0.4321 | f1: 0.4299\n",
            "Epoch 00035\n",
            "Train: loss: 0.6659 | accuracy: 0.6076 | f-acore: 0.5938\n",
            "Test:  loss: 0.8117 | accuracy: 0.4274 | f1: 0.3679\n",
            "Validation:  loss: 0.7150 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00036\n",
            "Train: loss: 0.6649 | accuracy: 0.5925 | f-acore: 0.5756\n",
            "Test:  loss: 0.8146 | accuracy: 0.4301 | f1: 0.3766\n",
            "Validation:  loss: 0.7041 | accuracy: 0.4815 | f1: 0.4717\n",
            "Epoch 00037\n",
            "Train: loss: 0.6643 | accuracy: 0.5971 | f-acore: 0.5787\n",
            "Test:  loss: 0.8801 | accuracy: 0.4274 | f1: 0.3679\n",
            "Validation:  loss: 0.7288 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00038\n",
            "Train: loss: 0.6655 | accuracy: 0.6026 | f-acore: 0.5982\n",
            "Test:  loss: 0.8443 | accuracy: 0.4219 | f1: 0.3708\n",
            "Validation:  loss: 0.7104 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00039\n",
            "Train: loss: 0.6566 | accuracy: 0.6003 | f-acore: 0.5743\n",
            "Test:  loss: 0.8877 | accuracy: 0.4356 | f1: 0.3710\n",
            "Validation:  loss: 0.7430 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00040\n",
            "Train: loss: 0.6587 | accuracy: 0.6007 | f-acore: 0.5879\n",
            "Test:  loss: 0.8707 | accuracy: 0.4247 | f1: 0.3706\n",
            "Validation:  loss: 0.7342 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00041\n",
            "Train: loss: 0.6710 | accuracy: 0.5939 | f-acore: 0.5831\n",
            "Test:  loss: 0.8357 | accuracy: 0.4411 | f1: 0.4106\n",
            "Validation:  loss: 0.7043 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00042\n",
            "Train: loss: 0.6585 | accuracy: 0.6030 | f-acore: 0.5760\n",
            "Test:  loss: 0.8633 | accuracy: 0.4274 | f1: 0.3702\n",
            "Validation:  loss: 0.7297 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00043\n",
            "Train: loss: 0.6669 | accuracy: 0.5966 | f-acore: 0.5886\n",
            "Test:  loss: 0.8234 | accuracy: 0.4274 | f1: 0.3829\n",
            "Validation:  loss: 0.7136 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00044\n",
            "Train: loss: 0.6571 | accuracy: 0.5966 | f-acore: 0.5863\n",
            "Test:  loss: 0.8685 | accuracy: 0.4329 | f1: 0.3739\n",
            "Validation:  loss: 0.7222 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00045\n",
            "Train: loss: 0.6546 | accuracy: 0.6021 | f-acore: 0.5847\n",
            "Test:  loss: 0.9191 | accuracy: 0.4301 | f1: 0.3598\n",
            "Validation:  loss: 0.7489 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00046\n",
            "Train: loss: 0.6611 | accuracy: 0.5971 | f-acore: 0.5905\n",
            "Test:  loss: 0.8465 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7109 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00047\n",
            "Train: loss: 0.6566 | accuracy: 0.6007 | f-acore: 0.5819\n",
            "Test:  loss: 0.8500 | accuracy: 0.4384 | f1: 0.3728\n",
            "Validation:  loss: 0.7196 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00048\n",
            "Train: loss: 0.6672 | accuracy: 0.5984 | f-acore: 0.5880\n",
            "Test:  loss: 0.8722 | accuracy: 0.4411 | f1: 0.3771\n",
            "Validation:  loss: 0.7289 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00049\n",
            "Train: loss: 0.6613 | accuracy: 0.5975 | f-acore: 0.5938\n",
            "Test:  loss: 0.8432 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7129 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00050\n",
            "Train: loss: 0.6613 | accuracy: 0.5948 | f-acore: 0.5762\n",
            "Test:  loss: 0.8683 | accuracy: 0.4247 | f1: 0.3660\n",
            "Validation:  loss: 0.7320 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00051\n",
            "Train: loss: 0.6484 | accuracy: 0.6113 | f-acore: 0.6083\n",
            "Test:  loss: 0.8570 | accuracy: 0.4329 | f1: 0.3716\n",
            "Validation:  loss: 0.7146 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00052\n",
            "Train: loss: 0.6531 | accuracy: 0.6177 | f-acore: 0.6059\n",
            "Test:  loss: 0.8727 | accuracy: 0.4329 | f1: 0.3739\n",
            "Validation:  loss: 0.7184 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00053\n",
            "Train: loss: 0.6629 | accuracy: 0.6140 | f-acore: 0.6089\n",
            "Test:  loss: 0.8868 | accuracy: 0.4329 | f1: 0.3716\n",
            "Validation:  loss: 0.7389 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00054\n",
            "Train: loss: 0.6523 | accuracy: 0.6145 | f-acore: 0.6104\n",
            "Test:  loss: 0.8713 | accuracy: 0.4301 | f1: 0.3649\n",
            "Validation:  loss: 0.7345 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00055\n",
            "Train: loss: 0.6537 | accuracy: 0.6053 | f-acore: 0.6028\n",
            "Test:  loss: 0.9125 | accuracy: 0.4356 | f1: 0.3734\n",
            "Validation:  loss: 0.7599 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00056\n",
            "Train: loss: 0.6603 | accuracy: 0.6039 | f-acore: 0.5945\n",
            "Test:  loss: 0.8837 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7440 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00057\n",
            "Train: loss: 0.6528 | accuracy: 0.6126 | f-acore: 0.5988\n",
            "Test:  loss: 0.8918 | accuracy: 0.4274 | f1: 0.3606\n",
            "Validation:  loss: 0.7569 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00058\n",
            "Train: loss: 0.6501 | accuracy: 0.6126 | f-acore: 0.6081\n",
            "Test:  loss: 0.8717 | accuracy: 0.4301 | f1: 0.3721\n",
            "Validation:  loss: 0.7212 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00059\n",
            "Train: loss: 0.6508 | accuracy: 0.6053 | f-acore: 0.5978\n",
            "Test:  loss: 0.8908 | accuracy: 0.4301 | f1: 0.3743\n",
            "Validation:  loss: 0.7328 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00060\n",
            "Train: loss: 0.6460 | accuracy: 0.6062 | f-acore: 0.6005\n",
            "Test:  loss: 0.8826 | accuracy: 0.4274 | f1: 0.3829\n",
            "Validation:  loss: 0.7230 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00061\n",
            "Train: loss: 0.6505 | accuracy: 0.6085 | f-acore: 0.5993\n",
            "Test:  loss: 0.8919 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7327 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00062\n",
            "Train: loss: 0.6371 | accuracy: 0.6204 | f-acore: 0.6126\n",
            "Test:  loss: 0.9070 | accuracy: 0.4274 | f1: 0.3789\n",
            "Validation:  loss: 0.7230 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00063\n",
            "Train: loss: 0.6403 | accuracy: 0.6227 | f-acore: 0.6096\n",
            "Test:  loss: 0.9289 | accuracy: 0.4274 | f1: 0.3679\n",
            "Validation:  loss: 0.7381 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00064\n",
            "Train: loss: 0.6395 | accuracy: 0.6149 | f-acore: 0.6093\n",
            "Test:  loss: 0.8963 | accuracy: 0.4301 | f1: 0.3829\n",
            "Validation:  loss: 0.7302 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00065\n",
            "Train: loss: 0.6537 | accuracy: 0.6259 | f-acore: 0.6131\n",
            "Test:  loss: 0.9233 | accuracy: 0.4301 | f1: 0.3721\n",
            "Validation:  loss: 0.7360 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00066\n",
            "Train: loss: 0.6382 | accuracy: 0.6158 | f-acore: 0.6128\n",
            "Test:  loss: 0.8554 | accuracy: 0.4301 | f1: 0.3924\n",
            "Validation:  loss: 0.7191 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00067\n",
            "Train: loss: 0.6455 | accuracy: 0.6213 | f-acore: 0.6142\n",
            "Test:  loss: 0.9081 | accuracy: 0.4301 | f1: 0.3887\n",
            "Validation:  loss: 0.7547 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00068\n",
            "Train: loss: 0.6465 | accuracy: 0.6314 | f-acore: 0.6267\n",
            "Test:  loss: 0.9095 | accuracy: 0.4356 | f1: 0.3908\n",
            "Validation:  loss: 0.7500 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00069\n",
            "Train: loss: 0.6513 | accuracy: 0.6241 | f-acore: 0.6170\n",
            "Test:  loss: 0.8436 | accuracy: 0.4384 | f1: 0.4037\n",
            "Validation:  loss: 0.7216 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00070\n",
            "Train: loss: 0.6423 | accuracy: 0.6268 | f-acore: 0.6121\n",
            "Test:  loss: 0.8773 | accuracy: 0.4356 | f1: 0.3946\n",
            "Validation:  loss: 0.7395 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00071\n",
            "Train: loss: 0.6402 | accuracy: 0.6291 | f-acore: 0.6226\n",
            "Test:  loss: 0.9094 | accuracy: 0.4301 | f1: 0.3868\n",
            "Validation:  loss: 0.7497 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00072\n",
            "Train: loss: 0.6408 | accuracy: 0.6310 | f-acore: 0.6244\n",
            "Test:  loss: 0.8655 | accuracy: 0.4329 | f1: 0.4057\n",
            "Validation:  loss: 0.7149 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00073\n",
            "Train: loss: 0.6301 | accuracy: 0.6474 | f-acore: 0.6414\n",
            "Test:  loss: 0.8814 | accuracy: 0.4301 | f1: 0.3887\n",
            "Validation:  loss: 0.7224 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00074\n",
            "Train: loss: 0.6424 | accuracy: 0.6310 | f-acore: 0.6177\n",
            "Test:  loss: 0.8725 | accuracy: 0.4301 | f1: 0.4006\n",
            "Validation:  loss: 0.7187 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00075\n",
            "Train: loss: 0.6343 | accuracy: 0.6337 | f-acore: 0.6257\n",
            "Test:  loss: 0.9154 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7429 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00076\n",
            "Train: loss: 0.6353 | accuracy: 0.6282 | f-acore: 0.6254\n",
            "Test:  loss: 0.9007 | accuracy: 0.4274 | f1: 0.3921\n",
            "Validation:  loss: 0.7268 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00077\n",
            "Train: loss: 0.6350 | accuracy: 0.6351 | f-acore: 0.6206\n",
            "Test:  loss: 0.8903 | accuracy: 0.4274 | f1: 0.3937\n",
            "Validation:  loss: 0.7236 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00078\n",
            "Train: loss: 0.6328 | accuracy: 0.6488 | f-acore: 0.6440\n",
            "Test:  loss: 0.8395 | accuracy: 0.4329 | f1: 0.4027\n",
            "Validation:  loss: 0.7007 | accuracy: 0.5679 | f1: 0.5546\n",
            "Epoch 00079\n",
            "Train: loss: 0.6322 | accuracy: 0.6277 | f-acore: 0.6188\n",
            "Test:  loss: 0.8908 | accuracy: 0.4329 | f1: 0.3869\n",
            "Validation:  loss: 0.7414 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00080\n",
            "Train: loss: 0.6310 | accuracy: 0.6287 | f-acore: 0.6250\n",
            "Test:  loss: 0.9146 | accuracy: 0.4384 | f1: 0.4085\n",
            "Validation:  loss: 0.7372 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00081\n",
            "Train: loss: 0.6258 | accuracy: 0.6658 | f-acore: 0.6610\n",
            "Test:  loss: 0.9259 | accuracy: 0.4274 | f1: 0.3903\n",
            "Validation:  loss: 0.7474 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00082\n",
            "Train: loss: 0.6230 | accuracy: 0.6300 | f-acore: 0.6250\n",
            "Test:  loss: 0.9319 | accuracy: 0.4301 | f1: 0.3887\n",
            "Validation:  loss: 0.7445 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00083\n",
            "Train: loss: 0.6331 | accuracy: 0.6397 | f-acore: 0.6352\n",
            "Test:  loss: 0.9010 | accuracy: 0.4247 | f1: 0.3900\n",
            "Validation:  loss: 0.7277 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00084\n",
            "Train: loss: 0.6343 | accuracy: 0.6424 | f-acore: 0.6299\n",
            "Test:  loss: 0.9010 | accuracy: 0.4192 | f1: 0.3825\n",
            "Validation:  loss: 0.7518 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00085\n",
            "Train: loss: 0.6246 | accuracy: 0.6387 | f-acore: 0.6386\n",
            "Test:  loss: 0.9266 | accuracy: 0.4356 | f1: 0.3946\n",
            "Validation:  loss: 0.7561 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00086\n",
            "Train: loss: 0.6207 | accuracy: 0.6497 | f-acore: 0.6431\n",
            "Test:  loss: 0.8672 | accuracy: 0.4356 | f1: 0.4235\n",
            "Validation:  loss: 0.7064 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00087\n",
            "Train: loss: 0.6257 | accuracy: 0.6369 | f-acore: 0.6273\n",
            "Test:  loss: 0.8939 | accuracy: 0.4301 | f1: 0.4021\n",
            "Validation:  loss: 0.7387 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00088\n",
            "Train: loss: 0.6333 | accuracy: 0.6561 | f-acore: 0.6488\n",
            "Test:  loss: 0.8918 | accuracy: 0.4356 | f1: 0.4107\n",
            "Validation:  loss: 0.7078 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00089\n",
            "Train: loss: 0.6326 | accuracy: 0.6397 | f-acore: 0.6378\n",
            "Test:  loss: 0.9163 | accuracy: 0.4247 | f1: 0.3933\n",
            "Validation:  loss: 0.7446 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00090\n",
            "Train: loss: 0.6266 | accuracy: 0.6451 | f-acore: 0.6415\n",
            "Test:  loss: 0.9566 | accuracy: 0.4329 | f1: 0.4027\n",
            "Validation:  loss: 0.7471 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00091\n",
            "Train: loss: 0.6238 | accuracy: 0.6456 | f-acore: 0.6384\n",
            "Test:  loss: 0.9833 | accuracy: 0.4329 | f1: 0.3907\n",
            "Validation:  loss: 0.7674 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00092\n",
            "Train: loss: 0.6174 | accuracy: 0.6493 | f-acore: 0.6402\n",
            "Test:  loss: 1.0320 | accuracy: 0.4301 | f1: 0.3808\n",
            "Validation:  loss: 0.7788 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00093\n",
            "Train: loss: 0.6219 | accuracy: 0.6433 | f-acore: 0.6397\n",
            "Test:  loss: 0.9584 | accuracy: 0.4356 | f1: 0.3982\n",
            "Validation:  loss: 0.7639 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00094\n",
            "Train: loss: 0.6138 | accuracy: 0.6502 | f-acore: 0.6430\n",
            "Test:  loss: 0.9493 | accuracy: 0.4329 | f1: 0.4027\n",
            "Validation:  loss: 0.7408 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00095\n",
            "Train: loss: 0.6202 | accuracy: 0.6493 | f-acore: 0.6442\n",
            "Test:  loss: 1.0189 | accuracy: 0.4329 | f1: 0.3944\n",
            "Validation:  loss: 0.7650 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00096\n",
            "Train: loss: 0.6200 | accuracy: 0.6511 | f-acore: 0.6447\n",
            "Test:  loss: 0.9881 | accuracy: 0.4329 | f1: 0.3806\n",
            "Validation:  loss: 0.7588 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00097\n",
            "Train: loss: 0.6224 | accuracy: 0.6429 | f-acore: 0.6397\n",
            "Test:  loss: 0.9648 | accuracy: 0.4411 | f1: 0.4005\n",
            "Validation:  loss: 0.7662 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00098\n",
            "Train: loss: 0.6069 | accuracy: 0.6543 | f-acore: 0.6510\n",
            "Test:  loss: 0.9714 | accuracy: 0.4384 | f1: 0.4053\n",
            "Validation:  loss: 0.7711 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00099\n",
            "Train: loss: 0.6226 | accuracy: 0.6465 | f-acore: 0.6415\n",
            "Test:  loss: 0.9554 | accuracy: 0.4411 | f1: 0.4074\n",
            "Validation:  loss: 0.7558 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00100\n",
            "Train: loss: 0.6067 | accuracy: 0.6557 | f-acore: 0.6532\n",
            "Test:  loss: 0.9481 | accuracy: 0.4301 | f1: 0.4036\n",
            "Validation:  loss: 0.7512 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00101\n",
            "Train: loss: 0.6085 | accuracy: 0.6506 | f-acore: 0.6436\n",
            "Test:  loss: 0.9534 | accuracy: 0.4274 | f1: 0.4029\n",
            "Validation:  loss: 0.7470 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00102\n",
            "Train: loss: 0.6113 | accuracy: 0.6525 | f-acore: 0.6476\n",
            "Test:  loss: 0.9957 | accuracy: 0.4356 | f1: 0.3927\n",
            "Validation:  loss: 0.7779 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00103\n",
            "Train: loss: 0.6119 | accuracy: 0.6616 | f-acore: 0.6580\n",
            "Test:  loss: 0.9535 | accuracy: 0.4356 | f1: 0.4121\n",
            "Validation:  loss: 0.7482 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00104\n",
            "Train: loss: 0.5974 | accuracy: 0.6639 | f-acore: 0.6581\n",
            "Test:  loss: 1.0438 | accuracy: 0.4329 | f1: 0.3848\n",
            "Validation:  loss: 0.7945 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00105\n",
            "Train: loss: 0.6055 | accuracy: 0.6598 | f-acore: 0.6573\n",
            "Test:  loss: 0.9713 | accuracy: 0.4356 | f1: 0.4033\n",
            "Validation:  loss: 0.7650 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00106\n",
            "Train: loss: 0.6037 | accuracy: 0.6726 | f-acore: 0.6656\n",
            "Test:  loss: 0.9953 | accuracy: 0.4301 | f1: 0.3958\n",
            "Validation:  loss: 0.7789 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00107\n",
            "Train: loss: 0.6015 | accuracy: 0.6690 | f-acore: 0.6646\n",
            "Test:  loss: 0.9752 | accuracy: 0.4301 | f1: 0.4021\n",
            "Validation:  loss: 0.7805 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00108\n",
            "Train: loss: 0.6021 | accuracy: 0.6685 | f-acore: 0.6662\n",
            "Test:  loss: 0.9874 | accuracy: 0.4356 | f1: 0.3999\n",
            "Validation:  loss: 0.7896 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00109\n",
            "Train: loss: 0.5987 | accuracy: 0.6479 | f-acore: 0.6416\n",
            "Test:  loss: 0.9653 | accuracy: 0.4274 | f1: 0.4000\n",
            "Validation:  loss: 0.7569 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00110\n",
            "Train: loss: 0.6116 | accuracy: 0.6589 | f-acore: 0.6565\n",
            "Test:  loss: 0.9878 | accuracy: 0.4384 | f1: 0.4003\n",
            "Validation:  loss: 0.7686 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00111\n",
            "Train: loss: 0.6060 | accuracy: 0.6653 | f-acore: 0.6629\n",
            "Test:  loss: 1.0483 | accuracy: 0.4384 | f1: 0.3822\n",
            "Validation:  loss: 0.7999 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00112\n",
            "Train: loss: 0.6030 | accuracy: 0.6557 | f-acore: 0.6545\n",
            "Test:  loss: 0.9456 | accuracy: 0.4301 | f1: 0.3991\n",
            "Validation:  loss: 0.7638 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00113\n",
            "Train: loss: 0.6147 | accuracy: 0.6589 | f-acore: 0.6493\n",
            "Test:  loss: 1.0003 | accuracy: 0.4301 | f1: 0.4006\n",
            "Validation:  loss: 0.7843 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00114\n",
            "Train: loss: 0.6033 | accuracy: 0.6708 | f-acore: 0.6689\n",
            "Test:  loss: 0.9904 | accuracy: 0.4301 | f1: 0.4006\n",
            "Validation:  loss: 0.7616 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00115\n",
            "Train: loss: 0.5983 | accuracy: 0.6790 | f-acore: 0.6725\n",
            "Test:  loss: 1.0113 | accuracy: 0.4329 | f1: 0.4012\n",
            "Validation:  loss: 0.7659 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00116\n",
            "Train: loss: 0.5932 | accuracy: 0.6630 | f-acore: 0.6597\n",
            "Test:  loss: 1.0255 | accuracy: 0.4301 | f1: 0.3906\n",
            "Validation:  loss: 0.7825 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00117\n",
            "Train: loss: 0.5886 | accuracy: 0.6612 | f-acore: 0.6590\n",
            "Test:  loss: 1.0296 | accuracy: 0.4329 | f1: 0.3979\n",
            "Validation:  loss: 0.7726 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00118\n",
            "Train: loss: 0.5903 | accuracy: 0.6731 | f-acore: 0.6712\n",
            "Test:  loss: 1.0137 | accuracy: 0.4411 | f1: 0.4074\n",
            "Validation:  loss: 0.8001 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00119\n",
            "Train: loss: 0.6019 | accuracy: 0.6598 | f-acore: 0.6540\n",
            "Test:  loss: 1.0272 | accuracy: 0.4329 | f1: 0.3995\n",
            "Validation:  loss: 0.7958 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00120\n",
            "Train: loss: 0.5859 | accuracy: 0.6758 | f-acore: 0.6724\n",
            "Test:  loss: 0.9637 | accuracy: 0.4247 | f1: 0.3964\n",
            "Validation:  loss: 0.7779 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00121\n",
            "Train: loss: 0.5905 | accuracy: 0.6841 | f-acore: 0.6826\n",
            "Test:  loss: 0.9898 | accuracy: 0.4384 | f1: 0.4100\n",
            "Validation:  loss: 0.7835 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00122\n",
            "Train: loss: 0.5890 | accuracy: 0.6795 | f-acore: 0.6749\n",
            "Test:  loss: 0.9764 | accuracy: 0.4274 | f1: 0.4000\n",
            "Validation:  loss: 0.7598 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00123\n",
            "Train: loss: 0.5950 | accuracy: 0.6644 | f-acore: 0.6622\n",
            "Test:  loss: 0.9436 | accuracy: 0.4329 | f1: 0.4086\n",
            "Validation:  loss: 0.7466 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00124\n",
            "Train: loss: 0.5859 | accuracy: 0.6813 | f-acore: 0.6763\n",
            "Test:  loss: 1.0266 | accuracy: 0.4329 | f1: 0.4057\n",
            "Validation:  loss: 0.7940 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00125\n",
            "Train: loss: 0.6074 | accuracy: 0.6722 | f-acore: 0.6692\n",
            "Test:  loss: 0.9926 | accuracy: 0.4356 | f1: 0.4121\n",
            "Validation:  loss: 0.7841 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00126\n",
            "Train: loss: 0.5893 | accuracy: 0.6754 | f-acore: 0.6746\n",
            "Test:  loss: 0.9864 | accuracy: 0.4575 | f1: 0.4249\n",
            "Validation:  loss: 0.8018 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00127\n",
            "Train: loss: 0.5826 | accuracy: 0.6891 | f-acore: 0.6839\n",
            "Test:  loss: 1.0027 | accuracy: 0.4548 | f1: 0.4195\n",
            "Validation:  loss: 0.7906 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00128\n",
            "Train: loss: 0.5755 | accuracy: 0.6813 | f-acore: 0.6782\n",
            "Test:  loss: 1.0700 | accuracy: 0.4575 | f1: 0.4126\n",
            "Validation:  loss: 0.8369 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00129\n",
            "Train: loss: 0.5911 | accuracy: 0.6786 | f-acore: 0.6748\n",
            "Test:  loss: 1.0521 | accuracy: 0.4493 | f1: 0.4065\n",
            "Validation:  loss: 0.8233 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00130\n",
            "Train: loss: 0.5870 | accuracy: 0.6836 | f-acore: 0.6822\n",
            "Test:  loss: 0.9882 | accuracy: 0.4411 | f1: 0.4151\n",
            "Validation:  loss: 0.8092 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00131\n",
            "Train: loss: 0.5834 | accuracy: 0.6763 | f-acore: 0.6746\n",
            "Test:  loss: 1.0262 | accuracy: 0.4329 | f1: 0.4057\n",
            "Validation:  loss: 0.7956 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00132\n",
            "Train: loss: 0.5828 | accuracy: 0.6754 | f-acore: 0.6723\n",
            "Test:  loss: 1.0782 | accuracy: 0.4521 | f1: 0.4140\n",
            "Validation:  loss: 0.8316 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00133\n",
            "Train: loss: 0.5906 | accuracy: 0.6790 | f-acore: 0.6771\n",
            "Test:  loss: 1.0622 | accuracy: 0.4411 | f1: 0.4005\n",
            "Validation:  loss: 0.8147 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00134\n",
            "Train: loss: 0.5932 | accuracy: 0.6864 | f-acore: 0.6835\n",
            "Test:  loss: 1.1052 | accuracy: 0.4493 | f1: 0.4120\n",
            "Validation:  loss: 0.8505 | accuracy: 0.4444 | f1: 0.4414\n",
            "Epoch 00135\n",
            "Train: loss: 0.6022 | accuracy: 0.6749 | f-acore: 0.6728\n",
            "Test:  loss: 0.9738 | accuracy: 0.4493 | f1: 0.4215\n",
            "Validation:  loss: 0.8074 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00136\n",
            "Train: loss: 0.5984 | accuracy: 0.6854 | f-acore: 0.6842\n",
            "Test:  loss: 1.0168 | accuracy: 0.4575 | f1: 0.4106\n",
            "Validation:  loss: 0.8327 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00137\n",
            "Train: loss: 0.5905 | accuracy: 0.6790 | f-acore: 0.6777\n",
            "Test:  loss: 0.9830 | accuracy: 0.4438 | f1: 0.4172\n",
            "Validation:  loss: 0.7730 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00138\n",
            "Train: loss: 0.5879 | accuracy: 0.6809 | f-acore: 0.6758\n",
            "Test:  loss: 0.9914 | accuracy: 0.4521 | f1: 0.4190\n",
            "Validation:  loss: 0.8084 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00139\n",
            "Train: loss: 0.5879 | accuracy: 0.6882 | f-acore: 0.6870\n",
            "Test:  loss: 1.0206 | accuracy: 0.4466 | f1: 0.4116\n",
            "Validation:  loss: 0.7999 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00140\n",
            "Train: loss: 0.5810 | accuracy: 0.6850 | f-acore: 0.6810\n",
            "Test:  loss: 0.9762 | accuracy: 0.4356 | f1: 0.4048\n",
            "Validation:  loss: 0.7957 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00141\n",
            "Train: loss: 0.5831 | accuracy: 0.6983 | f-acore: 0.6947\n",
            "Test:  loss: 0.9752 | accuracy: 0.4466 | f1: 0.4164\n",
            "Validation:  loss: 0.7899 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00142\n",
            "Train: loss: 0.5780 | accuracy: 0.6941 | f-acore: 0.6905\n",
            "Test:  loss: 0.9264 | accuracy: 0.4493 | f1: 0.4257\n",
            "Validation:  loss: 0.7795 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00143\n",
            "Train: loss: 0.5840 | accuracy: 0.6918 | f-acore: 0.6891\n",
            "Test:  loss: 0.9716 | accuracy: 0.4466 | f1: 0.4132\n",
            "Validation:  loss: 0.7780 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00144\n",
            "Train: loss: 0.5909 | accuracy: 0.6841 | f-acore: 0.6826\n",
            "Test:  loss: 1.0205 | accuracy: 0.4548 | f1: 0.4195\n",
            "Validation:  loss: 0.7972 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00145\n",
            "Train: loss: 0.5885 | accuracy: 0.6900 | f-acore: 0.6872\n",
            "Test:  loss: 0.9660 | accuracy: 0.4521 | f1: 0.4222\n",
            "Validation:  loss: 0.7962 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00146\n",
            "Train: loss: 0.5780 | accuracy: 0.6983 | f-acore: 0.6938\n",
            "Test:  loss: 0.9260 | accuracy: 0.4575 | f1: 0.4336\n",
            "Validation:  loss: 0.7729 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00147\n",
            "Train: loss: 0.5723 | accuracy: 0.6960 | f-acore: 0.6924\n",
            "Test:  loss: 0.9773 | accuracy: 0.4493 | f1: 0.4084\n",
            "Validation:  loss: 0.7964 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00148\n",
            "Train: loss: 0.5712 | accuracy: 0.6928 | f-acore: 0.6907\n",
            "Test:  loss: 0.9397 | accuracy: 0.4630 | f1: 0.4352\n",
            "Validation:  loss: 0.7887 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00149\n",
            "Train: loss: 0.5712 | accuracy: 0.6877 | f-acore: 0.6831\n",
            "Test:  loss: 1.0111 | accuracy: 0.4493 | f1: 0.4007\n",
            "Validation:  loss: 0.8275 | accuracy: 0.4568 | f1: 0.4500\n",
            "Epoch 00150\n",
            "Train: loss: 0.5635 | accuracy: 0.7005 | f-acore: 0.6988\n",
            "Test:  loss: 0.9632 | accuracy: 0.4438 | f1: 0.4158\n",
            "Validation:  loss: 0.7999 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00151\n",
            "Train: loss: 0.5854 | accuracy: 0.6978 | f-acore: 0.6939\n",
            "Test:  loss: 1.0573 | accuracy: 0.4548 | f1: 0.4143\n",
            "Validation:  loss: 0.8357 | accuracy: 0.4321 | f1: 0.4278\n",
            "Epoch 00152\n",
            "Train: loss: 0.5767 | accuracy: 0.6983 | f-acore: 0.6970\n",
            "Test:  loss: 0.9754 | accuracy: 0.4356 | f1: 0.4048\n",
            "Validation:  loss: 0.7932 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00153\n",
            "Train: loss: 0.5756 | accuracy: 0.6973 | f-acore: 0.6929\n",
            "Test:  loss: 1.0069 | accuracy: 0.4575 | f1: 0.4249\n",
            "Validation:  loss: 0.8149 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00154\n",
            "Train: loss: 0.5710 | accuracy: 0.7015 | f-acore: 0.6996\n",
            "Test:  loss: 0.9654 | accuracy: 0.4356 | f1: 0.4183\n",
            "Validation:  loss: 0.7957 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00155\n",
            "Train: loss: 0.5654 | accuracy: 0.7047 | f-acore: 0.7013\n",
            "Test:  loss: 1.0395 | accuracy: 0.4384 | f1: 0.4003\n",
            "Validation:  loss: 0.8146 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00156\n",
            "Train: loss: 0.5702 | accuracy: 0.6914 | f-acore: 0.6889\n",
            "Test:  loss: 0.9645 | accuracy: 0.4356 | f1: 0.4159\n",
            "Validation:  loss: 0.8024 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00157\n",
            "Train: loss: 0.5571 | accuracy: 0.7074 | f-acore: 0.7054\n",
            "Test:  loss: 1.0179 | accuracy: 0.4384 | f1: 0.4037\n",
            "Validation:  loss: 0.8170 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00158\n",
            "Train: loss: 0.5519 | accuracy: 0.7097 | f-acore: 0.7066\n",
            "Test:  loss: 1.0398 | accuracy: 0.4493 | f1: 0.4084\n",
            "Validation:  loss: 0.8327 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00159\n",
            "Train: loss: 0.5732 | accuracy: 0.7083 | f-acore: 0.7062\n",
            "Test:  loss: 1.0503 | accuracy: 0.4575 | f1: 0.4199\n",
            "Validation:  loss: 0.8416 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00160\n",
            "Train: loss: 0.5831 | accuracy: 0.6983 | f-acore: 0.6969\n",
            "Test:  loss: 1.0366 | accuracy: 0.4493 | f1: 0.4137\n",
            "Validation:  loss: 0.8288 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00161\n",
            "Train: loss: 0.5471 | accuracy: 0.7106 | f-acore: 0.7080\n",
            "Test:  loss: 1.0365 | accuracy: 0.4384 | f1: 0.4069\n",
            "Validation:  loss: 0.8267 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00162\n",
            "Train: loss: 0.5776 | accuracy: 0.7033 | f-acore: 0.7011\n",
            "Test:  loss: 1.0312 | accuracy: 0.4356 | f1: 0.4033\n",
            "Validation:  loss: 0.8091 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00163\n",
            "Train: loss: 0.5744 | accuracy: 0.7024 | f-acore: 0.6981\n",
            "Test:  loss: 1.0517 | accuracy: 0.4521 | f1: 0.4122\n",
            "Validation:  loss: 0.8227 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00164\n",
            "Train: loss: 0.5686 | accuracy: 0.7038 | f-acore: 0.7032\n",
            "Test:  loss: 1.0633 | accuracy: 0.4521 | f1: 0.4026\n",
            "Validation:  loss: 0.8362 | accuracy: 0.4321 | f1: 0.4299\n",
            "Epoch 00165\n",
            "Train: loss: 0.5716 | accuracy: 0.7065 | f-acore: 0.7046\n",
            "Test:  loss: 1.0290 | accuracy: 0.4384 | f1: 0.4053\n",
            "Validation:  loss: 0.7997 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00166\n",
            "Train: loss: 0.5391 | accuracy: 0.7170 | f-acore: 0.7158\n",
            "Test:  loss: 1.0288 | accuracy: 0.4301 | f1: 0.4050\n",
            "Validation:  loss: 0.7715 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00167\n",
            "Train: loss: 0.5626 | accuracy: 0.7051 | f-acore: 0.7032\n",
            "Test:  loss: 1.0752 | accuracy: 0.4438 | f1: 0.4095\n",
            "Validation:  loss: 0.8141 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00168\n",
            "Train: loss: 0.5652 | accuracy: 0.7024 | f-acore: 0.7009\n",
            "Test:  loss: 1.0844 | accuracy: 0.4521 | f1: 0.4122\n",
            "Validation:  loss: 0.8379 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00169\n",
            "Train: loss: 0.5624 | accuracy: 0.7060 | f-acore: 0.7021\n",
            "Test:  loss: 1.0717 | accuracy: 0.4411 | f1: 0.4090\n",
            "Validation:  loss: 0.8324 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00170\n",
            "Train: loss: 0.5568 | accuracy: 0.7125 | f-acore: 0.7098\n",
            "Test:  loss: 1.0909 | accuracy: 0.4493 | f1: 0.4027\n",
            "Validation:  loss: 0.8317 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00171\n",
            "Train: loss: 0.5590 | accuracy: 0.7005 | f-acore: 0.7002\n",
            "Test:  loss: 1.0505 | accuracy: 0.4438 | f1: 0.4111\n",
            "Validation:  loss: 0.8155 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00172\n",
            "Train: loss: 0.5647 | accuracy: 0.7051 | f-acore: 0.7026\n",
            "Test:  loss: 1.1410 | accuracy: 0.4438 | f1: 0.4025\n",
            "Validation:  loss: 0.8551 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00173\n",
            "Train: loss: 0.5577 | accuracy: 0.7111 | f-acore: 0.7100\n",
            "Test:  loss: 1.0681 | accuracy: 0.4384 | f1: 0.4053\n",
            "Validation:  loss: 0.8278 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00174\n",
            "Train: loss: 0.5615 | accuracy: 0.7060 | f-acore: 0.7051\n",
            "Test:  loss: 1.1013 | accuracy: 0.4493 | f1: 0.4007\n",
            "Validation:  loss: 0.8433 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00175\n",
            "Train: loss: 0.5643 | accuracy: 0.7042 | f-acore: 0.7017\n",
            "Test:  loss: 1.0656 | accuracy: 0.4438 | f1: 0.4095\n",
            "Validation:  loss: 0.8256 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00176\n",
            "Train: loss: 0.5558 | accuracy: 0.7129 | f-acore: 0.7111\n",
            "Test:  loss: 1.0517 | accuracy: 0.4247 | f1: 0.3993\n",
            "Validation:  loss: 0.8067 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00177\n",
            "Train: loss: 0.5468 | accuracy: 0.7189 | f-acore: 0.7173\n",
            "Test:  loss: 1.0959 | accuracy: 0.4466 | f1: 0.4116\n",
            "Validation:  loss: 0.8377 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00178\n",
            "Train: loss: 0.5476 | accuracy: 0.7106 | f-acore: 0.7093\n",
            "Test:  loss: 1.0671 | accuracy: 0.4274 | f1: 0.3985\n",
            "Validation:  loss: 0.8312 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00179\n",
            "Train: loss: 0.5547 | accuracy: 0.7230 | f-acore: 0.7215\n",
            "Test:  loss: 1.0746 | accuracy: 0.4356 | f1: 0.4064\n",
            "Validation:  loss: 0.8235 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00180\n",
            "Train: loss: 0.5628 | accuracy: 0.7134 | f-acore: 0.7113\n",
            "Test:  loss: 1.0345 | accuracy: 0.4384 | f1: 0.4129\n",
            "Validation:  loss: 0.8225 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00181\n",
            "Train: loss: 0.5528 | accuracy: 0.7166 | f-acore: 0.7143\n",
            "Test:  loss: 1.0441 | accuracy: 0.4438 | f1: 0.4127\n",
            "Validation:  loss: 0.8243 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00182\n",
            "Train: loss: 0.5576 | accuracy: 0.7143 | f-acore: 0.7123\n",
            "Test:  loss: 0.9941 | accuracy: 0.4411 | f1: 0.4204\n",
            "Validation:  loss: 0.8002 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00183\n",
            "Train: loss: 0.5538 | accuracy: 0.7244 | f-acore: 0.7219\n",
            "Test:  loss: 1.0505 | accuracy: 0.4411 | f1: 0.4136\n",
            "Validation:  loss: 0.8063 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00184\n",
            "Train: loss: 0.5432 | accuracy: 0.7234 | f-acore: 0.7190\n",
            "Test:  loss: 1.0405 | accuracy: 0.4438 | f1: 0.4025\n",
            "Validation:  loss: 0.8287 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00185\n",
            "Train: loss: 0.5531 | accuracy: 0.7138 | f-acore: 0.7126\n",
            "Test:  loss: 1.0340 | accuracy: 0.4301 | f1: 0.4064\n",
            "Validation:  loss: 0.8105 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00186\n",
            "Train: loss: 0.5563 | accuracy: 0.7212 | f-acore: 0.7189\n",
            "Test:  loss: 1.0664 | accuracy: 0.4356 | f1: 0.4048\n",
            "Validation:  loss: 0.8328 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00187\n",
            "Train: loss: 0.5360 | accuracy: 0.7234 | f-acore: 0.7209\n",
            "Test:  loss: 1.0421 | accuracy: 0.4411 | f1: 0.4090\n",
            "Validation:  loss: 0.8129 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00188\n",
            "Train: loss: 0.5417 | accuracy: 0.7189 | f-acore: 0.7153\n",
            "Test:  loss: 1.1895 | accuracy: 0.4411 | f1: 0.3864\n",
            "Validation:  loss: 0.8732 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00189\n",
            "Train: loss: 0.5339 | accuracy: 0.7212 | f-acore: 0.7200\n",
            "Test:  loss: 1.0764 | accuracy: 0.4384 | f1: 0.4020\n",
            "Validation:  loss: 0.8201 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00190\n",
            "Train: loss: 0.5274 | accuracy: 0.7239 | f-acore: 0.7212\n",
            "Test:  loss: 1.1206 | accuracy: 0.4356 | f1: 0.3868\n",
            "Validation:  loss: 0.8500 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00191\n",
            "Train: loss: 0.5380 | accuracy: 0.7285 | f-acore: 0.7266\n",
            "Test:  loss: 1.0867 | accuracy: 0.4384 | f1: 0.3947\n",
            "Validation:  loss: 0.8428 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00192\n",
            "Train: loss: 0.5343 | accuracy: 0.7230 | f-acore: 0.7220\n",
            "Test:  loss: 1.0783 | accuracy: 0.4411 | f1: 0.4121\n",
            "Validation:  loss: 0.8585 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00193\n",
            "Train: loss: 0.5619 | accuracy: 0.7234 | f-acore: 0.7202\n",
            "Test:  loss: 0.9846 | accuracy: 0.4301 | f1: 0.4205\n",
            "Validation:  loss: 0.7802 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00194\n",
            "Train: loss: 0.5496 | accuracy: 0.7042 | f-acore: 0.7019\n",
            "Test:  loss: 0.9899 | accuracy: 0.4411 | f1: 0.4271\n",
            "Validation:  loss: 0.8101 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00195\n",
            "Train: loss: 0.5430 | accuracy: 0.7193 | f-acore: 0.7173\n",
            "Test:  loss: 1.0970 | accuracy: 0.4384 | f1: 0.4069\n",
            "Validation:  loss: 0.8467 | accuracy: 0.4198 | f1: 0.4194\n",
            "Epoch 00196\n",
            "Train: loss: 0.5557 | accuracy: 0.7157 | f-acore: 0.7143\n",
            "Test:  loss: 1.1001 | accuracy: 0.4356 | f1: 0.4016\n",
            "Validation:  loss: 0.8146 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00197\n",
            "Train: loss: 0.5412 | accuracy: 0.7312 | f-acore: 0.7292\n",
            "Test:  loss: 1.1385 | accuracy: 0.4384 | f1: 0.4037\n",
            "Validation:  loss: 0.8266 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00198\n",
            "Train: loss: 0.5704 | accuracy: 0.7225 | f-acore: 0.7198\n",
            "Test:  loss: 1.1378 | accuracy: 0.4411 | f1: 0.4023\n",
            "Validation:  loss: 0.8363 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00199\n",
            "Train: loss: 0.5364 | accuracy: 0.7221 | f-acore: 0.7209\n",
            "Test:  loss: 1.0430 | accuracy: 0.4247 | f1: 0.4007\n",
            "Validation:  loss: 0.7983 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00200\n",
            "Train: loss: 0.5616 | accuracy: 0.7248 | f-acore: 0.7227\n",
            "Test:  loss: 1.0965 | accuracy: 0.4329 | f1: 0.4057\n",
            "Validation:  loss: 0.8385 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00201\n",
            "Train: loss: 0.5377 | accuracy: 0.7303 | f-acore: 0.7288\n",
            "Test:  loss: 1.1273 | accuracy: 0.4329 | f1: 0.3848\n",
            "Validation:  loss: 0.8185 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00202\n",
            "Train: loss: 0.5407 | accuracy: 0.7207 | f-acore: 0.7170\n",
            "Test:  loss: 1.1782 | accuracy: 0.4329 | f1: 0.3785\n",
            "Validation:  loss: 0.8794 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00203\n",
            "Train: loss: 0.5492 | accuracy: 0.7147 | f-acore: 0.7138\n",
            "Test:  loss: 1.0220 | accuracy: 0.4356 | f1: 0.4134\n",
            "Validation:  loss: 0.8115 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00204\n",
            "Train: loss: 0.5455 | accuracy: 0.7289 | f-acore: 0.7272\n",
            "Test:  loss: 1.1577 | accuracy: 0.4356 | f1: 0.3847\n",
            "Validation:  loss: 0.8644 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00205\n",
            "Train: loss: 0.5264 | accuracy: 0.7262 | f-acore: 0.7253\n",
            "Test:  loss: 1.0466 | accuracy: 0.4356 | f1: 0.3982\n",
            "Validation:  loss: 0.8244 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00206\n",
            "Train: loss: 0.5315 | accuracy: 0.7248 | f-acore: 0.7216\n",
            "Test:  loss: 1.0561 | accuracy: 0.4274 | f1: 0.3829\n",
            "Validation:  loss: 0.8331 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00207\n",
            "Train: loss: 0.5543 | accuracy: 0.7152 | f-acore: 0.7139\n",
            "Test:  loss: 1.0250 | accuracy: 0.4411 | f1: 0.4191\n",
            "Validation:  loss: 0.8052 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00208\n",
            "Train: loss: 0.5273 | accuracy: 0.7303 | f-acore: 0.7274\n",
            "Test:  loss: 1.1043 | accuracy: 0.4329 | f1: 0.3979\n",
            "Validation:  loss: 0.8587 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00209\n",
            "Train: loss: 0.5390 | accuracy: 0.7216 | f-acore: 0.7207\n",
            "Test:  loss: 1.0863 | accuracy: 0.4411 | f1: 0.4074\n",
            "Validation:  loss: 0.8390 | accuracy: 0.4321 | f1: 0.4313\n",
            "Epoch 00210\n",
            "Train: loss: 0.5271 | accuracy: 0.7312 | f-acore: 0.7299\n",
            "Test:  loss: 1.1001 | accuracy: 0.4329 | f1: 0.3979\n",
            "Validation:  loss: 0.8443 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00211\n",
            "Train: loss: 0.5324 | accuracy: 0.7248 | f-acore: 0.7241\n",
            "Test:  loss: 1.0775 | accuracy: 0.4301 | f1: 0.4021\n",
            "Validation:  loss: 0.8608 | accuracy: 0.4198 | f1: 0.4194\n",
            "Epoch 00212\n",
            "Train: loss: 0.5494 | accuracy: 0.7166 | f-acore: 0.7146\n",
            "Test:  loss: 1.0094 | accuracy: 0.4274 | f1: 0.4115\n",
            "Validation:  loss: 0.8023 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00213\n",
            "Train: loss: 0.5343 | accuracy: 0.7340 | f-acore: 0.7329\n",
            "Test:  loss: 1.0897 | accuracy: 0.4384 | f1: 0.4003\n",
            "Validation:  loss: 0.8391 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00214\n",
            "Train: loss: 0.5265 | accuracy: 0.7285 | f-acore: 0.7275\n",
            "Test:  loss: 1.0132 | accuracy: 0.4384 | f1: 0.4156\n",
            "Validation:  loss: 0.8090 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00215\n",
            "Train: loss: 0.5385 | accuracy: 0.7257 | f-acore: 0.7233\n",
            "Test:  loss: 1.0269 | accuracy: 0.4438 | f1: 0.4078\n",
            "Validation:  loss: 0.8434 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00216\n",
            "Train: loss: 0.5459 | accuracy: 0.7285 | f-acore: 0.7278\n",
            "Test:  loss: 0.9860 | accuracy: 0.4411 | f1: 0.4291\n",
            "Validation:  loss: 0.8068 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00217\n",
            "Train: loss: 0.5274 | accuracy: 0.7408 | f-acore: 0.7391\n",
            "Test:  loss: 0.9878 | accuracy: 0.4329 | f1: 0.4192\n",
            "Validation:  loss: 0.8203 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00218\n",
            "Train: loss: 0.5039 | accuracy: 0.7459 | f-acore: 0.7445\n",
            "Test:  loss: 1.0249 | accuracy: 0.4384 | f1: 0.4069\n",
            "Validation:  loss: 0.8290 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00219\n",
            "Train: loss: 0.5126 | accuracy: 0.7317 | f-acore: 0.7306\n",
            "Test:  loss: 1.0029 | accuracy: 0.4384 | f1: 0.4258\n",
            "Validation:  loss: 0.8272 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00220\n",
            "Train: loss: 0.5228 | accuracy: 0.7321 | f-acore: 0.7292\n",
            "Test:  loss: 1.0576 | accuracy: 0.4384 | f1: 0.4129\n",
            "Validation:  loss: 0.8447 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00221\n",
            "Train: loss: 0.5298 | accuracy: 0.7372 | f-acore: 0.7364\n",
            "Test:  loss: 1.0169 | accuracy: 0.4548 | f1: 0.4426\n",
            "Validation:  loss: 0.7849 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00222\n",
            "Train: loss: 0.5169 | accuracy: 0.7399 | f-acore: 0.7382\n",
            "Test:  loss: 1.0649 | accuracy: 0.4274 | f1: 0.4042\n",
            "Validation:  loss: 0.8282 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00223\n",
            "Train: loss: 0.5348 | accuracy: 0.7408 | f-acore: 0.7394\n",
            "Test:  loss: 1.0695 | accuracy: 0.4411 | f1: 0.4178\n",
            "Validation:  loss: 0.8435 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00224\n",
            "Train: loss: 0.5145 | accuracy: 0.7340 | f-acore: 0.7325\n",
            "Test:  loss: 1.1035 | accuracy: 0.4438 | f1: 0.4186\n",
            "Validation:  loss: 0.8637 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00225\n",
            "Train: loss: 0.5242 | accuracy: 0.7317 | f-acore: 0.7304\n",
            "Test:  loss: 1.0654 | accuracy: 0.4438 | f1: 0.4172\n",
            "Validation:  loss: 0.8521 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00226\n",
            "Train: loss: 0.5193 | accuracy: 0.7436 | f-acore: 0.7401\n",
            "Test:  loss: 1.1496 | accuracy: 0.4384 | f1: 0.4053\n",
            "Validation:  loss: 0.8738 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00227\n",
            "Train: loss: 0.5266 | accuracy: 0.7473 | f-acore: 0.7464\n",
            "Test:  loss: 1.1093 | accuracy: 0.4329 | f1: 0.4057\n",
            "Validation:  loss: 0.8295 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00228\n",
            "Train: loss: 0.5258 | accuracy: 0.7427 | f-acore: 0.7407\n",
            "Test:  loss: 1.1704 | accuracy: 0.4356 | f1: 0.3868\n",
            "Validation:  loss: 0.8813 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00229\n",
            "Train: loss: 0.5247 | accuracy: 0.7363 | f-acore: 0.7352\n",
            "Test:  loss: 1.1719 | accuracy: 0.4438 | f1: 0.4025\n",
            "Validation:  loss: 0.8399 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00230\n",
            "Train: loss: 0.5196 | accuracy: 0.7450 | f-acore: 0.7435\n",
            "Test:  loss: 1.1948 | accuracy: 0.4247 | f1: 0.3749\n",
            "Validation:  loss: 0.8412 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00231\n",
            "Train: loss: 0.5177 | accuracy: 0.7395 | f-acore: 0.7384\n",
            "Test:  loss: 1.2097 | accuracy: 0.4356 | f1: 0.3826\n",
            "Validation:  loss: 0.8684 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00232\n",
            "Train: loss: 0.5095 | accuracy: 0.7509 | f-acore: 0.7501\n",
            "Test:  loss: 1.2241 | accuracy: 0.4329 | f1: 0.3828\n",
            "Validation:  loss: 0.8702 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00233\n",
            "Train: loss: 0.5232 | accuracy: 0.7463 | f-acore: 0.7448\n",
            "Test:  loss: 1.1518 | accuracy: 0.4466 | f1: 0.4132\n",
            "Validation:  loss: 0.8610 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00234\n",
            "Train: loss: 0.5172 | accuracy: 0.7468 | f-acore: 0.7446\n",
            "Test:  loss: 1.1719 | accuracy: 0.4493 | f1: 0.4120\n",
            "Validation:  loss: 0.8859 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00235\n",
            "Train: loss: 0.5103 | accuracy: 0.7468 | f-acore: 0.7457\n",
            "Test:  loss: 1.1656 | accuracy: 0.4438 | f1: 0.3987\n",
            "Validation:  loss: 0.8672 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00236\n",
            "Train: loss: 0.5163 | accuracy: 0.7386 | f-acore: 0.7369\n",
            "Test:  loss: 1.2323 | accuracy: 0.4356 | f1: 0.3847\n",
            "Validation:  loss: 0.8756 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00237\n",
            "Train: loss: 0.5142 | accuracy: 0.7468 | f-acore: 0.7453\n",
            "Test:  loss: 1.1601 | accuracy: 0.4247 | f1: 0.3917\n",
            "Validation:  loss: 0.8525 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00238\n",
            "Train: loss: 0.5127 | accuracy: 0.7468 | f-acore: 0.7455\n",
            "Test:  loss: 1.1351 | accuracy: 0.4356 | f1: 0.4033\n",
            "Validation:  loss: 0.8484 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00239\n",
            "Train: loss: 0.5072 | accuracy: 0.7495 | f-acore: 0.7477\n",
            "Test:  loss: 1.1675 | accuracy: 0.4521 | f1: 0.4157\n",
            "Validation:  loss: 0.8705 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00240\n",
            "Train: loss: 0.5152 | accuracy: 0.7376 | f-acore: 0.7352\n",
            "Test:  loss: 1.2254 | accuracy: 0.4301 | f1: 0.3829\n",
            "Validation:  loss: 0.8618 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00241\n",
            "Train: loss: 0.5081 | accuracy: 0.7527 | f-acore: 0.7503\n",
            "Test:  loss: 1.2678 | accuracy: 0.4356 | f1: 0.3847\n",
            "Validation:  loss: 0.8948 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00242\n",
            "Train: loss: 0.5210 | accuracy: 0.7399 | f-acore: 0.7382\n",
            "Test:  loss: 1.1717 | accuracy: 0.4301 | f1: 0.3868\n",
            "Validation:  loss: 0.8430 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00243\n",
            "Train: loss: 0.5094 | accuracy: 0.7495 | f-acore: 0.7476\n",
            "Test:  loss: 1.2581 | accuracy: 0.4438 | f1: 0.3860\n",
            "Validation:  loss: 0.9108 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00244\n",
            "Train: loss: 0.5023 | accuracy: 0.7440 | f-acore: 0.7432\n",
            "Test:  loss: 1.1401 | accuracy: 0.4356 | f1: 0.4033\n",
            "Validation:  loss: 0.8395 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00245\n",
            "Train: loss: 0.5111 | accuracy: 0.7486 | f-acore: 0.7466\n",
            "Test:  loss: 1.1870 | accuracy: 0.4411 | f1: 0.4074\n",
            "Validation:  loss: 0.8706 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00246\n",
            "Train: loss: 0.5036 | accuracy: 0.7550 | f-acore: 0.7535\n",
            "Test:  loss: 1.2813 | accuracy: 0.4384 | f1: 0.3845\n",
            "Validation:  loss: 0.8935 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00247\n",
            "Train: loss: 0.5138 | accuracy: 0.7482 | f-acore: 0.7474\n",
            "Test:  loss: 1.2674 | accuracy: 0.4384 | f1: 0.3845\n",
            "Validation:  loss: 0.8796 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00248\n",
            "Train: loss: 0.5170 | accuracy: 0.7408 | f-acore: 0.7386\n",
            "Test:  loss: 1.2468 | accuracy: 0.4329 | f1: 0.3806\n",
            "Validation:  loss: 0.8749 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00249\n",
            "Train: loss: 0.5137 | accuracy: 0.7395 | f-acore: 0.7380\n",
            "Test:  loss: 1.2411 | accuracy: 0.4301 | f1: 0.3787\n",
            "Validation:  loss: 0.8743 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00250\n",
            "Train: loss: 0.5093 | accuracy: 0.7473 | f-acore: 0.7455\n",
            "Test:  loss: 1.2066 | accuracy: 0.4356 | f1: 0.3888\n",
            "Validation:  loss: 0.8532 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00251\n",
            "Train: loss: 0.5136 | accuracy: 0.7505 | f-acore: 0.7490\n",
            "Test:  loss: 1.1939 | accuracy: 0.4356 | f1: 0.3982\n",
            "Validation:  loss: 0.8453 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00252\n",
            "Train: loss: 0.4936 | accuracy: 0.7610 | f-acore: 0.7601\n",
            "Test:  loss: 1.1335 | accuracy: 0.4356 | f1: 0.4016\n",
            "Validation:  loss: 0.8566 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00253\n",
            "Train: loss: 0.5219 | accuracy: 0.7477 | f-acore: 0.7461\n",
            "Test:  loss: 1.1837 | accuracy: 0.4329 | f1: 0.3944\n",
            "Validation:  loss: 0.8604 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00254\n",
            "Train: loss: 0.4986 | accuracy: 0.7614 | f-acore: 0.7600\n",
            "Test:  loss: 1.1294 | accuracy: 0.4329 | f1: 0.4057\n",
            "Validation:  loss: 0.8373 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00255\n",
            "Train: loss: 0.5028 | accuracy: 0.7527 | f-acore: 0.7520\n",
            "Test:  loss: 1.2505 | accuracy: 0.4356 | f1: 0.3888\n",
            "Validation:  loss: 0.9038 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00256\n",
            "Train: loss: 0.4967 | accuracy: 0.7527 | f-acore: 0.7512\n",
            "Test:  loss: 1.1974 | accuracy: 0.4247 | f1: 0.3900\n",
            "Validation:  loss: 0.8773 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00257\n",
            "Train: loss: 0.5206 | accuracy: 0.7491 | f-acore: 0.7480\n",
            "Test:  loss: 1.3113 | accuracy: 0.4329 | f1: 0.3828\n",
            "Validation:  loss: 0.8904 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00258\n",
            "Train: loss: 0.4959 | accuracy: 0.7477 | f-acore: 0.7458\n",
            "Test:  loss: 1.2518 | accuracy: 0.4411 | f1: 0.3967\n",
            "Validation:  loss: 0.8838 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00259\n",
            "Train: loss: 0.4897 | accuracy: 0.7518 | f-acore: 0.7510\n",
            "Test:  loss: 1.2748 | accuracy: 0.4356 | f1: 0.3927\n",
            "Validation:  loss: 0.8751 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00260\n",
            "Train: loss: 0.4941 | accuracy: 0.7560 | f-acore: 0.7541\n",
            "Test:  loss: 1.3562 | accuracy: 0.4329 | f1: 0.3785\n",
            "Validation:  loss: 0.9308 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00261\n",
            "Train: loss: 0.5110 | accuracy: 0.7477 | f-acore: 0.7466\n",
            "Test:  loss: 1.1967 | accuracy: 0.4384 | f1: 0.4069\n",
            "Validation:  loss: 0.8730 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00262\n",
            "Train: loss: 0.5059 | accuracy: 0.7363 | f-acore: 0.7333\n",
            "Test:  loss: 1.2105 | accuracy: 0.4411 | f1: 0.3948\n",
            "Validation:  loss: 0.8824 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00263\n",
            "Train: loss: 0.4919 | accuracy: 0.7555 | f-acore: 0.7544\n",
            "Test:  loss: 1.2101 | accuracy: 0.4411 | f1: 0.4041\n",
            "Validation:  loss: 0.8658 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00264\n",
            "Train: loss: 0.4906 | accuracy: 0.7596 | f-acore: 0.7569\n",
            "Test:  loss: 1.2583 | accuracy: 0.4329 | f1: 0.3869\n",
            "Validation:  loss: 0.9022 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00265\n",
            "Train: loss: 0.4931 | accuracy: 0.7660 | f-acore: 0.7645\n",
            "Test:  loss: 1.2098 | accuracy: 0.4384 | f1: 0.4020\n",
            "Validation:  loss: 0.8620 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00266\n",
            "Train: loss: 0.5011 | accuracy: 0.7495 | f-acore: 0.7471\n",
            "Test:  loss: 1.3906 | accuracy: 0.4384 | f1: 0.3800\n",
            "Validation:  loss: 0.9378 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00267\n",
            "Train: loss: 0.4984 | accuracy: 0.7527 | f-acore: 0.7514\n",
            "Test:  loss: 1.1974 | accuracy: 0.4356 | f1: 0.4048\n",
            "Validation:  loss: 0.8535 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00268\n",
            "Train: loss: 0.4878 | accuracy: 0.7509 | f-acore: 0.7489\n",
            "Test:  loss: 1.3655 | accuracy: 0.4411 | f1: 0.3795\n",
            "Validation:  loss: 0.9323 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00269\n",
            "Train: loss: 0.4935 | accuracy: 0.7596 | f-acore: 0.7578\n",
            "Test:  loss: 1.3302 | accuracy: 0.4301 | f1: 0.3743\n",
            "Validation:  loss: 0.8989 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00270\n",
            "Train: loss: 0.4931 | accuracy: 0.7546 | f-acore: 0.7536\n",
            "Test:  loss: 1.2420 | accuracy: 0.4384 | f1: 0.4069\n",
            "Validation:  loss: 0.8870 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00271\n",
            "Train: loss: 0.4932 | accuracy: 0.7587 | f-acore: 0.7573\n",
            "Test:  loss: 1.2689 | accuracy: 0.4384 | f1: 0.3985\n",
            "Validation:  loss: 0.9053 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00272\n",
            "Train: loss: 0.4926 | accuracy: 0.7637 | f-acore: 0.7614\n",
            "Test:  loss: 1.2345 | accuracy: 0.4301 | f1: 0.3906\n",
            "Validation:  loss: 0.8774 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00273\n",
            "Train: loss: 0.5116 | accuracy: 0.7473 | f-acore: 0.7455\n",
            "Test:  loss: 1.2809 | accuracy: 0.4438 | f1: 0.3987\n",
            "Validation:  loss: 0.9158 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00274\n",
            "Train: loss: 0.4793 | accuracy: 0.7614 | f-acore: 0.7597\n",
            "Test:  loss: 1.3121 | accuracy: 0.4329 | f1: 0.3888\n",
            "Validation:  loss: 0.8922 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00275\n",
            "Train: loss: 0.5318 | accuracy: 0.7532 | f-acore: 0.7518\n",
            "Test:  loss: 1.4928 | accuracy: 0.4384 | f1: 0.3800\n",
            "Validation:  loss: 0.9652 | accuracy: 0.4444 | f1: 0.4414\n",
            "Epoch 00276\n",
            "Train: loss: 0.4975 | accuracy: 0.7500 | f-acore: 0.7491\n",
            "Test:  loss: 1.2993 | accuracy: 0.4274 | f1: 0.3809\n",
            "Validation:  loss: 0.8580 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00277\n",
            "Train: loss: 0.4804 | accuracy: 0.7610 | f-acore: 0.7592\n",
            "Test:  loss: 1.5298 | accuracy: 0.4274 | f1: 0.3679\n",
            "Validation:  loss: 0.9766 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00278\n",
            "Train: loss: 0.4813 | accuracy: 0.7550 | f-acore: 0.7531\n",
            "Test:  loss: 1.3811 | accuracy: 0.4356 | f1: 0.3888\n",
            "Validation:  loss: 0.9269 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00279\n",
            "Train: loss: 0.4942 | accuracy: 0.7573 | f-acore: 0.7563\n",
            "Test:  loss: 1.3152 | accuracy: 0.4274 | f1: 0.3829\n",
            "Validation:  loss: 0.8798 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00280\n",
            "Train: loss: 0.4956 | accuracy: 0.7514 | f-acore: 0.7488\n",
            "Test:  loss: 1.3594 | accuracy: 0.4438 | f1: 0.3987\n",
            "Validation:  loss: 0.9193 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00281\n",
            "Train: loss: 0.4954 | accuracy: 0.7569 | f-acore: 0.7558\n",
            "Test:  loss: 1.3038 | accuracy: 0.4384 | f1: 0.3947\n",
            "Validation:  loss: 0.8770 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00282\n",
            "Train: loss: 0.4890 | accuracy: 0.7527 | f-acore: 0.7517\n",
            "Test:  loss: 1.3067 | accuracy: 0.4384 | f1: 0.3928\n",
            "Validation:  loss: 0.8929 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00283\n",
            "Train: loss: 0.4839 | accuracy: 0.7665 | f-acore: 0.7640\n",
            "Test:  loss: 1.2723 | accuracy: 0.4301 | f1: 0.3887\n",
            "Validation:  loss: 0.8977 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00284\n",
            "Train: loss: 0.4898 | accuracy: 0.7578 | f-acore: 0.7563\n",
            "Test:  loss: 1.2357 | accuracy: 0.4356 | f1: 0.3964\n",
            "Validation:  loss: 0.8914 | accuracy: 0.4198 | f1: 0.4183\n",
            "Epoch 00285\n",
            "Train: loss: 0.4902 | accuracy: 0.7674 | f-acore: 0.7664\n",
            "Test:  loss: 1.2275 | accuracy: 0.4356 | f1: 0.4048\n",
            "Validation:  loss: 0.8869 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00286\n",
            "Train: loss: 0.4823 | accuracy: 0.7683 | f-acore: 0.7659\n",
            "Test:  loss: 1.4664 | accuracy: 0.4411 | f1: 0.3818\n",
            "Validation:  loss: 0.9461 | accuracy: 0.4444 | f1: 0.4414\n",
            "Epoch 00287\n",
            "Train: loss: 0.4941 | accuracy: 0.7610 | f-acore: 0.7591\n",
            "Test:  loss: 1.3704 | accuracy: 0.4411 | f1: 0.3885\n",
            "Validation:  loss: 0.9425 | accuracy: 0.4321 | f1: 0.4299\n",
            "Epoch 00288\n",
            "Train: loss: 0.4733 | accuracy: 0.7688 | f-acore: 0.7682\n",
            "Test:  loss: 1.2879 | accuracy: 0.4329 | f1: 0.3944\n",
            "Validation:  loss: 0.8866 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00289\n",
            "Train: loss: 0.5010 | accuracy: 0.7505 | f-acore: 0.7496\n",
            "Test:  loss: 1.3409 | accuracy: 0.4301 | f1: 0.3906\n",
            "Validation:  loss: 0.9235 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00290\n",
            "Train: loss: 0.4936 | accuracy: 0.7660 | f-acore: 0.7641\n",
            "Test:  loss: 1.2562 | accuracy: 0.4384 | f1: 0.4129\n",
            "Validation:  loss: 0.9021 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00291\n",
            "Train: loss: 0.4851 | accuracy: 0.7706 | f-acore: 0.7697\n",
            "Test:  loss: 1.3337 | accuracy: 0.4301 | f1: 0.3941\n",
            "Validation:  loss: 0.9266 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00292\n",
            "Train: loss: 0.5048 | accuracy: 0.7619 | f-acore: 0.7607\n",
            "Test:  loss: 1.3516 | accuracy: 0.4247 | f1: 0.3809\n",
            "Validation:  loss: 0.9271 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00293\n",
            "Train: loss: 0.4952 | accuracy: 0.7633 | f-acore: 0.7623\n",
            "Test:  loss: 1.2500 | accuracy: 0.4329 | f1: 0.3979\n",
            "Validation:  loss: 0.8845 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00294\n",
            "Train: loss: 0.4975 | accuracy: 0.7619 | f-acore: 0.7606\n",
            "Test:  loss: 1.3316 | accuracy: 0.4329 | f1: 0.3888\n",
            "Validation:  loss: 0.9167 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00295\n",
            "Train: loss: 0.4905 | accuracy: 0.7468 | f-acore: 0.7442\n",
            "Test:  loss: 1.2876 | accuracy: 0.4329 | f1: 0.3995\n",
            "Validation:  loss: 0.9131 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00296\n",
            "Train: loss: 0.4852 | accuracy: 0.7537 | f-acore: 0.7517\n",
            "Test:  loss: 1.4056 | accuracy: 0.4384 | f1: 0.3866\n",
            "Validation:  loss: 0.9595 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00297\n",
            "Train: loss: 0.4815 | accuracy: 0.7624 | f-acore: 0.7607\n",
            "Test:  loss: 1.3259 | accuracy: 0.4301 | f1: 0.3906\n",
            "Validation:  loss: 0.9103 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00298\n",
            "Train: loss: 0.4773 | accuracy: 0.7624 | f-acore: 0.7617\n",
            "Test:  loss: 1.3630 | accuracy: 0.4356 | f1: 0.3888\n",
            "Validation:  loss: 0.9437 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00299\n",
            "Train: loss: 0.4809 | accuracy: 0.7523 | f-acore: 0.7513\n",
            "Test:  loss: 1.3444 | accuracy: 0.4329 | f1: 0.3888\n",
            "Validation:  loss: 0.9183 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00300\n",
            "Train: loss: 0.4755 | accuracy: 0.7660 | f-acore: 0.7646\n",
            "Test:  loss: 1.3321 | accuracy: 0.4411 | f1: 0.3967\n",
            "Validation:  loss: 0.9143 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00301\n",
            "Train: loss: 0.4806 | accuracy: 0.7679 | f-acore: 0.7669\n",
            "Test:  loss: 1.3579 | accuracy: 0.4329 | f1: 0.3926\n",
            "Validation:  loss: 0.9163 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00302\n",
            "Train: loss: 0.4705 | accuracy: 0.7807 | f-acore: 0.7795\n",
            "Test:  loss: 1.3545 | accuracy: 0.4384 | f1: 0.4003\n",
            "Validation:  loss: 0.9371 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00303\n",
            "Train: loss: 0.4627 | accuracy: 0.7674 | f-acore: 0.7659\n",
            "Test:  loss: 1.4098 | accuracy: 0.4411 | f1: 0.4005\n",
            "Validation:  loss: 0.9532 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00304\n",
            "Train: loss: 0.4696 | accuracy: 0.7637 | f-acore: 0.7625\n",
            "Test:  loss: 1.4420 | accuracy: 0.4301 | f1: 0.3787\n",
            "Validation:  loss: 0.9777 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00305\n",
            "Train: loss: 0.4913 | accuracy: 0.7610 | f-acore: 0.7589\n",
            "Test:  loss: 1.4518 | accuracy: 0.4356 | f1: 0.3847\n",
            "Validation:  loss: 0.9756 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00306\n",
            "Train: loss: 0.4619 | accuracy: 0.7738 | f-acore: 0.7726\n",
            "Test:  loss: 1.4452 | accuracy: 0.4384 | f1: 0.3887\n",
            "Validation:  loss: 0.9798 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00307\n",
            "Train: loss: 0.4700 | accuracy: 0.7770 | f-acore: 0.7758\n",
            "Test:  loss: 1.3822 | accuracy: 0.4384 | f1: 0.3985\n",
            "Validation:  loss: 0.9426 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00308\n",
            "Train: loss: 0.4750 | accuracy: 0.7706 | f-acore: 0.7680\n",
            "Test:  loss: 1.3251 | accuracy: 0.4247 | f1: 0.3865\n",
            "Validation:  loss: 0.9279 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00309\n",
            "Train: loss: 0.4676 | accuracy: 0.7679 | f-acore: 0.7657\n",
            "Test:  loss: 1.3400 | accuracy: 0.4384 | f1: 0.4003\n",
            "Validation:  loss: 0.9346 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00310\n",
            "Train: loss: 0.4620 | accuracy: 0.7770 | f-acore: 0.7760\n",
            "Test:  loss: 1.3406 | accuracy: 0.4356 | f1: 0.3964\n",
            "Validation:  loss: 0.9417 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00311\n",
            "Train: loss: 0.4782 | accuracy: 0.7619 | f-acore: 0.7608\n",
            "Test:  loss: 1.2951 | accuracy: 0.4274 | f1: 0.3937\n",
            "Validation:  loss: 0.9285 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00312\n",
            "Train: loss: 0.4825 | accuracy: 0.7587 | f-acore: 0.7569\n",
            "Test:  loss: 1.3970 | accuracy: 0.4384 | f1: 0.4020\n",
            "Validation:  loss: 0.9421 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00313\n",
            "Train: loss: 0.4761 | accuracy: 0.7729 | f-acore: 0.7709\n",
            "Test:  loss: 1.3179 | accuracy: 0.4384 | f1: 0.4037\n",
            "Validation:  loss: 0.9015 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00314\n",
            "Train: loss: 0.4997 | accuracy: 0.7624 | f-acore: 0.7602\n",
            "Test:  loss: 1.5171 | accuracy: 0.4356 | f1: 0.3804\n",
            "Validation:  loss: 0.9949 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00315\n",
            "Train: loss: 0.4869 | accuracy: 0.7596 | f-acore: 0.7594\n",
            "Test:  loss: 1.2263 | accuracy: 0.4384 | f1: 0.4228\n",
            "Validation:  loss: 0.8875 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00316\n",
            "Train: loss: 0.4880 | accuracy: 0.7752 | f-acore: 0.7734\n",
            "Test:  loss: 1.3491 | accuracy: 0.4384 | f1: 0.4020\n",
            "Validation:  loss: 0.9556 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00317\n",
            "Train: loss: 0.4818 | accuracy: 0.7656 | f-acore: 0.7644\n",
            "Test:  loss: 1.3000 | accuracy: 0.4438 | f1: 0.4143\n",
            "Validation:  loss: 0.9173 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00318\n",
            "Train: loss: 0.4662 | accuracy: 0.7665 | f-acore: 0.7651\n",
            "Test:  loss: 1.3905 | accuracy: 0.4274 | f1: 0.3867\n",
            "Validation:  loss: 0.9304 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00319\n",
            "Train: loss: 0.4660 | accuracy: 0.7688 | f-acore: 0.7668\n",
            "Test:  loss: 1.3772 | accuracy: 0.4274 | f1: 0.3903\n",
            "Validation:  loss: 0.9303 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00320\n",
            "Train: loss: 0.4817 | accuracy: 0.7711 | f-acore: 0.7701\n",
            "Test:  loss: 1.4238 | accuracy: 0.4274 | f1: 0.3829\n",
            "Validation:  loss: 0.9492 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00321\n",
            "Train: loss: 0.4740 | accuracy: 0.7788 | f-acore: 0.7778\n",
            "Test:  loss: 1.4194 | accuracy: 0.4356 | f1: 0.3927\n",
            "Validation:  loss: 0.9374 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00322\n",
            "Train: loss: 0.4775 | accuracy: 0.7656 | f-acore: 0.7645\n",
            "Test:  loss: 1.3616 | accuracy: 0.4466 | f1: 0.4148\n",
            "Validation:  loss: 0.9146 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00323\n",
            "Train: loss: 0.4830 | accuracy: 0.7784 | f-acore: 0.7772\n",
            "Test:  loss: 1.4475 | accuracy: 0.4438 | f1: 0.3926\n",
            "Validation:  loss: 0.9662 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00324\n",
            "Train: loss: 0.4639 | accuracy: 0.7701 | f-acore: 0.7699\n",
            "Test:  loss: 1.3122 | accuracy: 0.4356 | f1: 0.4147\n",
            "Validation:  loss: 0.9044 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00325\n",
            "Train: loss: 0.4781 | accuracy: 0.7601 | f-acore: 0.7573\n",
            "Test:  loss: 1.4826 | accuracy: 0.4356 | f1: 0.3908\n",
            "Validation:  loss: 1.0038 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00326\n",
            "Train: loss: 0.4680 | accuracy: 0.7720 | f-acore: 0.7703\n",
            "Test:  loss: 1.3181 | accuracy: 0.4384 | f1: 0.4115\n",
            "Validation:  loss: 0.9378 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00327\n",
            "Train: loss: 0.4664 | accuracy: 0.7697 | f-acore: 0.7687\n",
            "Test:  loss: 1.3214 | accuracy: 0.4411 | f1: 0.4058\n",
            "Validation:  loss: 0.9492 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00328\n",
            "Train: loss: 0.4624 | accuracy: 0.7674 | f-acore: 0.7664\n",
            "Test:  loss: 1.4123 | accuracy: 0.4384 | f1: 0.3947\n",
            "Validation:  loss: 0.9805 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00329\n",
            "Train: loss: 0.4735 | accuracy: 0.7738 | f-acore: 0.7727\n",
            "Test:  loss: 1.3279 | accuracy: 0.4356 | f1: 0.4016\n",
            "Validation:  loss: 0.9289 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00330\n",
            "Train: loss: 0.4857 | accuracy: 0.7706 | f-acore: 0.7690\n",
            "Test:  loss: 1.3140 | accuracy: 0.4411 | f1: 0.4121\n",
            "Validation:  loss: 0.9137 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00331\n",
            "Train: loss: 0.4751 | accuracy: 0.7647 | f-acore: 0.7629\n",
            "Test:  loss: 1.4279 | accuracy: 0.4329 | f1: 0.3944\n",
            "Validation:  loss: 0.9738 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00332\n",
            "Train: loss: 0.4595 | accuracy: 0.7798 | f-acore: 0.7777\n",
            "Test:  loss: 1.4039 | accuracy: 0.4301 | f1: 0.3849\n",
            "Validation:  loss: 0.9664 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00333\n",
            "Train: loss: 0.4642 | accuracy: 0.7775 | f-acore: 0.7755\n",
            "Test:  loss: 1.3456 | accuracy: 0.4411 | f1: 0.4090\n",
            "Validation:  loss: 0.9504 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00334\n",
            "Train: loss: 0.4916 | accuracy: 0.7720 | f-acore: 0.7705\n",
            "Test:  loss: 1.4204 | accuracy: 0.4329 | f1: 0.3907\n",
            "Validation:  loss: 0.9853 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00335\n",
            "Train: loss: 0.4705 | accuracy: 0.7706 | f-acore: 0.7693\n",
            "Test:  loss: 1.3810 | accuracy: 0.4384 | f1: 0.4053\n",
            "Validation:  loss: 0.9344 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00336\n",
            "Train: loss: 0.4541 | accuracy: 0.7784 | f-acore: 0.7776\n",
            "Test:  loss: 1.4076 | accuracy: 0.4274 | f1: 0.3848\n",
            "Validation:  loss: 0.9402 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00337\n",
            "Train: loss: 0.4789 | accuracy: 0.7688 | f-acore: 0.7673\n",
            "Test:  loss: 1.4535 | accuracy: 0.4356 | f1: 0.3888\n",
            "Validation:  loss: 0.9671 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00338\n",
            "Train: loss: 0.4613 | accuracy: 0.7834 | f-acore: 0.7822\n",
            "Test:  loss: 1.4919 | accuracy: 0.4356 | f1: 0.3826\n",
            "Validation:  loss: 0.9800 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00339\n",
            "Train: loss: 0.4706 | accuracy: 0.7683 | f-acore: 0.7677\n",
            "Test:  loss: 1.3235 | accuracy: 0.4356 | f1: 0.3964\n",
            "Validation:  loss: 0.9115 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00340\n",
            "Train: loss: 0.4784 | accuracy: 0.7802 | f-acore: 0.7793\n",
            "Test:  loss: 1.2969 | accuracy: 0.4356 | f1: 0.4048\n",
            "Validation:  loss: 0.9103 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00341\n",
            "Train: loss: 0.4842 | accuracy: 0.7669 | f-acore: 0.7650\n",
            "Test:  loss: 1.4569 | accuracy: 0.4384 | f1: 0.3947\n",
            "Validation:  loss: 0.9827 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00342\n",
            "Train: loss: 0.4795 | accuracy: 0.7816 | f-acore: 0.7805\n",
            "Test:  loss: 1.3720 | accuracy: 0.4274 | f1: 0.3903\n",
            "Validation:  loss: 0.9384 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00343\n",
            "Train: loss: 0.4626 | accuracy: 0.7779 | f-acore: 0.7769\n",
            "Test:  loss: 1.3418 | accuracy: 0.4301 | f1: 0.3868\n",
            "Validation:  loss: 0.9361 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00344\n",
            "Train: loss: 0.4623 | accuracy: 0.7683 | f-acore: 0.7668\n",
            "Test:  loss: 1.2694 | accuracy: 0.4301 | f1: 0.4050\n",
            "Validation:  loss: 0.9217 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00345\n",
            "Train: loss: 0.4450 | accuracy: 0.7866 | f-acore: 0.7850\n",
            "Test:  loss: 1.3359 | accuracy: 0.4219 | f1: 0.3845\n",
            "Validation:  loss: 0.9621 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00346\n",
            "Train: loss: 0.4583 | accuracy: 0.7752 | f-acore: 0.7733\n",
            "Test:  loss: 1.3612 | accuracy: 0.4329 | f1: 0.3944\n",
            "Validation:  loss: 0.9533 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00347\n",
            "Train: loss: 0.4654 | accuracy: 0.7775 | f-acore: 0.7759\n",
            "Test:  loss: 1.3607 | accuracy: 0.4356 | f1: 0.3999\n",
            "Validation:  loss: 0.9614 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00348\n",
            "Train: loss: 0.4505 | accuracy: 0.7853 | f-acore: 0.7835\n",
            "Test:  loss: 1.4389 | accuracy: 0.4329 | f1: 0.3806\n",
            "Validation:  loss: 1.0038 | accuracy: 0.4321 | f1: 0.4278\n",
            "Epoch 00349\n",
            "Train: loss: 0.4483 | accuracy: 0.7784 | f-acore: 0.7773\n",
            "Test:  loss: 1.3735 | accuracy: 0.4329 | f1: 0.3962\n",
            "Validation:  loss: 0.9653 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00350\n",
            "Train: loss: 0.4429 | accuracy: 0.7889 | f-acore: 0.7875\n",
            "Test:  loss: 1.4412 | accuracy: 0.4356 | f1: 0.3908\n",
            "Validation:  loss: 0.9929 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00351\n",
            "Train: loss: 0.4401 | accuracy: 0.7894 | f-acore: 0.7885\n",
            "Test:  loss: 1.3125 | accuracy: 0.4411 | f1: 0.4106\n",
            "Validation:  loss: 0.9335 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00352\n",
            "Train: loss: 0.4686 | accuracy: 0.7875 | f-acore: 0.7860\n",
            "Test:  loss: 1.3290 | accuracy: 0.4384 | f1: 0.4085\n",
            "Validation:  loss: 0.9640 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00353\n",
            "Train: loss: 0.4604 | accuracy: 0.7816 | f-acore: 0.7807\n",
            "Test:  loss: 1.4272 | accuracy: 0.4384 | f1: 0.3928\n",
            "Validation:  loss: 1.0016 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00354\n",
            "Train: loss: 0.4597 | accuracy: 0.7793 | f-acore: 0.7775\n",
            "Test:  loss: 1.3401 | accuracy: 0.4384 | f1: 0.4069\n",
            "Validation:  loss: 0.9735 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00355\n",
            "Train: loss: 0.5060 | accuracy: 0.7862 | f-acore: 0.7847\n",
            "Test:  loss: 1.4232 | accuracy: 0.4384 | f1: 0.3928\n",
            "Validation:  loss: 1.0043 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00356\n",
            "Train: loss: 0.4750 | accuracy: 0.7830 | f-acore: 0.7819\n",
            "Test:  loss: 1.2638 | accuracy: 0.4438 | f1: 0.4200\n",
            "Validation:  loss: 0.9381 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00357\n",
            "Train: loss: 0.4671 | accuracy: 0.7706 | f-acore: 0.7687\n",
            "Test:  loss: 1.4156 | accuracy: 0.4356 | f1: 0.3804\n",
            "Validation:  loss: 1.0017 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00358\n",
            "Train: loss: 0.4600 | accuracy: 0.7880 | f-acore: 0.7870\n",
            "Test:  loss: 1.4690 | accuracy: 0.4384 | f1: 0.3887\n",
            "Validation:  loss: 0.9922 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00359\n",
            "Train: loss: 0.4673 | accuracy: 0.7834 | f-acore: 0.7825\n",
            "Test:  loss: 1.4006 | accuracy: 0.4411 | f1: 0.4005\n",
            "Validation:  loss: 0.9837 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00360\n",
            "Train: loss: 0.4719 | accuracy: 0.7798 | f-acore: 0.7783\n",
            "Test:  loss: 1.3534 | accuracy: 0.4384 | f1: 0.4020\n",
            "Validation:  loss: 0.9632 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00361\n",
            "Train: loss: 0.4684 | accuracy: 0.7729 | f-acore: 0.7710\n",
            "Test:  loss: 1.4900 | accuracy: 0.4356 | f1: 0.3847\n",
            "Validation:  loss: 1.0328 | accuracy: 0.4321 | f1: 0.4278\n",
            "Epoch 00362\n",
            "Train: loss: 0.4369 | accuracy: 0.7898 | f-acore: 0.7895\n",
            "Test:  loss: 1.3525 | accuracy: 0.4329 | f1: 0.4012\n",
            "Validation:  loss: 0.9657 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00363\n",
            "Train: loss: 0.4469 | accuracy: 0.7894 | f-acore: 0.7871\n",
            "Test:  loss: 1.4924 | accuracy: 0.4356 | f1: 0.3826\n",
            "Validation:  loss: 1.0156 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00364\n",
            "Train: loss: 0.4683 | accuracy: 0.7724 | f-acore: 0.7708\n",
            "Test:  loss: 1.3369 | accuracy: 0.4329 | f1: 0.4072\n",
            "Validation:  loss: 0.9366 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00365\n",
            "Train: loss: 0.4748 | accuracy: 0.7734 | f-acore: 0.7721\n",
            "Test:  loss: 1.5301 | accuracy: 0.4356 | f1: 0.3888\n",
            "Validation:  loss: 1.0300 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00366\n",
            "Train: loss: 0.4645 | accuracy: 0.7729 | f-acore: 0.7717\n",
            "Test:  loss: 1.4146 | accuracy: 0.4411 | f1: 0.4041\n",
            "Validation:  loss: 0.9922 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00367\n",
            "Train: loss: 0.4662 | accuracy: 0.7724 | f-acore: 0.7712\n",
            "Test:  loss: 1.4332 | accuracy: 0.4411 | f1: 0.3967\n",
            "Validation:  loss: 0.9998 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00368\n",
            "Train: loss: 0.4658 | accuracy: 0.7898 | f-acore: 0.7888\n",
            "Test:  loss: 1.2767 | accuracy: 0.4384 | f1: 0.4194\n",
            "Validation:  loss: 0.9225 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00369\n",
            "Train: loss: 0.4726 | accuracy: 0.7761 | f-acore: 0.7747\n",
            "Test:  loss: 1.4401 | accuracy: 0.4356 | f1: 0.3927\n",
            "Validation:  loss: 0.9912 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00370\n",
            "Train: loss: 0.4686 | accuracy: 0.7793 | f-acore: 0.7775\n",
            "Test:  loss: 1.2941 | accuracy: 0.4466 | f1: 0.4132\n",
            "Validation:  loss: 0.9650 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00371\n",
            "Train: loss: 0.4457 | accuracy: 0.7967 | f-acore: 0.7957\n",
            "Test:  loss: 1.2699 | accuracy: 0.4466 | f1: 0.4194\n",
            "Validation:  loss: 0.9355 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00372\n",
            "Train: loss: 0.4517 | accuracy: 0.7880 | f-acore: 0.7868\n",
            "Test:  loss: 1.4208 | accuracy: 0.4411 | f1: 0.3967\n",
            "Validation:  loss: 0.9975 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00373\n",
            "Train: loss: 0.4586 | accuracy: 0.7798 | f-acore: 0.7785\n",
            "Test:  loss: 1.3657 | accuracy: 0.4301 | f1: 0.3924\n",
            "Validation:  loss: 0.9642 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00374\n",
            "Train: loss: 0.4528 | accuracy: 0.7853 | f-acore: 0.7841\n",
            "Test:  loss: 1.3289 | accuracy: 0.4384 | f1: 0.4085\n",
            "Validation:  loss: 0.9641 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00375\n",
            "Train: loss: 0.4504 | accuracy: 0.7908 | f-acore: 0.7897\n",
            "Test:  loss: 1.4404 | accuracy: 0.4301 | f1: 0.3906\n",
            "Validation:  loss: 1.0062 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00376\n",
            "Train: loss: 0.4826 | accuracy: 0.7761 | f-acore: 0.7755\n",
            "Test:  loss: 1.3103 | accuracy: 0.4521 | f1: 0.4292\n",
            "Validation:  loss: 0.9644 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00377\n",
            "Train: loss: 0.4528 | accuracy: 0.7747 | f-acore: 0.7735\n",
            "Test:  loss: 1.3373 | accuracy: 0.4329 | f1: 0.3979\n",
            "Validation:  loss: 0.9584 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00378\n",
            "Train: loss: 0.4181 | accuracy: 0.7972 | f-acore: 0.7956\n",
            "Test:  loss: 1.3875 | accuracy: 0.4411 | f1: 0.4041\n",
            "Validation:  loss: 0.9709 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00379\n",
            "Train: loss: 0.4494 | accuracy: 0.8045 | f-acore: 0.8029\n",
            "Test:  loss: 1.3927 | accuracy: 0.4329 | f1: 0.3944\n",
            "Validation:  loss: 0.9780 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00380\n",
            "Train: loss: 0.4476 | accuracy: 0.7862 | f-acore: 0.7851\n",
            "Test:  loss: 1.3130 | accuracy: 0.4493 | f1: 0.4270\n",
            "Validation:  loss: 0.9547 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00381\n",
            "Train: loss: 0.4569 | accuracy: 0.7784 | f-acore: 0.7763\n",
            "Test:  loss: 1.4848 | accuracy: 0.4356 | f1: 0.3982\n",
            "Validation:  loss: 1.0068 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00382\n",
            "Train: loss: 0.4369 | accuracy: 0.7972 | f-acore: 0.7957\n",
            "Test:  loss: 1.3905 | accuracy: 0.4384 | f1: 0.4037\n",
            "Validation:  loss: 0.9645 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00383\n",
            "Train: loss: 0.4538 | accuracy: 0.7825 | f-acore: 0.7820\n",
            "Test:  loss: 1.3740 | accuracy: 0.4493 | f1: 0.4215\n",
            "Validation:  loss: 0.9697 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00384\n",
            "Train: loss: 0.4543 | accuracy: 0.7898 | f-acore: 0.7880\n",
            "Test:  loss: 1.5511 | accuracy: 0.4301 | f1: 0.3868\n",
            "Validation:  loss: 1.0544 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00385\n",
            "Train: loss: 0.4319 | accuracy: 0.7962 | f-acore: 0.7947\n",
            "Test:  loss: 1.5094 | accuracy: 0.4301 | f1: 0.3849\n",
            "Validation:  loss: 1.0277 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00386\n",
            "Train: loss: 0.4398 | accuracy: 0.7981 | f-acore: 0.7969\n",
            "Test:  loss: 1.4780 | accuracy: 0.4301 | f1: 0.3849\n",
            "Validation:  loss: 1.0191 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00387\n",
            "Train: loss: 0.4377 | accuracy: 0.7962 | f-acore: 0.7953\n",
            "Test:  loss: 1.4148 | accuracy: 0.4356 | f1: 0.3908\n",
            "Validation:  loss: 1.0075 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00388\n",
            "Train: loss: 0.4460 | accuracy: 0.7912 | f-acore: 0.7903\n",
            "Test:  loss: 1.4139 | accuracy: 0.4411 | f1: 0.3967\n",
            "Validation:  loss: 1.0194 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00389\n",
            "Train: loss: 0.4507 | accuracy: 0.7793 | f-acore: 0.7767\n",
            "Test:  loss: 1.4774 | accuracy: 0.4356 | f1: 0.3964\n",
            "Validation:  loss: 1.0273 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00390\n",
            "Train: loss: 0.4387 | accuracy: 0.7921 | f-acore: 0.7917\n",
            "Test:  loss: 1.3387 | accuracy: 0.4575 | f1: 0.4374\n",
            "Validation:  loss: 0.9707 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00391\n",
            "Train: loss: 0.4399 | accuracy: 0.7903 | f-acore: 0.7890\n",
            "Test:  loss: 1.4265 | accuracy: 0.4493 | f1: 0.4185\n",
            "Validation:  loss: 1.0008 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00392\n",
            "Train: loss: 0.4590 | accuracy: 0.8027 | f-acore: 0.8019\n",
            "Test:  loss: 1.4595 | accuracy: 0.4356 | f1: 0.3927\n",
            "Validation:  loss: 1.0242 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00393\n",
            "Train: loss: 0.4534 | accuracy: 0.7784 | f-acore: 0.7769\n",
            "Test:  loss: 1.4817 | accuracy: 0.4329 | f1: 0.3926\n",
            "Validation:  loss: 1.0347 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00394\n",
            "Train: loss: 0.4479 | accuracy: 0.7821 | f-acore: 0.7809\n",
            "Test:  loss: 1.3402 | accuracy: 0.4521 | f1: 0.4363\n",
            "Validation:  loss: 0.9804 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00395\n",
            "Train: loss: 0.4361 | accuracy: 0.7981 | f-acore: 0.7968\n",
            "Test:  loss: 1.3255 | accuracy: 0.4521 | f1: 0.4317\n",
            "Validation:  loss: 0.9673 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00396\n",
            "Train: loss: 0.4533 | accuracy: 0.7962 | f-acore: 0.7950\n",
            "Test:  loss: 1.4564 | accuracy: 0.4493 | f1: 0.4153\n",
            "Validation:  loss: 1.0103 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00397\n",
            "Train: loss: 0.4490 | accuracy: 0.7816 | f-acore: 0.7807\n",
            "Test:  loss: 1.3258 | accuracy: 0.4301 | f1: 0.4213\n",
            "Validation:  loss: 0.9743 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00398\n",
            "Train: loss: 0.4475 | accuracy: 0.7821 | f-acore: 0.7815\n",
            "Test:  loss: 1.4502 | accuracy: 0.4356 | f1: 0.3982\n",
            "Validation:  loss: 1.0325 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00399\n",
            "Train: loss: 0.4472 | accuracy: 0.7944 | f-acore: 0.7930\n",
            "Test:  loss: 1.3124 | accuracy: 0.4384 | f1: 0.4276\n",
            "Validation:  loss: 0.9706 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00400\n",
            "Train: loss: 0.4411 | accuracy: 0.7875 | f-acore: 0.7867\n",
            "Test:  loss: 1.4506 | accuracy: 0.4356 | f1: 0.4033\n",
            "Validation:  loss: 1.0205 | accuracy: 0.4815 | f1: 0.4814\n",
            "-----------------------------------------------------------------------------------------\n",
            "^GSPC\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6880 | accuracy: 0.5476 | f-acore: 0.3566\n",
            "Test:  loss: 0.6872 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6821 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00002\n",
            "Train: loss: 0.6863 | accuracy: 0.5490 | f-acore: 0.3544\n",
            "Test:  loss: 0.6867 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6811 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00003\n",
            "Train: loss: 0.6876 | accuracy: 0.5490 | f-acore: 0.3544\n",
            "Test:  loss: 0.6873 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6831 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00004\n",
            "Train: loss: 0.6822 | accuracy: 0.5490 | f-acore: 0.3544\n",
            "Test:  loss: 0.6875 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6830 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00005\n",
            "Train: loss: 0.6843 | accuracy: 0.5490 | f-acore: 0.3544\n",
            "Test:  loss: 0.6872 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6822 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00006\n",
            "Train: loss: 0.6868 | accuracy: 0.5490 | f-acore: 0.3544\n",
            "Test:  loss: 0.6883 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6838 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00007\n",
            "Train: loss: 0.6877 | accuracy: 0.5499 | f-acore: 0.3567\n",
            "Test:  loss: 0.6904 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00008\n",
            "Train: loss: 0.6874 | accuracy: 0.5517 | f-acore: 0.3700\n",
            "Test:  loss: 0.6909 | accuracy: 0.5671 | f1: 0.3619\n",
            "Validation:  loss: 0.6879 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00009\n",
            "Train: loss: 0.6859 | accuracy: 0.5490 | f-acore: 0.3608\n",
            "Test:  loss: 0.6882 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6835 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00010\n",
            "Train: loss: 0.6833 | accuracy: 0.5522 | f-acore: 0.3649\n",
            "Test:  loss: 0.6858 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6815 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00011\n",
            "Train: loss: 0.6809 | accuracy: 0.5508 | f-acore: 0.3598\n",
            "Test:  loss: 0.6853 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6803 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00012\n",
            "Train: loss: 0.6817 | accuracy: 0.5527 | f-acore: 0.3669\n",
            "Test:  loss: 0.6877 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6823 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00013\n",
            "Train: loss: 0.6814 | accuracy: 0.5554 | f-acore: 0.3794\n",
            "Test:  loss: 0.6877 | accuracy: 0.5753 | f1: 0.3652\n",
            "Validation:  loss: 0.6813 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00014\n",
            "Train: loss: 0.6834 | accuracy: 0.5582 | f-acore: 0.4039\n",
            "Test:  loss: 0.6959 | accuracy: 0.4712 | f1: 0.4473\n",
            "Validation:  loss: 0.6862 | accuracy: 0.5802 | f1: 0.4357\n",
            "Epoch 00015\n",
            "Train: loss: 0.6777 | accuracy: 0.5618 | f-acore: 0.4544\n",
            "Test:  loss: 0.6899 | accuracy: 0.5534 | f1: 0.3874\n",
            "Validation:  loss: 0.6821 | accuracy: 0.5802 | f1: 0.3929\n",
            "Epoch 00016\n",
            "Train: loss: 0.6825 | accuracy: 0.5650 | f-acore: 0.4343\n",
            "Test:  loss: 0.6940 | accuracy: 0.4685 | f1: 0.4682\n",
            "Validation:  loss: 0.6857 | accuracy: 0.5802 | f1: 0.4536\n",
            "Epoch 00017\n",
            "Train: loss: 0.6819 | accuracy: 0.5710 | f-acore: 0.4597\n",
            "Test:  loss: 0.6964 | accuracy: 0.4630 | f1: 0.4486\n",
            "Validation:  loss: 0.6861 | accuracy: 0.5926 | f1: 0.4923\n",
            "Epoch 00018\n",
            "Train: loss: 0.6791 | accuracy: 0.5646 | f-acore: 0.4862\n",
            "Test:  loss: 0.6941 | accuracy: 0.4658 | f1: 0.4656\n",
            "Validation:  loss: 0.6858 | accuracy: 0.5802 | f1: 0.4536\n",
            "Epoch 00019\n",
            "Train: loss: 0.6789 | accuracy: 0.5641 | f-acore: 0.4514\n",
            "Test:  loss: 0.6988 | accuracy: 0.4685 | f1: 0.4299\n",
            "Validation:  loss: 0.6856 | accuracy: 0.5926 | f1: 0.4776\n",
            "Epoch 00020\n",
            "Train: loss: 0.6774 | accuracy: 0.5778 | f-acore: 0.5097\n",
            "Test:  loss: 0.6985 | accuracy: 0.4575 | f1: 0.4362\n",
            "Validation:  loss: 0.6838 | accuracy: 0.5926 | f1: 0.4776\n",
            "Epoch 00021\n",
            "Train: loss: 0.6722 | accuracy: 0.5682 | f-acore: 0.4834\n",
            "Test:  loss: 0.7103 | accuracy: 0.4274 | f1: 0.3034\n",
            "Validation:  loss: 0.6857 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00022\n",
            "Train: loss: 0.6804 | accuracy: 0.5705 | f-acore: 0.4926\n",
            "Test:  loss: 0.7025 | accuracy: 0.4466 | f1: 0.3676\n",
            "Validation:  loss: 0.6830 | accuracy: 0.6420 | f1: 0.5851\n",
            "Epoch 00023\n",
            "Train: loss: 0.6834 | accuracy: 0.5678 | f-acore: 0.5137\n",
            "Test:  loss: 0.6979 | accuracy: 0.4712 | f1: 0.4603\n",
            "Validation:  loss: 0.6794 | accuracy: 0.6543 | f1: 0.5950\n",
            "Epoch 00024\n",
            "Train: loss: 0.6788 | accuracy: 0.5742 | f-acore: 0.5369\n",
            "Test:  loss: 0.7040 | accuracy: 0.4438 | f1: 0.3479\n",
            "Validation:  loss: 0.6845 | accuracy: 0.6296 | f1: 0.5906\n",
            "Epoch 00025\n",
            "Train: loss: 0.6761 | accuracy: 0.5650 | f-acore: 0.5130\n",
            "Test:  loss: 0.6947 | accuracy: 0.4767 | f1: 0.4757\n",
            "Validation:  loss: 0.6792 | accuracy: 0.6296 | f1: 0.5446\n",
            "Epoch 00026\n",
            "Train: loss: 0.6811 | accuracy: 0.5797 | f-acore: 0.5095\n",
            "Test:  loss: 0.6966 | accuracy: 0.4767 | f1: 0.4641\n",
            "Validation:  loss: 0.6823 | accuracy: 0.6296 | f1: 0.5446\n",
            "Epoch 00027\n",
            "Train: loss: 0.6718 | accuracy: 0.5833 | f-acore: 0.5286\n",
            "Test:  loss: 0.6945 | accuracy: 0.4685 | f1: 0.4680\n",
            "Validation:  loss: 0.6809 | accuracy: 0.6173 | f1: 0.5231\n",
            "Epoch 00028\n",
            "Train: loss: 0.6750 | accuracy: 0.5714 | f-acore: 0.4870\n",
            "Test:  loss: 0.6943 | accuracy: 0.4767 | f1: 0.4757\n",
            "Validation:  loss: 0.6827 | accuracy: 0.6049 | f1: 0.5008\n",
            "Epoch 00029\n",
            "Train: loss: 0.6789 | accuracy: 0.5797 | f-acore: 0.5083\n",
            "Test:  loss: 0.6887 | accuracy: 0.5616 | f1: 0.4384\n",
            "Validation:  loss: 0.6784 | accuracy: 0.6049 | f1: 0.5008\n",
            "Epoch 00030\n",
            "Train: loss: 0.6734 | accuracy: 0.5774 | f-acore: 0.5017\n",
            "Test:  loss: 0.6979 | accuracy: 0.4767 | f1: 0.4650\n",
            "Validation:  loss: 0.6825 | accuracy: 0.5926 | f1: 0.5172\n",
            "Epoch 00031\n",
            "Train: loss: 0.6697 | accuracy: 0.5783 | f-acore: 0.5143\n",
            "Test:  loss: 0.6971 | accuracy: 0.4795 | f1: 0.4780\n",
            "Validation:  loss: 0.6841 | accuracy: 0.6049 | f1: 0.5371\n",
            "Epoch 00032\n",
            "Train: loss: 0.6798 | accuracy: 0.5760 | f-acore: 0.4973\n",
            "Test:  loss: 0.7063 | accuracy: 0.4411 | f1: 0.3746\n",
            "Validation:  loss: 0.6901 | accuracy: 0.5309 | f1: 0.4971\n",
            "Epoch 00033\n",
            "Train: loss: 0.6720 | accuracy: 0.5838 | f-acore: 0.5502\n",
            "Test:  loss: 0.7148 | accuracy: 0.4274 | f1: 0.3218\n",
            "Validation:  loss: 0.6926 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00034\n",
            "Train: loss: 0.6715 | accuracy: 0.5810 | f-acore: 0.5171\n",
            "Test:  loss: 0.6960 | accuracy: 0.5014 | f1: 0.5013\n",
            "Validation:  loss: 0.6797 | accuracy: 0.6296 | f1: 0.5559\n",
            "Epoch 00035\n",
            "Train: loss: 0.6654 | accuracy: 0.5856 | f-acore: 0.5304\n",
            "Test:  loss: 0.7136 | accuracy: 0.4356 | f1: 0.3804\n",
            "Validation:  loss: 0.6885 | accuracy: 0.6049 | f1: 0.5765\n",
            "Epoch 00036\n",
            "Train: loss: 0.6737 | accuracy: 0.5861 | f-acore: 0.5270\n",
            "Test:  loss: 0.7089 | accuracy: 0.4493 | f1: 0.4065\n",
            "Validation:  loss: 0.6902 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00037\n",
            "Train: loss: 0.6711 | accuracy: 0.5875 | f-acore: 0.5470\n",
            "Test:  loss: 0.7116 | accuracy: 0.4356 | f1: 0.3734\n",
            "Validation:  loss: 0.6910 | accuracy: 0.5556 | f1: 0.5539\n",
            "Epoch 00038\n",
            "Train: loss: 0.6725 | accuracy: 0.5879 | f-acore: 0.5520\n",
            "Test:  loss: 0.7021 | accuracy: 0.4493 | f1: 0.4404\n",
            "Validation:  loss: 0.6854 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00039\n",
            "Train: loss: 0.6651 | accuracy: 0.5824 | f-acore: 0.5435\n",
            "Test:  loss: 0.7174 | accuracy: 0.4301 | f1: 0.3125\n",
            "Validation:  loss: 0.6965 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00040\n",
            "Train: loss: 0.6663 | accuracy: 0.5879 | f-acore: 0.5358\n",
            "Test:  loss: 0.7070 | accuracy: 0.4384 | f1: 0.3596\n",
            "Validation:  loss: 0.6924 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00041\n",
            "Train: loss: 0.6673 | accuracy: 0.5810 | f-acore: 0.5585\n",
            "Test:  loss: 0.7222 | accuracy: 0.4274 | f1: 0.3034\n",
            "Validation:  loss: 0.7051 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00042\n",
            "Train: loss: 0.6637 | accuracy: 0.5861 | f-acore: 0.5547\n",
            "Test:  loss: 0.7074 | accuracy: 0.4384 | f1: 0.3596\n",
            "Validation:  loss: 0.6937 | accuracy: 0.5185 | f1: 0.4935\n",
            "Epoch 00043\n",
            "Train: loss: 0.6649 | accuracy: 0.6016 | f-acore: 0.5703\n",
            "Test:  loss: 0.7027 | accuracy: 0.4466 | f1: 0.4307\n",
            "Validation:  loss: 0.6885 | accuracy: 0.5679 | f1: 0.4992\n",
            "Epoch 00044\n",
            "Train: loss: 0.6638 | accuracy: 0.5815 | f-acore: 0.5354\n",
            "Test:  loss: 0.7086 | accuracy: 0.4356 | f1: 0.3804\n",
            "Validation:  loss: 0.6938 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00045\n",
            "Train: loss: 0.6638 | accuracy: 0.5897 | f-acore: 0.5649\n",
            "Test:  loss: 0.7065 | accuracy: 0.4411 | f1: 0.4005\n",
            "Validation:  loss: 0.6896 | accuracy: 0.5679 | f1: 0.5504\n",
            "Epoch 00046\n",
            "Train: loss: 0.6551 | accuracy: 0.5971 | f-acore: 0.5371\n",
            "Test:  loss: 0.7069 | accuracy: 0.4466 | f1: 0.4148\n",
            "Validation:  loss: 0.6898 | accuracy: 0.5802 | f1: 0.5361\n",
            "Epoch 00047\n",
            "Train: loss: 0.6566 | accuracy: 0.5852 | f-acore: 0.5620\n",
            "Test:  loss: 0.7016 | accuracy: 0.4575 | f1: 0.4541\n",
            "Validation:  loss: 0.6896 | accuracy: 0.5432 | f1: 0.4587\n",
            "Epoch 00048\n",
            "Train: loss: 0.6596 | accuracy: 0.5980 | f-acore: 0.5328\n",
            "Test:  loss: 0.7057 | accuracy: 0.4384 | f1: 0.4217\n",
            "Validation:  loss: 0.6930 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00049\n",
            "Train: loss: 0.6694 | accuracy: 0.5920 | f-acore: 0.5674\n",
            "Test:  loss: 0.7232 | accuracy: 0.4274 | f1: 0.3412\n",
            "Validation:  loss: 0.7027 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00050\n",
            "Train: loss: 0.6572 | accuracy: 0.5989 | f-acore: 0.5776\n",
            "Test:  loss: 0.7257 | accuracy: 0.4274 | f1: 0.3471\n",
            "Validation:  loss: 0.6998 | accuracy: 0.6049 | f1: 0.6044\n",
            "Epoch 00051\n",
            "Train: loss: 0.6586 | accuracy: 0.6016 | f-acore: 0.5650\n",
            "Test:  loss: 0.7135 | accuracy: 0.4274 | f1: 0.4126\n",
            "Validation:  loss: 0.6923 | accuracy: 0.6173 | f1: 0.5974\n",
            "Epoch 00052\n",
            "Train: loss: 0.6482 | accuracy: 0.6090 | f-acore: 0.5745\n",
            "Test:  loss: 0.7078 | accuracy: 0.4575 | f1: 0.4557\n",
            "Validation:  loss: 0.6898 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00053\n",
            "Train: loss: 0.6513 | accuracy: 0.6122 | f-acore: 0.5917\n",
            "Test:  loss: 0.7168 | accuracy: 0.4329 | f1: 0.3888\n",
            "Validation:  loss: 0.6986 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00054\n",
            "Train: loss: 0.6572 | accuracy: 0.6103 | f-acore: 0.5824\n",
            "Test:  loss: 0.7181 | accuracy: 0.4356 | f1: 0.4134\n",
            "Validation:  loss: 0.6970 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00055\n",
            "Train: loss: 0.6534 | accuracy: 0.6131 | f-acore: 0.5927\n",
            "Test:  loss: 0.7333 | accuracy: 0.4274 | f1: 0.3725\n",
            "Validation:  loss: 0.7078 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00056\n",
            "Train: loss: 0.6517 | accuracy: 0.6062 | f-acore: 0.5800\n",
            "Test:  loss: 0.7136 | accuracy: 0.4329 | f1: 0.4253\n",
            "Validation:  loss: 0.7037 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00057\n",
            "Train: loss: 0.6520 | accuracy: 0.6190 | f-acore: 0.5877\n",
            "Test:  loss: 0.7104 | accuracy: 0.4411 | f1: 0.4396\n",
            "Validation:  loss: 0.6990 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00058\n",
            "Train: loss: 0.6538 | accuracy: 0.6200 | f-acore: 0.5973\n",
            "Test:  loss: 0.7278 | accuracy: 0.4301 | f1: 0.4103\n",
            "Validation:  loss: 0.7082 | accuracy: 0.5802 | f1: 0.5797\n",
            "Epoch 00059\n",
            "Train: loss: 0.6602 | accuracy: 0.6190 | f-acore: 0.5940\n",
            "Test:  loss: 0.7284 | accuracy: 0.4356 | f1: 0.4134\n",
            "Validation:  loss: 0.7093 | accuracy: 0.5802 | f1: 0.5786\n",
            "Epoch 00060\n",
            "Train: loss: 0.6466 | accuracy: 0.6049 | f-acore: 0.5912\n",
            "Test:  loss: 0.7181 | accuracy: 0.4411 | f1: 0.3721\n",
            "Validation:  loss: 0.7026 | accuracy: 0.6049 | f1: 0.6049\n",
            "Epoch 00061\n",
            "Train: loss: 0.6547 | accuracy: 0.6071 | f-acore: 0.5867\n",
            "Test:  loss: 0.7265 | accuracy: 0.4438 | f1: 0.3947\n",
            "Validation:  loss: 0.7027 | accuracy: 0.6049 | f1: 0.6049\n",
            "Epoch 00062\n",
            "Train: loss: 0.6422 | accuracy: 0.6172 | f-acore: 0.6064\n",
            "Test:  loss: 0.7259 | accuracy: 0.4356 | f1: 0.3946\n",
            "Validation:  loss: 0.7003 | accuracy: 0.6296 | f1: 0.6291\n",
            "Epoch 00063\n",
            "Train: loss: 0.6416 | accuracy: 0.6099 | f-acore: 0.5864\n",
            "Test:  loss: 0.7332 | accuracy: 0.4466 | f1: 0.4208\n",
            "Validation:  loss: 0.7068 | accuracy: 0.6173 | f1: 0.6163\n",
            "Epoch 00064\n",
            "Train: loss: 0.6461 | accuracy: 0.6223 | f-acore: 0.6045\n",
            "Test:  loss: 0.7246 | accuracy: 0.4493 | f1: 0.4433\n",
            "Validation:  loss: 0.7014 | accuracy: 0.6420 | f1: 0.6364\n",
            "Epoch 00065\n",
            "Train: loss: 0.6551 | accuracy: 0.6282 | f-acore: 0.6026\n",
            "Test:  loss: 0.7217 | accuracy: 0.4493 | f1: 0.4318\n",
            "Validation:  loss: 0.7004 | accuracy: 0.6173 | f1: 0.6152\n",
            "Epoch 00066\n",
            "Train: loss: 0.6401 | accuracy: 0.6227 | f-acore: 0.6081\n",
            "Test:  loss: 0.7105 | accuracy: 0.4438 | f1: 0.4284\n",
            "Validation:  loss: 0.7002 | accuracy: 0.6543 | f1: 0.6478\n",
            "Epoch 00067\n",
            "Train: loss: 0.6422 | accuracy: 0.6195 | f-acore: 0.5877\n",
            "Test:  loss: 0.7118 | accuracy: 0.4603 | f1: 0.4595\n",
            "Validation:  loss: 0.6924 | accuracy: 0.6543 | f1: 0.6420\n",
            "Epoch 00068\n",
            "Train: loss: 0.6409 | accuracy: 0.6186 | f-acore: 0.6018\n",
            "Test:  loss: 0.7157 | accuracy: 0.4685 | f1: 0.4667\n",
            "Validation:  loss: 0.6992 | accuracy: 0.6296 | f1: 0.6165\n",
            "Epoch 00069\n",
            "Train: loss: 0.6486 | accuracy: 0.6103 | f-acore: 0.5758\n",
            "Test:  loss: 0.7251 | accuracy: 0.4493 | f1: 0.4493\n",
            "Validation:  loss: 0.7007 | accuracy: 0.6543 | f1: 0.6517\n",
            "Epoch 00070\n",
            "Train: loss: 0.6309 | accuracy: 0.6360 | f-acore: 0.6238\n",
            "Test:  loss: 0.7105 | accuracy: 0.4438 | f1: 0.4425\n",
            "Validation:  loss: 0.6963 | accuracy: 0.6543 | f1: 0.6452\n",
            "Epoch 00071\n",
            "Train: loss: 0.6364 | accuracy: 0.6291 | f-acore: 0.6158\n",
            "Test:  loss: 0.7242 | accuracy: 0.4466 | f1: 0.4440\n",
            "Validation:  loss: 0.7067 | accuracy: 0.6296 | f1: 0.6250\n",
            "Epoch 00072\n",
            "Train: loss: 0.6324 | accuracy: 0.6355 | f-acore: 0.6143\n",
            "Test:  loss: 0.7321 | accuracy: 0.4575 | f1: 0.4484\n",
            "Validation:  loss: 0.7092 | accuracy: 0.6296 | f1: 0.6282\n",
            "Epoch 00073\n",
            "Train: loss: 0.6402 | accuracy: 0.6172 | f-acore: 0.6021\n",
            "Test:  loss: 0.7307 | accuracy: 0.4521 | f1: 0.4481\n",
            "Validation:  loss: 0.7102 | accuracy: 0.6049 | f1: 0.6034\n",
            "Epoch 00074\n",
            "Train: loss: 0.6286 | accuracy: 0.6374 | f-acore: 0.6294\n",
            "Test:  loss: 0.7280 | accuracy: 0.4575 | f1: 0.4570\n",
            "Validation:  loss: 0.7021 | accuracy: 0.6543 | f1: 0.6517\n",
            "Epoch 00075\n",
            "Train: loss: 0.6414 | accuracy: 0.6401 | f-acore: 0.6234\n",
            "Test:  loss: 0.7380 | accuracy: 0.4548 | f1: 0.4544\n",
            "Validation:  loss: 0.7190 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00076\n",
            "Train: loss: 0.6383 | accuracy: 0.6342 | f-acore: 0.6202\n",
            "Test:  loss: 0.7290 | accuracy: 0.4630 | f1: 0.4629\n",
            "Validation:  loss: 0.7096 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00077\n",
            "Train: loss: 0.6382 | accuracy: 0.6374 | f-acore: 0.6264\n",
            "Test:  loss: 0.7107 | accuracy: 0.4548 | f1: 0.4494\n",
            "Validation:  loss: 0.7098 | accuracy: 0.6049 | f1: 0.5909\n",
            "Epoch 00078\n",
            "Train: loss: 0.6320 | accuracy: 0.6227 | f-acore: 0.6105\n",
            "Test:  loss: 0.7185 | accuracy: 0.4712 | f1: 0.4627\n",
            "Validation:  loss: 0.7115 | accuracy: 0.6173 | f1: 0.6087\n",
            "Epoch 00079\n",
            "Train: loss: 0.6278 | accuracy: 0.6346 | f-acore: 0.6209\n",
            "Test:  loss: 0.7252 | accuracy: 0.4822 | f1: 0.4746\n",
            "Validation:  loss: 0.7110 | accuracy: 0.6173 | f1: 0.6087\n",
            "Epoch 00080\n",
            "Train: loss: 0.6219 | accuracy: 0.6497 | f-acore: 0.6312\n",
            "Test:  loss: 0.7140 | accuracy: 0.4603 | f1: 0.4508\n",
            "Validation:  loss: 0.7213 | accuracy: 0.6296 | f1: 0.6250\n",
            "Epoch 00081\n",
            "Train: loss: 0.6326 | accuracy: 0.6474 | f-acore: 0.6381\n",
            "Test:  loss: 0.7215 | accuracy: 0.4904 | f1: 0.4832\n",
            "Validation:  loss: 0.7281 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00082\n",
            "Train: loss: 0.6341 | accuracy: 0.6364 | f-acore: 0.6139\n",
            "Test:  loss: 0.7221 | accuracy: 0.4575 | f1: 0.4568\n",
            "Validation:  loss: 0.7255 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00083\n",
            "Train: loss: 0.6114 | accuracy: 0.6543 | f-acore: 0.6444\n",
            "Test:  loss: 0.7335 | accuracy: 0.4603 | f1: 0.4523\n",
            "Validation:  loss: 0.7219 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00084\n",
            "Train: loss: 0.6275 | accuracy: 0.6442 | f-acore: 0.6298\n",
            "Test:  loss: 0.7183 | accuracy: 0.4685 | f1: 0.4542\n",
            "Validation:  loss: 0.7241 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00085\n",
            "Train: loss: 0.6266 | accuracy: 0.6401 | f-acore: 0.6228\n",
            "Test:  loss: 0.7116 | accuracy: 0.4986 | f1: 0.4485\n",
            "Validation:  loss: 0.7124 | accuracy: 0.5926 | f1: 0.5714\n",
            "Epoch 00086\n",
            "Train: loss: 0.6226 | accuracy: 0.6484 | f-acore: 0.6375\n",
            "Test:  loss: 0.7111 | accuracy: 0.4685 | f1: 0.4395\n",
            "Validation:  loss: 0.7275 | accuracy: 0.5926 | f1: 0.5800\n",
            "Epoch 00087\n",
            "Train: loss: 0.6255 | accuracy: 0.6447 | f-acore: 0.6302\n",
            "Test:  loss: 0.7416 | accuracy: 0.4411 | f1: 0.4385\n",
            "Validation:  loss: 0.7220 | accuracy: 0.6173 | f1: 0.6152\n",
            "Epoch 00088\n",
            "Train: loss: 0.6222 | accuracy: 0.6529 | f-acore: 0.6443\n",
            "Test:  loss: 0.7215 | accuracy: 0.4712 | f1: 0.4555\n",
            "Validation:  loss: 0.7226 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00089\n",
            "Train: loss: 0.6199 | accuracy: 0.6511 | f-acore: 0.6397\n",
            "Test:  loss: 0.7385 | accuracy: 0.4685 | f1: 0.4630\n",
            "Validation:  loss: 0.7221 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00090\n",
            "Train: loss: 0.6244 | accuracy: 0.6360 | f-acore: 0.6277\n",
            "Test:  loss: 0.7351 | accuracy: 0.4767 | f1: 0.4690\n",
            "Validation:  loss: 0.7158 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00091\n",
            "Train: loss: 0.6100 | accuracy: 0.6653 | f-acore: 0.6530\n",
            "Test:  loss: 0.7382 | accuracy: 0.4575 | f1: 0.4531\n",
            "Validation:  loss: 0.7161 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00092\n",
            "Train: loss: 0.6229 | accuracy: 0.6667 | f-acore: 0.6493\n",
            "Test:  loss: 0.7546 | accuracy: 0.4548 | f1: 0.4532\n",
            "Validation:  loss: 0.7337 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00093\n",
            "Train: loss: 0.6134 | accuracy: 0.6548 | f-acore: 0.6470\n",
            "Test:  loss: 0.7222 | accuracy: 0.4849 | f1: 0.4609\n",
            "Validation:  loss: 0.7378 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00094\n",
            "Train: loss: 0.6218 | accuracy: 0.6424 | f-acore: 0.6276\n",
            "Test:  loss: 0.7289 | accuracy: 0.4712 | f1: 0.4370\n",
            "Validation:  loss: 0.7210 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00095\n",
            "Train: loss: 0.6081 | accuracy: 0.6644 | f-acore: 0.6572\n",
            "Test:  loss: 0.7545 | accuracy: 0.4658 | f1: 0.4579\n",
            "Validation:  loss: 0.7339 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00096\n",
            "Train: loss: 0.6152 | accuracy: 0.6351 | f-acore: 0.6179\n",
            "Test:  loss: 0.7196 | accuracy: 0.4877 | f1: 0.4232\n",
            "Validation:  loss: 0.7226 | accuracy: 0.5926 | f1: 0.5761\n",
            "Epoch 00097\n",
            "Train: loss: 0.6066 | accuracy: 0.6580 | f-acore: 0.6407\n",
            "Test:  loss: 0.7295 | accuracy: 0.4849 | f1: 0.4539\n",
            "Validation:  loss: 0.7363 | accuracy: 0.6049 | f1: 0.5945\n",
            "Epoch 00098\n",
            "Train: loss: 0.6092 | accuracy: 0.6566 | f-acore: 0.6390\n",
            "Test:  loss: 0.7267 | accuracy: 0.4822 | f1: 0.4612\n",
            "Validation:  loss: 0.7330 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00099\n",
            "Train: loss: 0.6103 | accuracy: 0.6607 | f-acore: 0.6563\n",
            "Test:  loss: 0.7251 | accuracy: 0.4767 | f1: 0.4530\n",
            "Validation:  loss: 0.7423 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00100\n",
            "Train: loss: 0.6125 | accuracy: 0.6598 | f-acore: 0.6497\n",
            "Test:  loss: 0.7226 | accuracy: 0.4767 | f1: 0.4444\n",
            "Validation:  loss: 0.7272 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00101\n",
            "Train: loss: 0.6025 | accuracy: 0.6639 | f-acore: 0.6519\n",
            "Test:  loss: 0.7383 | accuracy: 0.4658 | f1: 0.4465\n",
            "Validation:  loss: 0.7421 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00102\n",
            "Train: loss: 0.6134 | accuracy: 0.6667 | f-acore: 0.6549\n",
            "Test:  loss: 0.7424 | accuracy: 0.4658 | f1: 0.4555\n",
            "Validation:  loss: 0.7512 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00103\n",
            "Train: loss: 0.5940 | accuracy: 0.6712 | f-acore: 0.6586\n",
            "Test:  loss: 0.7304 | accuracy: 0.4740 | f1: 0.4340\n",
            "Validation:  loss: 0.7538 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00104\n",
            "Train: loss: 0.5944 | accuracy: 0.6767 | f-acore: 0.6663\n",
            "Test:  loss: 0.7551 | accuracy: 0.4712 | f1: 0.4545\n",
            "Validation:  loss: 0.7566 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00105\n",
            "Train: loss: 0.5983 | accuracy: 0.6703 | f-acore: 0.6542\n",
            "Test:  loss: 0.7740 | accuracy: 0.4356 | f1: 0.4291\n",
            "Validation:  loss: 0.7476 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00106\n",
            "Train: loss: 0.6057 | accuracy: 0.6644 | f-acore: 0.6530\n",
            "Test:  loss: 0.7710 | accuracy: 0.4411 | f1: 0.4411\n",
            "Validation:  loss: 0.7671 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00107\n",
            "Train: loss: 0.5984 | accuracy: 0.6625 | f-acore: 0.6552\n",
            "Test:  loss: 0.7609 | accuracy: 0.4630 | f1: 0.4532\n",
            "Validation:  loss: 0.7449 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00108\n",
            "Train: loss: 0.5951 | accuracy: 0.6722 | f-acore: 0.6607\n",
            "Test:  loss: 0.7616 | accuracy: 0.4466 | f1: 0.4431\n",
            "Validation:  loss: 0.7539 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00109\n",
            "Train: loss: 0.6007 | accuracy: 0.6749 | f-acore: 0.6640\n",
            "Test:  loss: 0.7306 | accuracy: 0.4822 | f1: 0.4574\n",
            "Validation:  loss: 0.7404 | accuracy: 0.5062 | f1: 0.4886\n",
            "Epoch 00110\n",
            "Train: loss: 0.5899 | accuracy: 0.6648 | f-acore: 0.6597\n",
            "Test:  loss: 0.7403 | accuracy: 0.4685 | f1: 0.4561\n",
            "Validation:  loss: 0.7421 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00111\n",
            "Train: loss: 0.5925 | accuracy: 0.6763 | f-acore: 0.6697\n",
            "Test:  loss: 0.7303 | accuracy: 0.4712 | f1: 0.4417\n",
            "Validation:  loss: 0.7386 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00112\n",
            "Train: loss: 0.5819 | accuracy: 0.6795 | f-acore: 0.6671\n",
            "Test:  loss: 0.7410 | accuracy: 0.4603 | f1: 0.4491\n",
            "Validation:  loss: 0.7509 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00113\n",
            "Train: loss: 0.5901 | accuracy: 0.6758 | f-acore: 0.6646\n",
            "Test:  loss: 0.7523 | accuracy: 0.4685 | f1: 0.4603\n",
            "Validation:  loss: 0.7542 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00114\n",
            "Train: loss: 0.5883 | accuracy: 0.6731 | f-acore: 0.6655\n",
            "Test:  loss: 0.7437 | accuracy: 0.4740 | f1: 0.4495\n",
            "Validation:  loss: 0.7255 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00115\n",
            "Train: loss: 0.6059 | accuracy: 0.6731 | f-acore: 0.6647\n",
            "Test:  loss: 0.7452 | accuracy: 0.4548 | f1: 0.4340\n",
            "Validation:  loss: 0.7321 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00116\n",
            "Train: loss: 0.5869 | accuracy: 0.6827 | f-acore: 0.6767\n",
            "Test:  loss: 0.7502 | accuracy: 0.4932 | f1: 0.4749\n",
            "Validation:  loss: 0.7253 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00117\n",
            "Train: loss: 0.6024 | accuracy: 0.6717 | f-acore: 0.6635\n",
            "Test:  loss: 0.7284 | accuracy: 0.4904 | f1: 0.4444\n",
            "Validation:  loss: 0.7460 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00118\n",
            "Train: loss: 0.5850 | accuracy: 0.6836 | f-acore: 0.6761\n",
            "Test:  loss: 0.7536 | accuracy: 0.4658 | f1: 0.4555\n",
            "Validation:  loss: 0.7568 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00119\n",
            "Train: loss: 0.6121 | accuracy: 0.6845 | f-acore: 0.6760\n",
            "Test:  loss: 0.7442 | accuracy: 0.4767 | f1: 0.4697\n",
            "Validation:  loss: 0.7575 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00120\n",
            "Train: loss: 0.5949 | accuracy: 0.6735 | f-acore: 0.6684\n",
            "Test:  loss: 0.7657 | accuracy: 0.4521 | f1: 0.4403\n",
            "Validation:  loss: 0.7383 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00121\n",
            "Train: loss: 0.5834 | accuracy: 0.6777 | f-acore: 0.6662\n",
            "Test:  loss: 0.7642 | accuracy: 0.4575 | f1: 0.4525\n",
            "Validation:  loss: 0.7527 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00122\n",
            "Train: loss: 0.5735 | accuracy: 0.6973 | f-acore: 0.6921\n",
            "Test:  loss: 0.7631 | accuracy: 0.4849 | f1: 0.4762\n",
            "Validation:  loss: 0.7364 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00123\n",
            "Train: loss: 0.5749 | accuracy: 0.6854 | f-acore: 0.6748\n",
            "Test:  loss: 0.7567 | accuracy: 0.4658 | f1: 0.4634\n",
            "Validation:  loss: 0.7707 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00124\n",
            "Train: loss: 0.5819 | accuracy: 0.6822 | f-acore: 0.6753\n",
            "Test:  loss: 0.7650 | accuracy: 0.4685 | f1: 0.4646\n",
            "Validation:  loss: 0.7579 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00125\n",
            "Train: loss: 0.5807 | accuracy: 0.6987 | f-acore: 0.6935\n",
            "Test:  loss: 0.7834 | accuracy: 0.4548 | f1: 0.4535\n",
            "Validation:  loss: 0.7536 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00126\n",
            "Train: loss: 0.5765 | accuracy: 0.6923 | f-acore: 0.6827\n",
            "Test:  loss: 0.7619 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 0.7416 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00127\n",
            "Train: loss: 0.5649 | accuracy: 0.6983 | f-acore: 0.6905\n",
            "Test:  loss: 0.7438 | accuracy: 0.4740 | f1: 0.4635\n",
            "Validation:  loss: 0.7492 | accuracy: 0.6296 | f1: 0.6198\n",
            "Epoch 00128\n",
            "Train: loss: 0.5761 | accuracy: 0.6937 | f-acore: 0.6844\n",
            "Test:  loss: 0.7478 | accuracy: 0.4630 | f1: 0.4580\n",
            "Validation:  loss: 0.7509 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00129\n",
            "Train: loss: 0.5760 | accuracy: 0.6891 | f-acore: 0.6831\n",
            "Test:  loss: 0.7472 | accuracy: 0.4712 | f1: 0.4619\n",
            "Validation:  loss: 0.7534 | accuracy: 0.5926 | f1: 0.5800\n",
            "Epoch 00130\n",
            "Train: loss: 0.5771 | accuracy: 0.6978 | f-acore: 0.6922\n",
            "Test:  loss: 0.7660 | accuracy: 0.4658 | f1: 0.4605\n",
            "Validation:  loss: 0.7562 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00131\n",
            "Train: loss: 0.5634 | accuracy: 0.7074 | f-acore: 0.7022\n",
            "Test:  loss: 0.7597 | accuracy: 0.4658 | f1: 0.4509\n",
            "Validation:  loss: 0.7588 | accuracy: 0.5802 | f1: 0.5691\n",
            "Epoch 00132\n",
            "Train: loss: 0.5631 | accuracy: 0.6983 | f-acore: 0.6938\n",
            "Test:  loss: 0.7517 | accuracy: 0.4767 | f1: 0.4632\n",
            "Validation:  loss: 0.7618 | accuracy: 0.5802 | f1: 0.5653\n",
            "Epoch 00133\n",
            "Train: loss: 0.5948 | accuracy: 0.6868 | f-acore: 0.6758\n",
            "Test:  loss: 0.7547 | accuracy: 0.4575 | f1: 0.4545\n",
            "Validation:  loss: 0.7558 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00134\n",
            "Train: loss: 0.5780 | accuracy: 0.6964 | f-acore: 0.6901\n",
            "Test:  loss: 0.7601 | accuracy: 0.4822 | f1: 0.4738\n",
            "Validation:  loss: 0.7527 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00135\n",
            "Train: loss: 0.5712 | accuracy: 0.7047 | f-acore: 0.7019\n",
            "Test:  loss: 0.7602 | accuracy: 0.4575 | f1: 0.4513\n",
            "Validation:  loss: 0.7655 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00136\n",
            "Train: loss: 0.5742 | accuracy: 0.7028 | f-acore: 0.6947\n",
            "Test:  loss: 0.7507 | accuracy: 0.4740 | f1: 0.4453\n",
            "Validation:  loss: 0.7589 | accuracy: 0.6049 | f1: 0.5909\n",
            "Epoch 00137\n",
            "Train: loss: 0.5669 | accuracy: 0.7102 | f-acore: 0.6969\n",
            "Test:  loss: 0.7965 | accuracy: 0.4658 | f1: 0.4630\n",
            "Validation:  loss: 0.7591 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00138\n",
            "Train: loss: 0.5592 | accuracy: 0.7083 | f-acore: 0.7008\n",
            "Test:  loss: 0.7521 | accuracy: 0.4630 | f1: 0.4609\n",
            "Validation:  loss: 0.7673 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00139\n",
            "Train: loss: 0.5738 | accuracy: 0.6964 | f-acore: 0.6922\n",
            "Test:  loss: 0.7696 | accuracy: 0.4658 | f1: 0.4652\n",
            "Validation:  loss: 0.7686 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00140\n",
            "Train: loss: 0.5802 | accuracy: 0.6886 | f-acore: 0.6858\n",
            "Test:  loss: 0.7745 | accuracy: 0.4877 | f1: 0.4842\n",
            "Validation:  loss: 0.7757 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00141\n",
            "Train: loss: 0.5698 | accuracy: 0.7092 | f-acore: 0.7062\n",
            "Test:  loss: 0.7902 | accuracy: 0.4712 | f1: 0.4619\n",
            "Validation:  loss: 0.7597 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00142\n",
            "Train: loss: 0.5761 | accuracy: 0.6873 | f-acore: 0.6782\n",
            "Test:  loss: 0.7432 | accuracy: 0.4849 | f1: 0.4609\n",
            "Validation:  loss: 0.7392 | accuracy: 0.5926 | f1: 0.5800\n",
            "Epoch 00143\n",
            "Train: loss: 0.5730 | accuracy: 0.6955 | f-acore: 0.6844\n",
            "Test:  loss: 0.7904 | accuracy: 0.4521 | f1: 0.4481\n",
            "Validation:  loss: 0.7423 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00144\n",
            "Train: loss: 0.5475 | accuracy: 0.7170 | f-acore: 0.7119\n",
            "Test:  loss: 0.7942 | accuracy: 0.4466 | f1: 0.4461\n",
            "Validation:  loss: 0.7725 | accuracy: 0.6049 | f1: 0.6020\n",
            "Epoch 00145\n",
            "Train: loss: 0.5750 | accuracy: 0.7056 | f-acore: 0.7021\n",
            "Test:  loss: 0.7720 | accuracy: 0.4658 | f1: 0.4519\n",
            "Validation:  loss: 0.7585 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00146\n",
            "Train: loss: 0.5495 | accuracy: 0.7138 | f-acore: 0.7064\n",
            "Test:  loss: 0.7627 | accuracy: 0.4658 | f1: 0.4611\n",
            "Validation:  loss: 0.7683 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00147\n",
            "Train: loss: 0.5474 | accuracy: 0.7047 | f-acore: 0.7012\n",
            "Test:  loss: 0.7863 | accuracy: 0.4658 | f1: 0.4621\n",
            "Validation:  loss: 0.7747 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00148\n",
            "Train: loss: 0.5605 | accuracy: 0.6951 | f-acore: 0.6895\n",
            "Test:  loss: 0.7964 | accuracy: 0.4493 | f1: 0.4483\n",
            "Validation:  loss: 0.7806 | accuracy: 0.6173 | f1: 0.6152\n",
            "Epoch 00149\n",
            "Train: loss: 0.5601 | accuracy: 0.7088 | f-acore: 0.7026\n",
            "Test:  loss: 0.7900 | accuracy: 0.4822 | f1: 0.4777\n",
            "Validation:  loss: 0.7674 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00150\n",
            "Train: loss: 0.5551 | accuracy: 0.7083 | f-acore: 0.7049\n",
            "Test:  loss: 0.7888 | accuracy: 0.4658 | f1: 0.4650\n",
            "Validation:  loss: 0.7845 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00151\n",
            "Train: loss: 0.5592 | accuracy: 0.7115 | f-acore: 0.7049\n",
            "Test:  loss: 0.7496 | accuracy: 0.4685 | f1: 0.4595\n",
            "Validation:  loss: 0.7766 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00152\n",
            "Train: loss: 0.5458 | accuracy: 0.7120 | f-acore: 0.7051\n",
            "Test:  loss: 0.7672 | accuracy: 0.4575 | f1: 0.4531\n",
            "Validation:  loss: 0.7876 | accuracy: 0.5802 | f1: 0.5724\n",
            "Epoch 00153\n",
            "Train: loss: 0.5360 | accuracy: 0.7152 | f-acore: 0.7097\n",
            "Test:  loss: 0.7773 | accuracy: 0.4658 | f1: 0.4634\n",
            "Validation:  loss: 0.7741 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00154\n",
            "Train: loss: 0.5486 | accuracy: 0.7070 | f-acore: 0.7025\n",
            "Test:  loss: 0.7677 | accuracy: 0.4712 | f1: 0.4660\n",
            "Validation:  loss: 0.7843 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00155\n",
            "Train: loss: 0.5413 | accuracy: 0.7207 | f-acore: 0.7158\n",
            "Test:  loss: 0.7823 | accuracy: 0.4877 | f1: 0.4801\n",
            "Validation:  loss: 0.7964 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00156\n",
            "Train: loss: 0.5478 | accuracy: 0.7216 | f-acore: 0.7166\n",
            "Test:  loss: 0.8080 | accuracy: 0.4575 | f1: 0.4550\n",
            "Validation:  loss: 0.7932 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00157\n",
            "Train: loss: 0.5584 | accuracy: 0.7170 | f-acore: 0.7099\n",
            "Test:  loss: 0.7764 | accuracy: 0.4658 | f1: 0.4605\n",
            "Validation:  loss: 0.8013 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00158\n",
            "Train: loss: 0.5606 | accuracy: 0.7065 | f-acore: 0.7039\n",
            "Test:  loss: 0.7733 | accuracy: 0.4521 | f1: 0.4464\n",
            "Validation:  loss: 0.7898 | accuracy: 0.6296 | f1: 0.6227\n",
            "Epoch 00159\n",
            "Train: loss: 0.5727 | accuracy: 0.7056 | f-acore: 0.7005\n",
            "Test:  loss: 0.8033 | accuracy: 0.4685 | f1: 0.4646\n",
            "Validation:  loss: 0.7715 | accuracy: 0.6173 | f1: 0.6087\n",
            "Epoch 00160\n",
            "Train: loss: 0.5561 | accuracy: 0.7047 | f-acore: 0.7002\n",
            "Test:  loss: 0.7527 | accuracy: 0.4740 | f1: 0.4666\n",
            "Validation:  loss: 0.7954 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00161\n",
            "Train: loss: 0.5450 | accuracy: 0.7312 | f-acore: 0.7248\n",
            "Test:  loss: 0.7852 | accuracy: 0.4767 | f1: 0.4704\n",
            "Validation:  loss: 0.7663 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00162\n",
            "Train: loss: 0.5319 | accuracy: 0.7207 | f-acore: 0.7177\n",
            "Test:  loss: 0.8137 | accuracy: 0.4575 | f1: 0.4572\n",
            "Validation:  loss: 0.7984 | accuracy: 0.6049 | f1: 0.6049\n",
            "Epoch 00163\n",
            "Train: loss: 0.5480 | accuracy: 0.7184 | f-acore: 0.7125\n",
            "Test:  loss: 0.7883 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.7789 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00164\n",
            "Train: loss: 0.5377 | accuracy: 0.7193 | f-acore: 0.7143\n",
            "Test:  loss: 0.7849 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.7809 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00165\n",
            "Train: loss: 0.5410 | accuracy: 0.7248 | f-acore: 0.7191\n",
            "Test:  loss: 0.7770 | accuracy: 0.4658 | f1: 0.4630\n",
            "Validation:  loss: 0.7922 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00166\n",
            "Train: loss: 0.5345 | accuracy: 0.7276 | f-acore: 0.7226\n",
            "Test:  loss: 0.7686 | accuracy: 0.4685 | f1: 0.4656\n",
            "Validation:  loss: 0.7846 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00167\n",
            "Train: loss: 0.5446 | accuracy: 0.7065 | f-acore: 0.7013\n",
            "Test:  loss: 0.7788 | accuracy: 0.4795 | f1: 0.4757\n",
            "Validation:  loss: 0.7788 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00168\n",
            "Train: loss: 0.5421 | accuracy: 0.7239 | f-acore: 0.7154\n",
            "Test:  loss: 0.7803 | accuracy: 0.4658 | f1: 0.4616\n",
            "Validation:  loss: 0.7880 | accuracy: 0.5802 | f1: 0.5724\n",
            "Epoch 00169\n",
            "Train: loss: 0.5470 | accuracy: 0.7225 | f-acore: 0.7176\n",
            "Test:  loss: 0.7738 | accuracy: 0.4630 | f1: 0.4596\n",
            "Validation:  loss: 0.7944 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00170\n",
            "Train: loss: 0.5453 | accuracy: 0.7143 | f-acore: 0.7102\n",
            "Test:  loss: 0.7879 | accuracy: 0.4658 | f1: 0.4616\n",
            "Validation:  loss: 0.7886 | accuracy: 0.6420 | f1: 0.6364\n",
            "Epoch 00171\n",
            "Train: loss: 0.5326 | accuracy: 0.7111 | f-acore: 0.7052\n",
            "Test:  loss: 0.7907 | accuracy: 0.4603 | f1: 0.4561\n",
            "Validation:  loss: 0.7837 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00172\n",
            "Train: loss: 0.5461 | accuracy: 0.7326 | f-acore: 0.7270\n",
            "Test:  loss: 0.7898 | accuracy: 0.4493 | f1: 0.4469\n",
            "Validation:  loss: 0.7903 | accuracy: 0.6049 | f1: 0.6034\n",
            "Epoch 00173\n",
            "Train: loss: 0.5475 | accuracy: 0.7326 | f-acore: 0.7290\n",
            "Test:  loss: 0.7845 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.7833 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00174\n",
            "Train: loss: 0.5271 | accuracy: 0.7331 | f-acore: 0.7280\n",
            "Test:  loss: 0.7710 | accuracy: 0.4712 | f1: 0.4634\n",
            "Validation:  loss: 0.7929 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00175\n",
            "Train: loss: 0.5443 | accuracy: 0.7340 | f-acore: 0.7283\n",
            "Test:  loss: 0.7857 | accuracy: 0.4685 | f1: 0.4587\n",
            "Validation:  loss: 0.7888 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00176\n",
            "Train: loss: 0.5314 | accuracy: 0.7381 | f-acore: 0.7335\n",
            "Test:  loss: 0.7642 | accuracy: 0.4521 | f1: 0.4384\n",
            "Validation:  loss: 0.8048 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00177\n",
            "Train: loss: 0.5294 | accuracy: 0.7422 | f-acore: 0.7371\n",
            "Test:  loss: 0.8220 | accuracy: 0.4438 | f1: 0.4414\n",
            "Validation:  loss: 0.7912 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00178\n",
            "Train: loss: 0.5270 | accuracy: 0.7266 | f-acore: 0.7214\n",
            "Test:  loss: 0.8149 | accuracy: 0.4466 | f1: 0.4435\n",
            "Validation:  loss: 0.7969 | accuracy: 0.5802 | f1: 0.5786\n",
            "Epoch 00179\n",
            "Train: loss: 0.5410 | accuracy: 0.7344 | f-acore: 0.7283\n",
            "Test:  loss: 0.7952 | accuracy: 0.4384 | f1: 0.4363\n",
            "Validation:  loss: 0.8112 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00180\n",
            "Train: loss: 0.5374 | accuracy: 0.7271 | f-acore: 0.7241\n",
            "Test:  loss: 0.7759 | accuracy: 0.4466 | f1: 0.4317\n",
            "Validation:  loss: 0.8122 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00181\n",
            "Train: loss: 0.5394 | accuracy: 0.7280 | f-acore: 0.7213\n",
            "Test:  loss: 0.7930 | accuracy: 0.4685 | f1: 0.4630\n",
            "Validation:  loss: 0.8007 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00182\n",
            "Train: loss: 0.5384 | accuracy: 0.7299 | f-acore: 0.7268\n",
            "Test:  loss: 0.7768 | accuracy: 0.4548 | f1: 0.4494\n",
            "Validation:  loss: 0.7955 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00183\n",
            "Train: loss: 0.5354 | accuracy: 0.7312 | f-acore: 0.7271\n",
            "Test:  loss: 0.7950 | accuracy: 0.4658 | f1: 0.4586\n",
            "Validation:  loss: 0.7993 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00184\n",
            "Train: loss: 0.5161 | accuracy: 0.7321 | f-acore: 0.7276\n",
            "Test:  loss: 0.7825 | accuracy: 0.4548 | f1: 0.4488\n",
            "Validation:  loss: 0.8051 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00185\n",
            "Train: loss: 0.5432 | accuracy: 0.7303 | f-acore: 0.7259\n",
            "Test:  loss: 0.7858 | accuracy: 0.4630 | f1: 0.4580\n",
            "Validation:  loss: 0.8103 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00186\n",
            "Train: loss: 0.5332 | accuracy: 0.7244 | f-acore: 0.7206\n",
            "Test:  loss: 0.7946 | accuracy: 0.4822 | f1: 0.4771\n",
            "Validation:  loss: 0.8256 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00187\n",
            "Train: loss: 0.5448 | accuracy: 0.7198 | f-acore: 0.7148\n",
            "Test:  loss: 0.7705 | accuracy: 0.4603 | f1: 0.4516\n",
            "Validation:  loss: 0.8141 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00188\n",
            "Train: loss: 0.5116 | accuracy: 0.7386 | f-acore: 0.7341\n",
            "Test:  loss: 0.7865 | accuracy: 0.4740 | f1: 0.4659\n",
            "Validation:  loss: 0.8008 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00189\n",
            "Train: loss: 0.5366 | accuracy: 0.7344 | f-acore: 0.7282\n",
            "Test:  loss: 0.7793 | accuracy: 0.4274 | f1: 0.4235\n",
            "Validation:  loss: 0.8232 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00190\n",
            "Train: loss: 0.5345 | accuracy: 0.7198 | f-acore: 0.7160\n",
            "Test:  loss: 0.7987 | accuracy: 0.4630 | f1: 0.4574\n",
            "Validation:  loss: 0.8377 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00191\n",
            "Train: loss: 0.5279 | accuracy: 0.7353 | f-acore: 0.7274\n",
            "Test:  loss: 0.7958 | accuracy: 0.4301 | f1: 0.4254\n",
            "Validation:  loss: 0.8214 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00192\n",
            "Train: loss: 0.5312 | accuracy: 0.7376 | f-acore: 0.7328\n",
            "Test:  loss: 0.8192 | accuracy: 0.4466 | f1: 0.4435\n",
            "Validation:  loss: 0.8181 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00193\n",
            "Train: loss: 0.5258 | accuracy: 0.7299 | f-acore: 0.7250\n",
            "Test:  loss: 0.8043 | accuracy: 0.4466 | f1: 0.4435\n",
            "Validation:  loss: 0.8221 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00194\n",
            "Train: loss: 0.5237 | accuracy: 0.7257 | f-acore: 0.7204\n",
            "Test:  loss: 0.8104 | accuracy: 0.4630 | f1: 0.4591\n",
            "Validation:  loss: 0.8177 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00195\n",
            "Train: loss: 0.5256 | accuracy: 0.7349 | f-acore: 0.7299\n",
            "Test:  loss: 0.7994 | accuracy: 0.4795 | f1: 0.4721\n",
            "Validation:  loss: 0.7905 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00196\n",
            "Train: loss: 0.5175 | accuracy: 0.7509 | f-acore: 0.7447\n",
            "Test:  loss: 0.8045 | accuracy: 0.4466 | f1: 0.4402\n",
            "Validation:  loss: 0.8050 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00197\n",
            "Train: loss: 0.5287 | accuracy: 0.7395 | f-acore: 0.7363\n",
            "Test:  loss: 0.8037 | accuracy: 0.4685 | f1: 0.4630\n",
            "Validation:  loss: 0.8224 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00198\n",
            "Train: loss: 0.5323 | accuracy: 0.7418 | f-acore: 0.7371\n",
            "Test:  loss: 0.8065 | accuracy: 0.4219 | f1: 0.4190\n",
            "Validation:  loss: 0.7851 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00199\n",
            "Train: loss: 0.5283 | accuracy: 0.7395 | f-acore: 0.7363\n",
            "Test:  loss: 0.8088 | accuracy: 0.4603 | f1: 0.4590\n",
            "Validation:  loss: 0.8328 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00200\n",
            "Train: loss: 0.5237 | accuracy: 0.7317 | f-acore: 0.7264\n",
            "Test:  loss: 0.7930 | accuracy: 0.4740 | f1: 0.4706\n",
            "Validation:  loss: 0.7963 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00201\n",
            "Train: loss: 0.5122 | accuracy: 0.7459 | f-acore: 0.7413\n",
            "Test:  loss: 0.8194 | accuracy: 0.4658 | f1: 0.4630\n",
            "Validation:  loss: 0.8266 | accuracy: 0.5926 | f1: 0.5903\n",
            "Epoch 00202\n",
            "Train: loss: 0.5454 | accuracy: 0.7248 | f-acore: 0.7215\n",
            "Test:  loss: 0.8044 | accuracy: 0.4740 | f1: 0.4719\n",
            "Validation:  loss: 0.8408 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00203\n",
            "Train: loss: 0.5046 | accuracy: 0.7431 | f-acore: 0.7376\n",
            "Test:  loss: 0.8114 | accuracy: 0.4630 | f1: 0.4609\n",
            "Validation:  loss: 0.8359 | accuracy: 0.5679 | f1: 0.5668\n",
            "Epoch 00204\n",
            "Train: loss: 0.5330 | accuracy: 0.7326 | f-acore: 0.7290\n",
            "Test:  loss: 0.8218 | accuracy: 0.4685 | f1: 0.4656\n",
            "Validation:  loss: 0.8387 | accuracy: 0.5926 | f1: 0.5903\n",
            "Epoch 00205\n",
            "Train: loss: 0.5194 | accuracy: 0.7427 | f-acore: 0.7376\n",
            "Test:  loss: 0.8276 | accuracy: 0.4603 | f1: 0.4586\n",
            "Validation:  loss: 0.8391 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00206\n",
            "Train: loss: 0.5187 | accuracy: 0.7321 | f-acore: 0.7304\n",
            "Test:  loss: 0.8062 | accuracy: 0.4822 | f1: 0.4796\n",
            "Validation:  loss: 0.8351 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00207\n",
            "Train: loss: 0.5129 | accuracy: 0.7523 | f-acore: 0.7484\n",
            "Test:  loss: 0.8361 | accuracy: 0.4493 | f1: 0.4469\n",
            "Validation:  loss: 0.8332 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00208\n",
            "Train: loss: 0.5049 | accuracy: 0.7445 | f-acore: 0.7398\n",
            "Test:  loss: 0.7987 | accuracy: 0.4548 | f1: 0.4506\n",
            "Validation:  loss: 0.8439 | accuracy: 0.6049 | f1: 0.6034\n",
            "Epoch 00209\n",
            "Train: loss: 0.5084 | accuracy: 0.7427 | f-acore: 0.7382\n",
            "Test:  loss: 0.8101 | accuracy: 0.4795 | f1: 0.4774\n",
            "Validation:  loss: 0.8421 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00210\n",
            "Train: loss: 0.5032 | accuracy: 0.7569 | f-acore: 0.7521\n",
            "Test:  loss: 0.8124 | accuracy: 0.4685 | f1: 0.4670\n",
            "Validation:  loss: 0.8515 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00211\n",
            "Train: loss: 0.5132 | accuracy: 0.7399 | f-acore: 0.7355\n",
            "Test:  loss: 0.8126 | accuracy: 0.4658 | f1: 0.4645\n",
            "Validation:  loss: 0.8537 | accuracy: 0.5556 | f1: 0.5539\n",
            "Epoch 00212\n",
            "Train: loss: 0.5107 | accuracy: 0.7376 | f-acore: 0.7318\n",
            "Test:  loss: 0.8109 | accuracy: 0.4795 | f1: 0.4770\n",
            "Validation:  loss: 0.8318 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00213\n",
            "Train: loss: 0.5197 | accuracy: 0.7408 | f-acore: 0.7379\n",
            "Test:  loss: 0.7952 | accuracy: 0.4521 | f1: 0.4490\n",
            "Validation:  loss: 0.8332 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00214\n",
            "Train: loss: 0.5019 | accuracy: 0.7477 | f-acore: 0.7442\n",
            "Test:  loss: 0.8114 | accuracy: 0.4603 | f1: 0.4583\n",
            "Validation:  loss: 0.8370 | accuracy: 0.5556 | f1: 0.5539\n",
            "Epoch 00215\n",
            "Train: loss: 0.5045 | accuracy: 0.7408 | f-acore: 0.7375\n",
            "Test:  loss: 0.8054 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 0.8426 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00216\n",
            "Train: loss: 0.5274 | accuracy: 0.7431 | f-acore: 0.7373\n",
            "Test:  loss: 0.8123 | accuracy: 0.4740 | f1: 0.4719\n",
            "Validation:  loss: 0.8444 | accuracy: 0.5802 | f1: 0.5797\n",
            "Epoch 00217\n",
            "Train: loss: 0.5001 | accuracy: 0.7427 | f-acore: 0.7388\n",
            "Test:  loss: 0.8116 | accuracy: 0.4438 | f1: 0.4401\n",
            "Validation:  loss: 0.8374 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00218\n",
            "Train: loss: 0.5034 | accuracy: 0.7550 | f-acore: 0.7514\n",
            "Test:  loss: 0.8231 | accuracy: 0.4384 | f1: 0.4359\n",
            "Validation:  loss: 0.8392 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00219\n",
            "Train: loss: 0.5156 | accuracy: 0.7541 | f-acore: 0.7512\n",
            "Test:  loss: 0.8096 | accuracy: 0.4493 | f1: 0.4450\n",
            "Validation:  loss: 0.8581 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00220\n",
            "Train: loss: 0.5150 | accuracy: 0.7505 | f-acore: 0.7460\n",
            "Test:  loss: 0.7729 | accuracy: 0.4521 | f1: 0.4470\n",
            "Validation:  loss: 0.8557 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00221\n",
            "Train: loss: 0.5145 | accuracy: 0.7491 | f-acore: 0.7438\n",
            "Test:  loss: 0.8136 | accuracy: 0.4767 | f1: 0.4748\n",
            "Validation:  loss: 0.8410 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00222\n",
            "Train: loss: 0.5090 | accuracy: 0.7440 | f-acore: 0.7409\n",
            "Test:  loss: 0.8083 | accuracy: 0.4795 | f1: 0.4780\n",
            "Validation:  loss: 0.8411 | accuracy: 0.5926 | f1: 0.5916\n",
            "Epoch 00223\n",
            "Train: loss: 0.5071 | accuracy: 0.7427 | f-acore: 0.7390\n",
            "Test:  loss: 0.8046 | accuracy: 0.4247 | f1: 0.4215\n",
            "Validation:  loss: 0.8531 | accuracy: 0.5679 | f1: 0.5668\n",
            "Epoch 00224\n",
            "Train: loss: 0.5006 | accuracy: 0.7500 | f-acore: 0.7461\n",
            "Test:  loss: 0.8238 | accuracy: 0.4603 | f1: 0.4566\n",
            "Validation:  loss: 0.8398 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00225\n",
            "Train: loss: 0.5022 | accuracy: 0.7482 | f-acore: 0.7433\n",
            "Test:  loss: 0.7875 | accuracy: 0.4493 | f1: 0.4445\n",
            "Validation:  loss: 0.8576 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00226\n",
            "Train: loss: 0.5029 | accuracy: 0.7582 | f-acore: 0.7548\n",
            "Test:  loss: 0.8246 | accuracy: 0.4740 | f1: 0.4673\n",
            "Validation:  loss: 0.8313 | accuracy: 0.5926 | f1: 0.5903\n",
            "Epoch 00227\n",
            "Train: loss: 0.4923 | accuracy: 0.7500 | f-acore: 0.7455\n",
            "Test:  loss: 0.7992 | accuracy: 0.4521 | f1: 0.4443\n",
            "Validation:  loss: 0.8624 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00228\n",
            "Train: loss: 0.4995 | accuracy: 0.7491 | f-acore: 0.7448\n",
            "Test:  loss: 0.8138 | accuracy: 0.4411 | f1: 0.4375\n",
            "Validation:  loss: 0.8541 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00229\n",
            "Train: loss: 0.5165 | accuracy: 0.7527 | f-acore: 0.7487\n",
            "Test:  loss: 0.8013 | accuracy: 0.4356 | f1: 0.4325\n",
            "Validation:  loss: 0.8442 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00230\n",
            "Train: loss: 0.4940 | accuracy: 0.7532 | f-acore: 0.7481\n",
            "Test:  loss: 0.8231 | accuracy: 0.4658 | f1: 0.4593\n",
            "Validation:  loss: 0.8408 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00231\n",
            "Train: loss: 0.5040 | accuracy: 0.7532 | f-acore: 0.7485\n",
            "Test:  loss: 0.8055 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.8901 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00232\n",
            "Train: loss: 0.5117 | accuracy: 0.7440 | f-acore: 0.7403\n",
            "Test:  loss: 0.7947 | accuracy: 0.4685 | f1: 0.4624\n",
            "Validation:  loss: 0.8620 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00233\n",
            "Train: loss: 0.4974 | accuracy: 0.7482 | f-acore: 0.7437\n",
            "Test:  loss: 0.8173 | accuracy: 0.4740 | f1: 0.4702\n",
            "Validation:  loss: 0.8383 | accuracy: 0.6049 | f1: 0.6020\n",
            "Epoch 00234\n",
            "Train: loss: 0.5151 | accuracy: 0.7482 | f-acore: 0.7453\n",
            "Test:  loss: 0.8127 | accuracy: 0.4822 | f1: 0.4803\n",
            "Validation:  loss: 0.8677 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00235\n",
            "Train: loss: 0.5032 | accuracy: 0.7473 | f-acore: 0.7430\n",
            "Test:  loss: 0.8043 | accuracy: 0.4603 | f1: 0.4579\n",
            "Validation:  loss: 0.8585 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00236\n",
            "Train: loss: 0.4780 | accuracy: 0.7587 | f-acore: 0.7554\n",
            "Test:  loss: 0.7966 | accuracy: 0.4630 | f1: 0.4596\n",
            "Validation:  loss: 0.8670 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00237\n",
            "Train: loss: 0.4943 | accuracy: 0.7573 | f-acore: 0.7532\n",
            "Test:  loss: 0.8070 | accuracy: 0.4795 | f1: 0.4746\n",
            "Validation:  loss: 0.8583 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00238\n",
            "Train: loss: 0.4960 | accuracy: 0.7614 | f-acore: 0.7578\n",
            "Test:  loss: 0.7968 | accuracy: 0.4603 | f1: 0.4555\n",
            "Validation:  loss: 0.8850 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00239\n",
            "Train: loss: 0.4949 | accuracy: 0.7523 | f-acore: 0.7474\n",
            "Test:  loss: 0.8285 | accuracy: 0.4603 | f1: 0.4550\n",
            "Validation:  loss: 0.8859 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00240\n",
            "Train: loss: 0.4920 | accuracy: 0.7560 | f-acore: 0.7528\n",
            "Test:  loss: 0.8165 | accuracy: 0.4548 | f1: 0.4500\n",
            "Validation:  loss: 0.8629 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00241\n",
            "Train: loss: 0.5048 | accuracy: 0.7550 | f-acore: 0.7511\n",
            "Test:  loss: 0.8385 | accuracy: 0.4740 | f1: 0.4685\n",
            "Validation:  loss: 0.8571 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00242\n",
            "Train: loss: 0.4906 | accuracy: 0.7491 | f-acore: 0.7445\n",
            "Test:  loss: 0.8264 | accuracy: 0.4658 | f1: 0.4605\n",
            "Validation:  loss: 0.8804 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00243\n",
            "Train: loss: 0.4911 | accuracy: 0.7523 | f-acore: 0.7495\n",
            "Test:  loss: 0.8064 | accuracy: 0.4493 | f1: 0.4439\n",
            "Validation:  loss: 0.8992 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00244\n",
            "Train: loss: 0.4939 | accuracy: 0.7473 | f-acore: 0.7429\n",
            "Test:  loss: 0.8272 | accuracy: 0.4630 | f1: 0.4562\n",
            "Validation:  loss: 0.8758 | accuracy: 0.5802 | f1: 0.5691\n",
            "Epoch 00245\n",
            "Train: loss: 0.4866 | accuracy: 0.7527 | f-acore: 0.7465\n",
            "Test:  loss: 0.8220 | accuracy: 0.4767 | f1: 0.4690\n",
            "Validation:  loss: 0.8918 | accuracy: 0.5926 | f1: 0.5835\n",
            "Epoch 00246\n",
            "Train: loss: 0.5087 | accuracy: 0.7541 | f-acore: 0.7507\n",
            "Test:  loss: 0.8052 | accuracy: 0.4685 | f1: 0.4595\n",
            "Validation:  loss: 0.8806 | accuracy: 0.6173 | f1: 0.6055\n",
            "Epoch 00247\n",
            "Train: loss: 0.4873 | accuracy: 0.7610 | f-acore: 0.7578\n",
            "Test:  loss: 0.8260 | accuracy: 0.4603 | f1: 0.4561\n",
            "Validation:  loss: 0.8809 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00248\n",
            "Train: loss: 0.4874 | accuracy: 0.7532 | f-acore: 0.7499\n",
            "Test:  loss: 0.8207 | accuracy: 0.4411 | f1: 0.4370\n",
            "Validation:  loss: 0.9027 | accuracy: 0.5926 | f1: 0.5863\n",
            "Epoch 00249\n",
            "Train: loss: 0.4786 | accuracy: 0.7624 | f-acore: 0.7597\n",
            "Test:  loss: 0.8190 | accuracy: 0.4521 | f1: 0.4457\n",
            "Validation:  loss: 0.8968 | accuracy: 0.5802 | f1: 0.5724\n",
            "Epoch 00250\n",
            "Train: loss: 0.5012 | accuracy: 0.7541 | f-acore: 0.7506\n",
            "Test:  loss: 0.8268 | accuracy: 0.4575 | f1: 0.4513\n",
            "Validation:  loss: 0.8775 | accuracy: 0.6296 | f1: 0.6227\n",
            "Epoch 00251\n",
            "Train: loss: 0.5119 | accuracy: 0.7633 | f-acore: 0.7586\n",
            "Test:  loss: 0.8215 | accuracy: 0.4658 | f1: 0.4555\n",
            "Validation:  loss: 0.8780 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00252\n",
            "Train: loss: 0.5365 | accuracy: 0.7408 | f-acore: 0.7376\n",
            "Test:  loss: 0.8324 | accuracy: 0.4685 | f1: 0.4630\n",
            "Validation:  loss: 0.8652 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00253\n",
            "Train: loss: 0.5081 | accuracy: 0.7505 | f-acore: 0.7485\n",
            "Test:  loss: 0.7984 | accuracy: 0.4384 | f1: 0.4328\n",
            "Validation:  loss: 0.8684 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00254\n",
            "Train: loss: 0.5031 | accuracy: 0.7628 | f-acore: 0.7602\n",
            "Test:  loss: 0.8216 | accuracy: 0.4658 | f1: 0.4579\n",
            "Validation:  loss: 0.8958 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00255\n",
            "Train: loss: 0.4893 | accuracy: 0.7555 | f-acore: 0.7515\n",
            "Test:  loss: 0.8057 | accuracy: 0.4658 | f1: 0.4555\n",
            "Validation:  loss: 0.8770 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00256\n",
            "Train: loss: 0.4893 | accuracy: 0.7482 | f-acore: 0.7413\n",
            "Test:  loss: 0.8465 | accuracy: 0.4767 | f1: 0.4740\n",
            "Validation:  loss: 0.8993 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00257\n",
            "Train: loss: 0.4736 | accuracy: 0.7564 | f-acore: 0.7526\n",
            "Test:  loss: 0.8201 | accuracy: 0.4548 | f1: 0.4506\n",
            "Validation:  loss: 0.9271 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00258\n",
            "Train: loss: 0.4980 | accuracy: 0.7656 | f-acore: 0.7615\n",
            "Test:  loss: 0.8337 | accuracy: 0.4438 | f1: 0.4410\n",
            "Validation:  loss: 0.9162 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00259\n",
            "Train: loss: 0.4872 | accuracy: 0.7656 | f-acore: 0.7626\n",
            "Test:  loss: 0.8234 | accuracy: 0.4493 | f1: 0.4469\n",
            "Validation:  loss: 0.9085 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00260\n",
            "Train: loss: 0.4891 | accuracy: 0.7605 | f-acore: 0.7592\n",
            "Test:  loss: 0.8273 | accuracy: 0.4493 | f1: 0.4450\n",
            "Validation:  loss: 0.9196 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00261\n",
            "Train: loss: 0.4877 | accuracy: 0.7523 | f-acore: 0.7481\n",
            "Test:  loss: 0.8202 | accuracy: 0.4466 | f1: 0.4426\n",
            "Validation:  loss: 0.8809 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00262\n",
            "Train: loss: 0.4879 | accuracy: 0.7550 | f-acore: 0.7509\n",
            "Test:  loss: 0.8281 | accuracy: 0.4712 | f1: 0.4660\n",
            "Validation:  loss: 0.9079 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00263\n",
            "Train: loss: 0.4861 | accuracy: 0.7592 | f-acore: 0.7551\n",
            "Test:  loss: 0.8147 | accuracy: 0.4548 | f1: 0.4537\n",
            "Validation:  loss: 0.9353 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00264\n",
            "Train: loss: 0.4877 | accuracy: 0.7628 | f-acore: 0.7583\n",
            "Test:  loss: 0.8250 | accuracy: 0.4767 | f1: 0.4727\n",
            "Validation:  loss: 0.9137 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00265\n",
            "Train: loss: 0.5061 | accuracy: 0.7628 | f-acore: 0.7587\n",
            "Test:  loss: 0.8257 | accuracy: 0.4658 | f1: 0.4621\n",
            "Validation:  loss: 0.9168 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00266\n",
            "Train: loss: 0.4852 | accuracy: 0.7688 | f-acore: 0.7655\n",
            "Test:  loss: 0.8441 | accuracy: 0.4740 | f1: 0.4711\n",
            "Validation:  loss: 0.9235 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00267\n",
            "Train: loss: 0.4737 | accuracy: 0.7532 | f-acore: 0.7476\n",
            "Test:  loss: 0.8178 | accuracy: 0.4466 | f1: 0.4435\n",
            "Validation:  loss: 0.9347 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00268\n",
            "Train: loss: 0.4882 | accuracy: 0.7669 | f-acore: 0.7640\n",
            "Test:  loss: 0.8347 | accuracy: 0.4548 | f1: 0.4516\n",
            "Validation:  loss: 0.9200 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00269\n",
            "Train: loss: 0.5083 | accuracy: 0.7596 | f-acore: 0.7546\n",
            "Test:  loss: 0.8351 | accuracy: 0.4603 | f1: 0.4575\n",
            "Validation:  loss: 0.9039 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00270\n",
            "Train: loss: 0.4732 | accuracy: 0.7601 | f-acore: 0.7561\n",
            "Test:  loss: 0.8268 | accuracy: 0.4603 | f1: 0.4579\n",
            "Validation:  loss: 0.9238 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00271\n",
            "Train: loss: 0.4802 | accuracy: 0.7596 | f-acore: 0.7552\n",
            "Test:  loss: 0.8315 | accuracy: 0.4658 | f1: 0.4626\n",
            "Validation:  loss: 0.9142 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00272\n",
            "Train: loss: 0.5008 | accuracy: 0.7614 | f-acore: 0.7577\n",
            "Test:  loss: 0.8191 | accuracy: 0.4466 | f1: 0.4431\n",
            "Validation:  loss: 0.9348 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00273\n",
            "Train: loss: 0.4759 | accuracy: 0.7610 | f-acore: 0.7587\n",
            "Test:  loss: 0.8394 | accuracy: 0.4630 | f1: 0.4591\n",
            "Validation:  loss: 0.9528 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00274\n",
            "Train: loss: 0.4788 | accuracy: 0.7729 | f-acore: 0.7680\n",
            "Test:  loss: 0.8359 | accuracy: 0.4493 | f1: 0.4465\n",
            "Validation:  loss: 0.9293 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00275\n",
            "Train: loss: 0.4681 | accuracy: 0.7743 | f-acore: 0.7706\n",
            "Test:  loss: 0.8622 | accuracy: 0.4740 | f1: 0.4728\n",
            "Validation:  loss: 0.9384 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00276\n",
            "Train: loss: 0.4877 | accuracy: 0.7523 | f-acore: 0.7482\n",
            "Test:  loss: 0.8224 | accuracy: 0.4575 | f1: 0.4570\n",
            "Validation:  loss: 0.9802 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00277\n",
            "Train: loss: 0.4786 | accuracy: 0.7573 | f-acore: 0.7529\n",
            "Test:  loss: 0.8330 | accuracy: 0.4575 | f1: 0.4566\n",
            "Validation:  loss: 0.9215 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00278\n",
            "Train: loss: 0.4892 | accuracy: 0.7614 | f-acore: 0.7577\n",
            "Test:  loss: 0.8229 | accuracy: 0.4493 | f1: 0.4477\n",
            "Validation:  loss: 0.9432 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00279\n",
            "Train: loss: 0.4859 | accuracy: 0.7532 | f-acore: 0.7508\n",
            "Test:  loss: 0.8158 | accuracy: 0.4466 | f1: 0.4447\n",
            "Validation:  loss: 0.9375 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00280\n",
            "Train: loss: 0.4736 | accuracy: 0.7706 | f-acore: 0.7676\n",
            "Test:  loss: 0.8373 | accuracy: 0.4603 | f1: 0.4586\n",
            "Validation:  loss: 0.9430 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00281\n",
            "Train: loss: 0.4855 | accuracy: 0.7656 | f-acore: 0.7626\n",
            "Test:  loss: 0.8164 | accuracy: 0.4575 | f1: 0.4531\n",
            "Validation:  loss: 0.9329 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00282\n",
            "Train: loss: 0.4683 | accuracy: 0.7683 | f-acore: 0.7655\n",
            "Test:  loss: 0.8342 | accuracy: 0.4575 | f1: 0.4545\n",
            "Validation:  loss: 0.9433 | accuracy: 0.5802 | f1: 0.5724\n",
            "Epoch 00283\n",
            "Train: loss: 0.4981 | accuracy: 0.7811 | f-acore: 0.7770\n",
            "Test:  loss: 0.8328 | accuracy: 0.4548 | f1: 0.4520\n",
            "Validation:  loss: 0.9687 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00284\n",
            "Train: loss: 0.5110 | accuracy: 0.7582 | f-acore: 0.7563\n",
            "Test:  loss: 0.8496 | accuracy: 0.4493 | f1: 0.4487\n",
            "Validation:  loss: 0.9690 | accuracy: 0.5556 | f1: 0.5539\n",
            "Epoch 00285\n",
            "Train: loss: 0.4728 | accuracy: 0.7637 | f-acore: 0.7602\n",
            "Test:  loss: 0.8295 | accuracy: 0.4575 | f1: 0.4554\n",
            "Validation:  loss: 0.9494 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00286\n",
            "Train: loss: 0.4720 | accuracy: 0.7665 | f-acore: 0.7633\n",
            "Test:  loss: 0.8261 | accuracy: 0.4658 | f1: 0.4634\n",
            "Validation:  loss: 0.9524 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00287\n",
            "Train: loss: 0.4869 | accuracy: 0.7619 | f-acore: 0.7584\n",
            "Test:  loss: 0.8081 | accuracy: 0.4548 | f1: 0.4516\n",
            "Validation:  loss: 0.9511 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00288\n",
            "Train: loss: 0.4707 | accuracy: 0.7811 | f-acore: 0.7770\n",
            "Test:  loss: 0.8139 | accuracy: 0.4384 | f1: 0.4355\n",
            "Validation:  loss: 0.9389 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00289\n",
            "Train: loss: 0.4806 | accuracy: 0.7701 | f-acore: 0.7666\n",
            "Test:  loss: 0.8060 | accuracy: 0.4466 | f1: 0.4431\n",
            "Validation:  loss: 0.9383 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00290\n",
            "Train: loss: 0.4728 | accuracy: 0.7683 | f-acore: 0.7640\n",
            "Test:  loss: 0.8116 | accuracy: 0.4603 | f1: 0.4550\n",
            "Validation:  loss: 0.9544 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00291\n",
            "Train: loss: 0.4597 | accuracy: 0.7779 | f-acore: 0.7740\n",
            "Test:  loss: 0.8055 | accuracy: 0.4493 | f1: 0.4456\n",
            "Validation:  loss: 0.9681 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00292\n",
            "Train: loss: 0.4812 | accuracy: 0.7692 | f-acore: 0.7664\n",
            "Test:  loss: 0.8108 | accuracy: 0.4493 | f1: 0.4461\n",
            "Validation:  loss: 0.9575 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00293\n",
            "Train: loss: 0.4797 | accuracy: 0.7651 | f-acore: 0.7617\n",
            "Test:  loss: 0.8093 | accuracy: 0.4466 | f1: 0.4440\n",
            "Validation:  loss: 0.9670 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00294\n",
            "Train: loss: 0.4710 | accuracy: 0.7669 | f-acore: 0.7633\n",
            "Test:  loss: 0.8173 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.9411 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00295\n",
            "Train: loss: 0.4802 | accuracy: 0.7656 | f-acore: 0.7616\n",
            "Test:  loss: 0.7855 | accuracy: 0.4438 | f1: 0.4418\n",
            "Validation:  loss: 0.9638 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00296\n",
            "Train: loss: 0.4828 | accuracy: 0.7743 | f-acore: 0.7711\n",
            "Test:  loss: 0.7982 | accuracy: 0.4411 | f1: 0.4396\n",
            "Validation:  loss: 0.9444 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00297\n",
            "Train: loss: 0.4808 | accuracy: 0.7523 | f-acore: 0.7481\n",
            "Test:  loss: 0.7893 | accuracy: 0.4301 | f1: 0.4270\n",
            "Validation:  loss: 0.9424 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00298\n",
            "Train: loss: 0.4845 | accuracy: 0.7674 | f-acore: 0.7635\n",
            "Test:  loss: 0.8140 | accuracy: 0.4466 | f1: 0.4440\n",
            "Validation:  loss: 0.9583 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00299\n",
            "Train: loss: 0.4990 | accuracy: 0.7715 | f-acore: 0.7691\n",
            "Test:  loss: 0.8134 | accuracy: 0.4438 | f1: 0.4418\n",
            "Validation:  loss: 0.9718 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00300\n",
            "Train: loss: 0.4773 | accuracy: 0.7523 | f-acore: 0.7481\n",
            "Test:  loss: 0.7982 | accuracy: 0.4575 | f1: 0.4550\n",
            "Validation:  loss: 0.9382 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00301\n",
            "Train: loss: 0.4769 | accuracy: 0.7701 | f-acore: 0.7664\n",
            "Test:  loss: 0.8123 | accuracy: 0.4384 | f1: 0.4363\n",
            "Validation:  loss: 0.9424 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00302\n",
            "Train: loss: 0.4813 | accuracy: 0.7761 | f-acore: 0.7725\n",
            "Test:  loss: 0.8040 | accuracy: 0.4384 | f1: 0.4345\n",
            "Validation:  loss: 0.9533 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00303\n",
            "Train: loss: 0.4791 | accuracy: 0.7642 | f-acore: 0.7621\n",
            "Test:  loss: 0.7821 | accuracy: 0.4548 | f1: 0.4482\n",
            "Validation:  loss: 0.9800 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00304\n",
            "Train: loss: 0.4595 | accuracy: 0.7715 | f-acore: 0.7685\n",
            "Test:  loss: 0.8336 | accuracy: 0.4630 | f1: 0.4580\n",
            "Validation:  loss: 0.9317 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00305\n",
            "Train: loss: 0.4658 | accuracy: 0.7747 | f-acore: 0.7709\n",
            "Test:  loss: 0.8056 | accuracy: 0.4438 | f1: 0.4395\n",
            "Validation:  loss: 0.9707 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00306\n",
            "Train: loss: 0.4557 | accuracy: 0.7706 | f-acore: 0.7672\n",
            "Test:  loss: 0.8293 | accuracy: 0.4521 | f1: 0.4486\n",
            "Validation:  loss: 0.9697 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00307\n",
            "Train: loss: 0.4564 | accuracy: 0.7752 | f-acore: 0.7717\n",
            "Test:  loss: 0.8164 | accuracy: 0.4630 | f1: 0.4591\n",
            "Validation:  loss: 0.9640 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00308\n",
            "Train: loss: 0.4768 | accuracy: 0.7683 | f-acore: 0.7658\n",
            "Test:  loss: 0.8186 | accuracy: 0.4658 | f1: 0.4626\n",
            "Validation:  loss: 0.9327 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00309\n",
            "Train: loss: 0.4854 | accuracy: 0.7697 | f-acore: 0.7658\n",
            "Test:  loss: 0.8198 | accuracy: 0.4548 | f1: 0.4528\n",
            "Validation:  loss: 0.9416 | accuracy: 0.5802 | f1: 0.5724\n",
            "Epoch 00310\n",
            "Train: loss: 0.4636 | accuracy: 0.7596 | f-acore: 0.7571\n",
            "Test:  loss: 0.8225 | accuracy: 0.4219 | f1: 0.4208\n",
            "Validation:  loss: 0.9881 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00311\n",
            "Train: loss: 0.4876 | accuracy: 0.7761 | f-acore: 0.7739\n",
            "Test:  loss: 0.8158 | accuracy: 0.4603 | f1: 0.4583\n",
            "Validation:  loss: 0.9750 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00312\n",
            "Train: loss: 0.4761 | accuracy: 0.7697 | f-acore: 0.7667\n",
            "Test:  loss: 0.8441 | accuracy: 0.4740 | f1: 0.4731\n",
            "Validation:  loss: 0.9670 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00313\n",
            "Train: loss: 0.4710 | accuracy: 0.7701 | f-acore: 0.7676\n",
            "Test:  loss: 0.8263 | accuracy: 0.4795 | f1: 0.4774\n",
            "Validation:  loss: 0.9665 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00314\n",
            "Train: loss: 0.4586 | accuracy: 0.7770 | f-acore: 0.7756\n",
            "Test:  loss: 0.8220 | accuracy: 0.4658 | f1: 0.4630\n",
            "Validation:  loss: 0.9694 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00315\n",
            "Train: loss: 0.4739 | accuracy: 0.7756 | f-acore: 0.7724\n",
            "Test:  loss: 0.8361 | accuracy: 0.4603 | f1: 0.4583\n",
            "Validation:  loss: 0.9415 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00316\n",
            "Train: loss: 0.4818 | accuracy: 0.7683 | f-acore: 0.7664\n",
            "Test:  loss: 0.8200 | accuracy: 0.4356 | f1: 0.4337\n",
            "Validation:  loss: 0.9481 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00317\n",
            "Train: loss: 0.4755 | accuracy: 0.7706 | f-acore: 0.7687\n",
            "Test:  loss: 0.8257 | accuracy: 0.4438 | f1: 0.4418\n",
            "Validation:  loss: 0.9610 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00318\n",
            "Train: loss: 0.4795 | accuracy: 0.7761 | f-acore: 0.7723\n",
            "Test:  loss: 0.8535 | accuracy: 0.4493 | f1: 0.4456\n",
            "Validation:  loss: 0.9497 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00319\n",
            "Train: loss: 0.4815 | accuracy: 0.7798 | f-acore: 0.7770\n",
            "Test:  loss: 0.8417 | accuracy: 0.4493 | f1: 0.4456\n",
            "Validation:  loss: 0.9557 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00320\n",
            "Train: loss: 0.4617 | accuracy: 0.7770 | f-acore: 0.7733\n",
            "Test:  loss: 0.8309 | accuracy: 0.4630 | f1: 0.4574\n",
            "Validation:  loss: 0.9652 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00321\n",
            "Train: loss: 0.4656 | accuracy: 0.7788 | f-acore: 0.7758\n",
            "Test:  loss: 0.8285 | accuracy: 0.4712 | f1: 0.4676\n",
            "Validation:  loss: 0.9369 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00322\n",
            "Train: loss: 0.4699 | accuracy: 0.7642 | f-acore: 0.7616\n",
            "Test:  loss: 0.8319 | accuracy: 0.4466 | f1: 0.4459\n",
            "Validation:  loss: 0.9505 | accuracy: 0.5802 | f1: 0.5786\n",
            "Epoch 00323\n",
            "Train: loss: 0.4706 | accuracy: 0.7734 | f-acore: 0.7704\n",
            "Test:  loss: 0.8322 | accuracy: 0.4411 | f1: 0.4396\n",
            "Validation:  loss: 0.9563 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00324\n",
            "Train: loss: 0.4741 | accuracy: 0.7743 | f-acore: 0.7701\n",
            "Test:  loss: 0.8345 | accuracy: 0.4712 | f1: 0.4685\n",
            "Validation:  loss: 0.9704 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00325\n",
            "Train: loss: 0.4902 | accuracy: 0.7848 | f-acore: 0.7822\n",
            "Test:  loss: 0.8058 | accuracy: 0.4384 | f1: 0.4367\n",
            "Validation:  loss: 0.9970 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00326\n",
            "Train: loss: 0.4731 | accuracy: 0.7743 | f-acore: 0.7717\n",
            "Test:  loss: 0.8197 | accuracy: 0.4548 | f1: 0.4524\n",
            "Validation:  loss: 0.9466 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00327\n",
            "Train: loss: 0.4628 | accuracy: 0.7715 | f-acore: 0.7673\n",
            "Test:  loss: 0.8201 | accuracy: 0.4712 | f1: 0.4696\n",
            "Validation:  loss: 0.9778 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00328\n",
            "Train: loss: 0.4813 | accuracy: 0.7706 | f-acore: 0.7669\n",
            "Test:  loss: 0.8248 | accuracy: 0.4603 | f1: 0.4595\n",
            "Validation:  loss: 0.9835 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00329\n",
            "Train: loss: 0.4585 | accuracy: 0.7825 | f-acore: 0.7794\n",
            "Test:  loss: 0.8371 | accuracy: 0.4658 | f1: 0.4656\n",
            "Validation:  loss: 0.9905 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00330\n",
            "Train: loss: 0.4591 | accuracy: 0.7724 | f-acore: 0.7689\n",
            "Test:  loss: 0.8272 | accuracy: 0.4493 | f1: 0.4485\n",
            "Validation:  loss: 1.0148 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00331\n",
            "Train: loss: 0.4734 | accuracy: 0.7779 | f-acore: 0.7755\n",
            "Test:  loss: 0.8247 | accuracy: 0.4767 | f1: 0.4751\n",
            "Validation:  loss: 0.9786 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00332\n",
            "Train: loss: 0.4579 | accuracy: 0.7729 | f-acore: 0.7682\n",
            "Test:  loss: 0.8239 | accuracy: 0.4548 | f1: 0.4532\n",
            "Validation:  loss: 0.9822 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00333\n",
            "Train: loss: 0.4582 | accuracy: 0.7940 | f-acore: 0.7909\n",
            "Test:  loss: 0.8344 | accuracy: 0.4603 | f1: 0.4597\n",
            "Validation:  loss: 0.9966 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00334\n",
            "Train: loss: 0.4603 | accuracy: 0.7811 | f-acore: 0.7775\n",
            "Test:  loss: 0.8423 | accuracy: 0.4575 | f1: 0.4561\n",
            "Validation:  loss: 0.9988 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00335\n",
            "Train: loss: 0.4451 | accuracy: 0.7816 | f-acore: 0.7782\n",
            "Test:  loss: 0.8372 | accuracy: 0.4575 | f1: 0.4566\n",
            "Validation:  loss: 1.0147 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00336\n",
            "Train: loss: 0.4554 | accuracy: 0.7853 | f-acore: 0.7819\n",
            "Test:  loss: 0.8556 | accuracy: 0.4603 | f1: 0.4592\n",
            "Validation:  loss: 0.9927 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00337\n",
            "Train: loss: 0.4512 | accuracy: 0.7839 | f-acore: 0.7812\n",
            "Test:  loss: 0.8465 | accuracy: 0.4603 | f1: 0.4597\n",
            "Validation:  loss: 1.0035 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00338\n",
            "Train: loss: 0.4758 | accuracy: 0.7779 | f-acore: 0.7741\n",
            "Test:  loss: 0.8437 | accuracy: 0.4575 | f1: 0.4568\n",
            "Validation:  loss: 1.0126 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00339\n",
            "Train: loss: 0.4676 | accuracy: 0.7692 | f-acore: 0.7657\n",
            "Test:  loss: 0.8374 | accuracy: 0.4630 | f1: 0.4609\n",
            "Validation:  loss: 1.0083 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00340\n",
            "Train: loss: 0.4503 | accuracy: 0.7743 | f-acore: 0.7711\n",
            "Test:  loss: 0.8450 | accuracy: 0.4685 | f1: 0.4670\n",
            "Validation:  loss: 1.0043 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00341\n",
            "Train: loss: 0.4470 | accuracy: 0.7784 | f-acore: 0.7752\n",
            "Test:  loss: 0.8272 | accuracy: 0.4384 | f1: 0.4370\n",
            "Validation:  loss: 1.0192 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00342\n",
            "Train: loss: 0.4757 | accuracy: 0.7665 | f-acore: 0.7634\n",
            "Test:  loss: 0.8271 | accuracy: 0.4630 | f1: 0.4596\n",
            "Validation:  loss: 0.9823 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00343\n",
            "Train: loss: 0.4392 | accuracy: 0.7853 | f-acore: 0.7832\n",
            "Test:  loss: 0.8291 | accuracy: 0.4548 | f1: 0.4520\n",
            "Validation:  loss: 0.9787 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00344\n",
            "Train: loss: 0.4486 | accuracy: 0.7926 | f-acore: 0.7890\n",
            "Test:  loss: 0.8301 | accuracy: 0.4685 | f1: 0.4660\n",
            "Validation:  loss: 0.9758 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00345\n",
            "Train: loss: 0.4502 | accuracy: 0.7779 | f-acore: 0.7742\n",
            "Test:  loss: 0.8403 | accuracy: 0.4575 | f1: 0.4561\n",
            "Validation:  loss: 0.9925 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00346\n",
            "Train: loss: 0.4613 | accuracy: 0.7756 | f-acore: 0.7728\n",
            "Test:  loss: 0.8485 | accuracy: 0.4548 | f1: 0.4528\n",
            "Validation:  loss: 1.0016 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00347\n",
            "Train: loss: 0.4402 | accuracy: 0.7949 | f-acore: 0.7924\n",
            "Test:  loss: 0.8216 | accuracy: 0.4548 | f1: 0.4537\n",
            "Validation:  loss: 1.0062 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00348\n",
            "Train: loss: 0.4598 | accuracy: 0.7834 | f-acore: 0.7807\n",
            "Test:  loss: 0.8463 | accuracy: 0.4603 | f1: 0.4583\n",
            "Validation:  loss: 0.9997 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00349\n",
            "Train: loss: 0.4615 | accuracy: 0.7825 | f-acore: 0.7793\n",
            "Test:  loss: 0.8393 | accuracy: 0.4685 | f1: 0.4670\n",
            "Validation:  loss: 0.9939 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00350\n",
            "Train: loss: 0.4510 | accuracy: 0.7816 | f-acore: 0.7779\n",
            "Test:  loss: 0.8431 | accuracy: 0.4658 | f1: 0.4645\n",
            "Validation:  loss: 0.9720 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00351\n",
            "Train: loss: 0.4714 | accuracy: 0.7784 | f-acore: 0.7755\n",
            "Test:  loss: 0.8153 | accuracy: 0.4685 | f1: 0.4664\n",
            "Validation:  loss: 0.9960 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00352\n",
            "Train: loss: 0.4524 | accuracy: 0.7802 | f-acore: 0.7772\n",
            "Test:  loss: 0.8125 | accuracy: 0.4712 | f1: 0.4705\n",
            "Validation:  loss: 1.0159 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00353\n",
            "Train: loss: 0.4593 | accuracy: 0.7903 | f-acore: 0.7875\n",
            "Test:  loss: 0.8339 | accuracy: 0.4493 | f1: 0.4485\n",
            "Validation:  loss: 1.0175 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00354\n",
            "Train: loss: 0.4582 | accuracy: 0.7839 | f-acore: 0.7814\n",
            "Test:  loss: 0.8339 | accuracy: 0.4685 | f1: 0.4680\n",
            "Validation:  loss: 1.0201 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00355\n",
            "Train: loss: 0.4543 | accuracy: 0.7866 | f-acore: 0.7838\n",
            "Test:  loss: 0.8388 | accuracy: 0.4740 | f1: 0.4725\n",
            "Validation:  loss: 1.0107 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00356\n",
            "Train: loss: 0.4561 | accuracy: 0.7880 | f-acore: 0.7852\n",
            "Test:  loss: 0.8685 | accuracy: 0.4685 | f1: 0.4676\n",
            "Validation:  loss: 1.0254 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00357\n",
            "Train: loss: 0.4488 | accuracy: 0.7807 | f-acore: 0.7782\n",
            "Test:  loss: 0.8254 | accuracy: 0.4877 | f1: 0.4851\n",
            "Validation:  loss: 1.0358 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00358\n",
            "Train: loss: 0.4636 | accuracy: 0.7697 | f-acore: 0.7662\n",
            "Test:  loss: 0.8608 | accuracy: 0.4603 | f1: 0.4590\n",
            "Validation:  loss: 1.0331 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00359\n",
            "Train: loss: 0.4560 | accuracy: 0.7830 | f-acore: 0.7799\n",
            "Test:  loss: 0.8723 | accuracy: 0.4712 | f1: 0.4699\n",
            "Validation:  loss: 1.0003 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00360\n",
            "Train: loss: 0.4460 | accuracy: 0.7798 | f-acore: 0.7772\n",
            "Test:  loss: 0.8505 | accuracy: 0.4521 | f1: 0.4506\n",
            "Validation:  loss: 1.0166 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00361\n",
            "Train: loss: 0.4297 | accuracy: 0.7875 | f-acore: 0.7841\n",
            "Test:  loss: 0.8467 | accuracy: 0.4712 | f1: 0.4699\n",
            "Validation:  loss: 1.0201 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00362\n",
            "Train: loss: 0.4483 | accuracy: 0.7839 | f-acore: 0.7813\n",
            "Test:  loss: 0.8533 | accuracy: 0.4740 | f1: 0.4719\n",
            "Validation:  loss: 1.0341 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00363\n",
            "Train: loss: 0.4748 | accuracy: 0.7848 | f-acore: 0.7815\n",
            "Test:  loss: 0.8169 | accuracy: 0.4438 | f1: 0.4432\n",
            "Validation:  loss: 1.0158 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00364\n",
            "Train: loss: 0.4457 | accuracy: 0.7853 | f-acore: 0.7812\n",
            "Test:  loss: 0.8239 | accuracy: 0.4466 | f1: 0.4459\n",
            "Validation:  loss: 0.9882 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00365\n",
            "Train: loss: 0.4520 | accuracy: 0.7908 | f-acore: 0.7883\n",
            "Test:  loss: 0.8593 | accuracy: 0.4740 | f1: 0.4715\n",
            "Validation:  loss: 1.0276 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00366\n",
            "Train: loss: 0.4597 | accuracy: 0.7674 | f-acore: 0.7638\n",
            "Test:  loss: 0.8221 | accuracy: 0.4630 | f1: 0.4616\n",
            "Validation:  loss: 1.0017 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00367\n",
            "Train: loss: 0.4724 | accuracy: 0.7775 | f-acore: 0.7752\n",
            "Test:  loss: 0.8043 | accuracy: 0.4685 | f1: 0.4673\n",
            "Validation:  loss: 1.0237 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00368\n",
            "Train: loss: 0.4596 | accuracy: 0.7880 | f-acore: 0.7846\n",
            "Test:  loss: 0.8316 | accuracy: 0.4658 | f1: 0.4638\n",
            "Validation:  loss: 1.0174 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00369\n",
            "Train: loss: 0.4467 | accuracy: 0.7880 | f-acore: 0.7843\n",
            "Test:  loss: 0.8192 | accuracy: 0.4740 | f1: 0.4715\n",
            "Validation:  loss: 1.0642 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00370\n",
            "Train: loss: 0.4607 | accuracy: 0.7752 | f-acore: 0.7733\n",
            "Test:  loss: 0.8242 | accuracy: 0.4575 | f1: 0.4566\n",
            "Validation:  loss: 1.0438 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00371\n",
            "Train: loss: 0.4420 | accuracy: 0.7976 | f-acore: 0.7954\n",
            "Test:  loss: 0.8394 | accuracy: 0.4849 | f1: 0.4825\n",
            "Validation:  loss: 1.0323 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00372\n",
            "Train: loss: 0.4486 | accuracy: 0.7875 | f-acore: 0.7849\n",
            "Test:  loss: 0.8338 | accuracy: 0.4795 | f1: 0.4761\n",
            "Validation:  loss: 1.0219 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00373\n",
            "Train: loss: 0.4388 | accuracy: 0.7811 | f-acore: 0.7781\n",
            "Test:  loss: 0.8487 | accuracy: 0.4548 | f1: 0.4535\n",
            "Validation:  loss: 1.0236 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00374\n",
            "Train: loss: 0.4491 | accuracy: 0.7871 | f-acore: 0.7845\n",
            "Test:  loss: 0.8534 | accuracy: 0.4658 | f1: 0.4650\n",
            "Validation:  loss: 1.0381 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00375\n",
            "Train: loss: 0.4598 | accuracy: 0.7875 | f-acore: 0.7846\n",
            "Test:  loss: 0.8369 | accuracy: 0.4521 | f1: 0.4495\n",
            "Validation:  loss: 1.0157 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00376\n",
            "Train: loss: 0.4575 | accuracy: 0.7788 | f-acore: 0.7750\n",
            "Test:  loss: 0.8617 | accuracy: 0.4795 | f1: 0.4757\n",
            "Validation:  loss: 1.0341 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00377\n",
            "Train: loss: 0.4435 | accuracy: 0.7862 | f-acore: 0.7831\n",
            "Test:  loss: 0.8280 | accuracy: 0.4740 | f1: 0.4722\n",
            "Validation:  loss: 1.0299 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00378\n",
            "Train: loss: 0.4442 | accuracy: 0.7843 | f-acore: 0.7809\n",
            "Test:  loss: 0.8457 | accuracy: 0.4630 | f1: 0.4621\n",
            "Validation:  loss: 1.0375 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00379\n",
            "Train: loss: 0.4591 | accuracy: 0.7853 | f-acore: 0.7817\n",
            "Test:  loss: 0.8363 | accuracy: 0.4712 | f1: 0.4705\n",
            "Validation:  loss: 1.0014 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00380\n",
            "Train: loss: 0.4583 | accuracy: 0.7706 | f-acore: 0.7690\n",
            "Test:  loss: 0.8339 | accuracy: 0.4712 | f1: 0.4708\n",
            "Validation:  loss: 1.0032 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00381\n",
            "Train: loss: 0.4435 | accuracy: 0.7715 | f-acore: 0.7676\n",
            "Test:  loss: 0.8250 | accuracy: 0.4712 | f1: 0.4702\n",
            "Validation:  loss: 1.0110 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00382\n",
            "Train: loss: 0.4282 | accuracy: 0.7917 | f-acore: 0.7896\n",
            "Test:  loss: 0.8313 | accuracy: 0.4685 | f1: 0.4673\n",
            "Validation:  loss: 1.0412 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00383\n",
            "Train: loss: 0.4330 | accuracy: 0.7843 | f-acore: 0.7816\n",
            "Test:  loss: 0.8523 | accuracy: 0.4658 | f1: 0.4647\n",
            "Validation:  loss: 1.0333 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00384\n",
            "Train: loss: 0.4552 | accuracy: 0.7862 | f-acore: 0.7826\n",
            "Test:  loss: 0.8302 | accuracy: 0.4822 | f1: 0.4806\n",
            "Validation:  loss: 1.0351 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00385\n",
            "Train: loss: 0.4674 | accuracy: 0.7857 | f-acore: 0.7831\n",
            "Test:  loss: 0.8262 | accuracy: 0.4603 | f1: 0.4599\n",
            "Validation:  loss: 1.0711 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00386\n",
            "Train: loss: 0.4406 | accuracy: 0.7917 | f-acore: 0.7904\n",
            "Test:  loss: 0.8330 | accuracy: 0.4603 | f1: 0.4599\n",
            "Validation:  loss: 1.0471 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00387\n",
            "Train: loss: 0.4523 | accuracy: 0.7958 | f-acore: 0.7928\n",
            "Test:  loss: 0.8253 | accuracy: 0.4712 | f1: 0.4710\n",
            "Validation:  loss: 1.0640 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00388\n",
            "Train: loss: 0.4526 | accuracy: 0.8013 | f-acore: 0.7988\n",
            "Test:  loss: 0.8392 | accuracy: 0.4603 | f1: 0.4592\n",
            "Validation:  loss: 1.0405 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00389\n",
            "Train: loss: 0.4663 | accuracy: 0.7798 | f-acore: 0.7755\n",
            "Test:  loss: 0.8268 | accuracy: 0.4630 | f1: 0.4616\n",
            "Validation:  loss: 1.0379 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00390\n",
            "Train: loss: 0.4468 | accuracy: 0.7802 | f-acore: 0.7761\n",
            "Test:  loss: 0.8189 | accuracy: 0.4521 | f1: 0.4509\n",
            "Validation:  loss: 1.1011 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00391\n",
            "Train: loss: 0.4457 | accuracy: 0.7930 | f-acore: 0.7898\n",
            "Test:  loss: 0.8405 | accuracy: 0.4712 | f1: 0.4712\n",
            "Validation:  loss: 1.0913 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00392\n",
            "Train: loss: 0.4633 | accuracy: 0.7784 | f-acore: 0.7755\n",
            "Test:  loss: 0.8404 | accuracy: 0.4685 | f1: 0.4684\n",
            "Validation:  loss: 1.0527 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00393\n",
            "Train: loss: 0.4603 | accuracy: 0.7871 | f-acore: 0.7844\n",
            "Test:  loss: 0.8131 | accuracy: 0.4521 | f1: 0.4514\n",
            "Validation:  loss: 1.0778 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00394\n",
            "Train: loss: 0.4526 | accuracy: 0.7944 | f-acore: 0.7904\n",
            "Test:  loss: 0.8058 | accuracy: 0.4795 | f1: 0.4791\n",
            "Validation:  loss: 1.0821 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00395\n",
            "Train: loss: 0.4447 | accuracy: 0.7839 | f-acore: 0.7815\n",
            "Test:  loss: 0.8090 | accuracy: 0.4548 | f1: 0.4544\n",
            "Validation:  loss: 1.0574 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00396\n",
            "Train: loss: 0.4349 | accuracy: 0.7958 | f-acore: 0.7923\n",
            "Test:  loss: 0.7925 | accuracy: 0.4630 | f1: 0.4616\n",
            "Validation:  loss: 1.0541 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00397\n",
            "Train: loss: 0.4542 | accuracy: 0.7784 | f-acore: 0.7746\n",
            "Test:  loss: 0.8010 | accuracy: 0.4658 | f1: 0.4650\n",
            "Validation:  loss: 1.0645 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00398\n",
            "Train: loss: 0.4338 | accuracy: 0.7775 | f-acore: 0.7747\n",
            "Test:  loss: 0.8010 | accuracy: 0.4795 | f1: 0.4791\n",
            "Validation:  loss: 1.0564 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00399\n",
            "Train: loss: 0.4455 | accuracy: 0.8022 | f-acore: 0.7992\n",
            "Test:  loss: 0.8266 | accuracy: 0.4795 | f1: 0.4786\n",
            "Validation:  loss: 1.0459 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00400\n",
            "Train: loss: 0.4259 | accuracy: 0.7940 | f-acore: 0.7915\n",
            "Test:  loss: 0.8226 | accuracy: 0.4877 | f1: 0.4869\n",
            "Validation:  loss: 1.0616 | accuracy: 0.5309 | f1: 0.5250\n",
            "-----------------------------------------------------------------------------------------\n",
            "^IXIC\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6934 | accuracy: 0.4826 | f-acore: 0.4609\n",
            "Test:  loss: 0.6916 | accuracy: 0.5288 | f1: 0.4345\n",
            "Validation:  loss: 0.6934 | accuracy: 0.4815 | f1: 0.4052\n",
            "Epoch 00002\n",
            "Train: loss: 0.6903 | accuracy: 0.5462 | f-acore: 0.4256\n",
            "Test:  loss: 0.6845 | accuracy: 0.5863 | f1: 0.3696\n",
            "Validation:  loss: 0.6957 | accuracy: 0.4938 | f1: 0.3306\n",
            "Epoch 00003\n",
            "Train: loss: 0.6896 | accuracy: 0.5476 | f-acore: 0.3766\n",
            "Test:  loss: 0.6851 | accuracy: 0.5753 | f1: 0.3711\n",
            "Validation:  loss: 0.6985 | accuracy: 0.4938 | f1: 0.3306\n",
            "Epoch 00004\n",
            "Train: loss: 0.6911 | accuracy: 0.5472 | f-acore: 0.3820\n",
            "Test:  loss: 0.6852 | accuracy: 0.5781 | f1: 0.3780\n",
            "Validation:  loss: 0.6969 | accuracy: 0.4938 | f1: 0.3692\n",
            "Epoch 00005\n",
            "Train: loss: 0.6861 | accuracy: 0.5495 | f-acore: 0.4475\n",
            "Test:  loss: 0.6892 | accuracy: 0.5616 | f1: 0.3815\n",
            "Validation:  loss: 0.6951 | accuracy: 0.4938 | f1: 0.4002\n",
            "Epoch 00006\n",
            "Train: loss: 0.6849 | accuracy: 0.5462 | f-acore: 0.4412\n",
            "Test:  loss: 0.6899 | accuracy: 0.5452 | f1: 0.4095\n",
            "Validation:  loss: 0.6980 | accuracy: 0.4938 | f1: 0.4002\n",
            "Epoch 00007\n",
            "Train: loss: 0.6840 | accuracy: 0.5481 | f-acore: 0.4434\n",
            "Test:  loss: 0.6937 | accuracy: 0.5370 | f1: 0.4571\n",
            "Validation:  loss: 0.6991 | accuracy: 0.5062 | f1: 0.4214\n",
            "Epoch 00008\n",
            "Train: loss: 0.6855 | accuracy: 0.5531 | f-acore: 0.4632\n",
            "Test:  loss: 0.6925 | accuracy: 0.5288 | f1: 0.4515\n",
            "Validation:  loss: 0.6966 | accuracy: 0.5062 | f1: 0.4214\n",
            "Epoch 00009\n",
            "Train: loss: 0.6845 | accuracy: 0.5600 | f-acore: 0.4648\n",
            "Test:  loss: 0.6913 | accuracy: 0.5452 | f1: 0.4572\n",
            "Validation:  loss: 0.6975 | accuracy: 0.5185 | f1: 0.4295\n",
            "Epoch 00010\n",
            "Train: loss: 0.6815 | accuracy: 0.5527 | f-acore: 0.4507\n",
            "Test:  loss: 0.6985 | accuracy: 0.5205 | f1: 0.4646\n",
            "Validation:  loss: 0.7029 | accuracy: 0.4938 | f1: 0.4134\n",
            "Epoch 00011\n",
            "Train: loss: 0.6845 | accuracy: 0.5513 | f-acore: 0.4519\n",
            "Test:  loss: 0.6941 | accuracy: 0.5315 | f1: 0.4480\n",
            "Validation:  loss: 0.7025 | accuracy: 0.5062 | f1: 0.4214\n",
            "Epoch 00012\n",
            "Train: loss: 0.6827 | accuracy: 0.5614 | f-acore: 0.4877\n",
            "Test:  loss: 0.6954 | accuracy: 0.5096 | f1: 0.4822\n",
            "Validation:  loss: 0.6999 | accuracy: 0.4938 | f1: 0.4134\n",
            "Epoch 00013\n",
            "Train: loss: 0.6830 | accuracy: 0.5682 | f-acore: 0.5030\n",
            "Test:  loss: 0.7054 | accuracy: 0.5041 | f1: 0.4639\n",
            "Validation:  loss: 0.7074 | accuracy: 0.4815 | f1: 0.4052\n",
            "Epoch 00014\n",
            "Train: loss: 0.6815 | accuracy: 0.5733 | f-acore: 0.5148\n",
            "Test:  loss: 0.6967 | accuracy: 0.4849 | f1: 0.4730\n",
            "Validation:  loss: 0.7013 | accuracy: 0.5062 | f1: 0.4886\n",
            "Epoch 00015\n",
            "Train: loss: 0.6811 | accuracy: 0.5783 | f-acore: 0.5172\n",
            "Test:  loss: 0.6990 | accuracy: 0.4658 | f1: 0.4621\n",
            "Validation:  loss: 0.7061 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00016\n",
            "Train: loss: 0.6827 | accuracy: 0.5646 | f-acore: 0.5402\n",
            "Test:  loss: 0.7006 | accuracy: 0.4767 | f1: 0.4489\n",
            "Validation:  loss: 0.7113 | accuracy: 0.4691 | f1: 0.4416\n",
            "Epoch 00017\n",
            "Train: loss: 0.6775 | accuracy: 0.5609 | f-acore: 0.4774\n",
            "Test:  loss: 0.6861 | accuracy: 0.5370 | f1: 0.4429\n",
            "Validation:  loss: 0.7099 | accuracy: 0.4938 | f1: 0.4451\n",
            "Epoch 00018\n",
            "Train: loss: 0.6723 | accuracy: 0.5701 | f-acore: 0.5066\n",
            "Test:  loss: 0.6961 | accuracy: 0.5014 | f1: 0.4982\n",
            "Validation:  loss: 0.7151 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00019\n",
            "Train: loss: 0.6770 | accuracy: 0.5531 | f-acore: 0.5224\n",
            "Test:  loss: 0.6979 | accuracy: 0.5123 | f1: 0.5083\n",
            "Validation:  loss: 0.7079 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00020\n",
            "Train: loss: 0.6738 | accuracy: 0.5696 | f-acore: 0.5103\n",
            "Test:  loss: 0.6978 | accuracy: 0.5041 | f1: 0.4526\n",
            "Validation:  loss: 0.7216 | accuracy: 0.5185 | f1: 0.4802\n",
            "Epoch 00021\n",
            "Train: loss: 0.6734 | accuracy: 0.5742 | f-acore: 0.5007\n",
            "Test:  loss: 0.6946 | accuracy: 0.5068 | f1: 0.4897\n",
            "Validation:  loss: 0.7089 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00022\n",
            "Train: loss: 0.6704 | accuracy: 0.5842 | f-acore: 0.5447\n",
            "Test:  loss: 0.7008 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 0.7189 | accuracy: 0.4691 | f1: 0.4572\n",
            "Epoch 00023\n",
            "Train: loss: 0.6779 | accuracy: 0.5788 | f-acore: 0.5405\n",
            "Test:  loss: 0.7030 | accuracy: 0.4877 | f1: 0.4874\n",
            "Validation:  loss: 0.7132 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00024\n",
            "Train: loss: 0.6742 | accuracy: 0.5769 | f-acore: 0.5582\n",
            "Test:  loss: 0.7017 | accuracy: 0.4877 | f1: 0.4724\n",
            "Validation:  loss: 0.7172 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00025\n",
            "Train: loss: 0.6715 | accuracy: 0.5856 | f-acore: 0.5216\n",
            "Test:  loss: 0.6940 | accuracy: 0.5123 | f1: 0.5026\n",
            "Validation:  loss: 0.7107 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00026\n",
            "Train: loss: 0.6662 | accuracy: 0.5856 | f-acore: 0.5484\n",
            "Test:  loss: 0.7020 | accuracy: 0.4767 | f1: 0.4767\n",
            "Validation:  loss: 0.7153 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00027\n",
            "Train: loss: 0.6623 | accuracy: 0.5810 | f-acore: 0.5539\n",
            "Test:  loss: 0.7052 | accuracy: 0.4904 | f1: 0.4903\n",
            "Validation:  loss: 0.7293 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00028\n",
            "Train: loss: 0.6734 | accuracy: 0.5856 | f-acore: 0.5658\n",
            "Test:  loss: 0.6972 | accuracy: 0.5096 | f1: 0.5058\n",
            "Validation:  loss: 0.7201 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00029\n",
            "Train: loss: 0.6675 | accuracy: 0.6049 | f-acore: 0.5784\n",
            "Test:  loss: 0.6969 | accuracy: 0.5315 | f1: 0.5287\n",
            "Validation:  loss: 0.7182 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00030\n",
            "Train: loss: 0.6616 | accuracy: 0.6058 | f-acore: 0.5855\n",
            "Test:  loss: 0.7040 | accuracy: 0.5068 | f1: 0.5060\n",
            "Validation:  loss: 0.7218 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00031\n",
            "Train: loss: 0.6580 | accuracy: 0.6049 | f-acore: 0.5887\n",
            "Test:  loss: 0.6950 | accuracy: 0.5260 | f1: 0.4686\n",
            "Validation:  loss: 0.7221 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00032\n",
            "Train: loss: 0.6595 | accuracy: 0.6067 | f-acore: 0.5843\n",
            "Test:  loss: 0.6928 | accuracy: 0.5452 | f1: 0.4989\n",
            "Validation:  loss: 0.7275 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00033\n",
            "Train: loss: 0.6525 | accuracy: 0.6113 | f-acore: 0.5897\n",
            "Test:  loss: 0.7029 | accuracy: 0.5205 | f1: 0.4880\n",
            "Validation:  loss: 0.7387 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00034\n",
            "Train: loss: 0.6591 | accuracy: 0.6053 | f-acore: 0.5784\n",
            "Test:  loss: 0.7006 | accuracy: 0.5425 | f1: 0.5314\n",
            "Validation:  loss: 0.7293 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00035\n",
            "Train: loss: 0.6567 | accuracy: 0.6085 | f-acore: 0.5916\n",
            "Test:  loss: 0.7124 | accuracy: 0.5315 | f1: 0.5012\n",
            "Validation:  loss: 0.7431 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00036\n",
            "Train: loss: 0.6562 | accuracy: 0.6071 | f-acore: 0.5910\n",
            "Test:  loss: 0.6988 | accuracy: 0.5260 | f1: 0.4642\n",
            "Validation:  loss: 0.7317 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00037\n",
            "Train: loss: 0.6566 | accuracy: 0.6177 | f-acore: 0.5938\n",
            "Test:  loss: 0.7050 | accuracy: 0.5096 | f1: 0.4861\n",
            "Validation:  loss: 0.7349 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00038\n",
            "Train: loss: 0.6598 | accuracy: 0.6117 | f-acore: 0.5901\n",
            "Test:  loss: 0.7073 | accuracy: 0.4740 | f1: 0.4739\n",
            "Validation:  loss: 0.7175 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00039\n",
            "Train: loss: 0.6538 | accuracy: 0.6094 | f-acore: 0.5983\n",
            "Test:  loss: 0.7108 | accuracy: 0.5288 | f1: 0.5102\n",
            "Validation:  loss: 0.7379 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00040\n",
            "Train: loss: 0.6538 | accuracy: 0.6255 | f-acore: 0.6125\n",
            "Test:  loss: 0.7168 | accuracy: 0.4795 | f1: 0.4740\n",
            "Validation:  loss: 0.7446 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00041\n",
            "Train: loss: 0.6568 | accuracy: 0.6021 | f-acore: 0.5891\n",
            "Test:  loss: 0.7123 | accuracy: 0.5068 | f1: 0.4962\n",
            "Validation:  loss: 0.7333 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00042\n",
            "Train: loss: 0.6495 | accuracy: 0.6204 | f-acore: 0.6017\n",
            "Test:  loss: 0.6991 | accuracy: 0.5205 | f1: 0.4782\n",
            "Validation:  loss: 0.7350 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00043\n",
            "Train: loss: 0.6563 | accuracy: 0.6277 | f-acore: 0.6112\n",
            "Test:  loss: 0.7041 | accuracy: 0.5315 | f1: 0.4982\n",
            "Validation:  loss: 0.7359 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00044\n",
            "Train: loss: 0.6517 | accuracy: 0.6342 | f-acore: 0.6206\n",
            "Test:  loss: 0.7137 | accuracy: 0.4904 | f1: 0.4811\n",
            "Validation:  loss: 0.7285 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00045\n",
            "Train: loss: 0.6483 | accuracy: 0.6255 | f-acore: 0.6104\n",
            "Test:  loss: 0.7089 | accuracy: 0.4986 | f1: 0.4706\n",
            "Validation:  loss: 0.7262 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00046\n",
            "Train: loss: 0.6450 | accuracy: 0.6319 | f-acore: 0.6186\n",
            "Test:  loss: 0.7110 | accuracy: 0.5014 | f1: 0.4889\n",
            "Validation:  loss: 0.7316 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00047\n",
            "Train: loss: 0.6519 | accuracy: 0.6346 | f-acore: 0.6178\n",
            "Test:  loss: 0.7060 | accuracy: 0.5233 | f1: 0.5034\n",
            "Validation:  loss: 0.7325 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00048\n",
            "Train: loss: 0.6486 | accuracy: 0.6461 | f-acore: 0.6407\n",
            "Test:  loss: 0.7129 | accuracy: 0.4767 | f1: 0.4697\n",
            "Validation:  loss: 0.7373 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00049\n",
            "Train: loss: 0.6420 | accuracy: 0.6323 | f-acore: 0.6181\n",
            "Test:  loss: 0.7134 | accuracy: 0.4932 | f1: 0.4892\n",
            "Validation:  loss: 0.7344 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00050\n",
            "Train: loss: 0.6377 | accuracy: 0.6410 | f-acore: 0.6242\n",
            "Test:  loss: 0.7208 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 0.7458 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00051\n",
            "Train: loss: 0.6548 | accuracy: 0.6369 | f-acore: 0.6223\n",
            "Test:  loss: 0.7157 | accuracy: 0.5041 | f1: 0.4992\n",
            "Validation:  loss: 0.7402 | accuracy: 0.5556 | f1: 0.5539\n",
            "Epoch 00052\n",
            "Train: loss: 0.6499 | accuracy: 0.6488 | f-acore: 0.6406\n",
            "Test:  loss: 0.7233 | accuracy: 0.5014 | f1: 0.4930\n",
            "Validation:  loss: 0.7390 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00053\n",
            "Train: loss: 0.6420 | accuracy: 0.6351 | f-acore: 0.6256\n",
            "Test:  loss: 0.7214 | accuracy: 0.4822 | f1: 0.4731\n",
            "Validation:  loss: 0.7342 | accuracy: 0.5802 | f1: 0.5750\n",
            "Epoch 00054\n",
            "Train: loss: 0.6458 | accuracy: 0.6456 | f-acore: 0.6332\n",
            "Test:  loss: 0.7083 | accuracy: 0.5178 | f1: 0.5066\n",
            "Validation:  loss: 0.7342 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00055\n",
            "Train: loss: 0.6388 | accuracy: 0.6474 | f-acore: 0.6274\n",
            "Test:  loss: 0.7176 | accuracy: 0.4932 | f1: 0.4850\n",
            "Validation:  loss: 0.7284 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00056\n",
            "Train: loss: 0.6352 | accuracy: 0.6392 | f-acore: 0.6342\n",
            "Test:  loss: 0.7350 | accuracy: 0.4959 | f1: 0.4724\n",
            "Validation:  loss: 0.7447 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00057\n",
            "Train: loss: 0.6372 | accuracy: 0.6429 | f-acore: 0.6327\n",
            "Test:  loss: 0.7138 | accuracy: 0.5151 | f1: 0.5086\n",
            "Validation:  loss: 0.7365 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00058\n",
            "Train: loss: 0.6317 | accuracy: 0.6456 | f-acore: 0.6282\n",
            "Test:  loss: 0.7154 | accuracy: 0.4959 | f1: 0.4922\n",
            "Validation:  loss: 0.7383 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00059\n",
            "Train: loss: 0.6308 | accuracy: 0.6603 | f-acore: 0.6528\n",
            "Test:  loss: 0.7215 | accuracy: 0.4986 | f1: 0.4952\n",
            "Validation:  loss: 0.7521 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00060\n",
            "Train: loss: 0.6309 | accuracy: 0.6561 | f-acore: 0.6369\n",
            "Test:  loss: 0.7193 | accuracy: 0.4877 | f1: 0.4877\n",
            "Validation:  loss: 0.7447 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00061\n",
            "Train: loss: 0.6224 | accuracy: 0.6488 | f-acore: 0.6430\n",
            "Test:  loss: 0.7313 | accuracy: 0.4959 | f1: 0.4917\n",
            "Validation:  loss: 0.7577 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00062\n",
            "Train: loss: 0.6321 | accuracy: 0.6488 | f-acore: 0.6377\n",
            "Test:  loss: 0.7265 | accuracy: 0.4466 | f1: 0.4402\n",
            "Validation:  loss: 0.7434 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00063\n",
            "Train: loss: 0.6374 | accuracy: 0.6493 | f-acore: 0.6430\n",
            "Test:  loss: 0.7428 | accuracy: 0.4740 | f1: 0.4618\n",
            "Validation:  loss: 0.7673 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00064\n",
            "Train: loss: 0.6358 | accuracy: 0.6456 | f-acore: 0.6320\n",
            "Test:  loss: 0.7194 | accuracy: 0.4603 | f1: 0.4602\n",
            "Validation:  loss: 0.7381 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00065\n",
            "Train: loss: 0.6311 | accuracy: 0.6497 | f-acore: 0.6423\n",
            "Test:  loss: 0.7209 | accuracy: 0.4575 | f1: 0.4541\n",
            "Validation:  loss: 0.7367 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00066\n",
            "Train: loss: 0.6245 | accuracy: 0.6552 | f-acore: 0.6490\n",
            "Test:  loss: 0.7368 | accuracy: 0.4740 | f1: 0.4740\n",
            "Validation:  loss: 0.7503 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00067\n",
            "Train: loss: 0.6159 | accuracy: 0.6625 | f-acore: 0.6531\n",
            "Test:  loss: 0.7268 | accuracy: 0.4630 | f1: 0.4630\n",
            "Validation:  loss: 0.7545 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00068\n",
            "Train: loss: 0.6289 | accuracy: 0.6502 | f-acore: 0.6439\n",
            "Test:  loss: 0.7370 | accuracy: 0.4849 | f1: 0.4817\n",
            "Validation:  loss: 0.7535 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00069\n",
            "Train: loss: 0.6283 | accuracy: 0.6488 | f-acore: 0.6360\n",
            "Test:  loss: 0.7381 | accuracy: 0.4356 | f1: 0.4310\n",
            "Validation:  loss: 0.7388 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00070\n",
            "Train: loss: 0.6221 | accuracy: 0.6625 | f-acore: 0.6586\n",
            "Test:  loss: 0.7327 | accuracy: 0.4712 | f1: 0.4712\n",
            "Validation:  loss: 0.7617 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00071\n",
            "Train: loss: 0.6202 | accuracy: 0.6511 | f-acore: 0.6494\n",
            "Test:  loss: 0.7420 | accuracy: 0.4521 | f1: 0.4490\n",
            "Validation:  loss: 0.7689 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00072\n",
            "Train: loss: 0.6247 | accuracy: 0.6612 | f-acore: 0.6492\n",
            "Test:  loss: 0.7269 | accuracy: 0.4740 | f1: 0.4728\n",
            "Validation:  loss: 0.7655 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00073\n",
            "Train: loss: 0.6114 | accuracy: 0.6612 | f-acore: 0.6559\n",
            "Test:  loss: 0.7285 | accuracy: 0.4712 | f1: 0.4712\n",
            "Validation:  loss: 0.7648 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00074\n",
            "Train: loss: 0.6194 | accuracy: 0.6506 | f-acore: 0.6423\n",
            "Test:  loss: 0.7315 | accuracy: 0.4685 | f1: 0.4670\n",
            "Validation:  loss: 0.7751 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00075\n",
            "Train: loss: 0.6294 | accuracy: 0.6598 | f-acore: 0.6532\n",
            "Test:  loss: 0.7489 | accuracy: 0.4521 | f1: 0.4509\n",
            "Validation:  loss: 0.7693 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00076\n",
            "Train: loss: 0.6074 | accuracy: 0.6671 | f-acore: 0.6633\n",
            "Test:  loss: 0.7272 | accuracy: 0.5096 | f1: 0.4994\n",
            "Validation:  loss: 0.7649 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00077\n",
            "Train: loss: 0.6190 | accuracy: 0.6603 | f-acore: 0.6459\n",
            "Test:  loss: 0.7262 | accuracy: 0.4603 | f1: 0.4603\n",
            "Validation:  loss: 0.7530 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00078\n",
            "Train: loss: 0.6146 | accuracy: 0.6648 | f-acore: 0.6581\n",
            "Test:  loss: 0.7264 | accuracy: 0.4795 | f1: 0.4788\n",
            "Validation:  loss: 0.7638 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00079\n",
            "Train: loss: 0.6175 | accuracy: 0.6690 | f-acore: 0.6645\n",
            "Test:  loss: 0.7302 | accuracy: 0.4795 | f1: 0.4774\n",
            "Validation:  loss: 0.7610 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00080\n",
            "Train: loss: 0.6055 | accuracy: 0.6639 | f-acore: 0.6559\n",
            "Test:  loss: 0.7317 | accuracy: 0.4712 | f1: 0.4689\n",
            "Validation:  loss: 0.7711 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00081\n",
            "Train: loss: 0.6055 | accuracy: 0.6648 | f-acore: 0.6595\n",
            "Test:  loss: 0.7229 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.7743 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00082\n",
            "Train: loss: 0.6180 | accuracy: 0.6735 | f-acore: 0.6644\n",
            "Test:  loss: 0.7367 | accuracy: 0.4712 | f1: 0.4710\n",
            "Validation:  loss: 0.7686 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00083\n",
            "Train: loss: 0.5968 | accuracy: 0.6754 | f-acore: 0.6692\n",
            "Test:  loss: 0.7179 | accuracy: 0.5068 | f1: 0.4970\n",
            "Validation:  loss: 0.7554 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00084\n",
            "Train: loss: 0.5952 | accuracy: 0.6832 | f-acore: 0.6744\n",
            "Test:  loss: 0.7331 | accuracy: 0.4877 | f1: 0.4846\n",
            "Validation:  loss: 0.7784 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00085\n",
            "Train: loss: 0.6078 | accuracy: 0.6809 | f-acore: 0.6756\n",
            "Test:  loss: 0.7308 | accuracy: 0.4712 | f1: 0.4693\n",
            "Validation:  loss: 0.7834 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00086\n",
            "Train: loss: 0.6053 | accuracy: 0.6699 | f-acore: 0.6618\n",
            "Test:  loss: 0.7319 | accuracy: 0.5014 | f1: 0.4962\n",
            "Validation:  loss: 0.7739 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00087\n",
            "Train: loss: 0.6052 | accuracy: 0.6767 | f-acore: 0.6725\n",
            "Test:  loss: 0.7274 | accuracy: 0.5205 | f1: 0.5106\n",
            "Validation:  loss: 0.7819 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00088\n",
            "Train: loss: 0.6026 | accuracy: 0.6859 | f-acore: 0.6772\n",
            "Test:  loss: 0.7461 | accuracy: 0.4822 | f1: 0.4782\n",
            "Validation:  loss: 0.7702 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00089\n",
            "Train: loss: 0.5933 | accuracy: 0.6822 | f-acore: 0.6777\n",
            "Test:  loss: 0.7336 | accuracy: 0.4767 | f1: 0.4744\n",
            "Validation:  loss: 0.7696 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00090\n",
            "Train: loss: 0.5918 | accuracy: 0.6818 | f-acore: 0.6744\n",
            "Test:  loss: 0.7479 | accuracy: 0.4822 | f1: 0.4819\n",
            "Validation:  loss: 0.7873 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00091\n",
            "Train: loss: 0.6010 | accuracy: 0.6680 | f-acore: 0.6603\n",
            "Test:  loss: 0.7368 | accuracy: 0.5041 | f1: 0.5012\n",
            "Validation:  loss: 0.7800 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00092\n",
            "Train: loss: 0.6020 | accuracy: 0.6822 | f-acore: 0.6754\n",
            "Test:  loss: 0.7350 | accuracy: 0.4658 | f1: 0.4634\n",
            "Validation:  loss: 0.7878 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00093\n",
            "Train: loss: 0.6131 | accuracy: 0.6749 | f-acore: 0.6705\n",
            "Test:  loss: 0.7397 | accuracy: 0.4959 | f1: 0.4917\n",
            "Validation:  loss: 0.7823 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00094\n",
            "Train: loss: 0.5942 | accuracy: 0.6767 | f-acore: 0.6642\n",
            "Test:  loss: 0.7293 | accuracy: 0.5151 | f1: 0.5130\n",
            "Validation:  loss: 0.7707 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00095\n",
            "Train: loss: 0.5959 | accuracy: 0.6868 | f-acore: 0.6820\n",
            "Test:  loss: 0.7429 | accuracy: 0.4740 | f1: 0.4737\n",
            "Validation:  loss: 0.7708 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00096\n",
            "Train: loss: 0.6087 | accuracy: 0.6804 | f-acore: 0.6722\n",
            "Test:  loss: 0.7393 | accuracy: 0.4740 | f1: 0.4739\n",
            "Validation:  loss: 0.7810 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00097\n",
            "Train: loss: 0.6045 | accuracy: 0.6818 | f-acore: 0.6743\n",
            "Test:  loss: 0.7372 | accuracy: 0.5123 | f1: 0.5088\n",
            "Validation:  loss: 0.7840 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00098\n",
            "Train: loss: 0.5933 | accuracy: 0.6854 | f-acore: 0.6750\n",
            "Test:  loss: 0.7338 | accuracy: 0.4822 | f1: 0.4822\n",
            "Validation:  loss: 0.7878 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00099\n",
            "Train: loss: 0.5870 | accuracy: 0.6841 | f-acore: 0.6788\n",
            "Test:  loss: 0.7540 | accuracy: 0.5068 | f1: 0.5068\n",
            "Validation:  loss: 0.7925 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00100\n",
            "Train: loss: 0.6002 | accuracy: 0.6900 | f-acore: 0.6800\n",
            "Test:  loss: 0.7270 | accuracy: 0.4877 | f1: 0.4867\n",
            "Validation:  loss: 0.7889 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00101\n",
            "Train: loss: 0.5920 | accuracy: 0.6809 | f-acore: 0.6749\n",
            "Test:  loss: 0.7411 | accuracy: 0.4685 | f1: 0.4676\n",
            "Validation:  loss: 0.7972 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00102\n",
            "Train: loss: 0.5855 | accuracy: 0.6914 | f-acore: 0.6817\n",
            "Test:  loss: 0.7456 | accuracy: 0.4822 | f1: 0.4809\n",
            "Validation:  loss: 0.7958 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00103\n",
            "Train: loss: 0.5844 | accuracy: 0.6964 | f-acore: 0.6919\n",
            "Test:  loss: 0.7429 | accuracy: 0.4795 | f1: 0.4786\n",
            "Validation:  loss: 0.7940 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00104\n",
            "Train: loss: 0.5878 | accuracy: 0.6845 | f-acore: 0.6778\n",
            "Test:  loss: 0.7290 | accuracy: 0.4986 | f1: 0.4968\n",
            "Validation:  loss: 0.7944 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00105\n",
            "Train: loss: 0.5782 | accuracy: 0.6973 | f-acore: 0.6903\n",
            "Test:  loss: 0.7387 | accuracy: 0.5096 | f1: 0.5058\n",
            "Validation:  loss: 0.7969 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00106\n",
            "Train: loss: 0.5890 | accuracy: 0.6896 | f-acore: 0.6843\n",
            "Test:  loss: 0.7402 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 0.7948 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00107\n",
            "Train: loss: 0.5858 | accuracy: 0.6973 | f-acore: 0.6922\n",
            "Test:  loss: 0.7362 | accuracy: 0.5014 | f1: 0.4962\n",
            "Validation:  loss: 0.8128 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00108\n",
            "Train: loss: 0.5871 | accuracy: 0.7010 | f-acore: 0.6955\n",
            "Test:  loss: 0.7405 | accuracy: 0.5178 | f1: 0.5155\n",
            "Validation:  loss: 0.8053 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00109\n",
            "Train: loss: 0.6040 | accuracy: 0.6987 | f-acore: 0.6935\n",
            "Test:  loss: 0.7677 | accuracy: 0.4904 | f1: 0.4904\n",
            "Validation:  loss: 0.8155 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00110\n",
            "Train: loss: 0.5780 | accuracy: 0.6914 | f-acore: 0.6883\n",
            "Test:  loss: 0.7562 | accuracy: 0.4959 | f1: 0.4953\n",
            "Validation:  loss: 0.8082 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00111\n",
            "Train: loss: 0.5868 | accuracy: 0.6928 | f-acore: 0.6864\n",
            "Test:  loss: 0.7484 | accuracy: 0.4849 | f1: 0.4846\n",
            "Validation:  loss: 0.7950 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00112\n",
            "Train: loss: 0.5742 | accuracy: 0.6909 | f-acore: 0.6853\n",
            "Test:  loss: 0.7508 | accuracy: 0.4877 | f1: 0.4867\n",
            "Validation:  loss: 0.7989 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00113\n",
            "Train: loss: 0.5727 | accuracy: 0.6891 | f-acore: 0.6849\n",
            "Test:  loss: 0.7667 | accuracy: 0.5096 | f1: 0.5053\n",
            "Validation:  loss: 0.8193 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00114\n",
            "Train: loss: 0.5885 | accuracy: 0.6909 | f-acore: 0.6826\n",
            "Test:  loss: 0.7410 | accuracy: 0.4740 | f1: 0.4740\n",
            "Validation:  loss: 0.7973 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00115\n",
            "Train: loss: 0.5887 | accuracy: 0.6983 | f-acore: 0.6912\n",
            "Test:  loss: 0.7392 | accuracy: 0.4877 | f1: 0.4871\n",
            "Validation:  loss: 0.7950 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00116\n",
            "Train: loss: 0.5728 | accuracy: 0.6978 | f-acore: 0.6914\n",
            "Test:  loss: 0.7464 | accuracy: 0.4959 | f1: 0.4953\n",
            "Validation:  loss: 0.7982 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00117\n",
            "Train: loss: 0.5905 | accuracy: 0.6900 | f-acore: 0.6806\n",
            "Test:  loss: 0.7417 | accuracy: 0.4822 | f1: 0.4816\n",
            "Validation:  loss: 0.8019 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00118\n",
            "Train: loss: 0.5888 | accuracy: 0.6882 | f-acore: 0.6848\n",
            "Test:  loss: 0.7665 | accuracy: 0.5014 | f1: 0.5000\n",
            "Validation:  loss: 0.8061 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00119\n",
            "Train: loss: 0.5733 | accuracy: 0.6992 | f-acore: 0.6945\n",
            "Test:  loss: 0.7338 | accuracy: 0.5068 | f1: 0.5033\n",
            "Validation:  loss: 0.8107 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00120\n",
            "Train: loss: 0.5842 | accuracy: 0.6886 | f-acore: 0.6790\n",
            "Test:  loss: 0.7427 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 0.8060 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00121\n",
            "Train: loss: 0.5706 | accuracy: 0.6918 | f-acore: 0.6870\n",
            "Test:  loss: 0.7659 | accuracy: 0.4767 | f1: 0.4754\n",
            "Validation:  loss: 0.8158 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00122\n",
            "Train: loss: 0.5714 | accuracy: 0.6964 | f-acore: 0.6905\n",
            "Test:  loss: 0.7495 | accuracy: 0.5041 | f1: 0.5023\n",
            "Validation:  loss: 0.8063 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00123\n",
            "Train: loss: 0.5772 | accuracy: 0.6836 | f-acore: 0.6736\n",
            "Test:  loss: 0.7401 | accuracy: 0.5178 | f1: 0.5170\n",
            "Validation:  loss: 0.7990 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00124\n",
            "Train: loss: 0.5745 | accuracy: 0.6960 | f-acore: 0.6927\n",
            "Test:  loss: 0.7347 | accuracy: 0.5233 | f1: 0.5153\n",
            "Validation:  loss: 0.8153 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00125\n",
            "Train: loss: 0.5861 | accuracy: 0.6918 | f-acore: 0.6838\n",
            "Test:  loss: 0.7446 | accuracy: 0.5068 | f1: 0.5037\n",
            "Validation:  loss: 0.8157 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00126\n",
            "Train: loss: 0.5798 | accuracy: 0.7083 | f-acore: 0.7028\n",
            "Test:  loss: 0.7371 | accuracy: 0.5041 | f1: 0.5007\n",
            "Validation:  loss: 0.8052 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00127\n",
            "Train: loss: 0.5608 | accuracy: 0.7134 | f-acore: 0.7073\n",
            "Test:  loss: 0.7593 | accuracy: 0.4849 | f1: 0.4835\n",
            "Validation:  loss: 0.8153 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00128\n",
            "Train: loss: 0.5770 | accuracy: 0.6992 | f-acore: 0.6939\n",
            "Test:  loss: 0.7682 | accuracy: 0.4767 | f1: 0.4766\n",
            "Validation:  loss: 0.8260 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00129\n",
            "Train: loss: 0.5739 | accuracy: 0.6983 | f-acore: 0.6933\n",
            "Test:  loss: 0.7389 | accuracy: 0.4959 | f1: 0.4912\n",
            "Validation:  loss: 0.8090 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00130\n",
            "Train: loss: 0.5859 | accuracy: 0.7005 | f-acore: 0.6922\n",
            "Test:  loss: 0.7523 | accuracy: 0.4877 | f1: 0.4864\n",
            "Validation:  loss: 0.8152 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00131\n",
            "Train: loss: 0.5714 | accuracy: 0.7056 | f-acore: 0.7023\n",
            "Test:  loss: 0.7480 | accuracy: 0.5068 | f1: 0.5045\n",
            "Validation:  loss: 0.8236 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00132\n",
            "Train: loss: 0.5646 | accuracy: 0.7065 | f-acore: 0.7026\n",
            "Test:  loss: 0.7514 | accuracy: 0.5123 | f1: 0.5078\n",
            "Validation:  loss: 0.8262 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00133\n",
            "Train: loss: 0.5633 | accuracy: 0.6923 | f-acore: 0.6853\n",
            "Test:  loss: 0.7615 | accuracy: 0.4740 | f1: 0.4739\n",
            "Validation:  loss: 0.8054 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00134\n",
            "Train: loss: 0.5603 | accuracy: 0.7120 | f-acore: 0.7090\n",
            "Test:  loss: 0.7486 | accuracy: 0.5288 | f1: 0.5221\n",
            "Validation:  loss: 0.8472 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00135\n",
            "Train: loss: 0.5681 | accuracy: 0.6987 | f-acore: 0.6909\n",
            "Test:  loss: 0.7518 | accuracy: 0.4904 | f1: 0.4895\n",
            "Validation:  loss: 0.8054 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00136\n",
            "Train: loss: 0.5602 | accuracy: 0.7115 | f-acore: 0.7057\n",
            "Test:  loss: 0.7720 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 0.8213 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00137\n",
            "Train: loss: 0.5664 | accuracy: 0.7074 | f-acore: 0.7033\n",
            "Test:  loss: 0.7561 | accuracy: 0.5068 | f1: 0.5045\n",
            "Validation:  loss: 0.8292 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00138\n",
            "Train: loss: 0.5624 | accuracy: 0.6996 | f-acore: 0.6946\n",
            "Test:  loss: 0.7648 | accuracy: 0.4986 | f1: 0.4977\n",
            "Validation:  loss: 0.8213 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00139\n",
            "Train: loss: 0.5838 | accuracy: 0.7092 | f-acore: 0.7061\n",
            "Test:  loss: 0.7671 | accuracy: 0.5041 | f1: 0.5029\n",
            "Validation:  loss: 0.8489 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00140\n",
            "Train: loss: 0.5725 | accuracy: 0.7097 | f-acore: 0.7056\n",
            "Test:  loss: 0.7687 | accuracy: 0.4877 | f1: 0.4861\n",
            "Validation:  loss: 0.8327 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00141\n",
            "Train: loss: 0.5621 | accuracy: 0.7070 | f-acore: 0.6990\n",
            "Test:  loss: 0.7642 | accuracy: 0.4849 | f1: 0.4845\n",
            "Validation:  loss: 0.8181 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00142\n",
            "Train: loss: 0.5644 | accuracy: 0.7042 | f-acore: 0.7009\n",
            "Test:  loss: 0.7386 | accuracy: 0.5096 | f1: 0.5063\n",
            "Validation:  loss: 0.8192 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00143\n",
            "Train: loss: 0.5483 | accuracy: 0.7166 | f-acore: 0.7071\n",
            "Test:  loss: 0.7603 | accuracy: 0.4849 | f1: 0.4845\n",
            "Validation:  loss: 0.8165 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00144\n",
            "Train: loss: 0.5583 | accuracy: 0.7038 | f-acore: 0.6966\n",
            "Test:  loss: 0.7547 | accuracy: 0.5096 | f1: 0.5086\n",
            "Validation:  loss: 0.8316 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00145\n",
            "Train: loss: 0.5464 | accuracy: 0.7166 | f-acore: 0.7115\n",
            "Test:  loss: 0.7623 | accuracy: 0.4822 | f1: 0.4816\n",
            "Validation:  loss: 0.8386 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00146\n",
            "Train: loss: 0.5576 | accuracy: 0.7157 | f-acore: 0.7098\n",
            "Test:  loss: 0.7704 | accuracy: 0.4795 | f1: 0.4794\n",
            "Validation:  loss: 0.8329 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00147\n",
            "Train: loss: 0.5522 | accuracy: 0.7083 | f-acore: 0.7045\n",
            "Test:  loss: 0.7683 | accuracy: 0.5123 | f1: 0.5119\n",
            "Validation:  loss: 0.8313 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00148\n",
            "Train: loss: 0.5559 | accuracy: 0.7092 | f-acore: 0.7033\n",
            "Test:  loss: 0.7624 | accuracy: 0.4986 | f1: 0.4974\n",
            "Validation:  loss: 0.8134 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00149\n",
            "Train: loss: 0.5571 | accuracy: 0.7152 | f-acore: 0.7087\n",
            "Test:  loss: 0.7533 | accuracy: 0.4986 | f1: 0.4957\n",
            "Validation:  loss: 0.8307 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00150\n",
            "Train: loss: 0.5622 | accuracy: 0.7120 | f-acore: 0.7079\n",
            "Test:  loss: 0.7494 | accuracy: 0.5288 | f1: 0.5258\n",
            "Validation:  loss: 0.8259 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00151\n",
            "Train: loss: 0.5484 | accuracy: 0.7060 | f-acore: 0.6983\n",
            "Test:  loss: 0.7520 | accuracy: 0.5014 | f1: 0.4994\n",
            "Validation:  loss: 0.8252 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00152\n",
            "Train: loss: 0.5677 | accuracy: 0.7106 | f-acore: 0.7070\n",
            "Test:  loss: 0.7547 | accuracy: 0.5096 | f1: 0.5042\n",
            "Validation:  loss: 0.8347 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00153\n",
            "Train: loss: 0.5573 | accuracy: 0.7115 | f-acore: 0.7050\n",
            "Test:  loss: 0.7587 | accuracy: 0.5205 | f1: 0.5188\n",
            "Validation:  loss: 0.8348 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00154\n",
            "Train: loss: 0.5521 | accuracy: 0.7161 | f-acore: 0.7119\n",
            "Test:  loss: 0.7407 | accuracy: 0.5014 | f1: 0.4990\n",
            "Validation:  loss: 0.8182 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00155\n",
            "Train: loss: 0.5643 | accuracy: 0.7253 | f-acore: 0.7205\n",
            "Test:  loss: 0.7370 | accuracy: 0.5205 | f1: 0.5135\n",
            "Validation:  loss: 0.8288 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00156\n",
            "Train: loss: 0.5598 | accuracy: 0.7184 | f-acore: 0.7117\n",
            "Test:  loss: 0.7560 | accuracy: 0.5123 | f1: 0.5100\n",
            "Validation:  loss: 0.8234 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00157\n",
            "Train: loss: 0.5394 | accuracy: 0.7134 | f-acore: 0.7096\n",
            "Test:  loss: 0.7632 | accuracy: 0.5205 | f1: 0.5196\n",
            "Validation:  loss: 0.8398 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00158\n",
            "Train: loss: 0.5521 | accuracy: 0.7125 | f-acore: 0.7088\n",
            "Test:  loss: 0.7687 | accuracy: 0.5151 | f1: 0.5133\n",
            "Validation:  loss: 0.8344 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00159\n",
            "Train: loss: 0.5390 | accuracy: 0.7207 | f-acore: 0.7144\n",
            "Test:  loss: 0.7717 | accuracy: 0.5205 | f1: 0.5202\n",
            "Validation:  loss: 0.8353 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00160\n",
            "Train: loss: 0.5414 | accuracy: 0.7179 | f-acore: 0.7143\n",
            "Test:  loss: 0.7678 | accuracy: 0.5151 | f1: 0.5133\n",
            "Validation:  loss: 0.8408 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00161\n",
            "Train: loss: 0.5626 | accuracy: 0.7202 | f-acore: 0.7137\n",
            "Test:  loss: 0.7520 | accuracy: 0.5014 | f1: 0.4994\n",
            "Validation:  loss: 0.8490 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00162\n",
            "Train: loss: 0.5522 | accuracy: 0.7244 | f-acore: 0.7213\n",
            "Test:  loss: 0.7674 | accuracy: 0.4986 | f1: 0.4965\n",
            "Validation:  loss: 0.8579 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00163\n",
            "Train: loss: 0.5614 | accuracy: 0.7161 | f-acore: 0.7132\n",
            "Test:  loss: 0.7712 | accuracy: 0.5068 | f1: 0.5058\n",
            "Validation:  loss: 0.8513 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00164\n",
            "Train: loss: 0.5594 | accuracy: 0.7170 | f-acore: 0.7128\n",
            "Test:  loss: 0.7456 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 0.8331 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00165\n",
            "Train: loss: 0.5607 | accuracy: 0.7051 | f-acore: 0.6980\n",
            "Test:  loss: 0.7771 | accuracy: 0.4986 | f1: 0.4981\n",
            "Validation:  loss: 0.8579 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00166\n",
            "Train: loss: 0.5559 | accuracy: 0.7184 | f-acore: 0.7135\n",
            "Test:  loss: 0.7640 | accuracy: 0.5068 | f1: 0.5055\n",
            "Validation:  loss: 0.8502 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00167\n",
            "Train: loss: 0.5464 | accuracy: 0.7115 | f-acore: 0.7082\n",
            "Test:  loss: 0.7622 | accuracy: 0.5041 | f1: 0.5026\n",
            "Validation:  loss: 0.8465 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00168\n",
            "Train: loss: 0.5432 | accuracy: 0.7253 | f-acore: 0.7205\n",
            "Test:  loss: 0.7872 | accuracy: 0.5068 | f1: 0.5065\n",
            "Validation:  loss: 0.8680 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00169\n",
            "Train: loss: 0.5540 | accuracy: 0.7170 | f-acore: 0.7124\n",
            "Test:  loss: 0.7641 | accuracy: 0.4986 | f1: 0.4961\n",
            "Validation:  loss: 0.8511 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00170\n",
            "Train: loss: 0.5506 | accuracy: 0.7212 | f-acore: 0.7141\n",
            "Test:  loss: 0.7568 | accuracy: 0.5041 | f1: 0.5003\n",
            "Validation:  loss: 0.8566 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00171\n",
            "Train: loss: 0.5472 | accuracy: 0.7134 | f-acore: 0.7063\n",
            "Test:  loss: 0.7608 | accuracy: 0.5205 | f1: 0.5153\n",
            "Validation:  loss: 0.8490 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00172\n",
            "Train: loss: 0.5507 | accuracy: 0.7303 | f-acore: 0.7242\n",
            "Test:  loss: 0.7483 | accuracy: 0.5233 | f1: 0.5159\n",
            "Validation:  loss: 0.8568 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00173\n",
            "Train: loss: 0.5467 | accuracy: 0.7102 | f-acore: 0.7056\n",
            "Test:  loss: 0.7434 | accuracy: 0.5260 | f1: 0.5203\n",
            "Validation:  loss: 0.8471 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00174\n",
            "Train: loss: 0.5467 | accuracy: 0.7276 | f-acore: 0.7233\n",
            "Test:  loss: 0.7615 | accuracy: 0.5096 | f1: 0.5058\n",
            "Validation:  loss: 0.8537 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00175\n",
            "Train: loss: 0.5508 | accuracy: 0.7170 | f-acore: 0.7101\n",
            "Test:  loss: 0.8028 | accuracy: 0.4932 | f1: 0.4931\n",
            "Validation:  loss: 0.8530 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00176\n",
            "Train: loss: 0.5317 | accuracy: 0.7299 | f-acore: 0.7251\n",
            "Test:  loss: 0.7568 | accuracy: 0.4986 | f1: 0.4942\n",
            "Validation:  loss: 0.8559 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00177\n",
            "Train: loss: 0.5465 | accuracy: 0.7239 | f-acore: 0.7186\n",
            "Test:  loss: 0.7545 | accuracy: 0.5178 | f1: 0.5147\n",
            "Validation:  loss: 0.8481 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00178\n",
            "Train: loss: 0.5419 | accuracy: 0.7390 | f-acore: 0.7337\n",
            "Test:  loss: 0.7738 | accuracy: 0.5096 | f1: 0.5089\n",
            "Validation:  loss: 0.8625 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00179\n",
            "Train: loss: 0.5584 | accuracy: 0.7221 | f-acore: 0.7196\n",
            "Test:  loss: 0.7628 | accuracy: 0.5123 | f1: 0.5092\n",
            "Validation:  loss: 0.8678 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00180\n",
            "Train: loss: 0.5510 | accuracy: 0.7143 | f-acore: 0.7099\n",
            "Test:  loss: 0.7613 | accuracy: 0.5205 | f1: 0.5168\n",
            "Validation:  loss: 0.8642 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00181\n",
            "Train: loss: 0.5389 | accuracy: 0.7294 | f-acore: 0.7233\n",
            "Test:  loss: 0.7544 | accuracy: 0.4959 | f1: 0.4942\n",
            "Validation:  loss: 0.8616 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00182\n",
            "Train: loss: 0.5440 | accuracy: 0.7271 | f-acore: 0.7230\n",
            "Test:  loss: 0.7687 | accuracy: 0.5151 | f1: 0.5130\n",
            "Validation:  loss: 0.8647 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00183\n",
            "Train: loss: 0.5348 | accuracy: 0.7285 | f-acore: 0.7259\n",
            "Test:  loss: 0.7724 | accuracy: 0.4986 | f1: 0.4952\n",
            "Validation:  loss: 0.8741 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00184\n",
            "Train: loss: 0.5524 | accuracy: 0.7266 | f-acore: 0.7210\n",
            "Test:  loss: 0.7678 | accuracy: 0.5041 | f1: 0.5032\n",
            "Validation:  loss: 0.8584 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00185\n",
            "Train: loss: 0.5388 | accuracy: 0.7321 | f-acore: 0.7280\n",
            "Test:  loss: 0.7666 | accuracy: 0.5178 | f1: 0.5168\n",
            "Validation:  loss: 0.8523 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00186\n",
            "Train: loss: 0.5657 | accuracy: 0.7047 | f-acore: 0.7018\n",
            "Test:  loss: 0.7733 | accuracy: 0.5123 | f1: 0.5096\n",
            "Validation:  loss: 0.8613 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00187\n",
            "Train: loss: 0.5432 | accuracy: 0.7225 | f-acore: 0.7198\n",
            "Test:  loss: 0.7595 | accuracy: 0.5205 | f1: 0.5173\n",
            "Validation:  loss: 0.8701 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00188\n",
            "Train: loss: 0.5488 | accuracy: 0.7157 | f-acore: 0.7102\n",
            "Test:  loss: 0.7563 | accuracy: 0.5178 | f1: 0.5152\n",
            "Validation:  loss: 0.8658 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00189\n",
            "Train: loss: 0.5430 | accuracy: 0.7161 | f-acore: 0.7140\n",
            "Test:  loss: 0.7593 | accuracy: 0.5205 | f1: 0.5141\n",
            "Validation:  loss: 0.8441 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00190\n",
            "Train: loss: 0.5500 | accuracy: 0.7340 | f-acore: 0.7280\n",
            "Test:  loss: 0.7640 | accuracy: 0.5205 | f1: 0.5185\n",
            "Validation:  loss: 0.8717 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00191\n",
            "Train: loss: 0.5381 | accuracy: 0.7262 | f-acore: 0.7215\n",
            "Test:  loss: 0.7589 | accuracy: 0.5123 | f1: 0.5092\n",
            "Validation:  loss: 0.8554 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00192\n",
            "Train: loss: 0.5246 | accuracy: 0.7285 | f-acore: 0.7250\n",
            "Test:  loss: 0.7750 | accuracy: 0.4986 | f1: 0.4952\n",
            "Validation:  loss: 0.8850 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00193\n",
            "Train: loss: 0.5311 | accuracy: 0.7340 | f-acore: 0.7299\n",
            "Test:  loss: 0.7586 | accuracy: 0.5178 | f1: 0.5040\n",
            "Validation:  loss: 0.8832 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00194\n",
            "Train: loss: 0.5262 | accuracy: 0.7344 | f-acore: 0.7310\n",
            "Test:  loss: 0.7600 | accuracy: 0.5123 | f1: 0.5055\n",
            "Validation:  loss: 0.8757 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00195\n",
            "Train: loss: 0.5402 | accuracy: 0.7431 | f-acore: 0.7396\n",
            "Test:  loss: 0.7504 | accuracy: 0.5096 | f1: 0.5048\n",
            "Validation:  loss: 0.8911 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00196\n",
            "Train: loss: 0.5216 | accuracy: 0.7399 | f-acore: 0.7375\n",
            "Test:  loss: 0.7688 | accuracy: 0.5096 | f1: 0.5058\n",
            "Validation:  loss: 0.8738 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00197\n",
            "Train: loss: 0.5280 | accuracy: 0.7331 | f-acore: 0.7278\n",
            "Test:  loss: 0.7699 | accuracy: 0.5233 | f1: 0.5198\n",
            "Validation:  loss: 0.8795 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00198\n",
            "Train: loss: 0.5382 | accuracy: 0.7289 | f-acore: 0.7257\n",
            "Test:  loss: 0.7574 | accuracy: 0.5041 | f1: 0.4954\n",
            "Validation:  loss: 0.8739 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00199\n",
            "Train: loss: 0.5230 | accuracy: 0.7299 | f-acore: 0.7247\n",
            "Test:  loss: 0.7754 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 0.8998 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00200\n",
            "Train: loss: 0.5204 | accuracy: 0.7349 | f-acore: 0.7301\n",
            "Test:  loss: 0.7772 | accuracy: 0.5068 | f1: 0.5041\n",
            "Validation:  loss: 0.9141 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00201\n",
            "Train: loss: 0.5332 | accuracy: 0.7353 | f-acore: 0.7311\n",
            "Test:  loss: 0.7754 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 0.9053 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00202\n",
            "Train: loss: 0.5260 | accuracy: 0.7445 | f-acore: 0.7418\n",
            "Test:  loss: 0.7962 | accuracy: 0.5014 | f1: 0.4944\n",
            "Validation:  loss: 0.9064 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00203\n",
            "Train: loss: 0.5346 | accuracy: 0.7202 | f-acore: 0.7152\n",
            "Test:  loss: 0.7804 | accuracy: 0.5178 | f1: 0.5152\n",
            "Validation:  loss: 0.8994 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00204\n",
            "Train: loss: 0.5390 | accuracy: 0.7367 | f-acore: 0.7344\n",
            "Test:  loss: 0.7783 | accuracy: 0.5178 | f1: 0.5090\n",
            "Validation:  loss: 0.9182 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00205\n",
            "Train: loss: 0.5361 | accuracy: 0.7408 | f-acore: 0.7368\n",
            "Test:  loss: 0.7737 | accuracy: 0.5260 | f1: 0.5170\n",
            "Validation:  loss: 0.9015 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00206\n",
            "Train: loss: 0.5375 | accuracy: 0.7285 | f-acore: 0.7226\n",
            "Test:  loss: 0.7806 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 0.8781 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00207\n",
            "Train: loss: 0.5302 | accuracy: 0.7344 | f-acore: 0.7285\n",
            "Test:  loss: 0.7777 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.8809 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00208\n",
            "Train: loss: 0.5397 | accuracy: 0.7358 | f-acore: 0.7330\n",
            "Test:  loss: 0.7561 | accuracy: 0.5123 | f1: 0.5041\n",
            "Validation:  loss: 0.9025 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00209\n",
            "Train: loss: 0.5288 | accuracy: 0.7271 | f-acore: 0.7235\n",
            "Test:  loss: 0.7787 | accuracy: 0.5041 | f1: 0.4992\n",
            "Validation:  loss: 0.9051 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00210\n",
            "Train: loss: 0.5302 | accuracy: 0.7450 | f-acore: 0.7415\n",
            "Test:  loss: 0.7890 | accuracy: 0.5151 | f1: 0.5103\n",
            "Validation:  loss: 0.9365 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00211\n",
            "Train: loss: 0.5151 | accuracy: 0.7312 | f-acore: 0.7271\n",
            "Test:  loss: 0.7807 | accuracy: 0.5096 | f1: 0.5002\n",
            "Validation:  loss: 0.9325 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00212\n",
            "Train: loss: 0.5270 | accuracy: 0.7372 | f-acore: 0.7311\n",
            "Test:  loss: 0.7784 | accuracy: 0.5205 | f1: 0.5147\n",
            "Validation:  loss: 0.8845 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00213\n",
            "Train: loss: 0.5169 | accuracy: 0.7285 | f-acore: 0.7238\n",
            "Test:  loss: 0.7631 | accuracy: 0.5315 | f1: 0.5274\n",
            "Validation:  loss: 0.8997 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00214\n",
            "Train: loss: 0.5148 | accuracy: 0.7303 | f-acore: 0.7280\n",
            "Test:  loss: 0.7773 | accuracy: 0.5014 | f1: 0.4950\n",
            "Validation:  loss: 0.9158 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00215\n",
            "Train: loss: 0.5246 | accuracy: 0.7349 | f-acore: 0.7296\n",
            "Test:  loss: 0.7696 | accuracy: 0.5260 | f1: 0.5208\n",
            "Validation:  loss: 0.9144 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00216\n",
            "Train: loss: 0.5250 | accuracy: 0.7363 | f-acore: 0.7295\n",
            "Test:  loss: 0.7654 | accuracy: 0.5151 | f1: 0.5118\n",
            "Validation:  loss: 0.8835 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00217\n",
            "Train: loss: 0.5397 | accuracy: 0.7331 | f-acore: 0.7299\n",
            "Test:  loss: 0.7752 | accuracy: 0.5123 | f1: 0.5073\n",
            "Validation:  loss: 0.9206 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00218\n",
            "Train: loss: 0.5360 | accuracy: 0.7280 | f-acore: 0.7209\n",
            "Test:  loss: 0.7982 | accuracy: 0.4904 | f1: 0.4890\n",
            "Validation:  loss: 0.9035 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00219\n",
            "Train: loss: 0.5228 | accuracy: 0.7440 | f-acore: 0.7408\n",
            "Test:  loss: 0.7812 | accuracy: 0.5151 | f1: 0.5122\n",
            "Validation:  loss: 0.9041 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00220\n",
            "Train: loss: 0.5228 | accuracy: 0.7386 | f-acore: 0.7355\n",
            "Test:  loss: 0.7793 | accuracy: 0.4959 | f1: 0.4927\n",
            "Validation:  loss: 0.8989 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00221\n",
            "Train: loss: 0.5241 | accuracy: 0.7335 | f-acore: 0.7299\n",
            "Test:  loss: 0.7929 | accuracy: 0.4959 | f1: 0.4948\n",
            "Validation:  loss: 0.9116 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00222\n",
            "Train: loss: 0.5158 | accuracy: 0.7495 | f-acore: 0.7433\n",
            "Test:  loss: 0.8010 | accuracy: 0.5041 | f1: 0.5034\n",
            "Validation:  loss: 0.9327 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00223\n",
            "Train: loss: 0.5381 | accuracy: 0.7495 | f-acore: 0.7487\n",
            "Test:  loss: 0.7955 | accuracy: 0.5068 | f1: 0.5058\n",
            "Validation:  loss: 0.9060 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00224\n",
            "Train: loss: 0.5247 | accuracy: 0.7408 | f-acore: 0.7364\n",
            "Test:  loss: 0.8100 | accuracy: 0.5096 | f1: 0.5081\n",
            "Validation:  loss: 0.9330 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00225\n",
            "Train: loss: 0.5398 | accuracy: 0.7395 | f-acore: 0.7379\n",
            "Test:  loss: 0.7925 | accuracy: 0.5041 | f1: 0.5016\n",
            "Validation:  loss: 0.9306 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00226\n",
            "Train: loss: 0.5044 | accuracy: 0.7537 | f-acore: 0.7495\n",
            "Test:  loss: 0.7872 | accuracy: 0.5041 | f1: 0.5036\n",
            "Validation:  loss: 0.9272 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00227\n",
            "Train: loss: 0.5092 | accuracy: 0.7527 | f-acore: 0.7497\n",
            "Test:  loss: 0.7844 | accuracy: 0.5205 | f1: 0.5147\n",
            "Validation:  loss: 0.9356 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00228\n",
            "Train: loss: 0.5237 | accuracy: 0.7500 | f-acore: 0.7444\n",
            "Test:  loss: 0.8024 | accuracy: 0.4877 | f1: 0.4867\n",
            "Validation:  loss: 0.9146 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00229\n",
            "Train: loss: 0.5249 | accuracy: 0.7555 | f-acore: 0.7525\n",
            "Test:  loss: 0.8159 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 0.9139 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00230\n",
            "Train: loss: 0.5233 | accuracy: 0.7532 | f-acore: 0.7493\n",
            "Test:  loss: 0.7989 | accuracy: 0.5041 | f1: 0.5041\n",
            "Validation:  loss: 0.9210 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00231\n",
            "Train: loss: 0.5158 | accuracy: 0.7431 | f-acore: 0.7401\n",
            "Test:  loss: 0.7969 | accuracy: 0.4767 | f1: 0.4740\n",
            "Validation:  loss: 0.9167 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00232\n",
            "Train: loss: 0.5201 | accuracy: 0.7413 | f-acore: 0.7383\n",
            "Test:  loss: 0.8011 | accuracy: 0.4822 | f1: 0.4814\n",
            "Validation:  loss: 0.9415 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00233\n",
            "Train: loss: 0.5092 | accuracy: 0.7482 | f-acore: 0.7436\n",
            "Test:  loss: 0.8039 | accuracy: 0.4822 | f1: 0.4806\n",
            "Validation:  loss: 0.9280 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00234\n",
            "Train: loss: 0.5055 | accuracy: 0.7500 | f-acore: 0.7458\n",
            "Test:  loss: 0.7996 | accuracy: 0.4877 | f1: 0.4842\n",
            "Validation:  loss: 0.9093 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00235\n",
            "Train: loss: 0.5171 | accuracy: 0.7431 | f-acore: 0.7387\n",
            "Test:  loss: 0.7969 | accuracy: 0.4849 | f1: 0.4821\n",
            "Validation:  loss: 0.9128 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00236\n",
            "Train: loss: 0.5050 | accuracy: 0.7527 | f-acore: 0.7490\n",
            "Test:  loss: 0.7957 | accuracy: 0.5151 | f1: 0.5122\n",
            "Validation:  loss: 0.8970 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00237\n",
            "Train: loss: 0.5002 | accuracy: 0.7473 | f-acore: 0.7456\n",
            "Test:  loss: 0.8038 | accuracy: 0.5068 | f1: 0.5017\n",
            "Validation:  loss: 0.9501 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00238\n",
            "Train: loss: 0.5546 | accuracy: 0.7326 | f-acore: 0.7264\n",
            "Test:  loss: 0.7949 | accuracy: 0.4904 | f1: 0.4899\n",
            "Validation:  loss: 0.9005 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00239\n",
            "Train: loss: 0.5265 | accuracy: 0.7285 | f-acore: 0.7276\n",
            "Test:  loss: 0.8002 | accuracy: 0.4959 | f1: 0.4922\n",
            "Validation:  loss: 0.9040 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00240\n",
            "Train: loss: 0.5363 | accuracy: 0.7431 | f-acore: 0.7374\n",
            "Test:  loss: 0.7941 | accuracy: 0.5123 | f1: 0.5083\n",
            "Validation:  loss: 0.8983 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00241\n",
            "Train: loss: 0.5207 | accuracy: 0.7358 | f-acore: 0.7329\n",
            "Test:  loss: 0.8147 | accuracy: 0.5205 | f1: 0.5181\n",
            "Validation:  loss: 0.9309 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00242\n",
            "Train: loss: 0.5225 | accuracy: 0.7326 | f-acore: 0.7275\n",
            "Test:  loss: 0.7828 | accuracy: 0.5068 | f1: 0.5033\n",
            "Validation:  loss: 0.9156 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00243\n",
            "Train: loss: 0.5011 | accuracy: 0.7546 | f-acore: 0.7510\n",
            "Test:  loss: 0.7889 | accuracy: 0.4904 | f1: 0.4872\n",
            "Validation:  loss: 0.9105 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00244\n",
            "Train: loss: 0.4989 | accuracy: 0.7578 | f-acore: 0.7535\n",
            "Test:  loss: 0.8109 | accuracy: 0.4986 | f1: 0.4957\n",
            "Validation:  loss: 0.9146 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00245\n",
            "Train: loss: 0.5170 | accuracy: 0.7427 | f-acore: 0.7369\n",
            "Test:  loss: 0.7881 | accuracy: 0.5205 | f1: 0.5188\n",
            "Validation:  loss: 0.9120 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00246\n",
            "Train: loss: 0.5269 | accuracy: 0.7445 | f-acore: 0.7414\n",
            "Test:  loss: 0.8098 | accuracy: 0.5014 | f1: 0.4990\n",
            "Validation:  loss: 0.9204 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00247\n",
            "Train: loss: 0.5198 | accuracy: 0.7440 | f-acore: 0.7407\n",
            "Test:  loss: 0.7872 | accuracy: 0.5068 | f1: 0.5045\n",
            "Validation:  loss: 0.8877 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00248\n",
            "Train: loss: 0.5151 | accuracy: 0.7353 | f-acore: 0.7309\n",
            "Test:  loss: 0.8072 | accuracy: 0.5068 | f1: 0.5045\n",
            "Validation:  loss: 0.9307 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00249\n",
            "Train: loss: 0.4937 | accuracy: 0.7477 | f-acore: 0.7455\n",
            "Test:  loss: 0.8092 | accuracy: 0.5288 | f1: 0.5239\n",
            "Validation:  loss: 0.9534 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00250\n",
            "Train: loss: 0.5311 | accuracy: 0.7445 | f-acore: 0.7384\n",
            "Test:  loss: 0.8260 | accuracy: 0.5096 | f1: 0.5075\n",
            "Validation:  loss: 0.9327 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00251\n",
            "Train: loss: 0.5265 | accuracy: 0.7422 | f-acore: 0.7379\n",
            "Test:  loss: 0.8115 | accuracy: 0.4822 | f1: 0.4809\n",
            "Validation:  loss: 0.9334 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00252\n",
            "Train: loss: 0.5258 | accuracy: 0.7454 | f-acore: 0.7415\n",
            "Test:  loss: 0.8058 | accuracy: 0.5123 | f1: 0.5100\n",
            "Validation:  loss: 0.9365 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00253\n",
            "Train: loss: 0.5054 | accuracy: 0.7440 | f-acore: 0.7416\n",
            "Test:  loss: 0.8457 | accuracy: 0.4932 | f1: 0.4916\n",
            "Validation:  loss: 0.9556 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00254\n",
            "Train: loss: 0.5067 | accuracy: 0.7532 | f-acore: 0.7515\n",
            "Test:  loss: 0.8122 | accuracy: 0.4932 | f1: 0.4882\n",
            "Validation:  loss: 0.9309 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00255\n",
            "Train: loss: 0.5009 | accuracy: 0.7486 | f-acore: 0.7420\n",
            "Test:  loss: 0.8090 | accuracy: 0.5260 | f1: 0.5255\n",
            "Validation:  loss: 0.9164 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00256\n",
            "Train: loss: 0.5112 | accuracy: 0.7550 | f-acore: 0.7534\n",
            "Test:  loss: 0.8274 | accuracy: 0.5178 | f1: 0.5168\n",
            "Validation:  loss: 0.9340 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00257\n",
            "Train: loss: 0.5146 | accuracy: 0.7514 | f-acore: 0.7468\n",
            "Test:  loss: 0.8185 | accuracy: 0.5151 | f1: 0.5139\n",
            "Validation:  loss: 0.9409 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00258\n",
            "Train: loss: 0.5361 | accuracy: 0.7592 | f-acore: 0.7560\n",
            "Test:  loss: 0.8035 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 0.9186 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00259\n",
            "Train: loss: 0.5189 | accuracy: 0.7578 | f-acore: 0.7563\n",
            "Test:  loss: 0.8074 | accuracy: 0.4932 | f1: 0.4887\n",
            "Validation:  loss: 0.9349 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00260\n",
            "Train: loss: 0.5075 | accuracy: 0.7564 | f-acore: 0.7510\n",
            "Test:  loss: 0.8112 | accuracy: 0.5205 | f1: 0.5191\n",
            "Validation:  loss: 0.9136 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00261\n",
            "Train: loss: 0.5076 | accuracy: 0.7509 | f-acore: 0.7459\n",
            "Test:  loss: 0.8331 | accuracy: 0.5123 | f1: 0.5110\n",
            "Validation:  loss: 0.9612 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00262\n",
            "Train: loss: 0.4966 | accuracy: 0.7532 | f-acore: 0.7486\n",
            "Test:  loss: 0.8219 | accuracy: 0.5041 | f1: 0.5034\n",
            "Validation:  loss: 0.9419 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00263\n",
            "Train: loss: 0.5046 | accuracy: 0.7614 | f-acore: 0.7577\n",
            "Test:  loss: 0.8338 | accuracy: 0.4986 | f1: 0.4968\n",
            "Validation:  loss: 0.9464 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00264\n",
            "Train: loss: 0.5258 | accuracy: 0.7422 | f-acore: 0.7407\n",
            "Test:  loss: 0.8495 | accuracy: 0.4932 | f1: 0.4902\n",
            "Validation:  loss: 0.9323 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00265\n",
            "Train: loss: 0.5132 | accuracy: 0.7431 | f-acore: 0.7398\n",
            "Test:  loss: 0.8004 | accuracy: 0.5425 | f1: 0.5380\n",
            "Validation:  loss: 0.9508 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00266\n",
            "Train: loss: 0.5023 | accuracy: 0.7459 | f-acore: 0.7412\n",
            "Test:  loss: 0.8022 | accuracy: 0.5178 | f1: 0.5116\n",
            "Validation:  loss: 0.9411 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00267\n",
            "Train: loss: 0.5017 | accuracy: 0.7463 | f-acore: 0.7429\n",
            "Test:  loss: 0.8171 | accuracy: 0.5096 | f1: 0.5058\n",
            "Validation:  loss: 0.9468 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00268\n",
            "Train: loss: 0.5032 | accuracy: 0.7527 | f-acore: 0.7461\n",
            "Test:  loss: 0.8255 | accuracy: 0.4959 | f1: 0.4927\n",
            "Validation:  loss: 0.9471 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00269\n",
            "Train: loss: 0.5176 | accuracy: 0.7477 | f-acore: 0.7465\n",
            "Test:  loss: 0.8169 | accuracy: 0.5068 | f1: 0.5023\n",
            "Validation:  loss: 0.9314 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00270\n",
            "Train: loss: 0.4946 | accuracy: 0.7679 | f-acore: 0.7634\n",
            "Test:  loss: 0.8070 | accuracy: 0.5178 | f1: 0.5155\n",
            "Validation:  loss: 0.9057 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00271\n",
            "Train: loss: 0.5061 | accuracy: 0.7596 | f-acore: 0.7580\n",
            "Test:  loss: 0.8200 | accuracy: 0.5041 | f1: 0.4987\n",
            "Validation:  loss: 0.9495 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00272\n",
            "Train: loss: 0.4997 | accuracy: 0.7642 | f-acore: 0.7609\n",
            "Test:  loss: 0.8167 | accuracy: 0.5014 | f1: 0.4950\n",
            "Validation:  loss: 0.9260 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00273\n",
            "Train: loss: 0.4948 | accuracy: 0.7637 | f-acore: 0.7612\n",
            "Test:  loss: 0.8468 | accuracy: 0.5014 | f1: 0.4973\n",
            "Validation:  loss: 0.9408 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00274\n",
            "Train: loss: 0.5188 | accuracy: 0.7569 | f-acore: 0.7539\n",
            "Test:  loss: 0.8213 | accuracy: 0.4932 | f1: 0.4857\n",
            "Validation:  loss: 0.9306 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00275\n",
            "Train: loss: 0.5024 | accuracy: 0.7578 | f-acore: 0.7524\n",
            "Test:  loss: 0.7963 | accuracy: 0.5096 | f1: 0.5042\n",
            "Validation:  loss: 0.9024 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00276\n",
            "Train: loss: 0.4951 | accuracy: 0.7582 | f-acore: 0.7551\n",
            "Test:  loss: 0.8094 | accuracy: 0.5123 | f1: 0.5088\n",
            "Validation:  loss: 0.9318 | accuracy: 0.5556 | f1: 0.5555\n",
            "Epoch 00277\n",
            "Train: loss: 0.5232 | accuracy: 0.7592 | f-acore: 0.7547\n",
            "Test:  loss: 0.8293 | accuracy: 0.5123 | f1: 0.5107\n",
            "Validation:  loss: 0.9256 | accuracy: 0.5556 | f1: 0.5555\n",
            "Epoch 00278\n",
            "Train: loss: 0.4957 | accuracy: 0.7592 | f-acore: 0.7564\n",
            "Test:  loss: 0.8260 | accuracy: 0.4822 | f1: 0.4787\n",
            "Validation:  loss: 0.9153 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00279\n",
            "Train: loss: 0.5148 | accuracy: 0.7697 | f-acore: 0.7659\n",
            "Test:  loss: 0.8243 | accuracy: 0.5096 | f1: 0.5067\n",
            "Validation:  loss: 0.9189 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00280\n",
            "Train: loss: 0.5194 | accuracy: 0.7564 | f-acore: 0.7519\n",
            "Test:  loss: 0.8174 | accuracy: 0.4986 | f1: 0.4957\n",
            "Validation:  loss: 0.9158 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00281\n",
            "Train: loss: 0.4862 | accuracy: 0.7679 | f-acore: 0.7640\n",
            "Test:  loss: 0.8133 | accuracy: 0.5068 | f1: 0.5033\n",
            "Validation:  loss: 0.9229 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00282\n",
            "Train: loss: 0.4865 | accuracy: 0.7601 | f-acore: 0.7576\n",
            "Test:  loss: 0.8181 | accuracy: 0.5178 | f1: 0.5116\n",
            "Validation:  loss: 0.9386 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00283\n",
            "Train: loss: 0.4871 | accuracy: 0.7633 | f-acore: 0.7596\n",
            "Test:  loss: 0.8369 | accuracy: 0.4959 | f1: 0.4922\n",
            "Validation:  loss: 0.9405 | accuracy: 0.5679 | f1: 0.5679\n",
            "Epoch 00284\n",
            "Train: loss: 0.4900 | accuracy: 0.7569 | f-acore: 0.7529\n",
            "Test:  loss: 0.8273 | accuracy: 0.5014 | f1: 0.4982\n",
            "Validation:  loss: 0.9421 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00285\n",
            "Train: loss: 0.4861 | accuracy: 0.7555 | f-acore: 0.7526\n",
            "Test:  loss: 0.8647 | accuracy: 0.4795 | f1: 0.4770\n",
            "Validation:  loss: 0.9502 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00286\n",
            "Train: loss: 0.4829 | accuracy: 0.7601 | f-acore: 0.7575\n",
            "Test:  loss: 0.8706 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 0.9518 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00287\n",
            "Train: loss: 0.4757 | accuracy: 0.7720 | f-acore: 0.7694\n",
            "Test:  loss: 0.8338 | accuracy: 0.5068 | f1: 0.5041\n",
            "Validation:  loss: 0.9383 | accuracy: 0.5556 | f1: 0.5555\n",
            "Epoch 00288\n",
            "Train: loss: 0.4751 | accuracy: 0.7756 | f-acore: 0.7732\n",
            "Test:  loss: 0.8486 | accuracy: 0.5014 | f1: 0.4967\n",
            "Validation:  loss: 0.9585 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00289\n",
            "Train: loss: 0.4825 | accuracy: 0.7633 | f-acore: 0.7607\n",
            "Test:  loss: 0.8757 | accuracy: 0.5014 | f1: 0.4962\n",
            "Validation:  loss: 0.9832 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00290\n",
            "Train: loss: 0.4961 | accuracy: 0.7633 | f-acore: 0.7588\n",
            "Test:  loss: 0.8462 | accuracy: 0.5288 | f1: 0.5269\n",
            "Validation:  loss: 0.9444 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00291\n",
            "Train: loss: 0.4784 | accuracy: 0.7724 | f-acore: 0.7703\n",
            "Test:  loss: 0.8707 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 0.9596 | accuracy: 0.5679 | f1: 0.5668\n",
            "Epoch 00292\n",
            "Train: loss: 0.4747 | accuracy: 0.7642 | f-acore: 0.7609\n",
            "Test:  loss: 0.8524 | accuracy: 0.4904 | f1: 0.4887\n",
            "Validation:  loss: 0.9682 | accuracy: 0.5556 | f1: 0.5555\n",
            "Epoch 00293\n",
            "Train: loss: 0.4831 | accuracy: 0.7605 | f-acore: 0.7573\n",
            "Test:  loss: 0.8546 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.9593 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00294\n",
            "Train: loss: 0.4958 | accuracy: 0.7839 | f-acore: 0.7817\n",
            "Test:  loss: 0.8683 | accuracy: 0.4986 | f1: 0.4971\n",
            "Validation:  loss: 0.9896 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00295\n",
            "Train: loss: 0.4917 | accuracy: 0.7514 | f-acore: 0.7500\n",
            "Test:  loss: 0.8579 | accuracy: 0.5014 | f1: 0.4962\n",
            "Validation:  loss: 0.9980 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00296\n",
            "Train: loss: 0.4883 | accuracy: 0.7669 | f-acore: 0.7617\n",
            "Test:  loss: 0.8444 | accuracy: 0.5014 | f1: 0.4986\n",
            "Validation:  loss: 0.9565 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00297\n",
            "Train: loss: 0.4825 | accuracy: 0.7560 | f-acore: 0.7523\n",
            "Test:  loss: 0.8606 | accuracy: 0.4849 | f1: 0.4825\n",
            "Validation:  loss: 0.9760 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00298\n",
            "Train: loss: 0.4709 | accuracy: 0.7720 | f-acore: 0.7683\n",
            "Test:  loss: 0.8553 | accuracy: 0.4986 | f1: 0.4947\n",
            "Validation:  loss: 0.9816 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00299\n",
            "Train: loss: 0.4923 | accuracy: 0.7518 | f-acore: 0.7479\n",
            "Test:  loss: 0.8510 | accuracy: 0.4959 | f1: 0.4931\n",
            "Validation:  loss: 0.9939 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00300\n",
            "Train: loss: 0.4848 | accuracy: 0.7596 | f-acore: 0.7577\n",
            "Test:  loss: 0.8492 | accuracy: 0.5123 | f1: 0.5083\n",
            "Validation:  loss: 0.9816 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00301\n",
            "Train: loss: 0.4950 | accuracy: 0.7596 | f-acore: 0.7554\n",
            "Test:  loss: 0.8798 | accuracy: 0.4767 | f1: 0.4757\n",
            "Validation:  loss: 0.9742 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00302\n",
            "Train: loss: 0.4944 | accuracy: 0.7665 | f-acore: 0.7648\n",
            "Test:  loss: 0.8545 | accuracy: 0.4877 | f1: 0.4821\n",
            "Validation:  loss: 0.9758 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00303\n",
            "Train: loss: 0.4934 | accuracy: 0.7642 | f-acore: 0.7611\n",
            "Test:  loss: 0.8790 | accuracy: 0.4959 | f1: 0.4931\n",
            "Validation:  loss: 0.9849 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00304\n",
            "Train: loss: 0.4864 | accuracy: 0.7766 | f-acore: 0.7742\n",
            "Test:  loss: 0.8465 | accuracy: 0.4877 | f1: 0.4869\n",
            "Validation:  loss: 0.9728 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00305\n",
            "Train: loss: 0.4816 | accuracy: 0.7647 | f-acore: 0.7617\n",
            "Test:  loss: 0.8441 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.9359 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00306\n",
            "Train: loss: 0.5049 | accuracy: 0.7651 | f-acore: 0.7616\n",
            "Test:  loss: 0.8455 | accuracy: 0.5151 | f1: 0.5103\n",
            "Validation:  loss: 0.9555 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00307\n",
            "Train: loss: 0.5151 | accuracy: 0.7660 | f-acore: 0.7643\n",
            "Test:  loss: 0.8404 | accuracy: 0.5123 | f1: 0.5055\n",
            "Validation:  loss: 0.9598 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00308\n",
            "Train: loss: 0.4753 | accuracy: 0.7647 | f-acore: 0.7610\n",
            "Test:  loss: 0.8416 | accuracy: 0.4986 | f1: 0.4952\n",
            "Validation:  loss: 0.9470 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00309\n",
            "Train: loss: 0.4834 | accuracy: 0.7720 | f-acore: 0.7696\n",
            "Test:  loss: 0.8696 | accuracy: 0.4795 | f1: 0.4752\n",
            "Validation:  loss: 0.9872 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00310\n",
            "Train: loss: 0.4757 | accuracy: 0.7775 | f-acore: 0.7743\n",
            "Test:  loss: 0.8554 | accuracy: 0.5014 | f1: 0.4950\n",
            "Validation:  loss: 0.9693 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00311\n",
            "Train: loss: 0.4832 | accuracy: 0.7706 | f-acore: 0.7681\n",
            "Test:  loss: 0.9001 | accuracy: 0.4795 | f1: 0.4766\n",
            "Validation:  loss: 0.9733 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00312\n",
            "Train: loss: 0.4871 | accuracy: 0.7688 | f-acore: 0.7665\n",
            "Test:  loss: 0.8455 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 0.9643 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00313\n",
            "Train: loss: 0.4762 | accuracy: 0.7674 | f-acore: 0.7647\n",
            "Test:  loss: 0.8659 | accuracy: 0.4822 | f1: 0.4796\n",
            "Validation:  loss: 0.9737 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00314\n",
            "Train: loss: 0.4785 | accuracy: 0.7688 | f-acore: 0.7654\n",
            "Test:  loss: 0.8758 | accuracy: 0.5014 | f1: 0.5003\n",
            "Validation:  loss: 0.9713 | accuracy: 0.5679 | f1: 0.5676\n",
            "Epoch 00315\n",
            "Train: loss: 0.4856 | accuracy: 0.7857 | f-acore: 0.7825\n",
            "Test:  loss: 0.8881 | accuracy: 0.4795 | f1: 0.4774\n",
            "Validation:  loss: 0.9828 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00316\n",
            "Train: loss: 0.4816 | accuracy: 0.7674 | f-acore: 0.7651\n",
            "Test:  loss: 0.9114 | accuracy: 0.4685 | f1: 0.4660\n",
            "Validation:  loss: 1.0180 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00317\n",
            "Train: loss: 0.4789 | accuracy: 0.7724 | f-acore: 0.7687\n",
            "Test:  loss: 0.8654 | accuracy: 0.5123 | f1: 0.5107\n",
            "Validation:  loss: 0.9715 | accuracy: 0.5679 | f1: 0.5676\n",
            "Epoch 00318\n",
            "Train: loss: 0.4945 | accuracy: 0.7779 | f-acore: 0.7742\n",
            "Test:  loss: 0.8661 | accuracy: 0.5233 | f1: 0.5194\n",
            "Validation:  loss: 0.9710 | accuracy: 0.5679 | f1: 0.5668\n",
            "Epoch 00319\n",
            "Train: loss: 0.4923 | accuracy: 0.7656 | f-acore: 0.7641\n",
            "Test:  loss: 0.8928 | accuracy: 0.4767 | f1: 0.4710\n",
            "Validation:  loss: 1.0233 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00320\n",
            "Train: loss: 0.4849 | accuracy: 0.7647 | f-acore: 0.7614\n",
            "Test:  loss: 0.8770 | accuracy: 0.4932 | f1: 0.4897\n",
            "Validation:  loss: 0.9750 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00321\n",
            "Train: loss: 0.4596 | accuracy: 0.7697 | f-acore: 0.7669\n",
            "Test:  loss: 0.8787 | accuracy: 0.4959 | f1: 0.4939\n",
            "Validation:  loss: 0.9556 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00322\n",
            "Train: loss: 0.4784 | accuracy: 0.7761 | f-acore: 0.7738\n",
            "Test:  loss: 0.8762 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 0.9784 | accuracy: 0.5432 | f1: 0.5432\n",
            "Epoch 00323\n",
            "Train: loss: 0.4773 | accuracy: 0.7752 | f-acore: 0.7727\n",
            "Test:  loss: 0.8965 | accuracy: 0.4877 | f1: 0.4861\n",
            "Validation:  loss: 1.0029 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00324\n",
            "Train: loss: 0.4937 | accuracy: 0.7688 | f-acore: 0.7666\n",
            "Test:  loss: 0.8929 | accuracy: 0.5041 | f1: 0.5020\n",
            "Validation:  loss: 0.9679 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00325\n",
            "Train: loss: 0.4680 | accuracy: 0.7642 | f-acore: 0.7617\n",
            "Test:  loss: 0.9418 | accuracy: 0.4685 | f1: 0.4680\n",
            "Validation:  loss: 1.0267 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00326\n",
            "Train: loss: 0.4795 | accuracy: 0.7734 | f-acore: 0.7707\n",
            "Test:  loss: 0.8778 | accuracy: 0.5178 | f1: 0.5159\n",
            "Validation:  loss: 0.9843 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00327\n",
            "Train: loss: 0.4691 | accuracy: 0.7761 | f-acore: 0.7739\n",
            "Test:  loss: 0.8920 | accuracy: 0.4822 | f1: 0.4809\n",
            "Validation:  loss: 0.9814 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00328\n",
            "Train: loss: 0.5020 | accuracy: 0.7715 | f-acore: 0.7679\n",
            "Test:  loss: 0.9105 | accuracy: 0.4822 | f1: 0.4821\n",
            "Validation:  loss: 0.9687 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00329\n",
            "Train: loss: 0.4878 | accuracy: 0.7734 | f-acore: 0.7719\n",
            "Test:  loss: 0.8825 | accuracy: 0.4849 | f1: 0.4832\n",
            "Validation:  loss: 0.9692 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00330\n",
            "Train: loss: 0.4881 | accuracy: 0.7637 | f-acore: 0.7604\n",
            "Test:  loss: 0.8809 | accuracy: 0.5068 | f1: 0.5055\n",
            "Validation:  loss: 0.9805 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00331\n",
            "Train: loss: 0.4778 | accuracy: 0.7697 | f-acore: 0.7661\n",
            "Test:  loss: 0.9031 | accuracy: 0.4795 | f1: 0.4786\n",
            "Validation:  loss: 0.9811 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00332\n",
            "Train: loss: 0.4751 | accuracy: 0.7706 | f-acore: 0.7669\n",
            "Test:  loss: 0.8650 | accuracy: 0.5123 | f1: 0.5088\n",
            "Validation:  loss: 0.9689 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00333\n",
            "Train: loss: 0.4788 | accuracy: 0.7734 | f-acore: 0.7700\n",
            "Test:  loss: 0.8874 | accuracy: 0.5123 | f1: 0.5110\n",
            "Validation:  loss: 0.9733 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00334\n",
            "Train: loss: 0.4734 | accuracy: 0.7862 | f-acore: 0.7827\n",
            "Test:  loss: 0.8840 | accuracy: 0.5041 | f1: 0.5023\n",
            "Validation:  loss: 1.0131 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00335\n",
            "Train: loss: 0.4863 | accuracy: 0.7761 | f-acore: 0.7739\n",
            "Test:  loss: 0.9077 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 1.0042 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00336\n",
            "Train: loss: 0.4900 | accuracy: 0.7738 | f-acore: 0.7712\n",
            "Test:  loss: 0.8979 | accuracy: 0.5041 | f1: 0.5036\n",
            "Validation:  loss: 0.9737 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00337\n",
            "Train: loss: 0.4685 | accuracy: 0.7830 | f-acore: 0.7804\n",
            "Test:  loss: 0.8800 | accuracy: 0.4932 | f1: 0.4906\n",
            "Validation:  loss: 0.9766 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00338\n",
            "Train: loss: 0.4852 | accuracy: 0.7642 | f-acore: 0.7617\n",
            "Test:  loss: 0.9037 | accuracy: 0.4767 | f1: 0.4761\n",
            "Validation:  loss: 0.9766 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00339\n",
            "Train: loss: 0.4872 | accuracy: 0.7692 | f-acore: 0.7666\n",
            "Test:  loss: 0.8826 | accuracy: 0.5123 | f1: 0.5100\n",
            "Validation:  loss: 0.9684 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00340\n",
            "Train: loss: 0.4872 | accuracy: 0.7701 | f-acore: 0.7660\n",
            "Test:  loss: 0.8779 | accuracy: 0.5014 | f1: 0.5000\n",
            "Validation:  loss: 0.9745 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00341\n",
            "Train: loss: 0.4608 | accuracy: 0.7734 | f-acore: 0.7707\n",
            "Test:  loss: 0.8976 | accuracy: 0.4959 | f1: 0.4939\n",
            "Validation:  loss: 0.9786 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00342\n",
            "Train: loss: 0.4633 | accuracy: 0.7839 | f-acore: 0.7811\n",
            "Test:  loss: 0.9073 | accuracy: 0.5096 | f1: 0.5086\n",
            "Validation:  loss: 1.0033 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00343\n",
            "Train: loss: 0.4718 | accuracy: 0.7784 | f-acore: 0.7757\n",
            "Test:  loss: 0.8843 | accuracy: 0.5068 | f1: 0.5055\n",
            "Validation:  loss: 1.0080 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00344\n",
            "Train: loss: 0.4525 | accuracy: 0.7912 | f-acore: 0.7877\n",
            "Test:  loss: 0.8882 | accuracy: 0.5068 | f1: 0.5052\n",
            "Validation:  loss: 0.9919 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00345\n",
            "Train: loss: 0.4770 | accuracy: 0.7816 | f-acore: 0.7793\n",
            "Test:  loss: 0.8981 | accuracy: 0.5041 | f1: 0.5016\n",
            "Validation:  loss: 1.0188 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00346\n",
            "Train: loss: 0.4647 | accuracy: 0.7734 | f-acore: 0.7699\n",
            "Test:  loss: 0.8877 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 0.9845 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00347\n",
            "Train: loss: 0.4744 | accuracy: 0.7816 | f-acore: 0.7799\n",
            "Test:  loss: 0.8974 | accuracy: 0.5014 | f1: 0.4977\n",
            "Validation:  loss: 0.9828 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00348\n",
            "Train: loss: 0.4750 | accuracy: 0.7793 | f-acore: 0.7760\n",
            "Test:  loss: 0.9194 | accuracy: 0.4932 | f1: 0.4909\n",
            "Validation:  loss: 0.9982 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00349\n",
            "Train: loss: 0.4606 | accuracy: 0.7921 | f-acore: 0.7888\n",
            "Test:  loss: 0.9162 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 1.0262 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00350\n",
            "Train: loss: 0.4637 | accuracy: 0.7816 | f-acore: 0.7778\n",
            "Test:  loss: 0.9073 | accuracy: 0.5233 | f1: 0.5227\n",
            "Validation:  loss: 0.9794 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00351\n",
            "Train: loss: 0.4786 | accuracy: 0.7857 | f-acore: 0.7844\n",
            "Test:  loss: 0.9306 | accuracy: 0.5014 | f1: 0.4994\n",
            "Validation:  loss: 1.0309 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00352\n",
            "Train: loss: 0.4984 | accuracy: 0.7523 | f-acore: 0.7510\n",
            "Test:  loss: 0.9796 | accuracy: 0.4932 | f1: 0.4916\n",
            "Validation:  loss: 1.0489 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00353\n",
            "Train: loss: 0.4615 | accuracy: 0.7811 | f-acore: 0.7788\n",
            "Test:  loss: 0.9073 | accuracy: 0.5123 | f1: 0.5092\n",
            "Validation:  loss: 0.9918 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00354\n",
            "Train: loss: 0.4707 | accuracy: 0.7766 | f-acore: 0.7728\n",
            "Test:  loss: 0.8979 | accuracy: 0.5014 | f1: 0.4962\n",
            "Validation:  loss: 0.9827 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00355\n",
            "Train: loss: 0.4516 | accuracy: 0.7775 | f-acore: 0.7740\n",
            "Test:  loss: 0.9477 | accuracy: 0.4959 | f1: 0.4950\n",
            "Validation:  loss: 1.0240 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00356\n",
            "Train: loss: 0.4580 | accuracy: 0.7839 | f-acore: 0.7809\n",
            "Test:  loss: 0.8991 | accuracy: 0.4986 | f1: 0.4971\n",
            "Validation:  loss: 0.9918 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00357\n",
            "Train: loss: 0.4633 | accuracy: 0.7743 | f-acore: 0.7715\n",
            "Test:  loss: 0.9272 | accuracy: 0.4904 | f1: 0.4902\n",
            "Validation:  loss: 0.9862 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00358\n",
            "Train: loss: 0.4603 | accuracy: 0.7848 | f-acore: 0.7835\n",
            "Test:  loss: 0.9123 | accuracy: 0.4986 | f1: 0.4942\n",
            "Validation:  loss: 1.0366 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00359\n",
            "Train: loss: 0.4649 | accuracy: 0.7720 | f-acore: 0.7675\n",
            "Test:  loss: 0.9118 | accuracy: 0.5096 | f1: 0.5084\n",
            "Validation:  loss: 1.0216 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00360\n",
            "Train: loss: 0.4509 | accuracy: 0.7857 | f-acore: 0.7833\n",
            "Test:  loss: 0.9342 | accuracy: 0.4932 | f1: 0.4916\n",
            "Validation:  loss: 1.0057 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00361\n",
            "Train: loss: 0.4671 | accuracy: 0.7802 | f-acore: 0.7773\n",
            "Test:  loss: 0.9123 | accuracy: 0.4986 | f1: 0.4977\n",
            "Validation:  loss: 0.9622 | accuracy: 0.5432 | f1: 0.5429\n",
            "Epoch 00362\n",
            "Train: loss: 0.4531 | accuracy: 0.7949 | f-acore: 0.7914\n",
            "Test:  loss: 0.9273 | accuracy: 0.4795 | f1: 0.4783\n",
            "Validation:  loss: 1.0122 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00363\n",
            "Train: loss: 0.4667 | accuracy: 0.7802 | f-acore: 0.7778\n",
            "Test:  loss: 0.9407 | accuracy: 0.5041 | f1: 0.5037\n",
            "Validation:  loss: 1.0055 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00364\n",
            "Train: loss: 0.4569 | accuracy: 0.7775 | f-acore: 0.7755\n",
            "Test:  loss: 0.9228 | accuracy: 0.4822 | f1: 0.4809\n",
            "Validation:  loss: 1.0240 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00365\n",
            "Train: loss: 0.4878 | accuracy: 0.7720 | f-acore: 0.7696\n",
            "Test:  loss: 0.9186 | accuracy: 0.5068 | f1: 0.5049\n",
            "Validation:  loss: 1.0299 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00366\n",
            "Train: loss: 0.4839 | accuracy: 0.7752 | f-acore: 0.7740\n",
            "Test:  loss: 0.9409 | accuracy: 0.5068 | f1: 0.5037\n",
            "Validation:  loss: 1.0510 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00367\n",
            "Train: loss: 0.4675 | accuracy: 0.7729 | f-acore: 0.7697\n",
            "Test:  loss: 0.9043 | accuracy: 0.4932 | f1: 0.4924\n",
            "Validation:  loss: 0.9904 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00368\n",
            "Train: loss: 0.4577 | accuracy: 0.7752 | f-acore: 0.7716\n",
            "Test:  loss: 0.9276 | accuracy: 0.4932 | f1: 0.4919\n",
            "Validation:  loss: 1.0173 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00369\n",
            "Train: loss: 0.4983 | accuracy: 0.7711 | f-acore: 0.7690\n",
            "Test:  loss: 0.9340 | accuracy: 0.4849 | f1: 0.4838\n",
            "Validation:  loss: 1.0139 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00370\n",
            "Train: loss: 0.4547 | accuracy: 0.7866 | f-acore: 0.7843\n",
            "Test:  loss: 0.9239 | accuracy: 0.5123 | f1: 0.5122\n",
            "Validation:  loss: 0.9895 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00371\n",
            "Train: loss: 0.4500 | accuracy: 0.7788 | f-acore: 0.7769\n",
            "Test:  loss: 0.9386 | accuracy: 0.5096 | f1: 0.5081\n",
            "Validation:  loss: 1.0231 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00372\n",
            "Train: loss: 0.4619 | accuracy: 0.7779 | f-acore: 0.7747\n",
            "Test:  loss: 0.9341 | accuracy: 0.5014 | f1: 0.5007\n",
            "Validation:  loss: 1.0067 | accuracy: 0.5556 | f1: 0.5549\n",
            "Epoch 00373\n",
            "Train: loss: 0.4611 | accuracy: 0.7770 | f-acore: 0.7738\n",
            "Test:  loss: 0.9134 | accuracy: 0.5178 | f1: 0.5168\n",
            "Validation:  loss: 1.0052 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00374\n",
            "Train: loss: 0.4543 | accuracy: 0.7889 | f-acore: 0.7858\n",
            "Test:  loss: 0.9083 | accuracy: 0.5068 | f1: 0.5052\n",
            "Validation:  loss: 1.0175 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00375\n",
            "Train: loss: 0.4444 | accuracy: 0.7834 | f-acore: 0.7811\n",
            "Test:  loss: 0.9277 | accuracy: 0.5123 | f1: 0.5107\n",
            "Validation:  loss: 1.0106 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00376\n",
            "Train: loss: 0.4692 | accuracy: 0.7862 | f-acore: 0.7834\n",
            "Test:  loss: 0.9059 | accuracy: 0.4877 | f1: 0.4869\n",
            "Validation:  loss: 0.9898 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00377\n",
            "Train: loss: 0.4406 | accuracy: 0.7885 | f-acore: 0.7864\n",
            "Test:  loss: 0.9155 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 1.0095 | accuracy: 0.5309 | f1: 0.5308\n",
            "Epoch 00378\n",
            "Train: loss: 0.4487 | accuracy: 0.7871 | f-acore: 0.7836\n",
            "Test:  loss: 0.9371 | accuracy: 0.4822 | f1: 0.4812\n",
            "Validation:  loss: 1.0066 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00379\n",
            "Train: loss: 0.4534 | accuracy: 0.7912 | f-acore: 0.7894\n",
            "Test:  loss: 0.9281 | accuracy: 0.4904 | f1: 0.4893\n",
            "Validation:  loss: 1.0051 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00380\n",
            "Train: loss: 0.4504 | accuracy: 0.7862 | f-acore: 0.7840\n",
            "Test:  loss: 0.9482 | accuracy: 0.5123 | f1: 0.5115\n",
            "Validation:  loss: 1.0242 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00381\n",
            "Train: loss: 0.4545 | accuracy: 0.7839 | f-acore: 0.7798\n",
            "Test:  loss: 0.9417 | accuracy: 0.4959 | f1: 0.4939\n",
            "Validation:  loss: 1.0398 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00382\n",
            "Train: loss: 0.4690 | accuracy: 0.7880 | f-acore: 0.7847\n",
            "Test:  loss: 0.9294 | accuracy: 0.5068 | f1: 0.5055\n",
            "Validation:  loss: 1.0083 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00383\n",
            "Train: loss: 0.4473 | accuracy: 0.7953 | f-acore: 0.7933\n",
            "Test:  loss: 0.9622 | accuracy: 0.5041 | f1: 0.5032\n",
            "Validation:  loss: 1.0395 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00384\n",
            "Train: loss: 0.4516 | accuracy: 0.7793 | f-acore: 0.7763\n",
            "Test:  loss: 0.9195 | accuracy: 0.4986 | f1: 0.4968\n",
            "Validation:  loss: 1.0186 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00385\n",
            "Train: loss: 0.4563 | accuracy: 0.7871 | f-acore: 0.7841\n",
            "Test:  loss: 0.9287 | accuracy: 0.4959 | f1: 0.4939\n",
            "Validation:  loss: 1.0259 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00386\n",
            "Train: loss: 0.4824 | accuracy: 0.7848 | f-acore: 0.7822\n",
            "Test:  loss: 0.9207 | accuracy: 0.5151 | f1: 0.5126\n",
            "Validation:  loss: 1.0387 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00387\n",
            "Train: loss: 0.4652 | accuracy: 0.7784 | f-acore: 0.7767\n",
            "Test:  loss: 0.9348 | accuracy: 0.4904 | f1: 0.4884\n",
            "Validation:  loss: 1.0507 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00388\n",
            "Train: loss: 0.4603 | accuracy: 0.7734 | f-acore: 0.7690\n",
            "Test:  loss: 0.9514 | accuracy: 0.4986 | f1: 0.4983\n",
            "Validation:  loss: 1.0095 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00389\n",
            "Train: loss: 0.4561 | accuracy: 0.7830 | f-acore: 0.7805\n",
            "Test:  loss: 0.9136 | accuracy: 0.4877 | f1: 0.4846\n",
            "Validation:  loss: 1.0162 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00390\n",
            "Train: loss: 0.4577 | accuracy: 0.7839 | f-acore: 0.7811\n",
            "Test:  loss: 0.9502 | accuracy: 0.4822 | f1: 0.4799\n",
            "Validation:  loss: 1.0173 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00391\n",
            "Train: loss: 0.4625 | accuracy: 0.7853 | f-acore: 0.7818\n",
            "Test:  loss: 0.9532 | accuracy: 0.4849 | f1: 0.4838\n",
            "Validation:  loss: 1.0244 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00392\n",
            "Train: loss: 0.4752 | accuracy: 0.7811 | f-acore: 0.7785\n",
            "Test:  loss: 0.9258 | accuracy: 0.4932 | f1: 0.4916\n",
            "Validation:  loss: 1.0268 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00393\n",
            "Train: loss: 0.4626 | accuracy: 0.7898 | f-acore: 0.7890\n",
            "Test:  loss: 0.9452 | accuracy: 0.4904 | f1: 0.4893\n",
            "Validation:  loss: 1.0438 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00394\n",
            "Train: loss: 0.4537 | accuracy: 0.7807 | f-acore: 0.7776\n",
            "Test:  loss: 0.9614 | accuracy: 0.5014 | f1: 0.5012\n",
            "Validation:  loss: 1.0462 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00395\n",
            "Train: loss: 0.4551 | accuracy: 0.7866 | f-acore: 0.7839\n",
            "Test:  loss: 0.9371 | accuracy: 0.5068 | f1: 0.5062\n",
            "Validation:  loss: 1.0475 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00396\n",
            "Train: loss: 0.4835 | accuracy: 0.7871 | f-acore: 0.7842\n",
            "Test:  loss: 0.9247 | accuracy: 0.5068 | f1: 0.5062\n",
            "Validation:  loss: 1.0203 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00397\n",
            "Train: loss: 0.4560 | accuracy: 0.7848 | f-acore: 0.7807\n",
            "Test:  loss: 0.9365 | accuracy: 0.4959 | f1: 0.4954\n",
            "Validation:  loss: 1.0374 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00398\n",
            "Train: loss: 0.4559 | accuracy: 0.7880 | f-acore: 0.7851\n",
            "Test:  loss: 0.9104 | accuracy: 0.5041 | f1: 0.4998\n",
            "Validation:  loss: 1.0209 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00399\n",
            "Train: loss: 0.4362 | accuracy: 0.7894 | f-acore: 0.7863\n",
            "Test:  loss: 0.9332 | accuracy: 0.5123 | f1: 0.5100\n",
            "Validation:  loss: 1.0232 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00400\n",
            "Train: loss: 0.4691 | accuracy: 0.7734 | f-acore: 0.7698\n",
            "Test:  loss: 0.9083 | accuracy: 0.4932 | f1: 0.4913\n",
            "Validation:  loss: 0.9990 | accuracy: 0.5062 | f1: 0.5061\n",
            "-----------------------------------------------------------------------------------------\n",
            "^NYA\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6970 | accuracy: 0.4611 | f-acore: 0.3249\n",
            "Test:  loss: 0.6936 | accuracy: 0.4740 | f1: 0.4304\n",
            "Validation:  loss: 0.6952 | accuracy: 0.4691 | f1: 0.4572\n",
            "Epoch 00002\n",
            "Train: loss: 0.6933 | accuracy: 0.5238 | f-acore: 0.4740\n",
            "Test:  loss: 0.6843 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6885 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00003\n",
            "Train: loss: 0.6911 | accuracy: 0.5398 | f-acore: 0.3533\n",
            "Test:  loss: 0.6869 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6889 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00004\n",
            "Train: loss: 0.6884 | accuracy: 0.5403 | f-acore: 0.3526\n",
            "Test:  loss: 0.6852 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00005\n",
            "Train: loss: 0.6864 | accuracy: 0.5403 | f-acore: 0.3508\n",
            "Test:  loss: 0.6851 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6867 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00006\n",
            "Train: loss: 0.6880 | accuracy: 0.5403 | f-acore: 0.3517\n",
            "Test:  loss: 0.6854 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00007\n",
            "Train: loss: 0.6871 | accuracy: 0.5421 | f-acore: 0.3569\n",
            "Test:  loss: 0.6883 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00008\n",
            "Train: loss: 0.6852 | accuracy: 0.5389 | f-acore: 0.3538\n",
            "Test:  loss: 0.6862 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6865 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00009\n",
            "Train: loss: 0.6865 | accuracy: 0.5412 | f-acore: 0.3539\n",
            "Test:  loss: 0.6872 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6861 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00010\n",
            "Train: loss: 0.6852 | accuracy: 0.5467 | f-acore: 0.3720\n",
            "Test:  loss: 0.6863 | accuracy: 0.5699 | f1: 0.3630\n",
            "Validation:  loss: 0.6868 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00011\n",
            "Train: loss: 0.6851 | accuracy: 0.5476 | f-acore: 0.3822\n",
            "Test:  loss: 0.6885 | accuracy: 0.5753 | f1: 0.4033\n",
            "Validation:  loss: 0.6878 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00012\n",
            "Train: loss: 0.6854 | accuracy: 0.5472 | f-acore: 0.4120\n",
            "Test:  loss: 0.6883 | accuracy: 0.5562 | f1: 0.4156\n",
            "Validation:  loss: 0.6877 | accuracy: 0.5679 | f1: 0.4755\n",
            "Epoch 00013\n",
            "Train: loss: 0.6832 | accuracy: 0.5696 | f-acore: 0.4902\n",
            "Test:  loss: 0.6888 | accuracy: 0.5562 | f1: 0.4456\n",
            "Validation:  loss: 0.6844 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00014\n",
            "Train: loss: 0.6830 | accuracy: 0.5481 | f-acore: 0.4000\n",
            "Test:  loss: 0.6855 | accuracy: 0.5589 | f1: 0.3750\n",
            "Validation:  loss: 0.6818 | accuracy: 0.5679 | f1: 0.3622\n",
            "Epoch 00015\n",
            "Train: loss: 0.6849 | accuracy: 0.5531 | f-acore: 0.4955\n",
            "Test:  loss: 0.6873 | accuracy: 0.5726 | f1: 0.5049\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5679 | f1: 0.4090\n",
            "Epoch 00016\n",
            "Train: loss: 0.6819 | accuracy: 0.5522 | f-acore: 0.4285\n",
            "Test:  loss: 0.6886 | accuracy: 0.5452 | f1: 0.4572\n",
            "Validation:  loss: 0.6829 | accuracy: 0.5556 | f1: 0.3812\n",
            "Epoch 00017\n",
            "Train: loss: 0.6799 | accuracy: 0.5495 | f-acore: 0.4888\n",
            "Test:  loss: 0.6892 | accuracy: 0.5507 | f1: 0.4692\n",
            "Validation:  loss: 0.6819 | accuracy: 0.6173 | f1: 0.5231\n",
            "Epoch 00018\n",
            "Train: loss: 0.6827 | accuracy: 0.5641 | f-acore: 0.4715\n",
            "Test:  loss: 0.6927 | accuracy: 0.4932 | f1: 0.4781\n",
            "Validation:  loss: 0.6820 | accuracy: 0.6173 | f1: 0.5805\n",
            "Epoch 00019\n",
            "Train: loss: 0.6825 | accuracy: 0.5673 | f-acore: 0.5057\n",
            "Test:  loss: 0.6943 | accuracy: 0.4767 | f1: 0.4757\n",
            "Validation:  loss: 0.6824 | accuracy: 0.6296 | f1: 0.6081\n",
            "Epoch 00020\n",
            "Train: loss: 0.6771 | accuracy: 0.5641 | f-acore: 0.5062\n",
            "Test:  loss: 0.6929 | accuracy: 0.5260 | f1: 0.5033\n",
            "Validation:  loss: 0.6856 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00021\n",
            "Train: loss: 0.6739 | accuracy: 0.5760 | f-acore: 0.5259\n",
            "Test:  loss: 0.6935 | accuracy: 0.4986 | f1: 0.4919\n",
            "Validation:  loss: 0.6844 | accuracy: 0.6173 | f1: 0.6055\n",
            "Epoch 00022\n",
            "Train: loss: 0.6712 | accuracy: 0.5719 | f-acore: 0.5258\n",
            "Test:  loss: 0.6960 | accuracy: 0.4740 | f1: 0.4740\n",
            "Validation:  loss: 0.6845 | accuracy: 0.5802 | f1: 0.5771\n",
            "Epoch 00023\n",
            "Train: loss: 0.6757 | accuracy: 0.5618 | f-acore: 0.4738\n",
            "Test:  loss: 0.6912 | accuracy: 0.5260 | f1: 0.4642\n",
            "Validation:  loss: 0.6801 | accuracy: 0.6173 | f1: 0.6017\n",
            "Epoch 00024\n",
            "Train: loss: 0.6761 | accuracy: 0.5650 | f-acore: 0.4882\n",
            "Test:  loss: 0.6954 | accuracy: 0.4575 | f1: 0.4531\n",
            "Validation:  loss: 0.6837 | accuracy: 0.6049 | f1: 0.5975\n",
            "Epoch 00025\n",
            "Train: loss: 0.6771 | accuracy: 0.5755 | f-acore: 0.5203\n",
            "Test:  loss: 0.6948 | accuracy: 0.4822 | f1: 0.4723\n",
            "Validation:  loss: 0.6828 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00026\n",
            "Train: loss: 0.6699 | accuracy: 0.5820 | f-acore: 0.5484\n",
            "Test:  loss: 0.6988 | accuracy: 0.4630 | f1: 0.4596\n",
            "Validation:  loss: 0.6859 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00027\n",
            "Train: loss: 0.6752 | accuracy: 0.5751 | f-acore: 0.5396\n",
            "Test:  loss: 0.6936 | accuracy: 0.5096 | f1: 0.4822\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5309 | f1: 0.5302\n",
            "Epoch 00028\n",
            "Train: loss: 0.6723 | accuracy: 0.5806 | f-acore: 0.5323\n",
            "Test:  loss: 0.6885 | accuracy: 0.5671 | f1: 0.4490\n",
            "Validation:  loss: 0.6783 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00029\n",
            "Train: loss: 0.6715 | accuracy: 0.5861 | f-acore: 0.5387\n",
            "Test:  loss: 0.6914 | accuracy: 0.5260 | f1: 0.4953\n",
            "Validation:  loss: 0.6798 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00030\n",
            "Train: loss: 0.6701 | accuracy: 0.5701 | f-acore: 0.5406\n",
            "Test:  loss: 0.6968 | accuracy: 0.4986 | f1: 0.4817\n",
            "Validation:  loss: 0.6833 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00031\n",
            "Train: loss: 0.6680 | accuracy: 0.5856 | f-acore: 0.5557\n",
            "Test:  loss: 0.6957 | accuracy: 0.4986 | f1: 0.4806\n",
            "Validation:  loss: 0.6822 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00032\n",
            "Train: loss: 0.6693 | accuracy: 0.5897 | f-acore: 0.5586\n",
            "Test:  loss: 0.6941 | accuracy: 0.5123 | f1: 0.4606\n",
            "Validation:  loss: 0.6855 | accuracy: 0.5926 | f1: 0.5916\n",
            "Epoch 00033\n",
            "Train: loss: 0.6646 | accuracy: 0.5980 | f-acore: 0.5668\n",
            "Test:  loss: 0.6943 | accuracy: 0.5041 | f1: 0.4840\n",
            "Validation:  loss: 0.6827 | accuracy: 0.5802 | f1: 0.5797\n",
            "Epoch 00034\n",
            "Train: loss: 0.6628 | accuracy: 0.6044 | f-acore: 0.5746\n",
            "Test:  loss: 0.6951 | accuracy: 0.4904 | f1: 0.4692\n",
            "Validation:  loss: 0.6803 | accuracy: 0.5679 | f1: 0.5655\n",
            "Epoch 00035\n",
            "Train: loss: 0.6636 | accuracy: 0.5925 | f-acore: 0.5485\n",
            "Test:  loss: 0.6918 | accuracy: 0.5425 | f1: 0.4662\n",
            "Validation:  loss: 0.6818 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00036\n",
            "Train: loss: 0.6603 | accuracy: 0.6021 | f-acore: 0.5852\n",
            "Test:  loss: 0.6912 | accuracy: 0.5260 | f1: 0.4787\n",
            "Validation:  loss: 0.6789 | accuracy: 0.6173 | f1: 0.6135\n",
            "Epoch 00037\n",
            "Train: loss: 0.6639 | accuracy: 0.6012 | f-acore: 0.5661\n",
            "Test:  loss: 0.6962 | accuracy: 0.4849 | f1: 0.4807\n",
            "Validation:  loss: 0.6821 | accuracy: 0.5556 | f1: 0.5555\n",
            "Epoch 00038\n",
            "Train: loss: 0.6672 | accuracy: 0.5948 | f-acore: 0.5919\n",
            "Test:  loss: 0.6944 | accuracy: 0.5068 | f1: 0.4660\n",
            "Validation:  loss: 0.6783 | accuracy: 0.6296 | f1: 0.6126\n",
            "Epoch 00039\n",
            "Train: loss: 0.6610 | accuracy: 0.6094 | f-acore: 0.5676\n",
            "Test:  loss: 0.6951 | accuracy: 0.5205 | f1: 0.5011\n",
            "Validation:  loss: 0.6822 | accuracy: 0.6049 | f1: 0.6049\n",
            "Epoch 00040\n",
            "Train: loss: 0.6606 | accuracy: 0.6131 | f-acore: 0.5999\n",
            "Test:  loss: 0.6951 | accuracy: 0.5178 | f1: 0.4687\n",
            "Validation:  loss: 0.6804 | accuracy: 0.6296 | f1: 0.6029\n",
            "Epoch 00041\n",
            "Train: loss: 0.6579 | accuracy: 0.6012 | f-acore: 0.5690\n",
            "Test:  loss: 0.6961 | accuracy: 0.4904 | f1: 0.4867\n",
            "Validation:  loss: 0.6794 | accuracy: 0.5679 | f1: 0.5668\n",
            "Epoch 00042\n",
            "Train: loss: 0.6540 | accuracy: 0.5948 | f-acore: 0.5796\n",
            "Test:  loss: 0.6931 | accuracy: 0.5233 | f1: 0.4687\n",
            "Validation:  loss: 0.6767 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00043\n",
            "Train: loss: 0.6570 | accuracy: 0.6136 | f-acore: 0.5929\n",
            "Test:  loss: 0.7007 | accuracy: 0.4986 | f1: 0.4942\n",
            "Validation:  loss: 0.6790 | accuracy: 0.5802 | f1: 0.5786\n",
            "Epoch 00044\n",
            "Train: loss: 0.6511 | accuracy: 0.6186 | f-acore: 0.6076\n",
            "Test:  loss: 0.6975 | accuracy: 0.5096 | f1: 0.4978\n",
            "Validation:  loss: 0.6803 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00045\n",
            "Train: loss: 0.6513 | accuracy: 0.6081 | f-acore: 0.5821\n",
            "Test:  loss: 0.6999 | accuracy: 0.5068 | f1: 0.5028\n",
            "Validation:  loss: 0.6819 | accuracy: 0.6296 | f1: 0.6291\n",
            "Epoch 00046\n",
            "Train: loss: 0.6496 | accuracy: 0.6076 | f-acore: 0.5963\n",
            "Test:  loss: 0.6974 | accuracy: 0.5014 | f1: 0.4818\n",
            "Validation:  loss: 0.6786 | accuracy: 0.6173 | f1: 0.6114\n",
            "Epoch 00047\n",
            "Train: loss: 0.6436 | accuracy: 0.6158 | f-acore: 0.5971\n",
            "Test:  loss: 0.6912 | accuracy: 0.5425 | f1: 0.4581\n",
            "Validation:  loss: 0.6731 | accuracy: 0.5679 | f1: 0.4880\n",
            "Epoch 00048\n",
            "Train: loss: 0.6447 | accuracy: 0.6049 | f-acore: 0.5776\n",
            "Test:  loss: 0.6966 | accuracy: 0.4822 | f1: 0.4812\n",
            "Validation:  loss: 0.6839 | accuracy: 0.5802 | f1: 0.5786\n",
            "Epoch 00049\n",
            "Train: loss: 0.6469 | accuracy: 0.6264 | f-acore: 0.6180\n",
            "Test:  loss: 0.6981 | accuracy: 0.4712 | f1: 0.4705\n",
            "Validation:  loss: 0.6753 | accuracy: 0.6296 | f1: 0.6282\n",
            "Epoch 00050\n",
            "Train: loss: 0.6423 | accuracy: 0.6158 | f-acore: 0.6034\n",
            "Test:  loss: 0.7001 | accuracy: 0.4904 | f1: 0.4902\n",
            "Validation:  loss: 0.6792 | accuracy: 0.5926 | f1: 0.5923\n",
            "Epoch 00051\n",
            "Train: loss: 0.6404 | accuracy: 0.6287 | f-acore: 0.6204\n",
            "Test:  loss: 0.7000 | accuracy: 0.4904 | f1: 0.4887\n",
            "Validation:  loss: 0.6784 | accuracy: 0.6420 | f1: 0.6418\n",
            "Epoch 00052\n",
            "Train: loss: 0.6459 | accuracy: 0.6113 | f-acore: 0.5928\n",
            "Test:  loss: 0.6970 | accuracy: 0.5068 | f1: 0.4978\n",
            "Validation:  loss: 0.6774 | accuracy: 0.6296 | f1: 0.6250\n",
            "Epoch 00053\n",
            "Train: loss: 0.6506 | accuracy: 0.6131 | f-acore: 0.5995\n",
            "Test:  loss: 0.6985 | accuracy: 0.5178 | f1: 0.4941\n",
            "Validation:  loss: 0.6752 | accuracy: 0.6173 | f1: 0.5974\n",
            "Epoch 00054\n",
            "Train: loss: 0.6421 | accuracy: 0.6296 | f-acore: 0.6257\n",
            "Test:  loss: 0.6971 | accuracy: 0.4822 | f1: 0.4454\n",
            "Validation:  loss: 0.6753 | accuracy: 0.6543 | f1: 0.6530\n",
            "Epoch 00055\n",
            "Train: loss: 0.6481 | accuracy: 0.6305 | f-acore: 0.6143\n",
            "Test:  loss: 0.7024 | accuracy: 0.4959 | f1: 0.4894\n",
            "Validation:  loss: 0.6768 | accuracy: 0.6173 | f1: 0.6163\n",
            "Epoch 00056\n",
            "Train: loss: 0.6426 | accuracy: 0.6337 | f-acore: 0.6279\n",
            "Test:  loss: 0.7077 | accuracy: 0.4849 | f1: 0.4847\n",
            "Validation:  loss: 0.6758 | accuracy: 0.6420 | f1: 0.6400\n",
            "Epoch 00057\n",
            "Train: loss: 0.6368 | accuracy: 0.6310 | f-acore: 0.6300\n",
            "Test:  loss: 0.7082 | accuracy: 0.4658 | f1: 0.4657\n",
            "Validation:  loss: 0.6721 | accuracy: 0.6543 | f1: 0.6530\n",
            "Epoch 00058\n",
            "Train: loss: 0.6311 | accuracy: 0.6268 | f-acore: 0.6120\n",
            "Test:  loss: 0.7054 | accuracy: 0.4740 | f1: 0.4739\n",
            "Validation:  loss: 0.6725 | accuracy: 0.6173 | f1: 0.6171\n",
            "Epoch 00059\n",
            "Train: loss: 0.6362 | accuracy: 0.6488 | f-acore: 0.6415\n",
            "Test:  loss: 0.7039 | accuracy: 0.4959 | f1: 0.4907\n",
            "Validation:  loss: 0.6726 | accuracy: 0.6420 | f1: 0.6339\n",
            "Epoch 00060\n",
            "Train: loss: 0.6266 | accuracy: 0.6346 | f-acore: 0.6209\n",
            "Test:  loss: 0.7060 | accuracy: 0.4795 | f1: 0.4766\n",
            "Validation:  loss: 0.6774 | accuracy: 0.6049 | f1: 0.6000\n",
            "Epoch 00061\n",
            "Train: loss: 0.6314 | accuracy: 0.6383 | f-acore: 0.6328\n",
            "Test:  loss: 0.7113 | accuracy: 0.4630 | f1: 0.4628\n",
            "Validation:  loss: 0.6684 | accuracy: 0.5926 | f1: 0.5886\n",
            "Epoch 00062\n",
            "Train: loss: 0.6345 | accuracy: 0.6497 | f-acore: 0.6412\n",
            "Test:  loss: 0.7053 | accuracy: 0.4877 | f1: 0.4837\n",
            "Validation:  loss: 0.6749 | accuracy: 0.6173 | f1: 0.6171\n",
            "Epoch 00063\n",
            "Train: loss: 0.6271 | accuracy: 0.6401 | f-acore: 0.6327\n",
            "Test:  loss: 0.7053 | accuracy: 0.4603 | f1: 0.4566\n",
            "Validation:  loss: 0.6791 | accuracy: 0.6049 | f1: 0.6049\n",
            "Epoch 00064\n",
            "Train: loss: 0.6271 | accuracy: 0.6392 | f-acore: 0.6296\n",
            "Test:  loss: 0.7006 | accuracy: 0.4932 | f1: 0.4818\n",
            "Validation:  loss: 0.6790 | accuracy: 0.5926 | f1: 0.5761\n",
            "Epoch 00065\n",
            "Train: loss: 0.6205 | accuracy: 0.6566 | f-acore: 0.6429\n",
            "Test:  loss: 0.7019 | accuracy: 0.5342 | f1: 0.4629\n",
            "Validation:  loss: 0.6726 | accuracy: 0.5556 | f1: 0.4902\n",
            "Epoch 00066\n",
            "Train: loss: 0.6215 | accuracy: 0.6442 | f-acore: 0.6310\n",
            "Test:  loss: 0.7080 | accuracy: 0.4849 | f1: 0.4783\n",
            "Validation:  loss: 0.6750 | accuracy: 0.6173 | f1: 0.5974\n",
            "Epoch 00067\n",
            "Train: loss: 0.6350 | accuracy: 0.6419 | f-acore: 0.6351\n",
            "Test:  loss: 0.7055 | accuracy: 0.4904 | f1: 0.4748\n",
            "Validation:  loss: 0.6671 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00068\n",
            "Train: loss: 0.6191 | accuracy: 0.6383 | f-acore: 0.6308\n",
            "Test:  loss: 0.7047 | accuracy: 0.4767 | f1: 0.4744\n",
            "Validation:  loss: 0.6727 | accuracy: 0.6420 | f1: 0.6384\n",
            "Epoch 00069\n",
            "Train: loss: 0.6272 | accuracy: 0.6525 | f-acore: 0.6449\n",
            "Test:  loss: 0.7068 | accuracy: 0.4740 | f1: 0.4719\n",
            "Validation:  loss: 0.6772 | accuracy: 0.6049 | f1: 0.6034\n",
            "Epoch 00070\n",
            "Train: loss: 0.6267 | accuracy: 0.6474 | f-acore: 0.6415\n",
            "Test:  loss: 0.7062 | accuracy: 0.4740 | f1: 0.4626\n",
            "Validation:  loss: 0.6734 | accuracy: 0.6049 | f1: 0.5909\n",
            "Epoch 00071\n",
            "Train: loss: 0.6088 | accuracy: 0.6548 | f-acore: 0.6460\n",
            "Test:  loss: 0.7100 | accuracy: 0.4767 | f1: 0.4727\n",
            "Validation:  loss: 0.6686 | accuracy: 0.6420 | f1: 0.6234\n",
            "Epoch 00072\n",
            "Train: loss: 0.6130 | accuracy: 0.6502 | f-acore: 0.6387\n",
            "Test:  loss: 0.7080 | accuracy: 0.4822 | f1: 0.4668\n",
            "Validation:  loss: 0.6709 | accuracy: 0.6049 | f1: 0.5765\n",
            "Epoch 00073\n",
            "Train: loss: 0.6270 | accuracy: 0.6584 | f-acore: 0.6519\n",
            "Test:  loss: 0.7143 | accuracy: 0.4822 | f1: 0.4731\n",
            "Validation:  loss: 0.6729 | accuracy: 0.6049 | f1: 0.5765\n",
            "Epoch 00074\n",
            "Train: loss: 0.6168 | accuracy: 0.6625 | f-acore: 0.6564\n",
            "Test:  loss: 0.7073 | accuracy: 0.5151 | f1: 0.4722\n",
            "Validation:  loss: 0.6708 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00075\n",
            "Train: loss: 0.6108 | accuracy: 0.6529 | f-acore: 0.6410\n",
            "Test:  loss: 0.7088 | accuracy: 0.4932 | f1: 0.4520\n",
            "Validation:  loss: 0.6683 | accuracy: 0.5926 | f1: 0.5601\n",
            "Epoch 00076\n",
            "Train: loss: 0.6117 | accuracy: 0.6630 | f-acore: 0.6545\n",
            "Test:  loss: 0.7126 | accuracy: 0.4685 | f1: 0.4552\n",
            "Validation:  loss: 0.6713 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00077\n",
            "Train: loss: 0.6063 | accuracy: 0.6662 | f-acore: 0.6603\n",
            "Test:  loss: 0.7134 | accuracy: 0.5288 | f1: 0.4845\n",
            "Validation:  loss: 0.6681 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00078\n",
            "Train: loss: 0.6233 | accuracy: 0.6667 | f-acore: 0.6594\n",
            "Test:  loss: 0.7128 | accuracy: 0.5041 | f1: 0.4852\n",
            "Validation:  loss: 0.6703 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00079\n",
            "Train: loss: 0.6073 | accuracy: 0.6557 | f-acore: 0.6467\n",
            "Test:  loss: 0.7197 | accuracy: 0.5123 | f1: 0.4964\n",
            "Validation:  loss: 0.6752 | accuracy: 0.5926 | f1: 0.5601\n",
            "Epoch 00080\n",
            "Train: loss: 0.6158 | accuracy: 0.6662 | f-acore: 0.6594\n",
            "Test:  loss: 0.7157 | accuracy: 0.4932 | f1: 0.4771\n",
            "Validation:  loss: 0.6803 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00081\n",
            "Train: loss: 0.6045 | accuracy: 0.6635 | f-acore: 0.6544\n",
            "Test:  loss: 0.7141 | accuracy: 0.4849 | f1: 0.4711\n",
            "Validation:  loss: 0.6780 | accuracy: 0.5926 | f1: 0.5714\n",
            "Epoch 00082\n",
            "Train: loss: 0.6120 | accuracy: 0.6836 | f-acore: 0.6824\n",
            "Test:  loss: 0.7125 | accuracy: 0.4904 | f1: 0.4612\n",
            "Validation:  loss: 0.6694 | accuracy: 0.6049 | f1: 0.5765\n",
            "Epoch 00083\n",
            "Train: loss: 0.5990 | accuracy: 0.6708 | f-acore: 0.6648\n",
            "Test:  loss: 0.7183 | accuracy: 0.4822 | f1: 0.4759\n",
            "Validation:  loss: 0.6775 | accuracy: 0.5802 | f1: 0.5558\n",
            "Epoch 00084\n",
            "Train: loss: 0.5930 | accuracy: 0.6758 | f-acore: 0.6707\n",
            "Test:  loss: 0.7217 | accuracy: 0.4959 | f1: 0.4842\n",
            "Validation:  loss: 0.6780 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00085\n",
            "Train: loss: 0.6025 | accuracy: 0.6662 | f-acore: 0.6609\n",
            "Test:  loss: 0.7170 | accuracy: 0.4904 | f1: 0.4811\n",
            "Validation:  loss: 0.6763 | accuracy: 0.5926 | f1: 0.5714\n",
            "Epoch 00086\n",
            "Train: loss: 0.6088 | accuracy: 0.6818 | f-acore: 0.6749\n",
            "Test:  loss: 0.7208 | accuracy: 0.4932 | f1: 0.4726\n",
            "Validation:  loss: 0.6663 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00087\n",
            "Train: loss: 0.6096 | accuracy: 0.6671 | f-acore: 0.6642\n",
            "Test:  loss: 0.7239 | accuracy: 0.5014 | f1: 0.4713\n",
            "Validation:  loss: 0.6650 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00088\n",
            "Train: loss: 0.6037 | accuracy: 0.6685 | f-acore: 0.6619\n",
            "Test:  loss: 0.7235 | accuracy: 0.4932 | f1: 0.4619\n",
            "Validation:  loss: 0.6699 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00089\n",
            "Train: loss: 0.6036 | accuracy: 0.6616 | f-acore: 0.6511\n",
            "Test:  loss: 0.7205 | accuracy: 0.4932 | f1: 0.4760\n",
            "Validation:  loss: 0.6712 | accuracy: 0.5802 | f1: 0.5609\n",
            "Epoch 00090\n",
            "Train: loss: 0.5863 | accuracy: 0.6662 | f-acore: 0.6636\n",
            "Test:  loss: 0.7278 | accuracy: 0.4986 | f1: 0.4579\n",
            "Validation:  loss: 0.6724 | accuracy: 0.5802 | f1: 0.5434\n",
            "Epoch 00091\n",
            "Train: loss: 0.6001 | accuracy: 0.6745 | f-acore: 0.6663\n",
            "Test:  loss: 0.7229 | accuracy: 0.4822 | f1: 0.4574\n",
            "Validation:  loss: 0.6722 | accuracy: 0.5802 | f1: 0.5558\n",
            "Epoch 00092\n",
            "Train: loss: 0.5950 | accuracy: 0.6781 | f-acore: 0.6733\n",
            "Test:  loss: 0.7316 | accuracy: 0.4959 | f1: 0.4724\n",
            "Validation:  loss: 0.6728 | accuracy: 0.5556 | f1: 0.5235\n",
            "Epoch 00093\n",
            "Train: loss: 0.5921 | accuracy: 0.6813 | f-acore: 0.6774\n",
            "Test:  loss: 0.7219 | accuracy: 0.4795 | f1: 0.4525\n",
            "Validation:  loss: 0.6691 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00094\n",
            "Train: loss: 0.5882 | accuracy: 0.6914 | f-acore: 0.6850\n",
            "Test:  loss: 0.7277 | accuracy: 0.4959 | f1: 0.4783\n",
            "Validation:  loss: 0.6732 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00095\n",
            "Train: loss: 0.5937 | accuracy: 0.6763 | f-acore: 0.6732\n",
            "Test:  loss: 0.7294 | accuracy: 0.5041 | f1: 0.4705\n",
            "Validation:  loss: 0.6751 | accuracy: 0.5802 | f1: 0.5434\n",
            "Epoch 00096\n",
            "Train: loss: 0.5907 | accuracy: 0.6818 | f-acore: 0.6739\n",
            "Test:  loss: 0.7281 | accuracy: 0.5014 | f1: 0.4829\n",
            "Validation:  loss: 0.6824 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00097\n",
            "Train: loss: 0.6123 | accuracy: 0.6836 | f-acore: 0.6802\n",
            "Test:  loss: 0.7264 | accuracy: 0.4877 | f1: 0.4561\n",
            "Validation:  loss: 0.6767 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00098\n",
            "Train: loss: 0.5976 | accuracy: 0.6905 | f-acore: 0.6884\n",
            "Test:  loss: 0.7294 | accuracy: 0.5014 | f1: 0.4506\n",
            "Validation:  loss: 0.6710 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00099\n",
            "Train: loss: 0.5981 | accuracy: 0.6854 | f-acore: 0.6757\n",
            "Test:  loss: 0.7267 | accuracy: 0.4822 | f1: 0.4624\n",
            "Validation:  loss: 0.6676 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00100\n",
            "Train: loss: 0.5957 | accuracy: 0.6822 | f-acore: 0.6777\n",
            "Test:  loss: 0.7299 | accuracy: 0.4849 | f1: 0.4492\n",
            "Validation:  loss: 0.6745 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00101\n",
            "Train: loss: 0.5981 | accuracy: 0.6804 | f-acore: 0.6760\n",
            "Test:  loss: 0.7269 | accuracy: 0.4986 | f1: 0.4706\n",
            "Validation:  loss: 0.6755 | accuracy: 0.5556 | f1: 0.5166\n",
            "Epoch 00102\n",
            "Train: loss: 0.5857 | accuracy: 0.6937 | f-acore: 0.6922\n",
            "Test:  loss: 0.7282 | accuracy: 0.4959 | f1: 0.4866\n",
            "Validation:  loss: 0.6679 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00103\n",
            "Train: loss: 0.5914 | accuracy: 0.6836 | f-acore: 0.6792\n",
            "Test:  loss: 0.7374 | accuracy: 0.4877 | f1: 0.4657\n",
            "Validation:  loss: 0.6730 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00104\n",
            "Train: loss: 0.5806 | accuracy: 0.6941 | f-acore: 0.6907\n",
            "Test:  loss: 0.7348 | accuracy: 0.4822 | f1: 0.4437\n",
            "Validation:  loss: 0.6772 | accuracy: 0.5556 | f1: 0.5166\n",
            "Epoch 00105\n",
            "Train: loss: 0.5858 | accuracy: 0.6983 | f-acore: 0.6933\n",
            "Test:  loss: 0.7328 | accuracy: 0.4849 | f1: 0.4554\n",
            "Validation:  loss: 0.6684 | accuracy: 0.5556 | f1: 0.5166\n",
            "Epoch 00106\n",
            "Train: loss: 0.5839 | accuracy: 0.6854 | f-acore: 0.6816\n",
            "Test:  loss: 0.7355 | accuracy: 0.4986 | f1: 0.4562\n",
            "Validation:  loss: 0.6774 | accuracy: 0.5556 | f1: 0.5166\n",
            "Epoch 00107\n",
            "Train: loss: 0.5853 | accuracy: 0.6983 | f-acore: 0.6913\n",
            "Test:  loss: 0.7418 | accuracy: 0.4959 | f1: 0.4772\n",
            "Validation:  loss: 0.6762 | accuracy: 0.5802 | f1: 0.5434\n",
            "Epoch 00108\n",
            "Train: loss: 0.5800 | accuracy: 0.6896 | f-acore: 0.6860\n",
            "Test:  loss: 0.7487 | accuracy: 0.4932 | f1: 0.4850\n",
            "Validation:  loss: 0.6759 | accuracy: 0.5926 | f1: 0.5661\n",
            "Epoch 00109\n",
            "Train: loss: 0.5717 | accuracy: 0.6987 | f-acore: 0.6967\n",
            "Test:  loss: 0.7523 | accuracy: 0.4986 | f1: 0.4759\n",
            "Validation:  loss: 0.6722 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00110\n",
            "Train: loss: 0.5733 | accuracy: 0.7015 | f-acore: 0.6973\n",
            "Test:  loss: 0.7528 | accuracy: 0.4849 | f1: 0.4568\n",
            "Validation:  loss: 0.6791 | accuracy: 0.5432 | f1: 0.5068\n",
            "Epoch 00111\n",
            "Train: loss: 0.5709 | accuracy: 0.6983 | f-acore: 0.6936\n",
            "Test:  loss: 0.7477 | accuracy: 0.4822 | f1: 0.4454\n",
            "Validation:  loss: 0.6810 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00112\n",
            "Train: loss: 0.5765 | accuracy: 0.7079 | f-acore: 0.7050\n",
            "Test:  loss: 0.7505 | accuracy: 0.4877 | f1: 0.4604\n",
            "Validation:  loss: 0.6748 | accuracy: 0.5309 | f1: 0.4971\n",
            "Epoch 00113\n",
            "Train: loss: 0.5727 | accuracy: 0.6813 | f-acore: 0.6765\n",
            "Test:  loss: 0.7575 | accuracy: 0.4822 | f1: 0.4574\n",
            "Validation:  loss: 0.6705 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00114\n",
            "Train: loss: 0.5757 | accuracy: 0.7019 | f-acore: 0.6976\n",
            "Test:  loss: 0.7538 | accuracy: 0.4932 | f1: 0.4294\n",
            "Validation:  loss: 0.6786 | accuracy: 0.5556 | f1: 0.5166\n",
            "Epoch 00115\n",
            "Train: loss: 0.5751 | accuracy: 0.6960 | f-acore: 0.6917\n",
            "Test:  loss: 0.7458 | accuracy: 0.5178 | f1: 0.4182\n",
            "Validation:  loss: 0.6884 | accuracy: 0.5309 | f1: 0.4815\n",
            "Epoch 00116\n",
            "Train: loss: 0.5605 | accuracy: 0.6946 | f-acore: 0.6886\n",
            "Test:  loss: 0.7457 | accuracy: 0.4877 | f1: 0.4385\n",
            "Validation:  loss: 0.6806 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00117\n",
            "Train: loss: 0.5712 | accuracy: 0.6987 | f-acore: 0.6953\n",
            "Test:  loss: 0.7555 | accuracy: 0.4822 | f1: 0.4345\n",
            "Validation:  loss: 0.6791 | accuracy: 0.5185 | f1: 0.4935\n",
            "Epoch 00118\n",
            "Train: loss: 0.5780 | accuracy: 0.7074 | f-acore: 0.7022\n",
            "Test:  loss: 0.7554 | accuracy: 0.4986 | f1: 0.4505\n",
            "Validation:  loss: 0.6803 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00119\n",
            "Train: loss: 0.5777 | accuracy: 0.6951 | f-acore: 0.6896\n",
            "Test:  loss: 0.7558 | accuracy: 0.4822 | f1: 0.4345\n",
            "Validation:  loss: 0.6802 | accuracy: 0.5432 | f1: 0.5068\n",
            "Epoch 00120\n",
            "Train: loss: 0.5594 | accuracy: 0.7079 | f-acore: 0.7051\n",
            "Test:  loss: 0.7559 | accuracy: 0.4822 | f1: 0.4678\n",
            "Validation:  loss: 0.6788 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00121\n",
            "Train: loss: 0.5800 | accuracy: 0.6978 | f-acore: 0.6926\n",
            "Test:  loss: 0.7481 | accuracy: 0.4877 | f1: 0.4762\n",
            "Validation:  loss: 0.6845 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00122\n",
            "Train: loss: 0.5706 | accuracy: 0.6996 | f-acore: 0.6954\n",
            "Test:  loss: 0.7370 | accuracy: 0.4849 | f1: 0.4259\n",
            "Validation:  loss: 0.6972 | accuracy: 0.5556 | f1: 0.5235\n",
            "Epoch 00123\n",
            "Train: loss: 0.5674 | accuracy: 0.7028 | f-acore: 0.7006\n",
            "Test:  loss: 0.7429 | accuracy: 0.4959 | f1: 0.4425\n",
            "Validation:  loss: 0.6932 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00124\n",
            "Train: loss: 0.5682 | accuracy: 0.7074 | f-acore: 0.7029\n",
            "Test:  loss: 0.7600 | accuracy: 0.4822 | f1: 0.4454\n",
            "Validation:  loss: 0.6894 | accuracy: 0.5802 | f1: 0.5500\n",
            "Epoch 00125\n",
            "Train: loss: 0.5569 | accuracy: 0.7088 | f-acore: 0.7033\n",
            "Test:  loss: 0.7694 | accuracy: 0.4822 | f1: 0.4325\n",
            "Validation:  loss: 0.6892 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00126\n",
            "Train: loss: 0.5928 | accuracy: 0.6946 | f-acore: 0.6906\n",
            "Test:  loss: 0.7531 | accuracy: 0.4767 | f1: 0.4395\n",
            "Validation:  loss: 0.6919 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00127\n",
            "Train: loss: 0.5638 | accuracy: 0.7065 | f-acore: 0.7035\n",
            "Test:  loss: 0.7467 | accuracy: 0.4795 | f1: 0.4565\n",
            "Validation:  loss: 0.6861 | accuracy: 0.5802 | f1: 0.5653\n",
            "Epoch 00128\n",
            "Train: loss: 0.5609 | accuracy: 0.7134 | f-acore: 0.7112\n",
            "Test:  loss: 0.7462 | accuracy: 0.4795 | f1: 0.4305\n",
            "Validation:  loss: 0.6989 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00129\n",
            "Train: loss: 0.5690 | accuracy: 0.7134 | f-acore: 0.7104\n",
            "Test:  loss: 0.7569 | accuracy: 0.4740 | f1: 0.4391\n",
            "Validation:  loss: 0.6964 | accuracy: 0.5309 | f1: 0.5035\n",
            "Epoch 00130\n",
            "Train: loss: 0.5543 | accuracy: 0.7189 | f-acore: 0.7144\n",
            "Test:  loss: 0.7648 | accuracy: 0.4685 | f1: 0.4244\n",
            "Validation:  loss: 0.6986 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00131\n",
            "Train: loss: 0.5558 | accuracy: 0.7015 | f-acore: 0.6981\n",
            "Test:  loss: 0.7580 | accuracy: 0.4685 | f1: 0.4263\n",
            "Validation:  loss: 0.7050 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00132\n",
            "Train: loss: 0.5682 | accuracy: 0.7097 | f-acore: 0.7053\n",
            "Test:  loss: 0.7683 | accuracy: 0.4712 | f1: 0.4302\n",
            "Validation:  loss: 0.7001 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00133\n",
            "Train: loss: 0.5676 | accuracy: 0.7170 | f-acore: 0.7124\n",
            "Test:  loss: 0.7763 | accuracy: 0.5123 | f1: 0.4268\n",
            "Validation:  loss: 0.7058 | accuracy: 0.5679 | f1: 0.5183\n",
            "Epoch 00134\n",
            "Train: loss: 0.5557 | accuracy: 0.7198 | f-acore: 0.7159\n",
            "Test:  loss: 0.7501 | accuracy: 0.4959 | f1: 0.4132\n",
            "Validation:  loss: 0.7075 | accuracy: 0.5309 | f1: 0.4897\n",
            "Epoch 00135\n",
            "Train: loss: 0.5754 | accuracy: 0.7202 | f-acore: 0.7174\n",
            "Test:  loss: 0.7598 | accuracy: 0.4904 | f1: 0.4321\n",
            "Validation:  loss: 0.7040 | accuracy: 0.5185 | f1: 0.4802\n",
            "Epoch 00136\n",
            "Train: loss: 0.5600 | accuracy: 0.7065 | f-acore: 0.6999\n",
            "Test:  loss: 0.7578 | accuracy: 0.4630 | f1: 0.4061\n",
            "Validation:  loss: 0.7103 | accuracy: 0.5309 | f1: 0.5092\n",
            "Epoch 00137\n",
            "Train: loss: 0.5634 | accuracy: 0.7051 | f-acore: 0.7026\n",
            "Test:  loss: 0.7727 | accuracy: 0.5014 | f1: 0.4351\n",
            "Validation:  loss: 0.7052 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00138\n",
            "Train: loss: 0.5435 | accuracy: 0.7179 | f-acore: 0.7134\n",
            "Test:  loss: 0.7744 | accuracy: 0.4877 | f1: 0.4279\n",
            "Validation:  loss: 0.7075 | accuracy: 0.5556 | f1: 0.5235\n",
            "Epoch 00139\n",
            "Train: loss: 0.5520 | accuracy: 0.7147 | f-acore: 0.7106\n",
            "Test:  loss: 0.7661 | accuracy: 0.4685 | f1: 0.4365\n",
            "Validation:  loss: 0.7041 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00140\n",
            "Train: loss: 0.5535 | accuracy: 0.7276 | f-acore: 0.7260\n",
            "Test:  loss: 0.7792 | accuracy: 0.4685 | f1: 0.4225\n",
            "Validation:  loss: 0.7064 | accuracy: 0.5309 | f1: 0.4971\n",
            "Epoch 00141\n",
            "Train: loss: 0.5368 | accuracy: 0.7225 | f-acore: 0.7196\n",
            "Test:  loss: 0.7792 | accuracy: 0.5041 | f1: 0.4546\n",
            "Validation:  loss: 0.7160 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00142\n",
            "Train: loss: 0.5533 | accuracy: 0.7179 | f-acore: 0.7149\n",
            "Test:  loss: 0.7656 | accuracy: 0.4767 | f1: 0.4305\n",
            "Validation:  loss: 0.7112 | accuracy: 0.5309 | f1: 0.5092\n",
            "Epoch 00143\n",
            "Train: loss: 0.5581 | accuracy: 0.7285 | f-acore: 0.7255\n",
            "Test:  loss: 0.7718 | accuracy: 0.4685 | f1: 0.4143\n",
            "Validation:  loss: 0.7047 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00144\n",
            "Train: loss: 0.5542 | accuracy: 0.7079 | f-acore: 0.7069\n",
            "Test:  loss: 0.7736 | accuracy: 0.4904 | f1: 0.4321\n",
            "Validation:  loss: 0.7131 | accuracy: 0.5309 | f1: 0.4971\n",
            "Epoch 00145\n",
            "Train: loss: 0.5423 | accuracy: 0.7184 | f-acore: 0.7136\n",
            "Test:  loss: 0.7606 | accuracy: 0.4904 | f1: 0.4177\n",
            "Validation:  loss: 0.7088 | accuracy: 0.5556 | f1: 0.5166\n",
            "Epoch 00146\n",
            "Train: loss: 0.5391 | accuracy: 0.7193 | f-acore: 0.7143\n",
            "Test:  loss: 0.7751 | accuracy: 0.4658 | f1: 0.4312\n",
            "Validation:  loss: 0.7103 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00147\n",
            "Train: loss: 0.5538 | accuracy: 0.7147 | f-acore: 0.7113\n",
            "Test:  loss: 0.7729 | accuracy: 0.4822 | f1: 0.4345\n",
            "Validation:  loss: 0.7141 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00148\n",
            "Train: loss: 0.5535 | accuracy: 0.7271 | f-acore: 0.7217\n",
            "Test:  loss: 0.7955 | accuracy: 0.5260 | f1: 0.4470\n",
            "Validation:  loss: 0.7127 | accuracy: 0.5556 | f1: 0.5235\n",
            "Epoch 00149\n",
            "Train: loss: 0.5725 | accuracy: 0.7271 | f-acore: 0.7260\n",
            "Test:  loss: 0.7919 | accuracy: 0.4740 | f1: 0.4225\n",
            "Validation:  loss: 0.7165 | accuracy: 0.5802 | f1: 0.5558\n",
            "Epoch 00150\n",
            "Train: loss: 0.5404 | accuracy: 0.7239 | f-acore: 0.7189\n",
            "Test:  loss: 0.7922 | accuracy: 0.4959 | f1: 0.4187\n",
            "Validation:  loss: 0.7125 | accuracy: 0.5556 | f1: 0.5088\n",
            "Epoch 00151\n",
            "Train: loss: 0.5437 | accuracy: 0.7138 | f-acore: 0.7102\n",
            "Test:  loss: 0.7668 | accuracy: 0.4904 | f1: 0.4227\n",
            "Validation:  loss: 0.7176 | accuracy: 0.5556 | f1: 0.5235\n",
            "Epoch 00152\n",
            "Train: loss: 0.5356 | accuracy: 0.7308 | f-acore: 0.7271\n",
            "Test:  loss: 0.7760 | accuracy: 0.4575 | f1: 0.4216\n",
            "Validation:  loss: 0.7184 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00153\n",
            "Train: loss: 0.5558 | accuracy: 0.7060 | f-acore: 0.7039\n",
            "Test:  loss: 0.7815 | accuracy: 0.4877 | f1: 0.4545\n",
            "Validation:  loss: 0.7202 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00154\n",
            "Train: loss: 0.5453 | accuracy: 0.7266 | f-acore: 0.7211\n",
            "Test:  loss: 0.7879 | accuracy: 0.4767 | f1: 0.4503\n",
            "Validation:  loss: 0.7164 | accuracy: 0.5309 | f1: 0.5035\n",
            "Epoch 00155\n",
            "Train: loss: 0.5402 | accuracy: 0.7234 | f-acore: 0.7209\n",
            "Test:  loss: 0.7832 | accuracy: 0.4658 | f1: 0.4278\n",
            "Validation:  loss: 0.7224 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00156\n",
            "Train: loss: 0.5390 | accuracy: 0.7376 | f-acore: 0.7332\n",
            "Test:  loss: 0.8089 | accuracy: 0.5014 | f1: 0.4276\n",
            "Validation:  loss: 0.7193 | accuracy: 0.5802 | f1: 0.5434\n",
            "Epoch 00157\n",
            "Train: loss: 0.5395 | accuracy: 0.7321 | f-acore: 0.7284\n",
            "Test:  loss: 0.7967 | accuracy: 0.4767 | f1: 0.4361\n",
            "Validation:  loss: 0.7163 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00158\n",
            "Train: loss: 0.5332 | accuracy: 0.7198 | f-acore: 0.7167\n",
            "Test:  loss: 0.8010 | accuracy: 0.4822 | f1: 0.4345\n",
            "Validation:  loss: 0.7253 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00159\n",
            "Train: loss: 0.5359 | accuracy: 0.7225 | f-acore: 0.7182\n",
            "Test:  loss: 0.8111 | accuracy: 0.4685 | f1: 0.4395\n",
            "Validation:  loss: 0.7296 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00160\n",
            "Train: loss: 0.5489 | accuracy: 0.7202 | f-acore: 0.7157\n",
            "Test:  loss: 0.7883 | accuracy: 0.4849 | f1: 0.4596\n",
            "Validation:  loss: 0.7274 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00161\n",
            "Train: loss: 0.5300 | accuracy: 0.7376 | f-acore: 0.7356\n",
            "Test:  loss: 0.8006 | accuracy: 0.5041 | f1: 0.4394\n",
            "Validation:  loss: 0.7206 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00162\n",
            "Train: loss: 0.5355 | accuracy: 0.7349 | f-acore: 0.7313\n",
            "Test:  loss: 0.7952 | accuracy: 0.4822 | f1: 0.4325\n",
            "Validation:  loss: 0.7237 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00163\n",
            "Train: loss: 0.5376 | accuracy: 0.7207 | f-acore: 0.7177\n",
            "Test:  loss: 0.7928 | accuracy: 0.4740 | f1: 0.4304\n",
            "Validation:  loss: 0.7250 | accuracy: 0.5802 | f1: 0.5558\n",
            "Epoch 00164\n",
            "Train: loss: 0.5209 | accuracy: 0.7271 | f-acore: 0.7246\n",
            "Test:  loss: 0.7928 | accuracy: 0.4740 | f1: 0.4391\n",
            "Validation:  loss: 0.7252 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00165\n",
            "Train: loss: 0.5306 | accuracy: 0.7303 | f-acore: 0.7268\n",
            "Test:  loss: 0.8031 | accuracy: 0.4712 | f1: 0.4337\n",
            "Validation:  loss: 0.7236 | accuracy: 0.5802 | f1: 0.5500\n",
            "Epoch 00166\n",
            "Train: loss: 0.5288 | accuracy: 0.7202 | f-acore: 0.7145\n",
            "Test:  loss: 0.8020 | accuracy: 0.4740 | f1: 0.4304\n",
            "Validation:  loss: 0.7273 | accuracy: 0.5926 | f1: 0.5714\n",
            "Epoch 00167\n",
            "Train: loss: 0.5398 | accuracy: 0.7395 | f-acore: 0.7384\n",
            "Test:  loss: 0.7977 | accuracy: 0.4658 | f1: 0.4388\n",
            "Validation:  loss: 0.7264 | accuracy: 0.5802 | f1: 0.5609\n",
            "Epoch 00168\n",
            "Train: loss: 0.5218 | accuracy: 0.7386 | f-acore: 0.7363\n",
            "Test:  loss: 0.8038 | accuracy: 0.4630 | f1: 0.4307\n",
            "Validation:  loss: 0.7269 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00169\n",
            "Train: loss: 0.5166 | accuracy: 0.7363 | f-acore: 0.7338\n",
            "Test:  loss: 0.8043 | accuracy: 0.4658 | f1: 0.4328\n",
            "Validation:  loss: 0.7312 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00170\n",
            "Train: loss: 0.5344 | accuracy: 0.7321 | f-acore: 0.7293\n",
            "Test:  loss: 0.8115 | accuracy: 0.4904 | f1: 0.4364\n",
            "Validation:  loss: 0.7270 | accuracy: 0.5802 | f1: 0.5609\n",
            "Epoch 00171\n",
            "Train: loss: 0.5262 | accuracy: 0.7303 | f-acore: 0.7260\n",
            "Test:  loss: 0.8038 | accuracy: 0.4685 | f1: 0.4281\n",
            "Validation:  loss: 0.7341 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00172\n",
            "Train: loss: 0.5362 | accuracy: 0.7308 | f-acore: 0.7274\n",
            "Test:  loss: 0.8065 | accuracy: 0.4630 | f1: 0.4307\n",
            "Validation:  loss: 0.7419 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00173\n",
            "Train: loss: 0.5274 | accuracy: 0.7390 | f-acore: 0.7375\n",
            "Test:  loss: 0.8173 | accuracy: 0.4575 | f1: 0.4249\n",
            "Validation:  loss: 0.7417 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00174\n",
            "Train: loss: 0.5407 | accuracy: 0.7422 | f-acore: 0.7389\n",
            "Test:  loss: 0.8005 | accuracy: 0.4767 | f1: 0.4517\n",
            "Validation:  loss: 0.7395 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00175\n",
            "Train: loss: 0.5242 | accuracy: 0.7216 | f-acore: 0.7201\n",
            "Test:  loss: 0.7873 | accuracy: 0.4712 | f1: 0.4431\n",
            "Validation:  loss: 0.7302 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00176\n",
            "Train: loss: 0.5267 | accuracy: 0.7335 | f-acore: 0.7297\n",
            "Test:  loss: 0.7990 | accuracy: 0.4877 | f1: 0.4365\n",
            "Validation:  loss: 0.7329 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00177\n",
            "Train: loss: 0.5258 | accuracy: 0.7372 | f-acore: 0.7344\n",
            "Test:  loss: 0.7829 | accuracy: 0.4877 | f1: 0.4385\n",
            "Validation:  loss: 0.7308 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00178\n",
            "Train: loss: 0.5289 | accuracy: 0.7321 | f-acore: 0.7300\n",
            "Test:  loss: 0.8050 | accuracy: 0.4575 | f1: 0.4323\n",
            "Validation:  loss: 0.7415 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00179\n",
            "Train: loss: 0.5177 | accuracy: 0.7317 | f-acore: 0.7281\n",
            "Test:  loss: 0.8072 | accuracy: 0.4740 | f1: 0.4391\n",
            "Validation:  loss: 0.7447 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00180\n",
            "Train: loss: 0.5171 | accuracy: 0.7445 | f-acore: 0.7417\n",
            "Test:  loss: 0.7994 | accuracy: 0.4767 | f1: 0.4503\n",
            "Validation:  loss: 0.7471 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00181\n",
            "Train: loss: 0.5203 | accuracy: 0.7422 | f-acore: 0.7400\n",
            "Test:  loss: 0.7924 | accuracy: 0.4849 | f1: 0.4237\n",
            "Validation:  loss: 0.7350 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00182\n",
            "Train: loss: 0.5252 | accuracy: 0.7491 | f-acore: 0.7476\n",
            "Test:  loss: 0.8028 | accuracy: 0.4904 | f1: 0.4321\n",
            "Validation:  loss: 0.7450 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00183\n",
            "Train: loss: 0.5161 | accuracy: 0.7431 | f-acore: 0.7397\n",
            "Test:  loss: 0.8045 | accuracy: 0.4849 | f1: 0.4422\n",
            "Validation:  loss: 0.7501 | accuracy: 0.5309 | f1: 0.5092\n",
            "Epoch 00184\n",
            "Train: loss: 0.5139 | accuracy: 0.7463 | f-acore: 0.7443\n",
            "Test:  loss: 0.8272 | accuracy: 0.4712 | f1: 0.4319\n",
            "Validation:  loss: 0.7640 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00185\n",
            "Train: loss: 0.5226 | accuracy: 0.7404 | f-acore: 0.7383\n",
            "Test:  loss: 0.8358 | accuracy: 0.4685 | f1: 0.4333\n",
            "Validation:  loss: 0.7507 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00186\n",
            "Train: loss: 0.5288 | accuracy: 0.7331 | f-acore: 0.7279\n",
            "Test:  loss: 0.8179 | accuracy: 0.4712 | f1: 0.4264\n",
            "Validation:  loss: 0.7548 | accuracy: 0.5679 | f1: 0.5546\n",
            "Epoch 00187\n",
            "Train: loss: 0.5255 | accuracy: 0.7367 | f-acore: 0.7349\n",
            "Test:  loss: 0.8045 | accuracy: 0.4603 | f1: 0.4285\n",
            "Validation:  loss: 0.7446 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00188\n",
            "Train: loss: 0.5176 | accuracy: 0.7408 | f-acore: 0.7373\n",
            "Test:  loss: 0.8224 | accuracy: 0.4685 | f1: 0.4244\n",
            "Validation:  loss: 0.7466 | accuracy: 0.5679 | f1: 0.5546\n",
            "Epoch 00189\n",
            "Train: loss: 0.5004 | accuracy: 0.7546 | f-acore: 0.7523\n",
            "Test:  loss: 0.8326 | accuracy: 0.4740 | f1: 0.4453\n",
            "Validation:  loss: 0.7603 | accuracy: 0.5679 | f1: 0.5504\n",
            "Epoch 00190\n",
            "Train: loss: 0.5174 | accuracy: 0.7454 | f-acore: 0.7433\n",
            "Test:  loss: 0.8357 | accuracy: 0.4630 | f1: 0.4380\n",
            "Validation:  loss: 0.7744 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00191\n",
            "Train: loss: 0.5119 | accuracy: 0.7436 | f-acore: 0.7391\n",
            "Test:  loss: 0.8071 | accuracy: 0.4712 | f1: 0.4417\n",
            "Validation:  loss: 0.7630 | accuracy: 0.5185 | f1: 0.4990\n",
            "Epoch 00192\n",
            "Train: loss: 0.5071 | accuracy: 0.7431 | f-acore: 0.7410\n",
            "Test:  loss: 0.8197 | accuracy: 0.4712 | f1: 0.4302\n",
            "Validation:  loss: 0.7519 | accuracy: 0.5185 | f1: 0.4935\n",
            "Epoch 00193\n",
            "Train: loss: 0.5013 | accuracy: 0.7541 | f-acore: 0.7511\n",
            "Test:  loss: 0.8082 | accuracy: 0.4822 | f1: 0.4587\n",
            "Validation:  loss: 0.7694 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00194\n",
            "Train: loss: 0.4872 | accuracy: 0.7573 | f-acore: 0.7550\n",
            "Test:  loss: 0.8373 | accuracy: 0.4575 | f1: 0.4264\n",
            "Validation:  loss: 0.7705 | accuracy: 0.5185 | f1: 0.4990\n",
            "Epoch 00195\n",
            "Train: loss: 0.5065 | accuracy: 0.7413 | f-acore: 0.7390\n",
            "Test:  loss: 0.8539 | accuracy: 0.4795 | f1: 0.4305\n",
            "Validation:  loss: 0.7736 | accuracy: 0.5556 | f1: 0.5297\n",
            "Epoch 00196\n",
            "Train: loss: 0.5054 | accuracy: 0.7509 | f-acore: 0.7484\n",
            "Test:  loss: 0.8260 | accuracy: 0.4685 | f1: 0.4185\n",
            "Validation:  loss: 0.7594 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00197\n",
            "Train: loss: 0.5086 | accuracy: 0.7376 | f-acore: 0.7359\n",
            "Test:  loss: 0.8292 | accuracy: 0.4932 | f1: 0.4484\n",
            "Validation:  loss: 0.7616 | accuracy: 0.5309 | f1: 0.5092\n",
            "Epoch 00198\n",
            "Train: loss: 0.5100 | accuracy: 0.7505 | f-acore: 0.7492\n",
            "Test:  loss: 0.8285 | accuracy: 0.4740 | f1: 0.4357\n",
            "Validation:  loss: 0.7668 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00199\n",
            "Train: loss: 0.5152 | accuracy: 0.7486 | f-acore: 0.7446\n",
            "Test:  loss: 0.8382 | accuracy: 0.4685 | f1: 0.4263\n",
            "Validation:  loss: 0.7698 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00200\n",
            "Train: loss: 0.5096 | accuracy: 0.7427 | f-acore: 0.7394\n",
            "Test:  loss: 0.8383 | accuracy: 0.4795 | f1: 0.4221\n",
            "Validation:  loss: 0.7613 | accuracy: 0.5185 | f1: 0.4935\n",
            "Epoch 00201\n",
            "Train: loss: 0.5079 | accuracy: 0.7514 | f-acore: 0.7494\n",
            "Test:  loss: 0.8562 | accuracy: 0.4849 | f1: 0.4259\n",
            "Validation:  loss: 0.7642 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00202\n",
            "Train: loss: 0.5042 | accuracy: 0.7532 | f-acore: 0.7511\n",
            "Test:  loss: 0.8433 | accuracy: 0.4767 | f1: 0.4201\n",
            "Validation:  loss: 0.7642 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00203\n",
            "Train: loss: 0.5096 | accuracy: 0.7555 | f-acore: 0.7531\n",
            "Test:  loss: 0.8480 | accuracy: 0.4658 | f1: 0.4328\n",
            "Validation:  loss: 0.7730 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00204\n",
            "Train: loss: 0.5123 | accuracy: 0.7596 | f-acore: 0.7578\n",
            "Test:  loss: 0.8294 | accuracy: 0.4877 | f1: 0.4344\n",
            "Validation:  loss: 0.7593 | accuracy: 0.4938 | f1: 0.4675\n",
            "Epoch 00205\n",
            "Train: loss: 0.4877 | accuracy: 0.7564 | f-acore: 0.7541\n",
            "Test:  loss: 0.8283 | accuracy: 0.4767 | f1: 0.4489\n",
            "Validation:  loss: 0.7555 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00206\n",
            "Train: loss: 0.5074 | accuracy: 0.7418 | f-acore: 0.7400\n",
            "Test:  loss: 0.8483 | accuracy: 0.4877 | f1: 0.4704\n",
            "Validation:  loss: 0.7719 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00207\n",
            "Train: loss: 0.5108 | accuracy: 0.7473 | f-acore: 0.7449\n",
            "Test:  loss: 0.8451 | accuracy: 0.4685 | f1: 0.4395\n",
            "Validation:  loss: 0.7712 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00208\n",
            "Train: loss: 0.5067 | accuracy: 0.7440 | f-acore: 0.7403\n",
            "Test:  loss: 0.8423 | accuracy: 0.4795 | f1: 0.4221\n",
            "Validation:  loss: 0.7630 | accuracy: 0.5062 | f1: 0.4834\n",
            "Epoch 00209\n",
            "Train: loss: 0.4933 | accuracy: 0.7578 | f-acore: 0.7556\n",
            "Test:  loss: 0.8613 | accuracy: 0.4904 | f1: 0.4463\n",
            "Validation:  loss: 0.7623 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00210\n",
            "Train: loss: 0.4930 | accuracy: 0.7582 | f-acore: 0.7557\n",
            "Test:  loss: 0.8422 | accuracy: 0.4712 | f1: 0.4445\n",
            "Validation:  loss: 0.7584 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00211\n",
            "Train: loss: 0.4978 | accuracy: 0.7500 | f-acore: 0.7470\n",
            "Test:  loss: 0.8352 | accuracy: 0.4712 | f1: 0.4445\n",
            "Validation:  loss: 0.7625 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00212\n",
            "Train: loss: 0.4808 | accuracy: 0.7633 | f-acore: 0.7616\n",
            "Test:  loss: 0.8623 | accuracy: 0.4740 | f1: 0.4357\n",
            "Validation:  loss: 0.7683 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00213\n",
            "Train: loss: 0.5083 | accuracy: 0.7459 | f-acore: 0.7421\n",
            "Test:  loss: 0.8470 | accuracy: 0.4767 | f1: 0.4579\n",
            "Validation:  loss: 0.7656 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00214\n",
            "Train: loss: 0.5053 | accuracy: 0.7555 | f-acore: 0.7535\n",
            "Test:  loss: 0.8644 | accuracy: 0.4712 | f1: 0.4354\n",
            "Validation:  loss: 0.7812 | accuracy: 0.5062 | f1: 0.4834\n",
            "Epoch 00215\n",
            "Train: loss: 0.4850 | accuracy: 0.7550 | f-acore: 0.7525\n",
            "Test:  loss: 0.8434 | accuracy: 0.4795 | f1: 0.4539\n",
            "Validation:  loss: 0.7763 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00216\n",
            "Train: loss: 0.4928 | accuracy: 0.7509 | f-acore: 0.7483\n",
            "Test:  loss: 0.8556 | accuracy: 0.4767 | f1: 0.4517\n",
            "Validation:  loss: 0.7753 | accuracy: 0.5062 | f1: 0.4886\n",
            "Epoch 00217\n",
            "Train: loss: 0.5084 | accuracy: 0.7486 | f-acore: 0.7457\n",
            "Test:  loss: 0.8574 | accuracy: 0.4712 | f1: 0.4510\n",
            "Validation:  loss: 0.7756 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00218\n",
            "Train: loss: 0.5190 | accuracy: 0.7527 | f-acore: 0.7507\n",
            "Test:  loss: 0.8415 | accuracy: 0.4712 | f1: 0.4205\n",
            "Validation:  loss: 0.7671 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00219\n",
            "Train: loss: 0.5008 | accuracy: 0.7592 | f-acore: 0.7550\n",
            "Test:  loss: 0.8434 | accuracy: 0.4658 | f1: 0.4328\n",
            "Validation:  loss: 0.7888 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00220\n",
            "Train: loss: 0.5014 | accuracy: 0.7587 | f-acore: 0.7570\n",
            "Test:  loss: 0.8591 | accuracy: 0.4575 | f1: 0.4294\n",
            "Validation:  loss: 0.7967 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00221\n",
            "Train: loss: 0.4964 | accuracy: 0.7546 | f-acore: 0.7524\n",
            "Test:  loss: 0.8494 | accuracy: 0.4767 | f1: 0.4244\n",
            "Validation:  loss: 0.7577 | accuracy: 0.5309 | f1: 0.5035\n",
            "Epoch 00222\n",
            "Train: loss: 0.5139 | accuracy: 0.7486 | f-acore: 0.7463\n",
            "Test:  loss: 0.8424 | accuracy: 0.4740 | f1: 0.4357\n",
            "Validation:  loss: 0.7632 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00223\n",
            "Train: loss: 0.5186 | accuracy: 0.7463 | f-acore: 0.7445\n",
            "Test:  loss: 0.8568 | accuracy: 0.4740 | f1: 0.4578\n",
            "Validation:  loss: 0.7877 | accuracy: 0.4938 | f1: 0.4782\n",
            "Epoch 00224\n",
            "Train: loss: 0.5133 | accuracy: 0.7335 | f-acore: 0.7325\n",
            "Test:  loss: 0.8475 | accuracy: 0.4822 | f1: 0.4487\n",
            "Validation:  loss: 0.7807 | accuracy: 0.5062 | f1: 0.4774\n",
            "Epoch 00225\n",
            "Train: loss: 0.5005 | accuracy: 0.7527 | f-acore: 0.7492\n",
            "Test:  loss: 0.8528 | accuracy: 0.4712 | f1: 0.4445\n",
            "Validation:  loss: 0.7807 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00226\n",
            "Train: loss: 0.5122 | accuracy: 0.7445 | f-acore: 0.7423\n",
            "Test:  loss: 0.8678 | accuracy: 0.4630 | f1: 0.4393\n",
            "Validation:  loss: 0.7842 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00227\n",
            "Train: loss: 0.4832 | accuracy: 0.7642 | f-acore: 0.7626\n",
            "Test:  loss: 0.8506 | accuracy: 0.4630 | f1: 0.4204\n",
            "Validation:  loss: 0.7850 | accuracy: 0.4938 | f1: 0.4733\n",
            "Epoch 00228\n",
            "Train: loss: 0.4877 | accuracy: 0.7505 | f-acore: 0.7487\n",
            "Test:  loss: 0.8643 | accuracy: 0.4767 | f1: 0.4428\n",
            "Validation:  loss: 0.7802 | accuracy: 0.5309 | f1: 0.5092\n",
            "Epoch 00229\n",
            "Train: loss: 0.4821 | accuracy: 0.7665 | f-acore: 0.7638\n",
            "Test:  loss: 0.8714 | accuracy: 0.4767 | f1: 0.4555\n",
            "Validation:  loss: 0.7855 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00230\n",
            "Train: loss: 0.4851 | accuracy: 0.7463 | f-acore: 0.7449\n",
            "Test:  loss: 0.8677 | accuracy: 0.4712 | f1: 0.4431\n",
            "Validation:  loss: 0.7702 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00231\n",
            "Train: loss: 0.4775 | accuracy: 0.7683 | f-acore: 0.7656\n",
            "Test:  loss: 0.8802 | accuracy: 0.4712 | f1: 0.4445\n",
            "Validation:  loss: 0.7723 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00232\n",
            "Train: loss: 0.4810 | accuracy: 0.7665 | f-acore: 0.7645\n",
            "Test:  loss: 0.8844 | accuracy: 0.4795 | f1: 0.4325\n",
            "Validation:  loss: 0.7774 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00233\n",
            "Train: loss: 0.5045 | accuracy: 0.7527 | f-acore: 0.7501\n",
            "Test:  loss: 0.8799 | accuracy: 0.4795 | f1: 0.4450\n",
            "Validation:  loss: 0.7742 | accuracy: 0.5802 | f1: 0.5691\n",
            "Epoch 00234\n",
            "Train: loss: 0.5108 | accuracy: 0.7463 | f-acore: 0.7444\n",
            "Test:  loss: 0.8604 | accuracy: 0.4630 | f1: 0.4061\n",
            "Validation:  loss: 0.7681 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00235\n",
            "Train: loss: 0.4828 | accuracy: 0.7660 | f-acore: 0.7639\n",
            "Test:  loss: 0.8753 | accuracy: 0.4658 | f1: 0.4328\n",
            "Validation:  loss: 0.7700 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00236\n",
            "Train: loss: 0.4798 | accuracy: 0.7532 | f-acore: 0.7509\n",
            "Test:  loss: 0.8899 | accuracy: 0.4740 | f1: 0.4340\n",
            "Validation:  loss: 0.7724 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00237\n",
            "Train: loss: 0.4689 | accuracy: 0.7679 | f-acore: 0.7651\n",
            "Test:  loss: 0.8942 | accuracy: 0.4822 | f1: 0.4420\n",
            "Validation:  loss: 0.7831 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00238\n",
            "Train: loss: 0.5155 | accuracy: 0.7546 | f-acore: 0.7531\n",
            "Test:  loss: 0.8898 | accuracy: 0.4658 | f1: 0.4165\n",
            "Validation:  loss: 0.7941 | accuracy: 0.5062 | f1: 0.4834\n",
            "Epoch 00239\n",
            "Train: loss: 0.4995 | accuracy: 0.7555 | f-acore: 0.7528\n",
            "Test:  loss: 0.8761 | accuracy: 0.4575 | f1: 0.4264\n",
            "Validation:  loss: 0.7994 | accuracy: 0.4568 | f1: 0.4318\n",
            "Epoch 00240\n",
            "Train: loss: 0.4892 | accuracy: 0.7592 | f-acore: 0.7571\n",
            "Test:  loss: 0.9126 | accuracy: 0.4904 | f1: 0.4679\n",
            "Validation:  loss: 0.7967 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00241\n",
            "Train: loss: 0.4847 | accuracy: 0.7596 | f-acore: 0.7565\n",
            "Test:  loss: 0.8877 | accuracy: 0.4849 | f1: 0.4568\n",
            "Validation:  loss: 0.7826 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00242\n",
            "Train: loss: 0.4862 | accuracy: 0.7550 | f-acore: 0.7529\n",
            "Test:  loss: 0.8759 | accuracy: 0.4740 | f1: 0.4265\n",
            "Validation:  loss: 0.7800 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00243\n",
            "Train: loss: 0.4767 | accuracy: 0.7706 | f-acore: 0.7694\n",
            "Test:  loss: 0.8773 | accuracy: 0.4712 | f1: 0.4354\n",
            "Validation:  loss: 0.7803 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00244\n",
            "Train: loss: 0.4842 | accuracy: 0.7706 | f-acore: 0.7679\n",
            "Test:  loss: 0.8699 | accuracy: 0.4795 | f1: 0.4363\n",
            "Validation:  loss: 0.7789 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00245\n",
            "Train: loss: 0.4738 | accuracy: 0.7724 | f-acore: 0.7698\n",
            "Test:  loss: 0.8858 | accuracy: 0.4740 | f1: 0.4225\n",
            "Validation:  loss: 0.7777 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00246\n",
            "Train: loss: 0.4806 | accuracy: 0.7555 | f-acore: 0.7536\n",
            "Test:  loss: 0.8759 | accuracy: 0.4877 | f1: 0.4443\n",
            "Validation:  loss: 0.7856 | accuracy: 0.5185 | f1: 0.4990\n",
            "Epoch 00247\n",
            "Train: loss: 0.4976 | accuracy: 0.7715 | f-acore: 0.7695\n",
            "Test:  loss: 0.8811 | accuracy: 0.4822 | f1: 0.4284\n",
            "Validation:  loss: 0.7841 | accuracy: 0.5062 | f1: 0.4886\n",
            "Epoch 00248\n",
            "Train: loss: 0.4865 | accuracy: 0.7555 | f-acore: 0.7540\n",
            "Test:  loss: 0.8749 | accuracy: 0.4767 | f1: 0.4201\n",
            "Validation:  loss: 0.7857 | accuracy: 0.4938 | f1: 0.4733\n",
            "Epoch 00249\n",
            "Train: loss: 0.4737 | accuracy: 0.7633 | f-acore: 0.7606\n",
            "Test:  loss: 0.8955 | accuracy: 0.4767 | f1: 0.4412\n",
            "Validation:  loss: 0.7837 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00250\n",
            "Train: loss: 0.4702 | accuracy: 0.7761 | f-acore: 0.7741\n",
            "Test:  loss: 0.9146 | accuracy: 0.4849 | f1: 0.4282\n",
            "Validation:  loss: 0.7865 | accuracy: 0.5062 | f1: 0.4834\n",
            "Epoch 00251\n",
            "Train: loss: 0.4818 | accuracy: 0.7578 | f-acore: 0.7545\n",
            "Test:  loss: 0.9068 | accuracy: 0.4767 | f1: 0.4109\n",
            "Validation:  loss: 0.7729 | accuracy: 0.5185 | f1: 0.4990\n",
            "Epoch 00252\n",
            "Train: loss: 0.4584 | accuracy: 0.7669 | f-acore: 0.7641\n",
            "Test:  loss: 0.9055 | accuracy: 0.4795 | f1: 0.4325\n",
            "Validation:  loss: 0.7880 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00253\n",
            "Train: loss: 0.4936 | accuracy: 0.7665 | f-acore: 0.7647\n",
            "Test:  loss: 0.8975 | accuracy: 0.4712 | f1: 0.4225\n",
            "Validation:  loss: 0.7803 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00254\n",
            "Train: loss: 0.4950 | accuracy: 0.7724 | f-acore: 0.7697\n",
            "Test:  loss: 0.9110 | accuracy: 0.4712 | f1: 0.4163\n",
            "Validation:  loss: 0.7773 | accuracy: 0.5062 | f1: 0.4886\n",
            "Epoch 00255\n",
            "Train: loss: 0.4826 | accuracy: 0.7674 | f-acore: 0.7655\n",
            "Test:  loss: 0.8926 | accuracy: 0.4822 | f1: 0.4171\n",
            "Validation:  loss: 0.7818 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00256\n",
            "Train: loss: 0.4813 | accuracy: 0.7578 | f-acore: 0.7547\n",
            "Test:  loss: 0.8856 | accuracy: 0.4767 | f1: 0.4503\n",
            "Validation:  loss: 0.7816 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00257\n",
            "Train: loss: 0.4770 | accuracy: 0.7729 | f-acore: 0.7713\n",
            "Test:  loss: 0.9048 | accuracy: 0.4712 | f1: 0.4264\n",
            "Validation:  loss: 0.7987 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00258\n",
            "Train: loss: 0.4876 | accuracy: 0.7706 | f-acore: 0.7684\n",
            "Test:  loss: 0.8947 | accuracy: 0.4822 | f1: 0.4121\n",
            "Validation:  loss: 0.7711 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00259\n",
            "Train: loss: 0.4616 | accuracy: 0.7734 | f-acore: 0.7714\n",
            "Test:  loss: 0.9348 | accuracy: 0.4795 | f1: 0.4344\n",
            "Validation:  loss: 0.7839 | accuracy: 0.4938 | f1: 0.4733\n",
            "Epoch 00260\n",
            "Train: loss: 0.4988 | accuracy: 0.7651 | f-acore: 0.7629\n",
            "Test:  loss: 0.8866 | accuracy: 0.4685 | f1: 0.4225\n",
            "Validation:  loss: 0.7649 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00261\n",
            "Train: loss: 0.4749 | accuracy: 0.7734 | f-acore: 0.7703\n",
            "Test:  loss: 0.8908 | accuracy: 0.4712 | f1: 0.4047\n",
            "Validation:  loss: 0.7628 | accuracy: 0.5432 | f1: 0.5247\n",
            "Epoch 00262\n",
            "Train: loss: 0.5106 | accuracy: 0.7610 | f-acore: 0.7599\n",
            "Test:  loss: 0.8823 | accuracy: 0.4904 | f1: 0.4202\n",
            "Validation:  loss: 0.7642 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00263\n",
            "Train: loss: 0.4937 | accuracy: 0.7592 | f-acore: 0.7577\n",
            "Test:  loss: 0.8754 | accuracy: 0.4712 | f1: 0.4431\n",
            "Validation:  loss: 0.7591 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00264\n",
            "Train: loss: 0.4784 | accuracy: 0.7738 | f-acore: 0.7719\n",
            "Test:  loss: 0.8831 | accuracy: 0.4658 | f1: 0.4295\n",
            "Validation:  loss: 0.7703 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00265\n",
            "Train: loss: 0.4818 | accuracy: 0.7669 | f-acore: 0.7647\n",
            "Test:  loss: 0.8829 | accuracy: 0.4959 | f1: 0.4313\n",
            "Validation:  loss: 0.7783 | accuracy: 0.5556 | f1: 0.5235\n",
            "Epoch 00266\n",
            "Train: loss: 0.4881 | accuracy: 0.7669 | f-acore: 0.7649\n",
            "Test:  loss: 0.8989 | accuracy: 0.4959 | f1: 0.4382\n",
            "Validation:  loss: 0.7685 | accuracy: 0.5432 | f1: 0.5136\n",
            "Epoch 00267\n",
            "Train: loss: 0.4678 | accuracy: 0.7683 | f-acore: 0.7655\n",
            "Test:  loss: 0.8889 | accuracy: 0.4603 | f1: 0.4301\n",
            "Validation:  loss: 0.7580 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00268\n",
            "Train: loss: 0.4778 | accuracy: 0.7917 | f-acore: 0.7892\n",
            "Test:  loss: 0.9060 | accuracy: 0.4740 | f1: 0.4340\n",
            "Validation:  loss: 0.7764 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00269\n",
            "Train: loss: 0.4685 | accuracy: 0.7701 | f-acore: 0.7691\n",
            "Test:  loss: 0.9101 | accuracy: 0.4658 | f1: 0.4328\n",
            "Validation:  loss: 0.7864 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00270\n",
            "Train: loss: 0.4924 | accuracy: 0.7679 | f-acore: 0.7654\n",
            "Test:  loss: 0.9040 | accuracy: 0.4822 | f1: 0.4437\n",
            "Validation:  loss: 0.7844 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00271\n",
            "Train: loss: 0.4719 | accuracy: 0.7592 | f-acore: 0.7561\n",
            "Test:  loss: 0.8754 | accuracy: 0.4740 | f1: 0.3962\n",
            "Validation:  loss: 0.8024 | accuracy: 0.4691 | f1: 0.4528\n",
            "Epoch 00272\n",
            "Train: loss: 0.4667 | accuracy: 0.7775 | f-acore: 0.7756\n",
            "Test:  loss: 0.8997 | accuracy: 0.4712 | f1: 0.4283\n",
            "Validation:  loss: 0.7926 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00273\n",
            "Train: loss: 0.4692 | accuracy: 0.7807 | f-acore: 0.7792\n",
            "Test:  loss: 0.8899 | accuracy: 0.4603 | f1: 0.4409\n",
            "Validation:  loss: 0.7808 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00274\n",
            "Train: loss: 0.4640 | accuracy: 0.7715 | f-acore: 0.7700\n",
            "Test:  loss: 0.8934 | accuracy: 0.4630 | f1: 0.4523\n",
            "Validation:  loss: 0.7753 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00275\n",
            "Train: loss: 0.4581 | accuracy: 0.7743 | f-acore: 0.7727\n",
            "Test:  loss: 0.8999 | accuracy: 0.4712 | f1: 0.4402\n",
            "Validation:  loss: 0.7855 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00276\n",
            "Train: loss: 0.4642 | accuracy: 0.7807 | f-acore: 0.7788\n",
            "Test:  loss: 0.9167 | accuracy: 0.4740 | f1: 0.4495\n",
            "Validation:  loss: 0.7794 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00277\n",
            "Train: loss: 0.4652 | accuracy: 0.7766 | f-acore: 0.7747\n",
            "Test:  loss: 0.9135 | accuracy: 0.4685 | f1: 0.4410\n",
            "Validation:  loss: 0.7725 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00278\n",
            "Train: loss: 0.4715 | accuracy: 0.7688 | f-acore: 0.7667\n",
            "Test:  loss: 0.9061 | accuracy: 0.4740 | f1: 0.4423\n",
            "Validation:  loss: 0.7864 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00279\n",
            "Train: loss: 0.4732 | accuracy: 0.7720 | f-acore: 0.7700\n",
            "Test:  loss: 0.9014 | accuracy: 0.4795 | f1: 0.4433\n",
            "Validation:  loss: 0.7764 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00280\n",
            "Train: loss: 0.4573 | accuracy: 0.7843 | f-acore: 0.7823\n",
            "Test:  loss: 0.8963 | accuracy: 0.4712 | f1: 0.4445\n",
            "Validation:  loss: 0.7754 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00281\n",
            "Train: loss: 0.4659 | accuracy: 0.7775 | f-acore: 0.7758\n",
            "Test:  loss: 0.8940 | accuracy: 0.4795 | f1: 0.4416\n",
            "Validation:  loss: 0.7800 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00282\n",
            "Train: loss: 0.4655 | accuracy: 0.7862 | f-acore: 0.7843\n",
            "Test:  loss: 0.9111 | accuracy: 0.4603 | f1: 0.4316\n",
            "Validation:  loss: 0.7682 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00283\n",
            "Train: loss: 0.4945 | accuracy: 0.7738 | f-acore: 0.7719\n",
            "Test:  loss: 0.9148 | accuracy: 0.4630 | f1: 0.4352\n",
            "Validation:  loss: 0.7853 | accuracy: 0.5556 | f1: 0.5472\n",
            "Epoch 00284\n",
            "Train: loss: 0.4690 | accuracy: 0.7775 | f-acore: 0.7758\n",
            "Test:  loss: 0.9181 | accuracy: 0.4603 | f1: 0.4432\n",
            "Validation:  loss: 0.7862 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00285\n",
            "Train: loss: 0.4635 | accuracy: 0.7614 | f-acore: 0.7598\n",
            "Test:  loss: 0.9127 | accuracy: 0.4575 | f1: 0.4349\n",
            "Validation:  loss: 0.7920 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00286\n",
            "Train: loss: 0.4833 | accuracy: 0.7674 | f-acore: 0.7652\n",
            "Test:  loss: 0.9074 | accuracy: 0.4603 | f1: 0.4384\n",
            "Validation:  loss: 0.8027 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00287\n",
            "Train: loss: 0.4721 | accuracy: 0.7853 | f-acore: 0.7834\n",
            "Test:  loss: 0.9081 | accuracy: 0.4658 | f1: 0.4402\n",
            "Validation:  loss: 0.7883 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00288\n",
            "Train: loss: 0.4673 | accuracy: 0.7821 | f-acore: 0.7809\n",
            "Test:  loss: 0.9076 | accuracy: 0.4685 | f1: 0.4522\n",
            "Validation:  loss: 0.7950 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00289\n",
            "Train: loss: 0.4600 | accuracy: 0.7775 | f-acore: 0.7759\n",
            "Test:  loss: 0.9204 | accuracy: 0.4630 | f1: 0.4419\n",
            "Validation:  loss: 0.7950 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00290\n",
            "Train: loss: 0.4806 | accuracy: 0.7756 | f-acore: 0.7730\n",
            "Test:  loss: 0.9138 | accuracy: 0.4493 | f1: 0.4295\n",
            "Validation:  loss: 0.7932 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00291\n",
            "Train: loss: 0.4560 | accuracy: 0.7830 | f-acore: 0.7814\n",
            "Test:  loss: 0.9427 | accuracy: 0.4603 | f1: 0.4409\n",
            "Validation:  loss: 0.8009 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00292\n",
            "Train: loss: 0.4549 | accuracy: 0.7788 | f-acore: 0.7768\n",
            "Test:  loss: 0.9341 | accuracy: 0.4438 | f1: 0.4250\n",
            "Validation:  loss: 0.7919 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00293\n",
            "Train: loss: 0.4548 | accuracy: 0.7871 | f-acore: 0.7857\n",
            "Test:  loss: 0.9358 | accuracy: 0.4548 | f1: 0.4301\n",
            "Validation:  loss: 0.7985 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00294\n",
            "Train: loss: 0.4574 | accuracy: 0.7720 | f-acore: 0.7696\n",
            "Test:  loss: 0.9404 | accuracy: 0.4603 | f1: 0.4358\n",
            "Validation:  loss: 0.7938 | accuracy: 0.5679 | f1: 0.5636\n",
            "Epoch 00295\n",
            "Train: loss: 0.4675 | accuracy: 0.7825 | f-acore: 0.7807\n",
            "Test:  loss: 0.9328 | accuracy: 0.4630 | f1: 0.4337\n",
            "Validation:  loss: 0.7926 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00296\n",
            "Train: loss: 0.4527 | accuracy: 0.7926 | f-acore: 0.7899\n",
            "Test:  loss: 0.9333 | accuracy: 0.4521 | f1: 0.4292\n",
            "Validation:  loss: 0.7855 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00297\n",
            "Train: loss: 0.4532 | accuracy: 0.7788 | f-acore: 0.7777\n",
            "Test:  loss: 0.9137 | accuracy: 0.4493 | f1: 0.4169\n",
            "Validation:  loss: 0.7814 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00298\n",
            "Train: loss: 0.4704 | accuracy: 0.7857 | f-acore: 0.7842\n",
            "Test:  loss: 0.9439 | accuracy: 0.4548 | f1: 0.4227\n",
            "Validation:  loss: 0.7725 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00299\n",
            "Train: loss: 0.5131 | accuracy: 0.7770 | f-acore: 0.7752\n",
            "Test:  loss: 0.9330 | accuracy: 0.4630 | f1: 0.4443\n",
            "Validation:  loss: 0.7667 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00300\n",
            "Train: loss: 0.4739 | accuracy: 0.7692 | f-acore: 0.7677\n",
            "Test:  loss: 0.8893 | accuracy: 0.4466 | f1: 0.4435\n",
            "Validation:  loss: 0.7931 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00301\n",
            "Train: loss: 0.4778 | accuracy: 0.7734 | f-acore: 0.7706\n",
            "Test:  loss: 0.9021 | accuracy: 0.4521 | f1: 0.4341\n",
            "Validation:  loss: 0.7780 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00302\n",
            "Train: loss: 0.4450 | accuracy: 0.7894 | f-acore: 0.7878\n",
            "Test:  loss: 0.9173 | accuracy: 0.4658 | f1: 0.4295\n",
            "Validation:  loss: 0.7726 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00303\n",
            "Train: loss: 0.4474 | accuracy: 0.7894 | f-acore: 0.7874\n",
            "Test:  loss: 0.9582 | accuracy: 0.4603 | f1: 0.4285\n",
            "Validation:  loss: 0.7877 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00304\n",
            "Train: loss: 0.4620 | accuracy: 0.7734 | f-acore: 0.7706\n",
            "Test:  loss: 0.9587 | accuracy: 0.4521 | f1: 0.4305\n",
            "Validation:  loss: 0.7831 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00305\n",
            "Train: loss: 0.4676 | accuracy: 0.7802 | f-acore: 0.7786\n",
            "Test:  loss: 0.9404 | accuracy: 0.4521 | f1: 0.4251\n",
            "Validation:  loss: 0.7834 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00306\n",
            "Train: loss: 0.4551 | accuracy: 0.7779 | f-acore: 0.7768\n",
            "Test:  loss: 0.9351 | accuracy: 0.4603 | f1: 0.4301\n",
            "Validation:  loss: 0.7871 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00307\n",
            "Train: loss: 0.4537 | accuracy: 0.7715 | f-acore: 0.7691\n",
            "Test:  loss: 0.9461 | accuracy: 0.4603 | f1: 0.4301\n",
            "Validation:  loss: 0.7734 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00308\n",
            "Train: loss: 0.4605 | accuracy: 0.7830 | f-acore: 0.7812\n",
            "Test:  loss: 0.9708 | accuracy: 0.4685 | f1: 0.4380\n",
            "Validation:  loss: 0.7897 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00309\n",
            "Train: loss: 0.4728 | accuracy: 0.7802 | f-acore: 0.7782\n",
            "Test:  loss: 0.9720 | accuracy: 0.4658 | f1: 0.4374\n",
            "Validation:  loss: 0.7953 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00310\n",
            "Train: loss: 0.4669 | accuracy: 0.7940 | f-acore: 0.7925\n",
            "Test:  loss: 0.9435 | accuracy: 0.4548 | f1: 0.4195\n",
            "Validation:  loss: 0.7920 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00311\n",
            "Train: loss: 0.4537 | accuracy: 0.7862 | f-acore: 0.7837\n",
            "Test:  loss: 0.9508 | accuracy: 0.4521 | f1: 0.4222\n",
            "Validation:  loss: 0.7864 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00312\n",
            "Train: loss: 0.4735 | accuracy: 0.7779 | f-acore: 0.7758\n",
            "Test:  loss: 0.9562 | accuracy: 0.4712 | f1: 0.4402\n",
            "Validation:  loss: 0.7904 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00313\n",
            "Train: loss: 0.4600 | accuracy: 0.7752 | f-acore: 0.7727\n",
            "Test:  loss: 0.9516 | accuracy: 0.4685 | f1: 0.4333\n",
            "Validation:  loss: 0.7906 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00314\n",
            "Train: loss: 0.4498 | accuracy: 0.7866 | f-acore: 0.7856\n",
            "Test:  loss: 0.9892 | accuracy: 0.4712 | f1: 0.4354\n",
            "Validation:  loss: 0.7950 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00315\n",
            "Train: loss: 0.4499 | accuracy: 0.7816 | f-acore: 0.7794\n",
            "Test:  loss: 0.9846 | accuracy: 0.4658 | f1: 0.4328\n",
            "Validation:  loss: 0.7847 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00316\n",
            "Train: loss: 0.4556 | accuracy: 0.7880 | f-acore: 0.7863\n",
            "Test:  loss: 0.9856 | accuracy: 0.4740 | f1: 0.4533\n",
            "Validation:  loss: 0.7834 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00317\n",
            "Train: loss: 0.4496 | accuracy: 0.7770 | f-acore: 0.7754\n",
            "Test:  loss: 0.9778 | accuracy: 0.4740 | f1: 0.4508\n",
            "Validation:  loss: 0.7806 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00318\n",
            "Train: loss: 0.4573 | accuracy: 0.7807 | f-acore: 0.7783\n",
            "Test:  loss: 0.9692 | accuracy: 0.4548 | f1: 0.4314\n",
            "Validation:  loss: 0.7906 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00319\n",
            "Train: loss: 0.4524 | accuracy: 0.7834 | f-acore: 0.7822\n",
            "Test:  loss: 0.9926 | accuracy: 0.4603 | f1: 0.4397\n",
            "Validation:  loss: 0.7994 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00320\n",
            "Train: loss: 0.4639 | accuracy: 0.7830 | f-acore: 0.7809\n",
            "Test:  loss: 0.9772 | accuracy: 0.4658 | f1: 0.4488\n",
            "Validation:  loss: 0.7880 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00321\n",
            "Train: loss: 0.4447 | accuracy: 0.7940 | f-acore: 0.7921\n",
            "Test:  loss: 0.9881 | accuracy: 0.4658 | f1: 0.4429\n",
            "Validation:  loss: 0.7976 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00322\n",
            "Train: loss: 0.4372 | accuracy: 0.7944 | f-acore: 0.7928\n",
            "Test:  loss: 0.9757 | accuracy: 0.4548 | f1: 0.4364\n",
            "Validation:  loss: 0.8050 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00323\n",
            "Train: loss: 0.4385 | accuracy: 0.7930 | f-acore: 0.7912\n",
            "Test:  loss: 0.9852 | accuracy: 0.4575 | f1: 0.4349\n",
            "Validation:  loss: 0.7972 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00324\n",
            "Train: loss: 0.4607 | accuracy: 0.7857 | f-acore: 0.7837\n",
            "Test:  loss: 0.9665 | accuracy: 0.4685 | f1: 0.4451\n",
            "Validation:  loss: 0.8011 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00325\n",
            "Train: loss: 0.4563 | accuracy: 0.7885 | f-acore: 0.7864\n",
            "Test:  loss: 0.9784 | accuracy: 0.4603 | f1: 0.4253\n",
            "Validation:  loss: 0.7951 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00326\n",
            "Train: loss: 0.4479 | accuracy: 0.7871 | f-acore: 0.7853\n",
            "Test:  loss: 0.9622 | accuracy: 0.4712 | f1: 0.4417\n",
            "Validation:  loss: 0.7842 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00327\n",
            "Train: loss: 0.4573 | accuracy: 0.7816 | f-acore: 0.7798\n",
            "Test:  loss: 0.9802 | accuracy: 0.4548 | f1: 0.4340\n",
            "Validation:  loss: 0.7913 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00328\n",
            "Train: loss: 0.4603 | accuracy: 0.7843 | f-acore: 0.7828\n",
            "Test:  loss: 0.9927 | accuracy: 0.4603 | f1: 0.4301\n",
            "Validation:  loss: 0.7835 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00329\n",
            "Train: loss: 0.4384 | accuracy: 0.7825 | f-acore: 0.7811\n",
            "Test:  loss: 0.9865 | accuracy: 0.4630 | f1: 0.4419\n",
            "Validation:  loss: 0.7754 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00330\n",
            "Train: loss: 0.4415 | accuracy: 0.7875 | f-acore: 0.7862\n",
            "Test:  loss: 0.9790 | accuracy: 0.4630 | f1: 0.4337\n",
            "Validation:  loss: 0.7855 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00331\n",
            "Train: loss: 0.4329 | accuracy: 0.8017 | f-acore: 0.8005\n",
            "Test:  loss: 0.9501 | accuracy: 0.4685 | f1: 0.4395\n",
            "Validation:  loss: 0.7926 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00332\n",
            "Train: loss: 0.4314 | accuracy: 0.8022 | f-acore: 0.8005\n",
            "Test:  loss: 0.9802 | accuracy: 0.4548 | f1: 0.4301\n",
            "Validation:  loss: 0.7913 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00333\n",
            "Train: loss: 0.4375 | accuracy: 0.7889 | f-acore: 0.7876\n",
            "Test:  loss: 0.9953 | accuracy: 0.4548 | f1: 0.4340\n",
            "Validation:  loss: 0.7871 | accuracy: 0.5679 | f1: 0.5582\n",
            "Epoch 00334\n",
            "Train: loss: 0.4534 | accuracy: 0.7926 | f-acore: 0.7906\n",
            "Test:  loss: 0.9960 | accuracy: 0.4575 | f1: 0.4386\n",
            "Validation:  loss: 0.7872 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00335\n",
            "Train: loss: 0.4522 | accuracy: 0.7816 | f-acore: 0.7796\n",
            "Test:  loss: 1.0236 | accuracy: 0.4630 | f1: 0.4443\n",
            "Validation:  loss: 0.7908 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00336\n",
            "Train: loss: 0.4451 | accuracy: 0.7866 | f-acore: 0.7852\n",
            "Test:  loss: 0.9710 | accuracy: 0.4548 | f1: 0.4352\n",
            "Validation:  loss: 0.7945 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00337\n",
            "Train: loss: 0.4316 | accuracy: 0.8013 | f-acore: 0.7989\n",
            "Test:  loss: 0.9627 | accuracy: 0.4685 | f1: 0.4500\n",
            "Validation:  loss: 0.8051 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00338\n",
            "Train: loss: 0.4274 | accuracy: 0.7985 | f-acore: 0.7967\n",
            "Test:  loss: 0.9878 | accuracy: 0.4575 | f1: 0.4294\n",
            "Validation:  loss: 0.7857 | accuracy: 0.5556 | f1: 0.5500\n",
            "Epoch 00339\n",
            "Train: loss: 0.4521 | accuracy: 0.7889 | f-acore: 0.7870\n",
            "Test:  loss: 0.9757 | accuracy: 0.4548 | f1: 0.4352\n",
            "Validation:  loss: 0.7908 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00340\n",
            "Train: loss: 0.4409 | accuracy: 0.7875 | f-acore: 0.7863\n",
            "Test:  loss: 0.9875 | accuracy: 0.4603 | f1: 0.4397\n",
            "Validation:  loss: 0.7963 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00341\n",
            "Train: loss: 0.4536 | accuracy: 0.7830 | f-acore: 0.7808\n",
            "Test:  loss: 0.9716 | accuracy: 0.4658 | f1: 0.4454\n",
            "Validation:  loss: 0.8028 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00342\n",
            "Train: loss: 0.4420 | accuracy: 0.7885 | f-acore: 0.7863\n",
            "Test:  loss: 1.0043 | accuracy: 0.4548 | f1: 0.4397\n",
            "Validation:  loss: 0.7998 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00343\n",
            "Train: loss: 0.4598 | accuracy: 0.7908 | f-acore: 0.7895\n",
            "Test:  loss: 0.9925 | accuracy: 0.4493 | f1: 0.4330\n",
            "Validation:  loss: 0.8051 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00344\n",
            "Train: loss: 0.4523 | accuracy: 0.7926 | f-acore: 0.7910\n",
            "Test:  loss: 1.0085 | accuracy: 0.4685 | f1: 0.4437\n",
            "Validation:  loss: 0.8042 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00345\n",
            "Train: loss: 0.4411 | accuracy: 0.8013 | f-acore: 0.7991\n",
            "Test:  loss: 1.0073 | accuracy: 0.4630 | f1: 0.4431\n",
            "Validation:  loss: 0.7974 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00346\n",
            "Train: loss: 0.4388 | accuracy: 0.7962 | f-acore: 0.7943\n",
            "Test:  loss: 1.0046 | accuracy: 0.4575 | f1: 0.4362\n",
            "Validation:  loss: 0.7939 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00347\n",
            "Train: loss: 0.4407 | accuracy: 0.7875 | f-acore: 0.7855\n",
            "Test:  loss: 0.9933 | accuracy: 0.4521 | f1: 0.4374\n",
            "Validation:  loss: 0.7861 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00348\n",
            "Train: loss: 0.4465 | accuracy: 0.7880 | f-acore: 0.7864\n",
            "Test:  loss: 1.0250 | accuracy: 0.4603 | f1: 0.4463\n",
            "Validation:  loss: 0.7863 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00349\n",
            "Train: loss: 0.4414 | accuracy: 0.7935 | f-acore: 0.7920\n",
            "Test:  loss: 1.0228 | accuracy: 0.4685 | f1: 0.4437\n",
            "Validation:  loss: 0.7612 | accuracy: 0.5679 | f1: 0.5612\n",
            "Epoch 00350\n",
            "Train: loss: 0.4551 | accuracy: 0.7953 | f-acore: 0.7939\n",
            "Test:  loss: 1.0120 | accuracy: 0.4603 | f1: 0.4432\n",
            "Validation:  loss: 0.7830 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00351\n",
            "Train: loss: 0.4575 | accuracy: 0.7871 | f-acore: 0.7856\n",
            "Test:  loss: 1.0185 | accuracy: 0.4630 | f1: 0.4419\n",
            "Validation:  loss: 0.7924 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00352\n",
            "Train: loss: 0.4499 | accuracy: 0.7889 | f-acore: 0.7873\n",
            "Test:  loss: 1.0494 | accuracy: 0.4630 | f1: 0.4486\n",
            "Validation:  loss: 0.8064 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00353\n",
            "Train: loss: 0.4388 | accuracy: 0.7903 | f-acore: 0.7888\n",
            "Test:  loss: 1.0629 | accuracy: 0.4685 | f1: 0.4424\n",
            "Validation:  loss: 0.7976 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00354\n",
            "Train: loss: 0.4336 | accuracy: 0.8031 | f-acore: 0.8010\n",
            "Test:  loss: 1.0720 | accuracy: 0.4548 | f1: 0.4314\n",
            "Validation:  loss: 0.7789 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00355\n",
            "Train: loss: 0.4450 | accuracy: 0.8027 | f-acore: 0.8006\n",
            "Test:  loss: 1.0396 | accuracy: 0.4575 | f1: 0.4323\n",
            "Validation:  loss: 0.7924 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00356\n",
            "Train: loss: 0.4250 | accuracy: 0.7981 | f-acore: 0.7966\n",
            "Test:  loss: 1.0204 | accuracy: 0.4575 | f1: 0.4419\n",
            "Validation:  loss: 0.7917 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00357\n",
            "Train: loss: 0.4464 | accuracy: 0.7885 | f-acore: 0.7868\n",
            "Test:  loss: 1.0398 | accuracy: 0.4740 | f1: 0.4545\n",
            "Validation:  loss: 0.8066 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00358\n",
            "Train: loss: 0.4498 | accuracy: 0.7972 | f-acore: 0.7953\n",
            "Test:  loss: 1.0257 | accuracy: 0.4712 | f1: 0.4522\n",
            "Validation:  loss: 0.8027 | accuracy: 0.4568 | f1: 0.4500\n",
            "Epoch 00359\n",
            "Train: loss: 0.4578 | accuracy: 0.7894 | f-acore: 0.7878\n",
            "Test:  loss: 1.0380 | accuracy: 0.4712 | f1: 0.4473\n",
            "Validation:  loss: 0.8057 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00360\n",
            "Train: loss: 0.4466 | accuracy: 0.7875 | f-acore: 0.7863\n",
            "Test:  loss: 1.0083 | accuracy: 0.4630 | f1: 0.4352\n",
            "Validation:  loss: 0.8293 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00361\n",
            "Train: loss: 0.4276 | accuracy: 0.8004 | f-acore: 0.7984\n",
            "Test:  loss: 1.0342 | accuracy: 0.4603 | f1: 0.4397\n",
            "Validation:  loss: 0.7970 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00362\n",
            "Train: loss: 0.4568 | accuracy: 0.7995 | f-acore: 0.7977\n",
            "Test:  loss: 1.0382 | accuracy: 0.4658 | f1: 0.4454\n",
            "Validation:  loss: 0.7752 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00363\n",
            "Train: loss: 0.4340 | accuracy: 0.7953 | f-acore: 0.7941\n",
            "Test:  loss: 1.0145 | accuracy: 0.4685 | f1: 0.4410\n",
            "Validation:  loss: 0.7844 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00364\n",
            "Train: loss: 0.4409 | accuracy: 0.7990 | f-acore: 0.7968\n",
            "Test:  loss: 1.0208 | accuracy: 0.4685 | f1: 0.4463\n",
            "Validation:  loss: 0.7831 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00365\n",
            "Train: loss: 0.4513 | accuracy: 0.7917 | f-acore: 0.7904\n",
            "Test:  loss: 1.0414 | accuracy: 0.4767 | f1: 0.4590\n",
            "Validation:  loss: 0.7923 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00366\n",
            "Train: loss: 0.4256 | accuracy: 0.7972 | f-acore: 0.7958\n",
            "Test:  loss: 1.0558 | accuracy: 0.4685 | f1: 0.4511\n",
            "Validation:  loss: 0.7824 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00367\n",
            "Train: loss: 0.4384 | accuracy: 0.7995 | f-acore: 0.7976\n",
            "Test:  loss: 1.0038 | accuracy: 0.4658 | f1: 0.4465\n",
            "Validation:  loss: 0.7941 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00368\n",
            "Train: loss: 0.4548 | accuracy: 0.7944 | f-acore: 0.7924\n",
            "Test:  loss: 1.0128 | accuracy: 0.4712 | f1: 0.4498\n",
            "Validation:  loss: 0.7882 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00369\n",
            "Train: loss: 0.4313 | accuracy: 0.7917 | f-acore: 0.7900\n",
            "Test:  loss: 1.0154 | accuracy: 0.4712 | f1: 0.4545\n",
            "Validation:  loss: 0.7885 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00370\n",
            "Train: loss: 0.4512 | accuracy: 0.7981 | f-acore: 0.7961\n",
            "Test:  loss: 1.0271 | accuracy: 0.4712 | f1: 0.4545\n",
            "Validation:  loss: 0.7832 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00371\n",
            "Train: loss: 0.4317 | accuracy: 0.8022 | f-acore: 0.8000\n",
            "Test:  loss: 1.0199 | accuracy: 0.4822 | f1: 0.4587\n",
            "Validation:  loss: 0.7929 | accuracy: 0.5062 | f1: 0.4886\n",
            "Epoch 00372\n",
            "Train: loss: 0.4583 | accuracy: 0.8082 | f-acore: 0.8071\n",
            "Test:  loss: 1.0334 | accuracy: 0.4740 | f1: 0.4556\n",
            "Validation:  loss: 0.8091 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00373\n",
            "Train: loss: 0.4523 | accuracy: 0.7875 | f-acore: 0.7864\n",
            "Test:  loss: 1.0337 | accuracy: 0.4712 | f1: 0.4302\n",
            "Validation:  loss: 0.7776 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00374\n",
            "Train: loss: 0.4494 | accuracy: 0.7798 | f-acore: 0.7775\n",
            "Test:  loss: 1.0424 | accuracy: 0.4630 | f1: 0.4486\n",
            "Validation:  loss: 0.7942 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00375\n",
            "Train: loss: 0.4534 | accuracy: 0.7871 | f-acore: 0.7846\n",
            "Test:  loss: 1.0622 | accuracy: 0.4740 | f1: 0.4508\n",
            "Validation:  loss: 0.7962 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00376\n",
            "Train: loss: 0.4408 | accuracy: 0.7949 | f-acore: 0.7932\n",
            "Test:  loss: 1.0273 | accuracy: 0.4685 | f1: 0.4380\n",
            "Validation:  loss: 0.8036 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00377\n",
            "Train: loss: 0.4397 | accuracy: 0.7985 | f-acore: 0.7970\n",
            "Test:  loss: 1.0179 | accuracy: 0.4685 | f1: 0.4463\n",
            "Validation:  loss: 0.8016 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00378\n",
            "Train: loss: 0.4327 | accuracy: 0.7976 | f-acore: 0.7958\n",
            "Test:  loss: 1.0589 | accuracy: 0.4630 | f1: 0.4431\n",
            "Validation:  loss: 0.7945 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00379\n",
            "Train: loss: 0.4321 | accuracy: 0.7917 | f-acore: 0.7890\n",
            "Test:  loss: 1.0204 | accuracy: 0.4575 | f1: 0.4398\n",
            "Validation:  loss: 0.8249 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00380\n",
            "Train: loss: 0.4544 | accuracy: 0.7995 | f-acore: 0.7982\n",
            "Test:  loss: 1.0608 | accuracy: 0.4712 | f1: 0.4473\n",
            "Validation:  loss: 0.8192 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00381\n",
            "Train: loss: 0.4343 | accuracy: 0.7885 | f-acore: 0.7873\n",
            "Test:  loss: 1.0640 | accuracy: 0.4795 | f1: 0.4590\n",
            "Validation:  loss: 0.8227 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00382\n",
            "Train: loss: 0.4162 | accuracy: 0.7848 | f-acore: 0.7823\n",
            "Test:  loss: 1.0825 | accuracy: 0.4740 | f1: 0.4533\n",
            "Validation:  loss: 0.8192 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00383\n",
            "Train: loss: 0.4493 | accuracy: 0.7981 | f-acore: 0.7963\n",
            "Test:  loss: 1.0609 | accuracy: 0.4685 | f1: 0.4476\n",
            "Validation:  loss: 0.8197 | accuracy: 0.4815 | f1: 0.4678\n",
            "Epoch 00384\n",
            "Train: loss: 0.4104 | accuracy: 0.8063 | f-acore: 0.8053\n",
            "Test:  loss: 1.0632 | accuracy: 0.4767 | f1: 0.4543\n",
            "Validation:  loss: 0.8125 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00385\n",
            "Train: loss: 0.4333 | accuracy: 0.8086 | f-acore: 0.8065\n",
            "Test:  loss: 1.0690 | accuracy: 0.4658 | f1: 0.4465\n",
            "Validation:  loss: 0.8033 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00386\n",
            "Train: loss: 0.4415 | accuracy: 0.8008 | f-acore: 0.7995\n",
            "Test:  loss: 1.0492 | accuracy: 0.4658 | f1: 0.4509\n",
            "Validation:  loss: 0.8062 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00387\n",
            "Train: loss: 0.4357 | accuracy: 0.7981 | f-acore: 0.7971\n",
            "Test:  loss: 1.0228 | accuracy: 0.4685 | f1: 0.4522\n",
            "Validation:  loss: 0.8313 | accuracy: 0.4691 | f1: 0.4639\n",
            "Epoch 00388\n",
            "Train: loss: 0.4277 | accuracy: 0.7949 | f-acore: 0.7929\n",
            "Test:  loss: 1.0291 | accuracy: 0.4630 | f1: 0.4393\n",
            "Validation:  loss: 0.8073 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00389\n",
            "Train: loss: 0.4280 | accuracy: 0.8109 | f-acore: 0.8088\n",
            "Test:  loss: 1.0539 | accuracy: 0.4630 | f1: 0.4476\n",
            "Validation:  loss: 0.8048 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00390\n",
            "Train: loss: 0.4301 | accuracy: 0.7990 | f-acore: 0.7971\n",
            "Test:  loss: 1.0295 | accuracy: 0.4630 | f1: 0.4486\n",
            "Validation:  loss: 0.7891 | accuracy: 0.4691 | f1: 0.4639\n",
            "Epoch 00391\n",
            "Train: loss: 0.4327 | accuracy: 0.7958 | f-acore: 0.7943\n",
            "Test:  loss: 1.0084 | accuracy: 0.4712 | f1: 0.4522\n",
            "Validation:  loss: 0.7990 | accuracy: 0.4815 | f1: 0.4717\n",
            "Epoch 00392\n",
            "Train: loss: 0.4197 | accuracy: 0.7962 | f-acore: 0.7951\n",
            "Test:  loss: 1.0407 | accuracy: 0.4685 | f1: 0.4500\n",
            "Validation:  loss: 0.8120 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00393\n",
            "Train: loss: 0.4339 | accuracy: 0.8027 | f-acore: 0.8008\n",
            "Test:  loss: 1.0525 | accuracy: 0.4603 | f1: 0.4371\n",
            "Validation:  loss: 0.8125 | accuracy: 0.4815 | f1: 0.4717\n",
            "Epoch 00394\n",
            "Train: loss: 0.4330 | accuracy: 0.8017 | f-acore: 0.8003\n",
            "Test:  loss: 1.0664 | accuracy: 0.4548 | f1: 0.4340\n",
            "Validation:  loss: 0.8100 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00395\n",
            "Train: loss: 0.4176 | accuracy: 0.7953 | f-acore: 0.7927\n",
            "Test:  loss: 1.0843 | accuracy: 0.4603 | f1: 0.4420\n",
            "Validation:  loss: 0.8125 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00396\n",
            "Train: loss: 0.4395 | accuracy: 0.7839 | f-acore: 0.7825\n",
            "Test:  loss: 1.0496 | accuracy: 0.4658 | f1: 0.4499\n",
            "Validation:  loss: 0.8088 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00397\n",
            "Train: loss: 0.4264 | accuracy: 0.8091 | f-acore: 0.8077\n",
            "Test:  loss: 1.0752 | accuracy: 0.4603 | f1: 0.4358\n",
            "Validation:  loss: 0.8145 | accuracy: 0.4938 | f1: 0.4782\n",
            "Epoch 00398\n",
            "Train: loss: 0.4268 | accuracy: 0.8027 | f-acore: 0.7996\n",
            "Test:  loss: 1.0711 | accuracy: 0.4795 | f1: 0.4613\n",
            "Validation:  loss: 0.8243 | accuracy: 0.4568 | f1: 0.4424\n",
            "Epoch 00399\n",
            "Train: loss: 0.4305 | accuracy: 0.7944 | f-acore: 0.7937\n",
            "Test:  loss: 1.0696 | accuracy: 0.4658 | f1: 0.4488\n",
            "Validation:  loss: 0.7988 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00400\n",
            "Train: loss: 0.4170 | accuracy: 0.8008 | f-acore: 0.7993\n",
            "Test:  loss: 1.0535 | accuracy: 0.4658 | f1: 0.4477\n",
            "Validation:  loss: 0.8238 | accuracy: 0.4815 | f1: 0.4678\n",
            "-----------------------------------------------------------------------------------------\n",
            "^RUT\n",
            "-----------------------------------------------------------------------------------------\n",
            "Epoch 00001\n",
            "Train: loss: 0.6914 | accuracy: 0.5234 | f-acore: 0.3761\n",
            "Test:  loss: 0.6903 | accuracy: 0.5534 | f1: 0.3563\n",
            "Validation:  loss: 0.6873 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00002\n",
            "Train: loss: 0.6914 | accuracy: 0.5252 | f-acore: 0.3443\n",
            "Test:  loss: 0.6893 | accuracy: 0.5534 | f1: 0.3563\n",
            "Validation:  loss: 0.6830 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00003\n",
            "Train: loss: 0.6914 | accuracy: 0.5252 | f-acore: 0.3443\n",
            "Test:  loss: 0.6902 | accuracy: 0.5534 | f1: 0.3563\n",
            "Validation:  loss: 0.6842 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00004\n",
            "Train: loss: 0.6905 | accuracy: 0.5243 | f-acore: 0.3465\n",
            "Test:  loss: 0.6903 | accuracy: 0.5507 | f1: 0.3606\n",
            "Validation:  loss: 0.6846 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00005\n",
            "Train: loss: 0.6914 | accuracy: 0.5256 | f-acore: 0.3728\n",
            "Test:  loss: 0.6918 | accuracy: 0.5342 | f1: 0.5062\n",
            "Validation:  loss: 0.6867 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00006\n",
            "Train: loss: 0.6909 | accuracy: 0.5243 | f-acore: 0.3474\n",
            "Test:  loss: 0.6902 | accuracy: 0.5534 | f1: 0.3563\n",
            "Validation:  loss: 0.6861 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00007\n",
            "Train: loss: 0.6931 | accuracy: 0.5229 | f-acore: 0.3543\n",
            "Test:  loss: 0.6920 | accuracy: 0.5479 | f1: 0.4500\n",
            "Validation:  loss: 0.6892 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00008\n",
            "Train: loss: 0.6918 | accuracy: 0.5353 | f-acore: 0.4836\n",
            "Test:  loss: 0.6957 | accuracy: 0.4575 | f1: 0.3382\n",
            "Validation:  loss: 0.6937 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00009\n",
            "Train: loss: 0.6913 | accuracy: 0.5330 | f-acore: 0.4863\n",
            "Test:  loss: 0.6918 | accuracy: 0.5397 | f1: 0.4999\n",
            "Validation:  loss: 0.6880 | accuracy: 0.5926 | f1: 0.3721\n",
            "Epoch 00010\n",
            "Train: loss: 0.6882 | accuracy: 0.5325 | f-acore: 0.4131\n",
            "Test:  loss: 0.6920 | accuracy: 0.5589 | f1: 0.5589\n",
            "Validation:  loss: 0.6861 | accuracy: 0.6049 | f1: 0.3769\n",
            "Epoch 00011\n",
            "Train: loss: 0.6882 | accuracy: 0.5357 | f-acore: 0.4573\n",
            "Test:  loss: 0.6954 | accuracy: 0.4795 | f1: 0.4399\n",
            "Validation:  loss: 0.6842 | accuracy: 0.5556 | f1: 0.3812\n",
            "Epoch 00012\n",
            "Train: loss: 0.6887 | accuracy: 0.5330 | f-acore: 0.4317\n",
            "Test:  loss: 0.7060 | accuracy: 0.4575 | f1: 0.3344\n",
            "Validation:  loss: 0.6947 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00013\n",
            "Train: loss: 0.6880 | accuracy: 0.5385 | f-acore: 0.4764\n",
            "Test:  loss: 0.7027 | accuracy: 0.4548 | f1: 0.3810\n",
            "Validation:  loss: 0.6876 | accuracy: 0.4938 | f1: 0.4733\n",
            "Epoch 00014\n",
            "Train: loss: 0.6872 | accuracy: 0.5385 | f-acore: 0.4435\n",
            "Test:  loss: 0.6952 | accuracy: 0.4986 | f1: 0.4856\n",
            "Validation:  loss: 0.6827 | accuracy: 0.5556 | f1: 0.4535\n",
            "Epoch 00015\n",
            "Train: loss: 0.6845 | accuracy: 0.5472 | f-acore: 0.4842\n",
            "Test:  loss: 0.6960 | accuracy: 0.4986 | f1: 0.4827\n",
            "Validation:  loss: 0.6722 | accuracy: 0.5926 | f1: 0.4776\n",
            "Epoch 00016\n",
            "Train: loss: 0.6869 | accuracy: 0.5325 | f-acore: 0.4319\n",
            "Test:  loss: 0.6893 | accuracy: 0.5425 | f1: 0.4986\n",
            "Validation:  loss: 0.6800 | accuracy: 0.5926 | f1: 0.5055\n",
            "Epoch 00017\n",
            "Train: loss: 0.6880 | accuracy: 0.5517 | f-acore: 0.4948\n",
            "Test:  loss: 0.7041 | accuracy: 0.4493 | f1: 0.4169\n",
            "Validation:  loss: 0.6888 | accuracy: 0.5802 | f1: 0.5500\n",
            "Epoch 00018\n",
            "Train: loss: 0.6830 | accuracy: 0.5614 | f-acore: 0.5571\n",
            "Test:  loss: 0.7032 | accuracy: 0.4685 | f1: 0.4205\n",
            "Validation:  loss: 0.6970 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00019\n",
            "Train: loss: 0.6819 | accuracy: 0.5517 | f-acore: 0.4913\n",
            "Test:  loss: 0.7004 | accuracy: 0.5041 | f1: 0.4829\n",
            "Validation:  loss: 0.6730 | accuracy: 0.5926 | f1: 0.5055\n",
            "Epoch 00020\n",
            "Train: loss: 0.6813 | accuracy: 0.5705 | f-acore: 0.5374\n",
            "Test:  loss: 0.7071 | accuracy: 0.5068 | f1: 0.4936\n",
            "Validation:  loss: 0.6753 | accuracy: 0.5926 | f1: 0.5278\n",
            "Epoch 00021\n",
            "Train: loss: 0.6826 | accuracy: 0.5687 | f-acore: 0.5324\n",
            "Test:  loss: 0.7197 | accuracy: 0.4411 | f1: 0.4411\n",
            "Validation:  loss: 0.6833 | accuracy: 0.5802 | f1: 0.5185\n",
            "Epoch 00022\n",
            "Train: loss: 0.6800 | accuracy: 0.5723 | f-acore: 0.5544\n",
            "Test:  loss: 0.7106 | accuracy: 0.4493 | f1: 0.4492\n",
            "Validation:  loss: 0.6874 | accuracy: 0.5679 | f1: 0.5093\n",
            "Epoch 00023\n",
            "Train: loss: 0.6780 | accuracy: 0.5728 | f-acore: 0.5590\n",
            "Test:  loss: 0.7003 | accuracy: 0.5123 | f1: 0.5120\n",
            "Validation:  loss: 0.6915 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00024\n",
            "Train: loss: 0.6845 | accuracy: 0.5664 | f-acore: 0.5520\n",
            "Test:  loss: 0.7257 | accuracy: 0.4575 | f1: 0.4513\n",
            "Validation:  loss: 0.6899 | accuracy: 0.5432 | f1: 0.4907\n",
            "Epoch 00025\n",
            "Train: loss: 0.6793 | accuracy: 0.5760 | f-acore: 0.5669\n",
            "Test:  loss: 0.7174 | accuracy: 0.4658 | f1: 0.4477\n",
            "Validation:  loss: 0.6905 | accuracy: 0.5679 | f1: 0.5546\n",
            "Epoch 00026\n",
            "Train: loss: 0.6764 | accuracy: 0.5861 | f-acore: 0.5824\n",
            "Test:  loss: 0.7139 | accuracy: 0.4712 | f1: 0.4710\n",
            "Validation:  loss: 0.6896 | accuracy: 0.6173 | f1: 0.5805\n",
            "Epoch 00027\n",
            "Train: loss: 0.6762 | accuracy: 0.5884 | f-acore: 0.5830\n",
            "Test:  loss: 0.7254 | accuracy: 0.4849 | f1: 0.4701\n",
            "Validation:  loss: 0.7025 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00028\n",
            "Train: loss: 0.6741 | accuracy: 0.5838 | f-acore: 0.5642\n",
            "Test:  loss: 0.7122 | accuracy: 0.4932 | f1: 0.4827\n",
            "Validation:  loss: 0.7012 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00029\n",
            "Train: loss: 0.6732 | accuracy: 0.5838 | f-acore: 0.5742\n",
            "Test:  loss: 0.7292 | accuracy: 0.4740 | f1: 0.4728\n",
            "Validation:  loss: 0.6946 | accuracy: 0.5926 | f1: 0.5761\n",
            "Epoch 00030\n",
            "Train: loss: 0.6681 | accuracy: 0.5966 | f-acore: 0.5857\n",
            "Test:  loss: 0.7231 | accuracy: 0.4603 | f1: 0.4597\n",
            "Validation:  loss: 0.6898 | accuracy: 0.5309 | f1: 0.4897\n",
            "Epoch 00031\n",
            "Train: loss: 0.6711 | accuracy: 0.5943 | f-acore: 0.5827\n",
            "Test:  loss: 0.7554 | accuracy: 0.4658 | f1: 0.4593\n",
            "Validation:  loss: 0.7041 | accuracy: 0.5802 | f1: 0.5724\n",
            "Epoch 00032\n",
            "Train: loss: 0.6646 | accuracy: 0.6026 | f-acore: 0.5899\n",
            "Test:  loss: 0.7176 | accuracy: 0.4767 | f1: 0.4727\n",
            "Validation:  loss: 0.6811 | accuracy: 0.5926 | f1: 0.5601\n",
            "Epoch 00033\n",
            "Train: loss: 0.6710 | accuracy: 0.5865 | f-acore: 0.5704\n",
            "Test:  loss: 0.7335 | accuracy: 0.4603 | f1: 0.4597\n",
            "Validation:  loss: 0.6903 | accuracy: 0.5926 | f1: 0.5373\n",
            "Epoch 00034\n",
            "Train: loss: 0.6666 | accuracy: 0.5907 | f-acore: 0.5762\n",
            "Test:  loss: 0.7478 | accuracy: 0.4630 | f1: 0.4623\n",
            "Validation:  loss: 0.6958 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00035\n",
            "Train: loss: 0.6570 | accuracy: 0.6067 | f-acore: 0.5900\n",
            "Test:  loss: 0.7468 | accuracy: 0.4658 | f1: 0.4650\n",
            "Validation:  loss: 0.6964 | accuracy: 0.5679 | f1: 0.5546\n",
            "Epoch 00036\n",
            "Train: loss: 0.6628 | accuracy: 0.5998 | f-acore: 0.5928\n",
            "Test:  loss: 0.7353 | accuracy: 0.4932 | f1: 0.4887\n",
            "Validation:  loss: 0.6897 | accuracy: 0.5556 | f1: 0.5088\n",
            "Epoch 00037\n",
            "Train: loss: 0.6624 | accuracy: 0.5875 | f-acore: 0.5579\n",
            "Test:  loss: 0.7365 | accuracy: 0.4685 | f1: 0.4656\n",
            "Validation:  loss: 0.7145 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00038\n",
            "Train: loss: 0.6605 | accuracy: 0.6067 | f-acore: 0.6050\n",
            "Test:  loss: 0.7250 | accuracy: 0.4685 | f1: 0.4561\n",
            "Validation:  loss: 0.6981 | accuracy: 0.5185 | f1: 0.4802\n",
            "Epoch 00039\n",
            "Train: loss: 0.6606 | accuracy: 0.6021 | f-acore: 0.5869\n",
            "Test:  loss: 0.7388 | accuracy: 0.4767 | f1: 0.4732\n",
            "Validation:  loss: 0.7279 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00040\n",
            "Train: loss: 0.6617 | accuracy: 0.5989 | f-acore: 0.5986\n",
            "Test:  loss: 0.7112 | accuracy: 0.4959 | f1: 0.4859\n",
            "Validation:  loss: 0.7104 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00041\n",
            "Train: loss: 0.6651 | accuracy: 0.6003 | f-acore: 0.5873\n",
            "Test:  loss: 0.7409 | accuracy: 0.4521 | f1: 0.4436\n",
            "Validation:  loss: 0.7030 | accuracy: 0.5309 | f1: 0.5035\n",
            "Epoch 00042\n",
            "Train: loss: 0.6600 | accuracy: 0.6103 | f-acore: 0.6021\n",
            "Test:  loss: 0.7235 | accuracy: 0.4959 | f1: 0.4866\n",
            "Validation:  loss: 0.7087 | accuracy: 0.5185 | f1: 0.4935\n",
            "Epoch 00043\n",
            "Train: loss: 0.6624 | accuracy: 0.6145 | f-acore: 0.6086\n",
            "Test:  loss: 0.7435 | accuracy: 0.4603 | f1: 0.4442\n",
            "Validation:  loss: 0.7282 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00044\n",
            "Train: loss: 0.6553 | accuracy: 0.6126 | f-acore: 0.6023\n",
            "Test:  loss: 0.7320 | accuracy: 0.4959 | f1: 0.4942\n",
            "Validation:  loss: 0.7132 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00045\n",
            "Train: loss: 0.6521 | accuracy: 0.6085 | f-acore: 0.6028\n",
            "Test:  loss: 0.7390 | accuracy: 0.4822 | f1: 0.4697\n",
            "Validation:  loss: 0.7024 | accuracy: 0.6173 | f1: 0.5868\n",
            "Epoch 00046\n",
            "Train: loss: 0.6575 | accuracy: 0.6067 | f-acore: 0.5882\n",
            "Test:  loss: 0.7398 | accuracy: 0.4575 | f1: 0.4574\n",
            "Validation:  loss: 0.7148 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00047\n",
            "Train: loss: 0.6562 | accuracy: 0.6177 | f-acore: 0.6153\n",
            "Test:  loss: 0.7406 | accuracy: 0.4575 | f1: 0.4566\n",
            "Validation:  loss: 0.7096 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00048\n",
            "Train: loss: 0.6606 | accuracy: 0.6136 | f-acore: 0.6113\n",
            "Test:  loss: 0.7408 | accuracy: 0.4932 | f1: 0.4924\n",
            "Validation:  loss: 0.7121 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00049\n",
            "Train: loss: 0.6519 | accuracy: 0.6117 | f-acore: 0.6094\n",
            "Test:  loss: 0.7380 | accuracy: 0.4904 | f1: 0.4839\n",
            "Validation:  loss: 0.7142 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00050\n",
            "Train: loss: 0.6497 | accuracy: 0.6213 | f-acore: 0.6171\n",
            "Test:  loss: 0.7585 | accuracy: 0.4959 | f1: 0.4917\n",
            "Validation:  loss: 0.7138 | accuracy: 0.5802 | f1: 0.5653\n",
            "Epoch 00051\n",
            "Train: loss: 0.6496 | accuracy: 0.6181 | f-acore: 0.6146\n",
            "Test:  loss: 0.7753 | accuracy: 0.4411 | f1: 0.4402\n",
            "Validation:  loss: 0.7321 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00052\n",
            "Train: loss: 0.6450 | accuracy: 0.6113 | f-acore: 0.6060\n",
            "Test:  loss: 0.7589 | accuracy: 0.4630 | f1: 0.4586\n",
            "Validation:  loss: 0.7105 | accuracy: 0.5679 | f1: 0.5263\n",
            "Epoch 00053\n",
            "Train: loss: 0.6495 | accuracy: 0.6126 | f-acore: 0.6077\n",
            "Test:  loss: 0.7587 | accuracy: 0.4466 | f1: 0.4447\n",
            "Validation:  loss: 0.7328 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00054\n",
            "Train: loss: 0.6439 | accuracy: 0.6259 | f-acore: 0.6243\n",
            "Test:  loss: 0.7481 | accuracy: 0.4712 | f1: 0.4486\n",
            "Validation:  loss: 0.7005 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00055\n",
            "Train: loss: 0.6445 | accuracy: 0.6140 | f-acore: 0.6041\n",
            "Test:  loss: 0.7816 | accuracy: 0.4575 | f1: 0.4440\n",
            "Validation:  loss: 0.7508 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00056\n",
            "Train: loss: 0.6478 | accuracy: 0.6213 | f-acore: 0.6178\n",
            "Test:  loss: 0.7548 | accuracy: 0.4822 | f1: 0.4647\n",
            "Validation:  loss: 0.7081 | accuracy: 0.6049 | f1: 0.5819\n",
            "Epoch 00057\n",
            "Train: loss: 0.6424 | accuracy: 0.6081 | f-acore: 0.6023\n",
            "Test:  loss: 0.7522 | accuracy: 0.4767 | f1: 0.4736\n",
            "Validation:  loss: 0.7207 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00058\n",
            "Train: loss: 0.6359 | accuracy: 0.6250 | f-acore: 0.6175\n",
            "Test:  loss: 0.7706 | accuracy: 0.4740 | f1: 0.4696\n",
            "Validation:  loss: 0.7298 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00059\n",
            "Train: loss: 0.6535 | accuracy: 0.6186 | f-acore: 0.6154\n",
            "Test:  loss: 0.7698 | accuracy: 0.4603 | f1: 0.4555\n",
            "Validation:  loss: 0.7284 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00060\n",
            "Train: loss: 0.6421 | accuracy: 0.6227 | f-acore: 0.6121\n",
            "Test:  loss: 0.7319 | accuracy: 0.4904 | f1: 0.4679\n",
            "Validation:  loss: 0.7114 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00061\n",
            "Train: loss: 0.6451 | accuracy: 0.6200 | f-acore: 0.6110\n",
            "Test:  loss: 0.7653 | accuracy: 0.4521 | f1: 0.4521\n",
            "Validation:  loss: 0.7306 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00062\n",
            "Train: loss: 0.6421 | accuracy: 0.6209 | f-acore: 0.6194\n",
            "Test:  loss: 0.7524 | accuracy: 0.4795 | f1: 0.4645\n",
            "Validation:  loss: 0.7246 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00063\n",
            "Train: loss: 0.6469 | accuracy: 0.6245 | f-acore: 0.6210\n",
            "Test:  loss: 0.7653 | accuracy: 0.4685 | f1: 0.4610\n",
            "Validation:  loss: 0.7262 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00064\n",
            "Train: loss: 0.6303 | accuracy: 0.6323 | f-acore: 0.6267\n",
            "Test:  loss: 0.7586 | accuracy: 0.4904 | f1: 0.4872\n",
            "Validation:  loss: 0.7292 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00065\n",
            "Train: loss: 0.6292 | accuracy: 0.6328 | f-acore: 0.6269\n",
            "Test:  loss: 0.7855 | accuracy: 0.4603 | f1: 0.4603\n",
            "Validation:  loss: 0.7351 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00066\n",
            "Train: loss: 0.6432 | accuracy: 0.6337 | f-acore: 0.6280\n",
            "Test:  loss: 0.7852 | accuracy: 0.4685 | f1: 0.4522\n",
            "Validation:  loss: 0.7168 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00067\n",
            "Train: loss: 0.6463 | accuracy: 0.6177 | f-acore: 0.6162\n",
            "Test:  loss: 0.7541 | accuracy: 0.4849 | f1: 0.4747\n",
            "Validation:  loss: 0.7228 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00068\n",
            "Train: loss: 0.6418 | accuracy: 0.6291 | f-acore: 0.6196\n",
            "Test:  loss: 0.7820 | accuracy: 0.4548 | f1: 0.4547\n",
            "Validation:  loss: 0.7367 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00069\n",
            "Train: loss: 0.6398 | accuracy: 0.6355 | f-acore: 0.6337\n",
            "Test:  loss: 0.7599 | accuracy: 0.4712 | f1: 0.4689\n",
            "Validation:  loss: 0.7297 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00070\n",
            "Train: loss: 0.6392 | accuracy: 0.6346 | f-acore: 0.6293\n",
            "Test:  loss: 0.7704 | accuracy: 0.4575 | f1: 0.4536\n",
            "Validation:  loss: 0.7379 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00071\n",
            "Train: loss: 0.6330 | accuracy: 0.6250 | f-acore: 0.6194\n",
            "Test:  loss: 0.7697 | accuracy: 0.4767 | f1: 0.4710\n",
            "Validation:  loss: 0.7354 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00072\n",
            "Train: loss: 0.6306 | accuracy: 0.6392 | f-acore: 0.6340\n",
            "Test:  loss: 0.7996 | accuracy: 0.4658 | f1: 0.4599\n",
            "Validation:  loss: 0.7460 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00073\n",
            "Train: loss: 0.6360 | accuracy: 0.6319 | f-acore: 0.6281\n",
            "Test:  loss: 0.7373 | accuracy: 0.4767 | f1: 0.4736\n",
            "Validation:  loss: 0.7504 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00074\n",
            "Train: loss: 0.6367 | accuracy: 0.6277 | f-acore: 0.6187\n",
            "Test:  loss: 0.7515 | accuracy: 0.4603 | f1: 0.4601\n",
            "Validation:  loss: 0.7282 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00075\n",
            "Train: loss: 0.6352 | accuracy: 0.6456 | f-acore: 0.6435\n",
            "Test:  loss: 0.7739 | accuracy: 0.4740 | f1: 0.4725\n",
            "Validation:  loss: 0.7340 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00076\n",
            "Train: loss: 0.6228 | accuracy: 0.6461 | f-acore: 0.6442\n",
            "Test:  loss: 0.7788 | accuracy: 0.4603 | f1: 0.4523\n",
            "Validation:  loss: 0.7311 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00077\n",
            "Train: loss: 0.6258 | accuracy: 0.6424 | f-acore: 0.6399\n",
            "Test:  loss: 0.7816 | accuracy: 0.4712 | f1: 0.4660\n",
            "Validation:  loss: 0.7411 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00078\n",
            "Train: loss: 0.6293 | accuracy: 0.6397 | f-acore: 0.6367\n",
            "Test:  loss: 0.7848 | accuracy: 0.4603 | f1: 0.4442\n",
            "Validation:  loss: 0.7361 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00079\n",
            "Train: loss: 0.6221 | accuracy: 0.6456 | f-acore: 0.6435\n",
            "Test:  loss: 0.7684 | accuracy: 0.4740 | f1: 0.4599\n",
            "Validation:  loss: 0.7431 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00080\n",
            "Train: loss: 0.6298 | accuracy: 0.6461 | f-acore: 0.6444\n",
            "Test:  loss: 0.7788 | accuracy: 0.4740 | f1: 0.4508\n",
            "Validation:  loss: 0.7352 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00081\n",
            "Train: loss: 0.6481 | accuracy: 0.6300 | f-acore: 0.6228\n",
            "Test:  loss: 0.7775 | accuracy: 0.4575 | f1: 0.4467\n",
            "Validation:  loss: 0.7486 | accuracy: 0.4321 | f1: 0.4214\n",
            "Epoch 00082\n",
            "Train: loss: 0.6260 | accuracy: 0.6461 | f-acore: 0.6434\n",
            "Test:  loss: 0.7919 | accuracy: 0.4795 | f1: 0.4624\n",
            "Validation:  loss: 0.7470 | accuracy: 0.4568 | f1: 0.4500\n",
            "Epoch 00083\n",
            "Train: loss: 0.6225 | accuracy: 0.6484 | f-acore: 0.6472\n",
            "Test:  loss: 0.7879 | accuracy: 0.4795 | f1: 0.4565\n",
            "Validation:  loss: 0.7480 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00084\n",
            "Train: loss: 0.6274 | accuracy: 0.6415 | f-acore: 0.6371\n",
            "Test:  loss: 0.7880 | accuracy: 0.4630 | f1: 0.4623\n",
            "Validation:  loss: 0.7736 | accuracy: 0.4198 | f1: 0.4183\n",
            "Epoch 00085\n",
            "Train: loss: 0.6259 | accuracy: 0.6493 | f-acore: 0.6485\n",
            "Test:  loss: 0.7713 | accuracy: 0.5068 | f1: 0.4642\n",
            "Validation:  loss: 0.7272 | accuracy: 0.5802 | f1: 0.5653\n",
            "Epoch 00086\n",
            "Train: loss: 0.6213 | accuracy: 0.6543 | f-acore: 0.6522\n",
            "Test:  loss: 0.7950 | accuracy: 0.4712 | f1: 0.4702\n",
            "Validation:  loss: 0.7836 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00087\n",
            "Train: loss: 0.6289 | accuracy: 0.6552 | f-acore: 0.6526\n",
            "Test:  loss: 0.7951 | accuracy: 0.4877 | f1: 0.4657\n",
            "Validation:  loss: 0.7379 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00088\n",
            "Train: loss: 0.6138 | accuracy: 0.6497 | f-acore: 0.6458\n",
            "Test:  loss: 0.8099 | accuracy: 0.4630 | f1: 0.4562\n",
            "Validation:  loss: 0.7630 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00089\n",
            "Train: loss: 0.6211 | accuracy: 0.6433 | f-acore: 0.6350\n",
            "Test:  loss: 0.8193 | accuracy: 0.4712 | f1: 0.4627\n",
            "Validation:  loss: 0.7630 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00090\n",
            "Train: loss: 0.6188 | accuracy: 0.6502 | f-acore: 0.6492\n",
            "Test:  loss: 0.8127 | accuracy: 0.4740 | f1: 0.4578\n",
            "Validation:  loss: 0.7466 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00091\n",
            "Train: loss: 0.6180 | accuracy: 0.6429 | f-acore: 0.6389\n",
            "Test:  loss: 0.8221 | accuracy: 0.4740 | f1: 0.4626\n",
            "Validation:  loss: 0.7464 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00092\n",
            "Train: loss: 0.6225 | accuracy: 0.6502 | f-acore: 0.6447\n",
            "Test:  loss: 0.8106 | accuracy: 0.4658 | f1: 0.4605\n",
            "Validation:  loss: 0.7615 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00093\n",
            "Train: loss: 0.6127 | accuracy: 0.6561 | f-acore: 0.6540\n",
            "Test:  loss: 0.7805 | accuracy: 0.4685 | f1: 0.4595\n",
            "Validation:  loss: 0.7528 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00094\n",
            "Train: loss: 0.6066 | accuracy: 0.6635 | f-acore: 0.6597\n",
            "Test:  loss: 0.8034 | accuracy: 0.4822 | f1: 0.4731\n",
            "Validation:  loss: 0.7386 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00095\n",
            "Train: loss: 0.6263 | accuracy: 0.6506 | f-acore: 0.6478\n",
            "Test:  loss: 0.8048 | accuracy: 0.4932 | f1: 0.4863\n",
            "Validation:  loss: 0.7478 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00096\n",
            "Train: loss: 0.6175 | accuracy: 0.6612 | f-acore: 0.6600\n",
            "Test:  loss: 0.7850 | accuracy: 0.4877 | f1: 0.4618\n",
            "Validation:  loss: 0.7289 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00097\n",
            "Train: loss: 0.6086 | accuracy: 0.6598 | f-acore: 0.6577\n",
            "Test:  loss: 0.7899 | accuracy: 0.4959 | f1: 0.4859\n",
            "Validation:  loss: 0.7603 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00098\n",
            "Train: loss: 0.6230 | accuracy: 0.6598 | f-acore: 0.6581\n",
            "Test:  loss: 0.7998 | accuracy: 0.4740 | f1: 0.4626\n",
            "Validation:  loss: 0.7756 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00099\n",
            "Train: loss: 0.6170 | accuracy: 0.6676 | f-acore: 0.6659\n",
            "Test:  loss: 0.8406 | accuracy: 0.4548 | f1: 0.4482\n",
            "Validation:  loss: 0.7620 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00100\n",
            "Train: loss: 0.6084 | accuracy: 0.6625 | f-acore: 0.6593\n",
            "Test:  loss: 0.7948 | accuracy: 0.4904 | f1: 0.4818\n",
            "Validation:  loss: 0.7805 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00101\n",
            "Train: loss: 0.6105 | accuracy: 0.6561 | f-acore: 0.6547\n",
            "Test:  loss: 0.8267 | accuracy: 0.4740 | f1: 0.4696\n",
            "Validation:  loss: 0.7729 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00102\n",
            "Train: loss: 0.6055 | accuracy: 0.6625 | f-acore: 0.6597\n",
            "Test:  loss: 0.8221 | accuracy: 0.4767 | f1: 0.4641\n",
            "Validation:  loss: 0.7615 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00103\n",
            "Train: loss: 0.6154 | accuracy: 0.6644 | f-acore: 0.6623\n",
            "Test:  loss: 0.8050 | accuracy: 0.4822 | f1: 0.4688\n",
            "Validation:  loss: 0.7657 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00104\n",
            "Train: loss: 0.6020 | accuracy: 0.6671 | f-acore: 0.6658\n",
            "Test:  loss: 0.8398 | accuracy: 0.4986 | f1: 0.4783\n",
            "Validation:  loss: 0.7668 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00105\n",
            "Train: loss: 0.5976 | accuracy: 0.6658 | f-acore: 0.6639\n",
            "Test:  loss: 0.8169 | accuracy: 0.4795 | f1: 0.4714\n",
            "Validation:  loss: 0.7754 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00106\n",
            "Train: loss: 0.6038 | accuracy: 0.6781 | f-acore: 0.6744\n",
            "Test:  loss: 0.8481 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 0.7976 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00107\n",
            "Train: loss: 0.6100 | accuracy: 0.6708 | f-acore: 0.6696\n",
            "Test:  loss: 0.8110 | accuracy: 0.4795 | f1: 0.4714\n",
            "Validation:  loss: 0.7940 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00108\n",
            "Train: loss: 0.6095 | accuracy: 0.6694 | f-acore: 0.6673\n",
            "Test:  loss: 0.8292 | accuracy: 0.4685 | f1: 0.4624\n",
            "Validation:  loss: 0.7851 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00109\n",
            "Train: loss: 0.6036 | accuracy: 0.6589 | f-acore: 0.6554\n",
            "Test:  loss: 0.8285 | accuracy: 0.4795 | f1: 0.4728\n",
            "Validation:  loss: 0.7867 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00110\n",
            "Train: loss: 0.6055 | accuracy: 0.6799 | f-acore: 0.6787\n",
            "Test:  loss: 0.8438 | accuracy: 0.4740 | f1: 0.4618\n",
            "Validation:  loss: 0.7834 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00111\n",
            "Train: loss: 0.5939 | accuracy: 0.6625 | f-acore: 0.6601\n",
            "Test:  loss: 0.8198 | accuracy: 0.4849 | f1: 0.4701\n",
            "Validation:  loss: 0.7753 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00112\n",
            "Train: loss: 0.5982 | accuracy: 0.6703 | f-acore: 0.6681\n",
            "Test:  loss: 0.8443 | accuracy: 0.4849 | f1: 0.4670\n",
            "Validation:  loss: 0.7646 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00113\n",
            "Train: loss: 0.5943 | accuracy: 0.6621 | f-acore: 0.6599\n",
            "Test:  loss: 0.8441 | accuracy: 0.4658 | f1: 0.4564\n",
            "Validation:  loss: 0.7780 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00114\n",
            "Train: loss: 0.5900 | accuracy: 0.6740 | f-acore: 0.6671\n",
            "Test:  loss: 0.8234 | accuracy: 0.4575 | f1: 0.4557\n",
            "Validation:  loss: 0.7800 | accuracy: 0.4074 | f1: 0.4066\n",
            "Epoch 00115\n",
            "Train: loss: 0.5958 | accuracy: 0.6827 | f-acore: 0.6794\n",
            "Test:  loss: 0.8566 | accuracy: 0.4740 | f1: 0.4608\n",
            "Validation:  loss: 0.7732 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00116\n",
            "Train: loss: 0.5913 | accuracy: 0.6772 | f-acore: 0.6765\n",
            "Test:  loss: 0.8670 | accuracy: 0.5260 | f1: 0.4892\n",
            "Validation:  loss: 0.7555 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00117\n",
            "Train: loss: 0.5922 | accuracy: 0.6722 | f-acore: 0.6671\n",
            "Test:  loss: 0.8423 | accuracy: 0.4712 | f1: 0.4707\n",
            "Validation:  loss: 0.8190 | accuracy: 0.3951 | f1: 0.3917\n",
            "Epoch 00118\n",
            "Train: loss: 0.5899 | accuracy: 0.6859 | f-acore: 0.6850\n",
            "Test:  loss: 0.8570 | accuracy: 0.5260 | f1: 0.4908\n",
            "Validation:  loss: 0.7660 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00119\n",
            "Train: loss: 0.5919 | accuracy: 0.6786 | f-acore: 0.6778\n",
            "Test:  loss: 0.8553 | accuracy: 0.4795 | f1: 0.4624\n",
            "Validation:  loss: 0.7696 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00120\n",
            "Train: loss: 0.5971 | accuracy: 0.6799 | f-acore: 0.6761\n",
            "Test:  loss: 0.8559 | accuracy: 0.4932 | f1: 0.4726\n",
            "Validation:  loss: 0.7724 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00121\n",
            "Train: loss: 0.6035 | accuracy: 0.6712 | f-acore: 0.6674\n",
            "Test:  loss: 0.8541 | accuracy: 0.4904 | f1: 0.4748\n",
            "Validation:  loss: 0.7910 | accuracy: 0.4691 | f1: 0.4639\n",
            "Epoch 00122\n",
            "Train: loss: 0.6112 | accuracy: 0.6712 | f-acore: 0.6688\n",
            "Test:  loss: 0.8491 | accuracy: 0.4822 | f1: 0.4746\n",
            "Validation:  loss: 0.7863 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00123\n",
            "Train: loss: 0.5983 | accuracy: 0.6717 | f-acore: 0.6715\n",
            "Test:  loss: 0.8487 | accuracy: 0.5452 | f1: 0.5007\n",
            "Validation:  loss: 0.7446 | accuracy: 0.5679 | f1: 0.5335\n",
            "Epoch 00124\n",
            "Train: loss: 0.6110 | accuracy: 0.6676 | f-acore: 0.6626\n",
            "Test:  loss: 0.8289 | accuracy: 0.5178 | f1: 0.4999\n",
            "Validation:  loss: 0.7500 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00125\n",
            "Train: loss: 0.6031 | accuracy: 0.6809 | f-acore: 0.6807\n",
            "Test:  loss: 0.8467 | accuracy: 0.5178 | f1: 0.4888\n",
            "Validation:  loss: 0.7490 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00126\n",
            "Train: loss: 0.5869 | accuracy: 0.6795 | f-acore: 0.6773\n",
            "Test:  loss: 0.8319 | accuracy: 0.5233 | f1: 0.4986\n",
            "Validation:  loss: 0.7728 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00127\n",
            "Train: loss: 0.5858 | accuracy: 0.6964 | f-acore: 0.6940\n",
            "Test:  loss: 0.8702 | accuracy: 0.5096 | f1: 0.4715\n",
            "Validation:  loss: 0.7697 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00128\n",
            "Train: loss: 0.5878 | accuracy: 0.6827 | f-acore: 0.6794\n",
            "Test:  loss: 0.8389 | accuracy: 0.5233 | f1: 0.4986\n",
            "Validation:  loss: 0.7594 | accuracy: 0.5432 | f1: 0.5387\n",
            "Epoch 00129\n",
            "Train: loss: 0.5966 | accuracy: 0.6777 | f-acore: 0.6763\n",
            "Test:  loss: 0.8597 | accuracy: 0.4849 | f1: 0.4691\n",
            "Validation:  loss: 0.7662 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00130\n",
            "Train: loss: 0.5864 | accuracy: 0.6864 | f-acore: 0.6855\n",
            "Test:  loss: 0.8425 | accuracy: 0.5151 | f1: 0.4837\n",
            "Validation:  loss: 0.7601 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00131\n",
            "Train: loss: 0.5819 | accuracy: 0.6841 | f-acore: 0.6830\n",
            "Test:  loss: 0.8757 | accuracy: 0.5178 | f1: 0.4902\n",
            "Validation:  loss: 0.7659 | accuracy: 0.5185 | f1: 0.4990\n",
            "Epoch 00132\n",
            "Train: loss: 0.5855 | accuracy: 0.6799 | f-acore: 0.6761\n",
            "Test:  loss: 0.8390 | accuracy: 0.4959 | f1: 0.4833\n",
            "Validation:  loss: 0.7833 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00133\n",
            "Train: loss: 0.5860 | accuracy: 0.6726 | f-acore: 0.6697\n",
            "Test:  loss: 0.8780 | accuracy: 0.5260 | f1: 0.5033\n",
            "Validation:  loss: 0.7611 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00134\n",
            "Train: loss: 0.5822 | accuracy: 0.6873 | f-acore: 0.6838\n",
            "Test:  loss: 0.8527 | accuracy: 0.5068 | f1: 0.4962\n",
            "Validation:  loss: 0.7892 | accuracy: 0.5185 | f1: 0.5111\n",
            "Epoch 00135\n",
            "Train: loss: 0.5867 | accuracy: 0.6841 | f-acore: 0.6826\n",
            "Test:  loss: 0.8569 | accuracy: 0.5096 | f1: 0.5002\n",
            "Validation:  loss: 0.7870 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00136\n",
            "Train: loss: 0.6035 | accuracy: 0.6804 | f-acore: 0.6794\n",
            "Test:  loss: 0.8851 | accuracy: 0.5178 | f1: 0.4873\n",
            "Validation:  loss: 0.7504 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00137\n",
            "Train: loss: 0.5856 | accuracy: 0.6822 | f-acore: 0.6814\n",
            "Test:  loss: 0.8449 | accuracy: 0.4932 | f1: 0.4738\n",
            "Validation:  loss: 0.7592 | accuracy: 0.5185 | f1: 0.4935\n",
            "Epoch 00138\n",
            "Train: loss: 0.5861 | accuracy: 0.6987 | f-acore: 0.6975\n",
            "Test:  loss: 0.8419 | accuracy: 0.4959 | f1: 0.4824\n",
            "Validation:  loss: 0.7829 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00139\n",
            "Train: loss: 0.5767 | accuracy: 0.6951 | f-acore: 0.6931\n",
            "Test:  loss: 0.8400 | accuracy: 0.5096 | f1: 0.4909\n",
            "Validation:  loss: 0.7591 | accuracy: 0.5309 | f1: 0.5142\n",
            "Epoch 00140\n",
            "Train: loss: 0.5811 | accuracy: 0.6868 | f-acore: 0.6847\n",
            "Test:  loss: 0.8920 | accuracy: 0.5205 | f1: 0.5000\n",
            "Validation:  loss: 0.7614 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00141\n",
            "Train: loss: 0.5771 | accuracy: 0.6937 | f-acore: 0.6920\n",
            "Test:  loss: 0.8835 | accuracy: 0.5068 | f1: 0.4936\n",
            "Validation:  loss: 0.7797 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00142\n",
            "Train: loss: 0.5741 | accuracy: 0.6923 | f-acore: 0.6908\n",
            "Test:  loss: 0.8942 | accuracy: 0.5123 | f1: 0.4974\n",
            "Validation:  loss: 0.7917 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00143\n",
            "Train: loss: 0.5767 | accuracy: 0.6946 | f-acore: 0.6934\n",
            "Test:  loss: 0.9169 | accuracy: 0.4959 | f1: 0.4814\n",
            "Validation:  loss: 0.7894 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00144\n",
            "Train: loss: 0.5717 | accuracy: 0.6909 | f-acore: 0.6899\n",
            "Test:  loss: 0.9322 | accuracy: 0.5123 | f1: 0.4736\n",
            "Validation:  loss: 0.7779 | accuracy: 0.5679 | f1: 0.5398\n",
            "Epoch 00145\n",
            "Train: loss: 0.5871 | accuracy: 0.6809 | f-acore: 0.6791\n",
            "Test:  loss: 0.8570 | accuracy: 0.5041 | f1: 0.4954\n",
            "Validation:  loss: 0.8073 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00146\n",
            "Train: loss: 0.5768 | accuracy: 0.6900 | f-acore: 0.6885\n",
            "Test:  loss: 0.8747 | accuracy: 0.5233 | f1: 0.4999\n",
            "Validation:  loss: 0.7781 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00147\n",
            "Train: loss: 0.5653 | accuracy: 0.6951 | f-acore: 0.6938\n",
            "Test:  loss: 0.9194 | accuracy: 0.5370 | f1: 0.4994\n",
            "Validation:  loss: 0.7746 | accuracy: 0.5556 | f1: 0.5351\n",
            "Epoch 00148\n",
            "Train: loss: 0.5698 | accuracy: 0.6850 | f-acore: 0.6802\n",
            "Test:  loss: 0.8801 | accuracy: 0.4904 | f1: 0.4851\n",
            "Validation:  loss: 0.7998 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00149\n",
            "Train: loss: 0.5615 | accuracy: 0.6983 | f-acore: 0.6953\n",
            "Test:  loss: 0.8941 | accuracy: 0.5041 | f1: 0.4873\n",
            "Validation:  loss: 0.7999 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00150\n",
            "Train: loss: 0.5555 | accuracy: 0.7079 | f-acore: 0.7073\n",
            "Test:  loss: 0.9305 | accuracy: 0.4986 | f1: 0.4662\n",
            "Validation:  loss: 0.7947 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00151\n",
            "Train: loss: 0.5682 | accuracy: 0.7028 | f-acore: 0.7013\n",
            "Test:  loss: 0.9098 | accuracy: 0.5370 | f1: 0.5084\n",
            "Validation:  loss: 0.7903 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00152\n",
            "Train: loss: 0.5756 | accuracy: 0.7015 | f-acore: 0.6993\n",
            "Test:  loss: 0.9574 | accuracy: 0.5260 | f1: 0.4968\n",
            "Validation:  loss: 0.8055 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00153\n",
            "Train: loss: 0.5801 | accuracy: 0.6909 | f-acore: 0.6873\n",
            "Test:  loss: 0.8579 | accuracy: 0.4959 | f1: 0.4859\n",
            "Validation:  loss: 0.8145 | accuracy: 0.4815 | f1: 0.4717\n",
            "Epoch 00154\n",
            "Train: loss: 0.5689 | accuracy: 0.6987 | f-acore: 0.6966\n",
            "Test:  loss: 0.8924 | accuracy: 0.5178 | f1: 0.5030\n",
            "Validation:  loss: 0.7908 | accuracy: 0.5062 | f1: 0.4931\n",
            "Epoch 00155\n",
            "Train: loss: 0.5738 | accuracy: 0.7083 | f-acore: 0.7061\n",
            "Test:  loss: 0.9030 | accuracy: 0.5068 | f1: 0.4851\n",
            "Validation:  loss: 0.8171 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00156\n",
            "Train: loss: 0.5765 | accuracy: 0.7005 | f-acore: 0.6989\n",
            "Test:  loss: 0.9179 | accuracy: 0.5123 | f1: 0.4908\n",
            "Validation:  loss: 0.8068 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00157\n",
            "Train: loss: 0.5602 | accuracy: 0.7065 | f-acore: 0.7053\n",
            "Test:  loss: 0.9358 | accuracy: 0.4822 | f1: 0.4706\n",
            "Validation:  loss: 0.8266 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00158\n",
            "Train: loss: 0.5583 | accuracy: 0.6983 | f-acore: 0.6967\n",
            "Test:  loss: 0.9144 | accuracy: 0.4822 | f1: 0.4658\n",
            "Validation:  loss: 0.8266 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00159\n",
            "Train: loss: 0.5531 | accuracy: 0.7047 | f-acore: 0.7027\n",
            "Test:  loss: 0.9312 | accuracy: 0.4767 | f1: 0.4690\n",
            "Validation:  loss: 0.8258 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00160\n",
            "Train: loss: 0.5753 | accuracy: 0.7019 | f-acore: 0.7014\n",
            "Test:  loss: 0.9338 | accuracy: 0.5260 | f1: 0.4841\n",
            "Validation:  loss: 0.8154 | accuracy: 0.5432 | f1: 0.5291\n",
            "Epoch 00161\n",
            "Train: loss: 0.5674 | accuracy: 0.6946 | f-acore: 0.6927\n",
            "Test:  loss: 0.9236 | accuracy: 0.5041 | f1: 0.4840\n",
            "Validation:  loss: 0.8207 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00162\n",
            "Train: loss: 0.5720 | accuracy: 0.7010 | f-acore: 0.6980\n",
            "Test:  loss: 0.9032 | accuracy: 0.4849 | f1: 0.4812\n",
            "Validation:  loss: 0.8211 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00163\n",
            "Train: loss: 0.5638 | accuracy: 0.6882 | f-acore: 0.6849\n",
            "Test:  loss: 0.9006 | accuracy: 0.5123 | f1: 0.4896\n",
            "Validation:  loss: 0.7944 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00164\n",
            "Train: loss: 0.5634 | accuracy: 0.7115 | f-acore: 0.7099\n",
            "Test:  loss: 0.9502 | accuracy: 0.5260 | f1: 0.4982\n",
            "Validation:  loss: 0.8259 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00165\n",
            "Train: loss: 0.5500 | accuracy: 0.7143 | f-acore: 0.7140\n",
            "Test:  loss: 0.9556 | accuracy: 0.4986 | f1: 0.4746\n",
            "Validation:  loss: 0.8296 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00166\n",
            "Train: loss: 0.5586 | accuracy: 0.7106 | f-acore: 0.7074\n",
            "Test:  loss: 0.9375 | accuracy: 0.5233 | f1: 0.5034\n",
            "Validation:  loss: 0.8172 | accuracy: 0.5432 | f1: 0.5330\n",
            "Epoch 00167\n",
            "Train: loss: 0.5629 | accuracy: 0.7102 | f-acore: 0.7092\n",
            "Test:  loss: 0.9909 | accuracy: 0.5068 | f1: 0.4694\n",
            "Validation:  loss: 0.8081 | accuracy: 0.5309 | f1: 0.5185\n",
            "Epoch 00168\n",
            "Train: loss: 0.5640 | accuracy: 0.7083 | f-acore: 0.7070\n",
            "Test:  loss: 0.9199 | accuracy: 0.5178 | f1: 0.5058\n",
            "Validation:  loss: 0.8170 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00169\n",
            "Train: loss: 0.5590 | accuracy: 0.6951 | f-acore: 0.6934\n",
            "Test:  loss: 0.9191 | accuracy: 0.4932 | f1: 0.4897\n",
            "Validation:  loss: 0.8307 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00170\n",
            "Train: loss: 0.5821 | accuracy: 0.7001 | f-acore: 0.6987\n",
            "Test:  loss: 0.9779 | accuracy: 0.5151 | f1: 0.4790\n",
            "Validation:  loss: 0.8042 | accuracy: 0.5185 | f1: 0.4990\n",
            "Epoch 00171\n",
            "Train: loss: 0.5593 | accuracy: 0.7079 | f-acore: 0.7039\n",
            "Test:  loss: 0.8819 | accuracy: 0.4932 | f1: 0.4827\n",
            "Validation:  loss: 0.8172 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00172\n",
            "Train: loss: 0.5573 | accuracy: 0.7060 | f-acore: 0.7059\n",
            "Test:  loss: 0.9873 | accuracy: 0.5342 | f1: 0.4829\n",
            "Validation:  loss: 0.8082 | accuracy: 0.5679 | f1: 0.5455\n",
            "Epoch 00173\n",
            "Train: loss: 0.5597 | accuracy: 0.6937 | f-acore: 0.6899\n",
            "Test:  loss: 0.9328 | accuracy: 0.5315 | f1: 0.5157\n",
            "Validation:  loss: 0.8053 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00174\n",
            "Train: loss: 0.5496 | accuracy: 0.7138 | f-acore: 0.7117\n",
            "Test:  loss: 0.9439 | accuracy: 0.5096 | f1: 0.5010\n",
            "Validation:  loss: 0.8590 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00175\n",
            "Train: loss: 0.5558 | accuracy: 0.7051 | f-acore: 0.7037\n",
            "Test:  loss: 0.9392 | accuracy: 0.5342 | f1: 0.5190\n",
            "Validation:  loss: 0.8476 | accuracy: 0.5432 | f1: 0.5407\n",
            "Epoch 00176\n",
            "Train: loss: 0.5335 | accuracy: 0.7207 | f-acore: 0.7193\n",
            "Test:  loss: 0.9784 | accuracy: 0.5370 | f1: 0.5056\n",
            "Validation:  loss: 0.8245 | accuracy: 0.5556 | f1: 0.5398\n",
            "Epoch 00177\n",
            "Train: loss: 0.5498 | accuracy: 0.7134 | f-acore: 0.7116\n",
            "Test:  loss: 0.9806 | accuracy: 0.5014 | f1: 0.4889\n",
            "Validation:  loss: 0.8594 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00178\n",
            "Train: loss: 0.5610 | accuracy: 0.7166 | f-acore: 0.7142\n",
            "Test:  loss: 0.9358 | accuracy: 0.4959 | f1: 0.4901\n",
            "Validation:  loss: 0.8625 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00179\n",
            "Train: loss: 0.5586 | accuracy: 0.7189 | f-acore: 0.7187\n",
            "Test:  loss: 0.9626 | accuracy: 0.5342 | f1: 0.4973\n",
            "Validation:  loss: 0.8369 | accuracy: 0.5556 | f1: 0.5438\n",
            "Epoch 00180\n",
            "Train: loss: 0.5475 | accuracy: 0.7024 | f-acore: 0.7015\n",
            "Test:  loss: 0.9345 | accuracy: 0.5014 | f1: 0.4944\n",
            "Validation:  loss: 0.8509 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00181\n",
            "Train: loss: 0.5610 | accuracy: 0.7129 | f-acore: 0.7103\n",
            "Test:  loss: 0.9350 | accuracy: 0.4986 | f1: 0.4905\n",
            "Validation:  loss: 0.8589 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00182\n",
            "Train: loss: 0.5355 | accuracy: 0.7129 | f-acore: 0.7112\n",
            "Test:  loss: 0.9800 | accuracy: 0.5151 | f1: 0.4987\n",
            "Validation:  loss: 0.8491 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00183\n",
            "Train: loss: 0.5497 | accuracy: 0.7088 | f-acore: 0.7070\n",
            "Test:  loss: 0.9581 | accuracy: 0.5014 | f1: 0.4898\n",
            "Validation:  loss: 0.8571 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00184\n",
            "Train: loss: 0.5448 | accuracy: 0.7134 | f-acore: 0.7114\n",
            "Test:  loss: 0.9568 | accuracy: 0.4959 | f1: 0.4866\n",
            "Validation:  loss: 0.8736 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00185\n",
            "Train: loss: 0.5468 | accuracy: 0.7088 | f-acore: 0.7074\n",
            "Test:  loss: 0.9655 | accuracy: 0.5178 | f1: 0.4953\n",
            "Validation:  loss: 0.8722 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00186\n",
            "Train: loss: 0.5738 | accuracy: 0.7234 | f-acore: 0.7223\n",
            "Test:  loss: 0.9177 | accuracy: 0.4986 | f1: 0.4847\n",
            "Validation:  loss: 0.8641 | accuracy: 0.5432 | f1: 0.5361\n",
            "Epoch 00187\n",
            "Train: loss: 0.5594 | accuracy: 0.7015 | f-acore: 0.7011\n",
            "Test:  loss: 0.9673 | accuracy: 0.5370 | f1: 0.4961\n",
            "Validation:  loss: 0.8397 | accuracy: 0.5432 | f1: 0.5195\n",
            "Epoch 00188\n",
            "Train: loss: 0.5294 | accuracy: 0.7175 | f-acore: 0.7154\n",
            "Test:  loss: 0.9535 | accuracy: 0.5014 | f1: 0.4889\n",
            "Validation:  loss: 0.8557 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00189\n",
            "Train: loss: 0.5615 | accuracy: 0.7212 | f-acore: 0.7184\n",
            "Test:  loss: 0.9621 | accuracy: 0.5123 | f1: 0.4896\n",
            "Validation:  loss: 0.8402 | accuracy: 0.5309 | f1: 0.5220\n",
            "Epoch 00190\n",
            "Train: loss: 0.5427 | accuracy: 0.7212 | f-acore: 0.7192\n",
            "Test:  loss: 0.9240 | accuracy: 0.5123 | f1: 0.4908\n",
            "Validation:  loss: 0.8625 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00191\n",
            "Train: loss: 0.5508 | accuracy: 0.7184 | f-acore: 0.7180\n",
            "Test:  loss: 1.0037 | accuracy: 0.5342 | f1: 0.5004\n",
            "Validation:  loss: 0.8445 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00192\n",
            "Train: loss: 0.5684 | accuracy: 0.7157 | f-acore: 0.7127\n",
            "Test:  loss: 0.9499 | accuracy: 0.4986 | f1: 0.4856\n",
            "Validation:  loss: 0.8460 | accuracy: 0.5556 | f1: 0.5522\n",
            "Epoch 00193\n",
            "Train: loss: 0.5344 | accuracy: 0.7065 | f-acore: 0.7042\n",
            "Test:  loss: 0.9916 | accuracy: 0.5315 | f1: 0.5114\n",
            "Validation:  loss: 0.8526 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00194\n",
            "Train: loss: 0.5527 | accuracy: 0.7244 | f-acore: 0.7223\n",
            "Test:  loss: 0.9322 | accuracy: 0.4877 | f1: 0.4842\n",
            "Validation:  loss: 0.9047 | accuracy: 0.4321 | f1: 0.4313\n",
            "Epoch 00195\n",
            "Train: loss: 0.5306 | accuracy: 0.7221 | f-acore: 0.7218\n",
            "Test:  loss: 1.0003 | accuracy: 0.5425 | f1: 0.5085\n",
            "Validation:  loss: 0.8494 | accuracy: 0.5185 | f1: 0.5037\n",
            "Epoch 00196\n",
            "Train: loss: 0.5596 | accuracy: 0.7166 | f-acore: 0.7145\n",
            "Test:  loss: 0.9455 | accuracy: 0.5041 | f1: 0.4946\n",
            "Validation:  loss: 0.8653 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00197\n",
            "Train: loss: 0.5469 | accuracy: 0.7143 | f-acore: 0.7128\n",
            "Test:  loss: 0.9436 | accuracy: 0.5452 | f1: 0.5151\n",
            "Validation:  loss: 0.8380 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00198\n",
            "Train: loss: 0.5435 | accuracy: 0.7161 | f-acore: 0.7131\n",
            "Test:  loss: 0.9084 | accuracy: 0.4740 | f1: 0.4696\n",
            "Validation:  loss: 0.8694 | accuracy: 0.4321 | f1: 0.4299\n",
            "Epoch 00199\n",
            "Train: loss: 0.5569 | accuracy: 0.7271 | f-acore: 0.7260\n",
            "Test:  loss: 0.9906 | accuracy: 0.5233 | f1: 0.5067\n",
            "Validation:  loss: 0.8326 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00200\n",
            "Train: loss: 0.5350 | accuracy: 0.7170 | f-acore: 0.7159\n",
            "Test:  loss: 0.9657 | accuracy: 0.5041 | f1: 0.4961\n",
            "Validation:  loss: 0.8525 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00201\n",
            "Train: loss: 0.5435 | accuracy: 0.7253 | f-acore: 0.7247\n",
            "Test:  loss: 0.9779 | accuracy: 0.4986 | f1: 0.4783\n",
            "Validation:  loss: 0.8611 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00202\n",
            "Train: loss: 0.5357 | accuracy: 0.7143 | f-acore: 0.7138\n",
            "Test:  loss: 0.9902 | accuracy: 0.5342 | f1: 0.5137\n",
            "Validation:  loss: 0.8671 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00203\n",
            "Train: loss: 0.5366 | accuracy: 0.7216 | f-acore: 0.7187\n",
            "Test:  loss: 0.9741 | accuracy: 0.4685 | f1: 0.4660\n",
            "Validation:  loss: 0.8921 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00204\n",
            "Train: loss: 0.5455 | accuracy: 0.7239 | f-acore: 0.7229\n",
            "Test:  loss: 0.9831 | accuracy: 0.4959 | f1: 0.4804\n",
            "Validation:  loss: 0.8843 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00205\n",
            "Train: loss: 0.5335 | accuracy: 0.7207 | f-acore: 0.7190\n",
            "Test:  loss: 0.9725 | accuracy: 0.4932 | f1: 0.4850\n",
            "Validation:  loss: 0.8819 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00206\n",
            "Train: loss: 0.5321 | accuracy: 0.7335 | f-acore: 0.7327\n",
            "Test:  loss: 0.9744 | accuracy: 0.5315 | f1: 0.5079\n",
            "Validation:  loss: 0.8793 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00207\n",
            "Train: loss: 0.5301 | accuracy: 0.7266 | f-acore: 0.7260\n",
            "Test:  loss: 1.0039 | accuracy: 0.5014 | f1: 0.4850\n",
            "Validation:  loss: 0.8748 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00208\n",
            "Train: loss: 0.5397 | accuracy: 0.7413 | f-acore: 0.7401\n",
            "Test:  loss: 1.0048 | accuracy: 0.5342 | f1: 0.5101\n",
            "Validation:  loss: 0.8947 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00209\n",
            "Train: loss: 0.5503 | accuracy: 0.7367 | f-acore: 0.7357\n",
            "Test:  loss: 0.9396 | accuracy: 0.5370 | f1: 0.5250\n",
            "Validation:  loss: 0.8740 | accuracy: 0.5309 | f1: 0.5273\n",
            "Epoch 00210\n",
            "Train: loss: 0.5394 | accuracy: 0.7125 | f-acore: 0.7109\n",
            "Test:  loss: 0.9814 | accuracy: 0.5315 | f1: 0.5125\n",
            "Validation:  loss: 0.8841 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00211\n",
            "Train: loss: 0.5294 | accuracy: 0.7266 | f-acore: 0.7252\n",
            "Test:  loss: 0.9902 | accuracy: 0.5041 | f1: 0.4946\n",
            "Validation:  loss: 0.8988 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00212\n",
            "Train: loss: 0.5361 | accuracy: 0.7363 | f-acore: 0.7351\n",
            "Test:  loss: 0.9684 | accuracy: 0.5260 | f1: 0.5079\n",
            "Validation:  loss: 0.8868 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00213\n",
            "Train: loss: 0.5202 | accuracy: 0.7321 | f-acore: 0.7310\n",
            "Test:  loss: 1.0280 | accuracy: 0.5123 | f1: 0.4871\n",
            "Validation:  loss: 0.8831 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00214\n",
            "Train: loss: 0.5274 | accuracy: 0.7363 | f-acore: 0.7347\n",
            "Test:  loss: 1.0040 | accuracy: 0.5178 | f1: 0.4988\n",
            "Validation:  loss: 0.8913 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00215\n",
            "Train: loss: 0.5259 | accuracy: 0.7257 | f-acore: 0.7240\n",
            "Test:  loss: 0.9931 | accuracy: 0.4877 | f1: 0.4808\n",
            "Validation:  loss: 0.9124 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00216\n",
            "Train: loss: 0.5207 | accuracy: 0.7202 | f-acore: 0.7191\n",
            "Test:  loss: 1.0023 | accuracy: 0.4986 | f1: 0.4817\n",
            "Validation:  loss: 0.8802 | accuracy: 0.5309 | f1: 0.5291\n",
            "Epoch 00217\n",
            "Train: loss: 0.5384 | accuracy: 0.7408 | f-acore: 0.7402\n",
            "Test:  loss: 1.0579 | accuracy: 0.5233 | f1: 0.4886\n",
            "Validation:  loss: 0.8771 | accuracy: 0.4938 | f1: 0.4782\n",
            "Epoch 00218\n",
            "Train: loss: 0.5276 | accuracy: 0.7248 | f-acore: 0.7231\n",
            "Test:  loss: 0.9711 | accuracy: 0.5014 | f1: 0.4906\n",
            "Validation:  loss: 0.8664 | accuracy: 0.4444 | f1: 0.4414\n",
            "Epoch 00219\n",
            "Train: loss: 0.5253 | accuracy: 0.7344 | f-acore: 0.7322\n",
            "Test:  loss: 0.9856 | accuracy: 0.4877 | f1: 0.4801\n",
            "Validation:  loss: 0.8895 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00220\n",
            "Train: loss: 0.5082 | accuracy: 0.7381 | f-acore: 0.7372\n",
            "Test:  loss: 1.0818 | accuracy: 0.5233 | f1: 0.4871\n",
            "Validation:  loss: 0.8825 | accuracy: 0.4691 | f1: 0.4528\n",
            "Epoch 00221\n",
            "Train: loss: 0.5207 | accuracy: 0.7381 | f-acore: 0.7365\n",
            "Test:  loss: 1.0082 | accuracy: 0.5014 | f1: 0.4850\n",
            "Validation:  loss: 0.8701 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00222\n",
            "Train: loss: 0.5267 | accuracy: 0.7372 | f-acore: 0.7349\n",
            "Test:  loss: 1.0195 | accuracy: 0.4959 | f1: 0.4901\n",
            "Validation:  loss: 0.9024 | accuracy: 0.5185 | f1: 0.5173\n",
            "Epoch 00223\n",
            "Train: loss: 0.5145 | accuracy: 0.7395 | f-acore: 0.7388\n",
            "Test:  loss: 1.0310 | accuracy: 0.5342 | f1: 0.5019\n",
            "Validation:  loss: 0.8865 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00224\n",
            "Train: loss: 0.5136 | accuracy: 0.7285 | f-acore: 0.7269\n",
            "Test:  loss: 1.0360 | accuracy: 0.5205 | f1: 0.4895\n",
            "Validation:  loss: 0.8858 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00225\n",
            "Train: loss: 0.5073 | accuracy: 0.7404 | f-acore: 0.7384\n",
            "Test:  loss: 1.0224 | accuracy: 0.4849 | f1: 0.4770\n",
            "Validation:  loss: 0.9044 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00226\n",
            "Train: loss: 0.5311 | accuracy: 0.7312 | f-acore: 0.7305\n",
            "Test:  loss: 1.0474 | accuracy: 0.5178 | f1: 0.4928\n",
            "Validation:  loss: 0.8954 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00227\n",
            "Train: loss: 0.5107 | accuracy: 0.7422 | f-acore: 0.7406\n",
            "Test:  loss: 1.0063 | accuracy: 0.4904 | f1: 0.4845\n",
            "Validation:  loss: 0.8951 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00228\n",
            "Train: loss: 0.5335 | accuracy: 0.7399 | f-acore: 0.7394\n",
            "Test:  loss: 1.0306 | accuracy: 0.5178 | f1: 0.4953\n",
            "Validation:  loss: 0.8945 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00229\n",
            "Train: loss: 0.5360 | accuracy: 0.7285 | f-acore: 0.7271\n",
            "Test:  loss: 1.0264 | accuracy: 0.5151 | f1: 0.4987\n",
            "Validation:  loss: 0.8924 | accuracy: 0.5185 | f1: 0.5159\n",
            "Epoch 00230\n",
            "Train: loss: 0.5314 | accuracy: 0.7344 | f-acore: 0.7325\n",
            "Test:  loss: 0.9848 | accuracy: 0.5151 | f1: 0.4943\n",
            "Validation:  loss: 0.8501 | accuracy: 0.5309 | f1: 0.5250\n",
            "Epoch 00231\n",
            "Train: loss: 0.5151 | accuracy: 0.7349 | f-acore: 0.7338\n",
            "Test:  loss: 1.0055 | accuracy: 0.5233 | f1: 0.4986\n",
            "Validation:  loss: 0.8806 | accuracy: 0.4815 | f1: 0.4717\n",
            "Epoch 00232\n",
            "Train: loss: 0.5312 | accuracy: 0.7248 | f-acore: 0.7227\n",
            "Test:  loss: 0.9822 | accuracy: 0.4603 | f1: 0.4603\n",
            "Validation:  loss: 0.9199 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00233\n",
            "Train: loss: 0.5246 | accuracy: 0.7440 | f-acore: 0.7428\n",
            "Test:  loss: 1.0442 | accuracy: 0.5205 | f1: 0.5033\n",
            "Validation:  loss: 0.8985 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00234\n",
            "Train: loss: 0.5327 | accuracy: 0.7248 | f-acore: 0.7244\n",
            "Test:  loss: 1.0421 | accuracy: 0.5151 | f1: 0.4919\n",
            "Validation:  loss: 0.9005 | accuracy: 0.4691 | f1: 0.4639\n",
            "Epoch 00235\n",
            "Train: loss: 0.5293 | accuracy: 0.7326 | f-acore: 0.7300\n",
            "Test:  loss: 0.9868 | accuracy: 0.5151 | f1: 0.4966\n",
            "Validation:  loss: 0.8993 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00236\n",
            "Train: loss: 0.5104 | accuracy: 0.7592 | f-acore: 0.7584\n",
            "Test:  loss: 1.0729 | accuracy: 0.5288 | f1: 0.5068\n",
            "Validation:  loss: 0.9075 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00237\n",
            "Train: loss: 0.5288 | accuracy: 0.7331 | f-acore: 0.7310\n",
            "Test:  loss: 0.9683 | accuracy: 0.4795 | f1: 0.4714\n",
            "Validation:  loss: 0.9213 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00238\n",
            "Train: loss: 0.5286 | accuracy: 0.7321 | f-acore: 0.7312\n",
            "Test:  loss: 0.9917 | accuracy: 0.5205 | f1: 0.5081\n",
            "Validation:  loss: 0.9079 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00239\n",
            "Train: loss: 0.5185 | accuracy: 0.7463 | f-acore: 0.7455\n",
            "Test:  loss: 1.0425 | accuracy: 0.5260 | f1: 0.5079\n",
            "Validation:  loss: 0.8985 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00240\n",
            "Train: loss: 0.5212 | accuracy: 0.7353 | f-acore: 0.7344\n",
            "Test:  loss: 0.9755 | accuracy: 0.5068 | f1: 0.4954\n",
            "Validation:  loss: 0.9134 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00241\n",
            "Train: loss: 0.5175 | accuracy: 0.7495 | f-acore: 0.7485\n",
            "Test:  loss: 0.9747 | accuracy: 0.4904 | f1: 0.4803\n",
            "Validation:  loss: 0.9073 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00242\n",
            "Train: loss: 0.5379 | accuracy: 0.7308 | f-acore: 0.7293\n",
            "Test:  loss: 1.0025 | accuracy: 0.5041 | f1: 0.4884\n",
            "Validation:  loss: 0.9214 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00243\n",
            "Train: loss: 0.5161 | accuracy: 0.7381 | f-acore: 0.7361\n",
            "Test:  loss: 0.9765 | accuracy: 0.5068 | f1: 0.4839\n",
            "Validation:  loss: 0.8990 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00244\n",
            "Train: loss: 0.5127 | accuracy: 0.7349 | f-acore: 0.7326\n",
            "Test:  loss: 1.0181 | accuracy: 0.4630 | f1: 0.4628\n",
            "Validation:  loss: 0.9528 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00245\n",
            "Train: loss: 0.5146 | accuracy: 0.7372 | f-acore: 0.7367\n",
            "Test:  loss: 1.0792 | accuracy: 0.5315 | f1: 0.4901\n",
            "Validation:  loss: 0.8785 | accuracy: 0.4815 | f1: 0.4678\n",
            "Epoch 00246\n",
            "Train: loss: 0.5191 | accuracy: 0.7459 | f-acore: 0.7439\n",
            "Test:  loss: 0.9915 | accuracy: 0.4795 | f1: 0.4774\n",
            "Validation:  loss: 0.9356 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00247\n",
            "Train: loss: 0.5135 | accuracy: 0.7340 | f-acore: 0.7319\n",
            "Test:  loss: 1.0221 | accuracy: 0.4712 | f1: 0.4676\n",
            "Validation:  loss: 0.9150 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00248\n",
            "Train: loss: 0.5192 | accuracy: 0.7418 | f-acore: 0.7410\n",
            "Test:  loss: 1.0139 | accuracy: 0.4959 | f1: 0.4804\n",
            "Validation:  loss: 0.9154 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00249\n",
            "Train: loss: 0.4926 | accuracy: 0.7624 | f-acore: 0.7617\n",
            "Test:  loss: 1.0721 | accuracy: 0.5014 | f1: 0.4794\n",
            "Validation:  loss: 0.9184 | accuracy: 0.5432 | f1: 0.5421\n",
            "Epoch 00250\n",
            "Train: loss: 0.4963 | accuracy: 0.7413 | f-acore: 0.7385\n",
            "Test:  loss: 0.9825 | accuracy: 0.4630 | f1: 0.4591\n",
            "Validation:  loss: 0.9451 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00251\n",
            "Train: loss: 0.5100 | accuracy: 0.7514 | f-acore: 0.7506\n",
            "Test:  loss: 1.0295 | accuracy: 0.4959 | f1: 0.4850\n",
            "Validation:  loss: 0.9226 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00252\n",
            "Train: loss: 0.5268 | accuracy: 0.7390 | f-acore: 0.7382\n",
            "Test:  loss: 0.9910 | accuracy: 0.5260 | f1: 0.5008\n",
            "Validation:  loss: 0.9009 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00253\n",
            "Train: loss: 0.5263 | accuracy: 0.7308 | f-acore: 0.7277\n",
            "Test:  loss: 0.9780 | accuracy: 0.4658 | f1: 0.4647\n",
            "Validation:  loss: 0.9626 | accuracy: 0.4444 | f1: 0.4390\n",
            "Epoch 00254\n",
            "Train: loss: 0.5258 | accuracy: 0.7445 | f-acore: 0.7438\n",
            "Test:  loss: 1.0652 | accuracy: 0.5260 | f1: 0.4982\n",
            "Validation:  loss: 0.9055 | accuracy: 0.5062 | f1: 0.4969\n",
            "Epoch 00255\n",
            "Train: loss: 0.5109 | accuracy: 0.7477 | f-acore: 0.7467\n",
            "Test:  loss: 1.0026 | accuracy: 0.4877 | f1: 0.4821\n",
            "Validation:  loss: 0.9271 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00256\n",
            "Train: loss: 0.5162 | accuracy: 0.7349 | f-acore: 0.7332\n",
            "Test:  loss: 0.9923 | accuracy: 0.4877 | f1: 0.4801\n",
            "Validation:  loss: 0.9087 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00257\n",
            "Train: loss: 0.5033 | accuracy: 0.7418 | f-acore: 0.7401\n",
            "Test:  loss: 1.0267 | accuracy: 0.4877 | f1: 0.4692\n",
            "Validation:  loss: 0.9234 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00258\n",
            "Train: loss: 0.5170 | accuracy: 0.7303 | f-acore: 0.7290\n",
            "Test:  loss: 1.0078 | accuracy: 0.4795 | f1: 0.4699\n",
            "Validation:  loss: 0.9383 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00259\n",
            "Train: loss: 0.5258 | accuracy: 0.7610 | f-acore: 0.7596\n",
            "Test:  loss: 1.0166 | accuracy: 0.5096 | f1: 0.4920\n",
            "Validation:  loss: 0.9343 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00260\n",
            "Train: loss: 0.5073 | accuracy: 0.7404 | f-acore: 0.7384\n",
            "Test:  loss: 0.9722 | accuracy: 0.4767 | f1: 0.4740\n",
            "Validation:  loss: 0.9725 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00261\n",
            "Train: loss: 0.4946 | accuracy: 0.7532 | f-acore: 0.7523\n",
            "Test:  loss: 1.0573 | accuracy: 0.4959 | f1: 0.4842\n",
            "Validation:  loss: 0.9394 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00262\n",
            "Train: loss: 0.5089 | accuracy: 0.7505 | f-acore: 0.7496\n",
            "Test:  loss: 1.0315 | accuracy: 0.4986 | f1: 0.4795\n",
            "Validation:  loss: 0.9193 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00263\n",
            "Train: loss: 0.5067 | accuracy: 0.7418 | f-acore: 0.7400\n",
            "Test:  loss: 1.0383 | accuracy: 0.5151 | f1: 0.5025\n",
            "Validation:  loss: 0.9622 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00264\n",
            "Train: loss: 0.5000 | accuracy: 0.7418 | f-acore: 0.7411\n",
            "Test:  loss: 1.0627 | accuracy: 0.5178 | f1: 0.4977\n",
            "Validation:  loss: 0.9432 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00265\n",
            "Train: loss: 0.5202 | accuracy: 0.7537 | f-acore: 0.7511\n",
            "Test:  loss: 0.9968 | accuracy: 0.4603 | f1: 0.4590\n",
            "Validation:  loss: 0.9937 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00266\n",
            "Train: loss: 0.5015 | accuracy: 0.7518 | f-acore: 0.7515\n",
            "Test:  loss: 1.1023 | accuracy: 0.5260 | f1: 0.4824\n",
            "Validation:  loss: 0.9219 | accuracy: 0.5185 | f1: 0.5077\n",
            "Epoch 00267\n",
            "Train: loss: 0.5208 | accuracy: 0.7495 | f-acore: 0.7482\n",
            "Test:  loss: 1.0187 | accuracy: 0.5178 | f1: 0.4988\n",
            "Validation:  loss: 0.9418 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00268\n",
            "Train: loss: 0.4947 | accuracy: 0.7477 | f-acore: 0.7460\n",
            "Test:  loss: 1.0832 | accuracy: 0.5205 | f1: 0.4937\n",
            "Validation:  loss: 0.9119 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00269\n",
            "Train: loss: 0.4945 | accuracy: 0.7482 | f-acore: 0.7477\n",
            "Test:  loss: 1.1035 | accuracy: 0.5178 | f1: 0.4953\n",
            "Validation:  loss: 0.9567 | accuracy: 0.5185 | f1: 0.5138\n",
            "Epoch 00270\n",
            "Train: loss: 0.4961 | accuracy: 0.7564 | f-acore: 0.7555\n",
            "Test:  loss: 1.0586 | accuracy: 0.5068 | f1: 0.4954\n",
            "Validation:  loss: 0.9816 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00271\n",
            "Train: loss: 0.5312 | accuracy: 0.7596 | f-acore: 0.7594\n",
            "Test:  loss: 1.1033 | accuracy: 0.5260 | f1: 0.4939\n",
            "Validation:  loss: 0.9250 | accuracy: 0.4938 | f1: 0.4888\n",
            "Epoch 00272\n",
            "Train: loss: 0.4969 | accuracy: 0.7573 | f-acore: 0.7565\n",
            "Test:  loss: 1.0720 | accuracy: 0.5370 | f1: 0.5084\n",
            "Validation:  loss: 0.8868 | accuracy: 0.4938 | f1: 0.4825\n",
            "Epoch 00273\n",
            "Train: loss: 0.5091 | accuracy: 0.7633 | f-acore: 0.7622\n",
            "Test:  loss: 1.0642 | accuracy: 0.5014 | f1: 0.4861\n",
            "Validation:  loss: 0.9624 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00274\n",
            "Train: loss: 0.4940 | accuracy: 0.7514 | f-acore: 0.7506\n",
            "Test:  loss: 1.0770 | accuracy: 0.5288 | f1: 0.4961\n",
            "Validation:  loss: 0.9345 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00275\n",
            "Train: loss: 0.5030 | accuracy: 0.7573 | f-acore: 0.7556\n",
            "Test:  loss: 1.0470 | accuracy: 0.4658 | f1: 0.4630\n",
            "Validation:  loss: 0.9965 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00276\n",
            "Train: loss: 0.4848 | accuracy: 0.7596 | f-acore: 0.7584\n",
            "Test:  loss: 1.0404 | accuracy: 0.5096 | f1: 0.4994\n",
            "Validation:  loss: 0.9541 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00277\n",
            "Train: loss: 0.4926 | accuracy: 0.7706 | f-acore: 0.7703\n",
            "Test:  loss: 1.0982 | accuracy: 0.5178 | f1: 0.4977\n",
            "Validation:  loss: 0.9805 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00278\n",
            "Train: loss: 0.4823 | accuracy: 0.7647 | f-acore: 0.7634\n",
            "Test:  loss: 1.0636 | accuracy: 0.5068 | f1: 0.4897\n",
            "Validation:  loss: 0.9676 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00279\n",
            "Train: loss: 0.4850 | accuracy: 0.7537 | f-acore: 0.7524\n",
            "Test:  loss: 1.0364 | accuracy: 0.4630 | f1: 0.4609\n",
            "Validation:  loss: 1.0013 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00280\n",
            "Train: loss: 0.4931 | accuracy: 0.7578 | f-acore: 0.7575\n",
            "Test:  loss: 1.1429 | accuracy: 0.5288 | f1: 0.4990\n",
            "Validation:  loss: 0.9538 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00281\n",
            "Train: loss: 0.4816 | accuracy: 0.7505 | f-acore: 0.7496\n",
            "Test:  loss: 1.0488 | accuracy: 0.5178 | f1: 0.4953\n",
            "Validation:  loss: 0.9319 | accuracy: 0.5062 | f1: 0.5000\n",
            "Epoch 00282\n",
            "Train: loss: 0.4996 | accuracy: 0.7596 | f-acore: 0.7578\n",
            "Test:  loss: 1.0869 | accuracy: 0.5178 | f1: 0.4953\n",
            "Validation:  loss: 0.9589 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00283\n",
            "Train: loss: 0.4761 | accuracy: 0.7660 | f-acore: 0.7647\n",
            "Test:  loss: 1.0852 | accuracy: 0.5342 | f1: 0.5075\n",
            "Validation:  loss: 0.9428 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00284\n",
            "Train: loss: 0.4892 | accuracy: 0.7587 | f-acore: 0.7577\n",
            "Test:  loss: 1.0505 | accuracy: 0.4904 | f1: 0.4845\n",
            "Validation:  loss: 1.0107 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00285\n",
            "Train: loss: 0.4729 | accuracy: 0.7546 | f-acore: 0.7527\n",
            "Test:  loss: 1.0764 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 0.9993 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00286\n",
            "Train: loss: 0.4978 | accuracy: 0.7624 | f-acore: 0.7613\n",
            "Test:  loss: 1.1116 | accuracy: 0.4959 | f1: 0.4859\n",
            "Validation:  loss: 1.0026 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00287\n",
            "Train: loss: 0.5083 | accuracy: 0.7518 | f-acore: 0.7504\n",
            "Test:  loss: 1.0615 | accuracy: 0.4849 | f1: 0.4802\n",
            "Validation:  loss: 1.0132 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00288\n",
            "Train: loss: 0.4936 | accuracy: 0.7578 | f-acore: 0.7562\n",
            "Test:  loss: 1.0453 | accuracy: 0.4548 | f1: 0.4482\n",
            "Validation:  loss: 0.9886 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00289\n",
            "Train: loss: 0.5068 | accuracy: 0.7473 | f-acore: 0.7467\n",
            "Test:  loss: 1.0700 | accuracy: 0.5178 | f1: 0.4941\n",
            "Validation:  loss: 0.9454 | accuracy: 0.4938 | f1: 0.4860\n",
            "Epoch 00290\n",
            "Train: loss: 0.4986 | accuracy: 0.7500 | f-acore: 0.7488\n",
            "Test:  loss: 1.0719 | accuracy: 0.4959 | f1: 0.4842\n",
            "Validation:  loss: 0.9932 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00291\n",
            "Train: loss: 0.5063 | accuracy: 0.7665 | f-acore: 0.7658\n",
            "Test:  loss: 1.1137 | accuracy: 0.5151 | f1: 0.4931\n",
            "Validation:  loss: 0.9890 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00292\n",
            "Train: loss: 0.5046 | accuracy: 0.7395 | f-acore: 0.7368\n",
            "Test:  loss: 1.0360 | accuracy: 0.4603 | f1: 0.4586\n",
            "Validation:  loss: 1.0095 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00293\n",
            "Train: loss: 0.4962 | accuracy: 0.7582 | f-acore: 0.7578\n",
            "Test:  loss: 1.1212 | accuracy: 0.5233 | f1: 0.4960\n",
            "Validation:  loss: 0.9666 | accuracy: 0.4691 | f1: 0.4639\n",
            "Epoch 00294\n",
            "Train: loss: 0.4970 | accuracy: 0.7482 | f-acore: 0.7466\n",
            "Test:  loss: 1.0550 | accuracy: 0.4822 | f1: 0.4706\n",
            "Validation:  loss: 0.9817 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00295\n",
            "Train: loss: 0.4999 | accuracy: 0.7637 | f-acore: 0.7631\n",
            "Test:  loss: 1.0890 | accuracy: 0.4932 | f1: 0.4760\n",
            "Validation:  loss: 0.9895 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00296\n",
            "Train: loss: 0.4755 | accuracy: 0.7605 | f-acore: 0.7583\n",
            "Test:  loss: 1.0710 | accuracy: 0.4767 | f1: 0.4683\n",
            "Validation:  loss: 0.9861 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00297\n",
            "Train: loss: 0.4798 | accuracy: 0.7697 | f-acore: 0.7683\n",
            "Test:  loss: 1.0817 | accuracy: 0.4685 | f1: 0.4610\n",
            "Validation:  loss: 1.0081 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00298\n",
            "Train: loss: 0.4813 | accuracy: 0.7624 | f-acore: 0.7615\n",
            "Test:  loss: 1.1419 | accuracy: 0.5041 | f1: 0.4913\n",
            "Validation:  loss: 1.0027 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00299\n",
            "Train: loss: 0.4844 | accuracy: 0.7578 | f-acore: 0.7575\n",
            "Test:  loss: 1.1351 | accuracy: 0.4904 | f1: 0.4758\n",
            "Validation:  loss: 0.9926 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00300\n",
            "Train: loss: 0.4831 | accuracy: 0.7610 | f-acore: 0.7597\n",
            "Test:  loss: 1.0563 | accuracy: 0.4932 | f1: 0.4897\n",
            "Validation:  loss: 1.0411 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00301\n",
            "Train: loss: 0.4944 | accuracy: 0.7633 | f-acore: 0.7626\n",
            "Test:  loss: 1.1997 | accuracy: 0.4986 | f1: 0.4806\n",
            "Validation:  loss: 1.0198 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00302\n",
            "Train: loss: 0.4821 | accuracy: 0.7541 | f-acore: 0.7536\n",
            "Test:  loss: 1.1365 | accuracy: 0.4932 | f1: 0.4714\n",
            "Validation:  loss: 0.9815 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00303\n",
            "Train: loss: 0.4807 | accuracy: 0.7537 | f-acore: 0.7525\n",
            "Test:  loss: 1.0913 | accuracy: 0.4822 | f1: 0.4723\n",
            "Validation:  loss: 1.0141 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00304\n",
            "Train: loss: 0.4727 | accuracy: 0.7674 | f-acore: 0.7660\n",
            "Test:  loss: 1.1281 | accuracy: 0.5014 | f1: 0.4870\n",
            "Validation:  loss: 1.0150 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00305\n",
            "Train: loss: 0.5024 | accuracy: 0.7660 | f-acore: 0.7653\n",
            "Test:  loss: 1.1071 | accuracy: 0.5068 | f1: 0.4886\n",
            "Validation:  loss: 1.0126 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00306\n",
            "Train: loss: 0.4900 | accuracy: 0.7596 | f-acore: 0.7591\n",
            "Test:  loss: 1.0833 | accuracy: 0.5123 | f1: 0.4920\n",
            "Validation:  loss: 1.0076 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00307\n",
            "Train: loss: 0.4828 | accuracy: 0.7674 | f-acore: 0.7662\n",
            "Test:  loss: 1.0595 | accuracy: 0.4712 | f1: 0.4648\n",
            "Validation:  loss: 1.0129 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00308\n",
            "Train: loss: 0.4892 | accuracy: 0.7674 | f-acore: 0.7662\n",
            "Test:  loss: 1.0905 | accuracy: 0.4630 | f1: 0.4586\n",
            "Validation:  loss: 1.0468 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00309\n",
            "Train: loss: 0.4904 | accuracy: 0.7527 | f-acore: 0.7516\n",
            "Test:  loss: 1.0819 | accuracy: 0.4986 | f1: 0.4856\n",
            "Validation:  loss: 1.0227 | accuracy: 0.5185 | f1: 0.5185\n",
            "Epoch 00310\n",
            "Train: loss: 0.4814 | accuracy: 0.7669 | f-acore: 0.7657\n",
            "Test:  loss: 1.1032 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 1.0154 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00311\n",
            "Train: loss: 0.4860 | accuracy: 0.7592 | f-acore: 0.7580\n",
            "Test:  loss: 1.1508 | accuracy: 0.4877 | f1: 0.4704\n",
            "Validation:  loss: 1.0056 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00312\n",
            "Train: loss: 0.4768 | accuracy: 0.7633 | f-acore: 0.7619\n",
            "Test:  loss: 1.0741 | accuracy: 0.4959 | f1: 0.4888\n",
            "Validation:  loss: 1.0354 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00313\n",
            "Train: loss: 0.4743 | accuracy: 0.7692 | f-acore: 0.7676\n",
            "Test:  loss: 1.0902 | accuracy: 0.4849 | f1: 0.4770\n",
            "Validation:  loss: 1.0329 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00314\n",
            "Train: loss: 0.4751 | accuracy: 0.7701 | f-acore: 0.7698\n",
            "Test:  loss: 1.1696 | accuracy: 0.4904 | f1: 0.4767\n",
            "Validation:  loss: 1.0410 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00315\n",
            "Train: loss: 0.4859 | accuracy: 0.7683 | f-acore: 0.7677\n",
            "Test:  loss: 1.0859 | accuracy: 0.4849 | f1: 0.4755\n",
            "Validation:  loss: 1.0182 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00316\n",
            "Train: loss: 0.4853 | accuracy: 0.7628 | f-acore: 0.7620\n",
            "Test:  loss: 1.0770 | accuracy: 0.4904 | f1: 0.4794\n",
            "Validation:  loss: 0.9995 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00317\n",
            "Train: loss: 0.4847 | accuracy: 0.7734 | f-acore: 0.7724\n",
            "Test:  loss: 1.1043 | accuracy: 0.4904 | f1: 0.4818\n",
            "Validation:  loss: 1.0454 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00318\n",
            "Train: loss: 0.4919 | accuracy: 0.7633 | f-acore: 0.7623\n",
            "Test:  loss: 1.1745 | accuracy: 0.4904 | f1: 0.4715\n",
            "Validation:  loss: 1.0052 | accuracy: 0.5062 | f1: 0.5043\n",
            "Epoch 00319\n",
            "Train: loss: 0.4812 | accuracy: 0.7720 | f-acore: 0.7707\n",
            "Test:  loss: 1.0911 | accuracy: 0.4767 | f1: 0.4650\n",
            "Validation:  loss: 1.0261 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00320\n",
            "Train: loss: 0.4937 | accuracy: 0.7610 | f-acore: 0.7596\n",
            "Test:  loss: 1.0884 | accuracy: 0.4712 | f1: 0.4666\n",
            "Validation:  loss: 1.0509 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00321\n",
            "Train: loss: 0.4846 | accuracy: 0.7610 | f-acore: 0.7595\n",
            "Test:  loss: 1.0549 | accuracy: 0.4712 | f1: 0.4654\n",
            "Validation:  loss: 1.0117 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00322\n",
            "Train: loss: 0.4789 | accuracy: 0.7752 | f-acore: 0.7737\n",
            "Test:  loss: 1.1254 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 1.0402 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00323\n",
            "Train: loss: 0.4784 | accuracy: 0.7706 | f-acore: 0.7702\n",
            "Test:  loss: 1.1328 | accuracy: 0.5014 | f1: 0.4794\n",
            "Validation:  loss: 1.0152 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00324\n",
            "Train: loss: 0.4761 | accuracy: 0.7743 | f-acore: 0.7734\n",
            "Test:  loss: 1.1269 | accuracy: 0.5123 | f1: 0.4992\n",
            "Validation:  loss: 1.0142 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00325\n",
            "Train: loss: 0.4758 | accuracy: 0.7766 | f-acore: 0.7749\n",
            "Test:  loss: 1.1247 | accuracy: 0.4986 | f1: 0.4912\n",
            "Validation:  loss: 1.0397 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00326\n",
            "Train: loss: 0.5013 | accuracy: 0.7665 | f-acore: 0.7656\n",
            "Test:  loss: 1.1076 | accuracy: 0.4904 | f1: 0.4777\n",
            "Validation:  loss: 1.0018 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00327\n",
            "Train: loss: 0.4728 | accuracy: 0.7756 | f-acore: 0.7744\n",
            "Test:  loss: 1.1889 | accuracy: 0.5096 | f1: 0.4861\n",
            "Validation:  loss: 1.0181 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00328\n",
            "Train: loss: 0.4844 | accuracy: 0.7628 | f-acore: 0.7615\n",
            "Test:  loss: 1.0817 | accuracy: 0.4849 | f1: 0.4770\n",
            "Validation:  loss: 1.0474 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00329\n",
            "Train: loss: 0.4957 | accuracy: 0.7605 | f-acore: 0.7591\n",
            "Test:  loss: 1.0770 | accuracy: 0.4877 | f1: 0.4826\n",
            "Validation:  loss: 1.0248 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00330\n",
            "Train: loss: 0.4962 | accuracy: 0.7734 | f-acore: 0.7722\n",
            "Test:  loss: 1.1423 | accuracy: 0.4849 | f1: 0.4681\n",
            "Validation:  loss: 1.0132 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00331\n",
            "Train: loss: 0.4619 | accuracy: 0.7761 | f-acore: 0.7749\n",
            "Test:  loss: 1.1216 | accuracy: 0.4877 | f1: 0.4734\n",
            "Validation:  loss: 0.9854 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00332\n",
            "Train: loss: 0.4924 | accuracy: 0.7706 | f-acore: 0.7697\n",
            "Test:  loss: 1.1448 | accuracy: 0.4822 | f1: 0.4697\n",
            "Validation:  loss: 1.0015 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00333\n",
            "Train: loss: 0.4699 | accuracy: 0.7784 | f-acore: 0.7774\n",
            "Test:  loss: 1.1185 | accuracy: 0.4822 | f1: 0.4771\n",
            "Validation:  loss: 1.0380 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00334\n",
            "Train: loss: 0.4627 | accuracy: 0.7734 | f-acore: 0.7721\n",
            "Test:  loss: 1.1116 | accuracy: 0.4904 | f1: 0.4811\n",
            "Validation:  loss: 1.0447 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00335\n",
            "Train: loss: 0.4588 | accuracy: 0.7756 | f-acore: 0.7743\n",
            "Test:  loss: 1.1339 | accuracy: 0.4685 | f1: 0.4651\n",
            "Validation:  loss: 1.0638 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00336\n",
            "Train: loss: 0.4761 | accuracy: 0.7729 | f-acore: 0.7722\n",
            "Test:  loss: 1.1938 | accuracy: 0.5096 | f1: 0.4920\n",
            "Validation:  loss: 1.0570 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00337\n",
            "Train: loss: 0.4742 | accuracy: 0.7555 | f-acore: 0.7535\n",
            "Test:  loss: 1.1319 | accuracy: 0.4658 | f1: 0.4616\n",
            "Validation:  loss: 1.0614 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00338\n",
            "Train: loss: 0.4668 | accuracy: 0.7784 | f-acore: 0.7772\n",
            "Test:  loss: 1.1427 | accuracy: 0.4658 | f1: 0.4599\n",
            "Validation:  loss: 1.0458 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00339\n",
            "Train: loss: 0.4731 | accuracy: 0.7715 | f-acore: 0.7706\n",
            "Test:  loss: 1.1356 | accuracy: 0.4932 | f1: 0.4897\n",
            "Validation:  loss: 1.0948 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00340\n",
            "Train: loss: 0.4717 | accuracy: 0.7766 | f-acore: 0.7764\n",
            "Test:  loss: 1.1638 | accuracy: 0.5096 | f1: 0.4897\n",
            "Validation:  loss: 1.0426 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00341\n",
            "Train: loss: 0.4739 | accuracy: 0.7798 | f-acore: 0.7793\n",
            "Test:  loss: 1.0984 | accuracy: 0.4849 | f1: 0.4747\n",
            "Validation:  loss: 1.0624 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00342\n",
            "Train: loss: 0.4677 | accuracy: 0.7715 | f-acore: 0.7706\n",
            "Test:  loss: 1.1695 | accuracy: 0.5014 | f1: 0.4850\n",
            "Validation:  loss: 1.0351 | accuracy: 0.5185 | f1: 0.5182\n",
            "Epoch 00343\n",
            "Train: loss: 0.4732 | accuracy: 0.7656 | f-acore: 0.7648\n",
            "Test:  loss: 1.1263 | accuracy: 0.4712 | f1: 0.4594\n",
            "Validation:  loss: 1.0570 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00344\n",
            "Train: loss: 0.4622 | accuracy: 0.7729 | f-acore: 0.7714\n",
            "Test:  loss: 1.1562 | accuracy: 0.4740 | f1: 0.4608\n",
            "Validation:  loss: 1.0553 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00345\n",
            "Train: loss: 0.4680 | accuracy: 0.7734 | f-acore: 0.7726\n",
            "Test:  loss: 1.2144 | accuracy: 0.5205 | f1: 0.4849\n",
            "Validation:  loss: 1.0449 | accuracy: 0.4691 | f1: 0.4609\n",
            "Epoch 00346\n",
            "Train: loss: 0.4795 | accuracy: 0.7770 | f-acore: 0.7758\n",
            "Test:  loss: 1.1619 | accuracy: 0.4822 | f1: 0.4668\n",
            "Validation:  loss: 1.0256 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00347\n",
            "Train: loss: 0.4759 | accuracy: 0.7697 | f-acore: 0.7682\n",
            "Test:  loss: 1.1165 | accuracy: 0.4822 | f1: 0.4782\n",
            "Validation:  loss: 1.1125 | accuracy: 0.4444 | f1: 0.4444\n",
            "Epoch 00348\n",
            "Train: loss: 0.4733 | accuracy: 0.7665 | f-acore: 0.7657\n",
            "Test:  loss: 1.1452 | accuracy: 0.4959 | f1: 0.4804\n",
            "Validation:  loss: 1.0634 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00349\n",
            "Train: loss: 0.4513 | accuracy: 0.7811 | f-acore: 0.7800\n",
            "Test:  loss: 1.1585 | accuracy: 0.4685 | f1: 0.4603\n",
            "Validation:  loss: 1.0788 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00350\n",
            "Train: loss: 0.4883 | accuracy: 0.7729 | f-acore: 0.7721\n",
            "Test:  loss: 1.2018 | accuracy: 0.4904 | f1: 0.4704\n",
            "Validation:  loss: 1.0452 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00351\n",
            "Train: loss: 0.4674 | accuracy: 0.7674 | f-acore: 0.7657\n",
            "Test:  loss: 1.1156 | accuracy: 0.4740 | f1: 0.4719\n",
            "Validation:  loss: 1.1319 | accuracy: 0.4815 | f1: 0.4808\n",
            "Epoch 00352\n",
            "Train: loss: 0.4735 | accuracy: 0.7761 | f-acore: 0.7756\n",
            "Test:  loss: 1.1708 | accuracy: 0.4904 | f1: 0.4767\n",
            "Validation:  loss: 1.0968 | accuracy: 0.4321 | f1: 0.4320\n",
            "Epoch 00353\n",
            "Train: loss: 0.4781 | accuracy: 0.7807 | f-acore: 0.7800\n",
            "Test:  loss: 1.1938 | accuracy: 0.5178 | f1: 0.4953\n",
            "Validation:  loss: 1.0366 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00354\n",
            "Train: loss: 0.4721 | accuracy: 0.7738 | f-acore: 0.7728\n",
            "Test:  loss: 1.0927 | accuracy: 0.4575 | f1: 0.4513\n",
            "Validation:  loss: 1.0295 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00355\n",
            "Train: loss: 0.4750 | accuracy: 0.7802 | f-acore: 0.7795\n",
            "Test:  loss: 1.1690 | accuracy: 0.4767 | f1: 0.4641\n",
            "Validation:  loss: 1.0451 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00356\n",
            "Train: loss: 0.4600 | accuracy: 0.7894 | f-acore: 0.7885\n",
            "Test:  loss: 1.1827 | accuracy: 0.4904 | f1: 0.4803\n",
            "Validation:  loss: 1.0628 | accuracy: 0.5062 | f1: 0.5061\n",
            "Epoch 00357\n",
            "Train: loss: 0.4607 | accuracy: 0.7788 | f-acore: 0.7782\n",
            "Test:  loss: 1.1712 | accuracy: 0.5096 | f1: 0.4930\n",
            "Validation:  loss: 1.0689 | accuracy: 0.5062 | f1: 0.5055\n",
            "Epoch 00358\n",
            "Train: loss: 0.4709 | accuracy: 0.7756 | f-acore: 0.7751\n",
            "Test:  loss: 1.2657 | accuracy: 0.4849 | f1: 0.4635\n",
            "Validation:  loss: 1.0888 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00359\n",
            "Train: loss: 0.4785 | accuracy: 0.7821 | f-acore: 0.7810\n",
            "Test:  loss: 1.2012 | accuracy: 0.5123 | f1: 0.4871\n",
            "Validation:  loss: 1.0603 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00360\n",
            "Train: loss: 0.4840 | accuracy: 0.7660 | f-acore: 0.7650\n",
            "Test:  loss: 1.2122 | accuracy: 0.5041 | f1: 0.4894\n",
            "Validation:  loss: 1.0637 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00361\n",
            "Train: loss: 0.4770 | accuracy: 0.7624 | f-acore: 0.7605\n",
            "Test:  loss: 1.1408 | accuracy: 0.4685 | f1: 0.4667\n",
            "Validation:  loss: 1.1597 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00362\n",
            "Train: loss: 0.4635 | accuracy: 0.7811 | f-acore: 0.7806\n",
            "Test:  loss: 1.2452 | accuracy: 0.4904 | f1: 0.4704\n",
            "Validation:  loss: 1.0730 | accuracy: 0.4815 | f1: 0.4776\n",
            "Epoch 00363\n",
            "Train: loss: 0.4445 | accuracy: 0.7747 | f-acore: 0.7732\n",
            "Test:  loss: 1.1403 | accuracy: 0.4767 | f1: 0.4765\n",
            "Validation:  loss: 1.2106 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00364\n",
            "Train: loss: 0.4697 | accuracy: 0.7825 | f-acore: 0.7821\n",
            "Test:  loss: 1.2240 | accuracy: 0.4822 | f1: 0.4624\n",
            "Validation:  loss: 1.0835 | accuracy: 0.4568 | f1: 0.4547\n",
            "Epoch 00365\n",
            "Train: loss: 0.4638 | accuracy: 0.7738 | f-acore: 0.7735\n",
            "Test:  loss: 1.1975 | accuracy: 0.5123 | f1: 0.4857\n",
            "Validation:  loss: 1.0677 | accuracy: 0.5062 | f1: 0.5025\n",
            "Epoch 00366\n",
            "Train: loss: 0.4664 | accuracy: 0.7711 | f-acore: 0.7703\n",
            "Test:  loss: 1.1712 | accuracy: 0.5068 | f1: 0.4875\n",
            "Validation:  loss: 1.0989 | accuracy: 0.4444 | f1: 0.4431\n",
            "Epoch 00367\n",
            "Train: loss: 0.4569 | accuracy: 0.7738 | f-acore: 0.7732\n",
            "Test:  loss: 1.2373 | accuracy: 0.5014 | f1: 0.4755\n",
            "Validation:  loss: 1.0718 | accuracy: 0.4568 | f1: 0.4527\n",
            "Epoch 00368\n",
            "Train: loss: 0.4670 | accuracy: 0.7752 | f-acore: 0.7742\n",
            "Test:  loss: 1.1735 | accuracy: 0.5041 | f1: 0.4968\n",
            "Validation:  loss: 1.1173 | accuracy: 0.4938 | f1: 0.4938\n",
            "Epoch 00369\n",
            "Train: loss: 0.4686 | accuracy: 0.7706 | f-acore: 0.7689\n",
            "Test:  loss: 1.1324 | accuracy: 0.4740 | f1: 0.4728\n",
            "Validation:  loss: 1.1437 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00370\n",
            "Train: loss: 0.4664 | accuracy: 0.7651 | f-acore: 0.7642\n",
            "Test:  loss: 1.2033 | accuracy: 0.4822 | f1: 0.4759\n",
            "Validation:  loss: 1.1210 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00371\n",
            "Train: loss: 0.4632 | accuracy: 0.7807 | f-acore: 0.7803\n",
            "Test:  loss: 1.1996 | accuracy: 0.4932 | f1: 0.4702\n",
            "Validation:  loss: 1.0739 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00372\n",
            "Train: loss: 0.4583 | accuracy: 0.7825 | f-acore: 0.7814\n",
            "Test:  loss: 1.2061 | accuracy: 0.4685 | f1: 0.4570\n",
            "Validation:  loss: 1.1189 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00373\n",
            "Train: loss: 0.4678 | accuracy: 0.7807 | f-acore: 0.7802\n",
            "Test:  loss: 1.2049 | accuracy: 0.5068 | f1: 0.4917\n",
            "Validation:  loss: 1.0991 | accuracy: 0.4321 | f1: 0.4313\n",
            "Epoch 00374\n",
            "Train: loss: 0.4650 | accuracy: 0.7715 | f-acore: 0.7707\n",
            "Test:  loss: 1.2058 | accuracy: 0.4767 | f1: 0.4690\n",
            "Validation:  loss: 1.1117 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00375\n",
            "Train: loss: 0.4600 | accuracy: 0.7798 | f-acore: 0.7794\n",
            "Test:  loss: 1.3116 | accuracy: 0.5315 | f1: 0.5066\n",
            "Validation:  loss: 1.0950 | accuracy: 0.4568 | f1: 0.4466\n",
            "Epoch 00376\n",
            "Train: loss: 0.4649 | accuracy: 0.7683 | f-acore: 0.7675\n",
            "Test:  loss: 1.1201 | accuracy: 0.4959 | f1: 0.4901\n",
            "Validation:  loss: 1.0933 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00377\n",
            "Train: loss: 0.4594 | accuracy: 0.7908 | f-acore: 0.7895\n",
            "Test:  loss: 1.2085 | accuracy: 0.4767 | f1: 0.4716\n",
            "Validation:  loss: 1.1563 | accuracy: 0.4321 | f1: 0.4313\n",
            "Epoch 00378\n",
            "Train: loss: 0.4583 | accuracy: 0.7798 | f-acore: 0.7795\n",
            "Test:  loss: 1.1721 | accuracy: 0.5342 | f1: 0.5088\n",
            "Validation:  loss: 1.0394 | accuracy: 0.4815 | f1: 0.4750\n",
            "Epoch 00379\n",
            "Train: loss: 0.4708 | accuracy: 0.7674 | f-acore: 0.7661\n",
            "Test:  loss: 1.1956 | accuracy: 0.4740 | f1: 0.4679\n",
            "Validation:  loss: 1.1174 | accuracy: 0.4691 | f1: 0.4691\n",
            "Epoch 00380\n",
            "Train: loss: 0.4551 | accuracy: 0.7821 | f-acore: 0.7814\n",
            "Test:  loss: 1.2152 | accuracy: 0.4877 | f1: 0.4801\n",
            "Validation:  loss: 1.1434 | accuracy: 0.4691 | f1: 0.4688\n",
            "Epoch 00381\n",
            "Train: loss: 0.4517 | accuracy: 0.7958 | f-acore: 0.7952\n",
            "Test:  loss: 1.1941 | accuracy: 0.5178 | f1: 0.4999\n",
            "Validation:  loss: 1.1077 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00382\n",
            "Train: loss: 0.4818 | accuracy: 0.7624 | f-acore: 0.7617\n",
            "Test:  loss: 1.2861 | accuracy: 0.4904 | f1: 0.4857\n",
            "Validation:  loss: 1.1693 | accuracy: 0.4568 | f1: 0.4567\n",
            "Epoch 00383\n",
            "Train: loss: 0.4780 | accuracy: 0.7816 | f-acore: 0.7810\n",
            "Test:  loss: 1.2189 | accuracy: 0.4822 | f1: 0.4731\n",
            "Validation:  loss: 1.0963 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00384\n",
            "Train: loss: 0.4729 | accuracy: 0.7770 | f-acore: 0.7769\n",
            "Test:  loss: 1.2543 | accuracy: 0.5041 | f1: 0.4852\n",
            "Validation:  loss: 1.0814 | accuracy: 0.4938 | f1: 0.4910\n",
            "Epoch 00385\n",
            "Train: loss: 0.4573 | accuracy: 0.7825 | f-acore: 0.7816\n",
            "Test:  loss: 1.1693 | accuracy: 0.4822 | f1: 0.4787\n",
            "Validation:  loss: 1.1556 | accuracy: 0.4321 | f1: 0.4313\n",
            "Epoch 00386\n",
            "Train: loss: 0.4498 | accuracy: 0.7898 | f-acore: 0.7888\n",
            "Test:  loss: 1.2036 | accuracy: 0.4822 | f1: 0.4731\n",
            "Validation:  loss: 1.1683 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00387\n",
            "Train: loss: 0.4625 | accuracy: 0.7738 | f-acore: 0.7731\n",
            "Test:  loss: 1.2079 | accuracy: 0.5014 | f1: 0.4806\n",
            "Validation:  loss: 1.0776 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00388\n",
            "Train: loss: 0.4557 | accuracy: 0.7903 | f-acore: 0.7897\n",
            "Test:  loss: 1.2023 | accuracy: 0.4877 | f1: 0.4753\n",
            "Validation:  loss: 1.0924 | accuracy: 0.4444 | f1: 0.4414\n",
            "Epoch 00389\n",
            "Train: loss: 0.4592 | accuracy: 0.7761 | f-acore: 0.7750\n",
            "Test:  loss: 1.2054 | accuracy: 0.4658 | f1: 0.4538\n",
            "Validation:  loss: 1.1093 | accuracy: 0.4691 | f1: 0.4662\n",
            "Epoch 00390\n",
            "Train: loss: 0.4359 | accuracy: 0.7866 | f-acore: 0.7855\n",
            "Test:  loss: 1.2183 | accuracy: 0.4630 | f1: 0.4486\n",
            "Validation:  loss: 1.1125 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00391\n",
            "Train: loss: 0.4651 | accuracy: 0.7734 | f-acore: 0.7719\n",
            "Test:  loss: 1.2112 | accuracy: 0.4932 | f1: 0.4800\n",
            "Validation:  loss: 1.1752 | accuracy: 0.4444 | f1: 0.4414\n",
            "Epoch 00392\n",
            "Train: loss: 0.4521 | accuracy: 0.7944 | f-acore: 0.7936\n",
            "Test:  loss: 1.2229 | accuracy: 0.4904 | f1: 0.4786\n",
            "Validation:  loss: 1.1470 | accuracy: 0.4691 | f1: 0.4678\n",
            "Epoch 00393\n",
            "Train: loss: 0.4705 | accuracy: 0.7830 | f-acore: 0.7824\n",
            "Test:  loss: 1.2342 | accuracy: 0.4877 | f1: 0.4762\n",
            "Validation:  loss: 1.1478 | accuracy: 0.4815 | f1: 0.4814\n",
            "Epoch 00394\n",
            "Train: loss: 0.4421 | accuracy: 0.7821 | f-acore: 0.7810\n",
            "Test:  loss: 1.1369 | accuracy: 0.4877 | f1: 0.4873\n",
            "Validation:  loss: 1.2075 | accuracy: 0.4568 | f1: 0.4560\n",
            "Epoch 00395\n",
            "Train: loss: 0.4314 | accuracy: 0.7921 | f-acore: 0.7914\n",
            "Test:  loss: 1.2256 | accuracy: 0.4959 | f1: 0.4833\n",
            "Validation:  loss: 1.1717 | accuracy: 0.4938 | f1: 0.4935\n",
            "Epoch 00396\n",
            "Train: loss: 0.4616 | accuracy: 0.7784 | f-acore: 0.7780\n",
            "Test:  loss: 1.2484 | accuracy: 0.5123 | f1: 0.4896\n",
            "Validation:  loss: 1.1259 | accuracy: 0.4938 | f1: 0.4926\n",
            "Epoch 00397\n",
            "Train: loss: 0.4706 | accuracy: 0.7766 | f-acore: 0.7754\n",
            "Test:  loss: 1.1972 | accuracy: 0.4658 | f1: 0.4564\n",
            "Validation:  loss: 1.1551 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00398\n",
            "Train: loss: 0.4785 | accuracy: 0.7752 | f-acore: 0.7732\n",
            "Test:  loss: 1.1689 | accuracy: 0.4959 | f1: 0.4927\n",
            "Validation:  loss: 1.1709 | accuracy: 0.4444 | f1: 0.4441\n",
            "Epoch 00399\n",
            "Train: loss: 0.4416 | accuracy: 0.7880 | f-acore: 0.7874\n",
            "Test:  loss: 1.2349 | accuracy: 0.4986 | f1: 0.4795\n",
            "Validation:  loss: 1.1719 | accuracy: 0.4815 | f1: 0.4795\n",
            "Epoch 00400\n",
            "Train: loss: 0.4435 | accuracy: 0.7862 | f-acore: 0.7854\n",
            "Test:  loss: 1.2875 | accuracy: 0.4932 | f1: 0.4771\n",
            "Validation:  loss: 1.1614 | accuracy: 0.4938 | f1: 0.4926\n"
          ]
        }
      ],
      "source": [
        "#Main.py script\n",
        "#Training loop\n",
        "import models #TODO: Put this at top of imports\n",
        "\n",
        "#Set up GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU instead.\")\n",
        "\n",
        "gen_num = 1 #TODO: Define this in the Config file\n",
        "for iteration in range(gen_num):\n",
        "\n",
        "\n",
        "  for index, _ in y_train.items():\n",
        "    #Get Model output path\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    print(index)\n",
        "    print(\"-----------------------------------------------------------------------------------------\")\n",
        "    model_path = next_file(config['model']['type'] + index[1:], join(\"./Results/\", os.path.basename(config_path)))\n",
        "    # for b, a, in train_dataloader[index]:\n",
        "    #   print(\"opppppppppppppppppppppppppppppppppppppppppppppppppppppppp\")\n",
        "    train(config, train_data[index], val_data[index], test_data[index], model_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
