{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb9q2_QZgdNk"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
    "\n",
    "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
    "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPT0ipYE28wL",
    "outputId": "75fcd958-c29f-44f0-85ea-4b4f6ae180ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wrds in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy<1.27,>=1.26 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from wrds) (1.26.4)\n",
      "Requirement already satisfied: packaging<23.3 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from wrds) (23.2)\n",
      "Requirement already satisfied: pandas<2.3,>=2.2 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from wrds) (2.2.2)\n",
      "Requirement already satisfied: psycopg2-binary<2.10,>=2.9 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from wrds) (2.9.9)\n",
      "Requirement already satisfied: scipy<1.13,>=1.12 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from wrds) (1.12.0)\n",
      "Requirement already satisfied: sqlalchemy<2.1,>=2 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from wrds) (2.0.29)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from pandas<2.3,>=2.2->wrds) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from pandas<2.3,>=2.2->wrds) (2024.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from sqlalchemy<2.1,>=2->wrds) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from sqlalchemy<2.1,>=2->wrds) (3.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<2.3,>=2.2->wrds) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: swig in /home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages (4.2.1)\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n"
     ]
    }
   ],
   "source": [
    "# ## install finrl library\n",
    "!pip install wrds\n",
    "!pip install swig\n",
    "!pip install -q condacolab\n",
    "#import condacolab\n",
    "#condacolab.install()\n",
    "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
    "#!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EeMK7Uentj1V"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lPqeTTwoh1hn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOW_5_TICKER = [\n",
    "    \"AXP\",\n",
    "    \"AMGN\",\n",
    "    \"AAPL\",\n",
    "    \"BA\",\n",
    "    \"CAT\",\n",
    "]\n",
    "INDEX_5_TICKER = [\n",
    "    \"^DJI\", \n",
    "    \"^IXIC\", \n",
    "    \"^NYA\", \n",
    "    \"^RUT\", \n",
    "    \"^GSPC\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    ")\n",
    "\n",
    "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "178c70ab-72e5-4ed7-cfa8-fd6ea7b1e8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n"
     ]
    }
   ],
   "source": [
    "print(DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "\n",
    "\n",
    "# # TRAIN_START_DATE = '2009-04-01'\n",
    "# # TRAIN_END_DATE = '2021-01-01'\n",
    "# # TEST_START_DATE = '2021-01-01'\n",
    "# # TEST_END_DATE = '2022-06-01'\n",
    "\n",
    "\n",
    "# TRAIN_START_DATE = '2009-06-01'\n",
    "# #TRAIN_START_DATE = '2010-01-01'\n",
    "# TRAIN_END_DATE = '2021-10-01'\n",
    "# TEST_START_DATE = '2021-10-01'\n",
    "# TEST_END_DATE = '2023-03-01'\n",
    "\n",
    "# dfexport = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "#                      end_date = TEST_END_DATE,\n",
    "#                      ticker_list = DOW_30_TICKER).fetch_data()\n",
    "\n",
    "\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dfexport.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Data export\n",
    "# import pickle\n",
    "# datasetName = \"dailydata\"\n",
    "# datasetDir = \"./datasets\"\n",
    "\n",
    "# os.makedirs(datasetDir, exist_ok=True)\n",
    "# datasetPath = os.path.join(datasetDir, datasetName) + \".pkl\"\n",
    "\n",
    "\n",
    "# with open(datasetPath, 'wb') as file:\n",
    "#     pickle.dump(dfexport, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "0a5b0405-7c4f-4afd-c3e1-1dabd55c81fb"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Can't determine version for tzdata",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32mtzconversion.pyx:83\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.tzconversion.Localizer.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimezones.pyx:81\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timezones.is_utc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtimezones.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timezones.is_utc_zoneinfo\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages/pandas/compat/_optional.py:150\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    148\u001b[0m minimum_version \u001b[38;5;241m=\u001b[39m min_version \u001b[38;5;28;01mif\u001b[39;00m min_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m VERSIONS\u001b[38;5;241m.\u001b[39mget(parent)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m minimum_version:\n\u001b[0;32m--> 150\u001b[0m     version \u001b[38;5;241m=\u001b[39m \u001b[43mget_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_to_get\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mand\u001b[39;00m Version(version) \u001b[38;5;241m<\u001b[39m Version(minimum_version):\n\u001b[1;32m    152\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    153\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPandas requires version \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminimum_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or newer of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(version \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m currently installed).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages/pandas/compat/_optional.py:78\u001b[0m, in \u001b[0;36mget_version\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     75\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__version__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt determine version for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpsycopg2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# psycopg2 appends \" (dt dec pq3 ext lo64)\" to it's version\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     version \u001b[38;5;241m=\u001b[39m version\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mImportError\u001b[0m: Can't determine version for tzdata"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.tslibs.conversion._localize_tso'\n",
      "Traceback (most recent call last):\n",
      "  File \"tzconversion.pyx\", line 83, in pandas._libs.tslibs.tzconversion.Localizer.__cinit__\n",
      "  File \"timezones.pyx\", line 81, in pandas._libs.tslibs.timezones.is_utc\n",
      "  File \"timezones.pyx\", line 70, in pandas._libs.tslibs.timezones.is_utc_zoneinfo\n",
      "  File \"/home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages/pandas/compat/_optional.py\", line 150, in import_optional_dependency\n",
      "    version = get_version(module_to_get)\n",
      "  File \"/home/drew/anaconda3/envs/FinRL_2020v2/lib/python3.9/site-packages/pandas/compat/_optional.py\", line 78, in get_version\n",
      "    raise ImportError(f\"Can't determine version for {module.__name__}\")\n",
      "ImportError: Can't determine version for tzdata\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (16555, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_START_DATE = '2009-04-01'\n",
    "# TRAIN_END_DATE = '2021-01-01'\n",
    "# TEST_START_DATE = '2021-01-01'\n",
    "# TEST_END_DATE = '2022-06-01'\n",
    "#TRAIN_START_DATE = '2000-01-01'\n",
    "# TRAIN_START_DATE = '2010-01-01'\n",
    "# TRAIN_END_DATE = '2021-10-01'\n",
    "# TEST_START_DATE = '2021-10-01'\n",
    "# TEST_END_DATE = '2023-03-01'\n",
    "TRAIN_START_DATE = '2010-01-01'\n",
    "TRAIN_END_DATE = '2017-10-01'\n",
    "TEST_START_DATE = '2017-10-01'\n",
    "TEST_END_DATE = '2023-03-01'\n",
    "\n",
    "\n",
    "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                     end_date = TEST_END_DATE,\n",
    "                     ticker_list = INDEX_5_TICKER).fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgXfBcjxtj1a",
    "outputId": "bd80d5c7-6ab7-4938-e1aa-f60ff642dc02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_turbulence=True,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)\n",
    "processed = processed.copy()\n",
    "processed = processed.fillna(0)\n",
    "processed = processed.replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Andrew Martin - UNCOMMENT BELOW TO ADD PREDICTION INDICATOR\n",
    "# import pickle\n",
    "# with open(\"./datasets/index_5_predictor_2.pkl\", 'rb') as file:\n",
    "#   df_prob = pickle.load(file)\n",
    "# df6 = df_prob.copy()\n",
    "# df6 = df6.loc[:, ~df6.columns.duplicated(keep='first')]\n",
    "# df6[\"date\"] = df6[\"date\"].dt.strftime('%Y-%m-%d')\n",
    "# df2 = processed.merge(df6[['tic', 'date', 'Predicted_Target']], on=['tic', 'date'], how='left')\n",
    "# processed = df2.copy()\n",
    "# INDICATORS.append(\"Predicted_Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "e16902dc-86b3-488e-ec15-234a3d6039c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 5, State Space: 51\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(processed.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001, \n",
    "    \"sell_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"print_verbosity\":5\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms.\n",
    "\n",
    "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "v-gthCxMtj1d"
   },
   "outputs": [],
   "source": [
    "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
    "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
    "\n",
    "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
    "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
    "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
    "                 rebalance_window=rebalance_window, \n",
    "                 validation_window=validation_window, \n",
    "                 **env_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KsfEHa_Etj1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "A2C_model_kwargs = {\n",
    "                    'n_steps': 5,\n",
    "                    'ent_coef': 0.005,\n",
    "                    'learning_rate': 0.0007\n",
    "                    }\n",
    "\n",
    "PPO_model_kwargs = {\n",
    "                    \"ent_coef\":0.01,\n",
    "                    \"n_steps\": 2048,\n",
    "                    \"learning_rate\": 0.00025,\n",
    "                    \"batch_size\": 128\n",
    "                    }\n",
    "\n",
    "DDPG_model_kwargs = {\n",
    "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
    "                      \"buffer_size\": 10_000,\n",
    "                      \"learning_rate\": 0.0005,\n",
    "                      \"batch_size\": 64\n",
    "                    }\n",
    "\n",
    "timesteps_dict = {'a2c' : 10_000, \n",
    "                 'ppo' : 10_000, \n",
    "                 'ddpg' : 10_000\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1lyCECstj1e",
    "outputId": "73e2d3f8-463a-42d5-d49f-c71385a26c92",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Start Ensemble Strategy============\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2017-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_126_27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 413       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -14       |\n",
      "|    reward             | 0.4192922 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 3.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 452       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -0.00354  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.09      |\n",
      "|    reward             | 1.3407724 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 2.63      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 473        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -15.6      |\n",
      "|    reward             | -1.8512374 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 7.37       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 479       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 11        |\n",
      "|    reward             | 0.6284966 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 4.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 477       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -16.5     |\n",
      "|    reward             | 1.4453762 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 6.79      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 479         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 6.53        |\n",
      "|    reward             | -0.17277218 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.52        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 480       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 8.64      |\n",
      "|    reward             | 1.5687248 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 1.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 476      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -48.1    |\n",
      "|    reward             | 4.236493 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 66.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 477       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -13.5     |\n",
      "|    reward             | 2.3844297 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.25      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 14.8     |\n",
      "|    reward             | 1.342733 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 5.69     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 477         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -18.7       |\n",
      "|    reward             | -0.89230233 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 7.52        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 478        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 3.4        |\n",
      "|    reward             | 0.88500804 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 1.38       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -21.6      |\n",
      "|    reward             | -2.3398798 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 15.2       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 480       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 9.8       |\n",
      "|    reward             | 0.7296299 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 2.49      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 4.3        |\n",
      "|    reward             | -0.4543701 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 1.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 481        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 5.51       |\n",
      "|    reward             | -2.1788707 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 0.663      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 483        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 3.18       |\n",
      "|    reward             | 0.25581995 |\n",
      "|    std                | 0.992      |\n",
      "|    value_loss         | 0.382      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -18        |\n",
      "|    reward             | -4.5442805 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 8.34       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 485      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -4.74    |\n",
      "|    reward             | -0.9366  |\n",
      "|    std                | 0.984    |\n",
      "|    value_loss         | 3.43     |\n",
      "------------------------------------\n",
      "day: 1949, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2328197.93\n",
      "total_reward: 1328197.93\n",
      "total_cost: 8577.32\n",
      "total_trades: 5958\n",
      "Sharpe: 0.676\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 485       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 8.26      |\n",
      "|    reward             | -0.079875 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 2.55      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2017-10-02 to  2018-01-02\n",
      "A2C Sharpe Ratio:  0.26973153283205004\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_126_26\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 659         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.20358893 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049375575 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.000883     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.19         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    reward               | 1.0124865    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.05         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 609         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007057543 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.0116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    reward               | -0.57641625 |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 3.33        |\n",
      "-----------------------------------------\n",
      "day: 1949, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 702475.59\n",
      "total_reward: -297524.41\n",
      "total_cost: 792287.49\n",
      "total_trades: 7765\n",
      "Sharpe: -0.223\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 602          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056678886 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.48         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    reward               | -0.7623235   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.44         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 598        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00967317 |\n",
      "|    clip_fraction        | 0.0739     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.1       |\n",
      "|    explained_variance   | 0.00829    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 1.62       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00495   |\n",
      "|    reward               | -1.3263131 |\n",
      "|    std                  | 0.999      |\n",
      "|    value_loss           | 3.99       |\n",
      "----------------------------------------\n",
      "======PPO Validation from:  2017-10-02 to  2018-01-02\n",
      "PPO Sharpe Ratio:  -0.06498611129021019\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_126_24\n",
      "day: 1949, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1938339.92\n",
      "total_reward: 938339.92\n",
      "total_cost: 998.79\n",
      "total_trades: 9744\n",
      "Sharpe: 0.617\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 221        |\n",
      "|    time_elapsed    | 35         |\n",
      "|    total_timesteps | 7800       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 241        |\n",
      "|    critic_loss     | 25         |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7699       |\n",
      "|    reward          | 0.68945426 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2017-10-02 to  2018-01-02\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-01-02\n",
      "======Trading from:  2018-01-02 to  2018-04-04\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2018-01-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_189_24\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 472        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -11.8      |\n",
      "|    reward             | 0.25249892 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 4.09       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 474       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.595    |\n",
      "|    reward             | 1.7309444 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.76      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 475        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -10.3      |\n",
      "|    reward             | -2.6814811 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.64       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 488         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -24.4       |\n",
      "|    reward             | -0.49892592 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 15.9        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 495          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.1         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 32           |\n",
      "|    reward             | -0.015124219 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 28.5         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 501         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 15.5        |\n",
      "|    reward             | 0.034162086 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 5.63        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 504        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 21.4       |\n",
      "|    reward             | -0.8129123 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 16.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -15.3      |\n",
      "|    reward             | 0.20544307 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 6.62       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 509       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -18.4     |\n",
      "|    reward             | -2.229989 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 512       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -23       |\n",
      "|    reward             | 0.3085922 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 11.6      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 514         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 14.6        |\n",
      "|    reward             | -0.51976746 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 8.41        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 515      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 32.6     |\n",
      "|    reward             | 2.13345  |\n",
      "|    std                | 0.992    |\n",
      "|    value_loss         | 21.5     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 514        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 20.4       |\n",
      "|    reward             | -2.2941897 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 9.45       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.07       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 21.4        |\n",
      "|    reward             | -0.14051478 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 10.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 17.8      |\n",
      "|    reward             | 3.4769413 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 5.48      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 517          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.07        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | 3.44         |\n",
      "|    reward             | -0.014783203 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 1.28         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 9.68       |\n",
      "|    reward             | 0.92656213 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 7.76       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 6          |\n",
      "|    reward             | -0.7297421 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 519       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -70       |\n",
      "|    reward             | 3.1940143 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 83.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -9.09      |\n",
      "|    reward             | 0.09753838 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 1.7        |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2018-01-02 to  2018-04-04\n",
      "A2C Sharpe Ratio:  -0.07930606522039776\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_189_24\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 692        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 2          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.69165957 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 648         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007532525 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0684     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.86        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    reward               | 0.07934244  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 638         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009865596 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.015      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.88        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    reward               | -1.6990778  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007972961 |\n",
      "|    clip_fraction        | 0.0881      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | -0.0161     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    reward               | 0.9975514   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "day: 2012, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1054020.83\n",
      "total_reward: 54020.83\n",
      "total_cost: 918491.64\n",
      "total_trades: 8164\n",
      "Sharpe: 0.118\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008113847 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.0233      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    reward               | -0.22716601 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.86        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-01-02 to  2018-04-04\n",
      "PPO Sharpe Ratio:  -0.07512358603138707\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_189_24\n",
      "day: 2012, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2038308.62\n",
      "total_reward: 1038308.62\n",
      "total_cost: 998.79\n",
      "total_trades: 8048\n",
      "Sharpe: 0.647\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 241        |\n",
      "|    time_elapsed    | 33         |\n",
      "|    total_timesteps | 8052       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.52e+03   |\n",
      "|    critic_loss     | 145        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 7951       |\n",
      "|    reward          | -0.9862836 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2018-01-02 to  2018-04-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-04-04\n",
      "======Trading from:  2018-04-04 to  2018-07-03\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2018-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_252_23\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 511          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.05        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -9.96        |\n",
      "|    reward             | -0.006570311 |\n",
      "|    std                | 0.991        |\n",
      "|    value_loss         | 3.39         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 508      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.05    |\n",
      "|    explained_variance | -0.162   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -3.31    |\n",
      "|    reward             | 0.632859 |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 1.52     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -3.27      |\n",
      "|    reward             | -1.9931873 |\n",
      "|    std                | 0.989      |\n",
      "|    value_loss         | 1.73       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 510        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 0.627      |\n",
      "|    reward             | 0.93670875 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 2.1        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 510        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 14.6       |\n",
      "|    reward             | -1.1190773 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 6.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 512        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -7.98      |\n",
      "|    reward             | 0.34423995 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 3.43       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 511        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -90.4      |\n",
      "|    reward             | -1.0400052 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 162        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 512        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.99      |\n",
      "|    explained_variance | 0.219      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -16        |\n",
      "|    reward             | -0.2523859 |\n",
      "|    std                | 0.98       |\n",
      "|    value_loss         | 6.23       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 511         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -10.3       |\n",
      "|    reward             | -0.88936895 |\n",
      "|    std                | 0.979       |\n",
      "|    value_loss         | 1.79        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 511       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 7.83      |\n",
      "|    reward             | 1.3654134 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.39      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 511          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.97        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -10.8        |\n",
      "|    reward             | -0.082820505 |\n",
      "|    std                | 0.977        |\n",
      "|    value_loss         | 3.79         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 512         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.98       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -1.81       |\n",
      "|    reward             | 0.055033464 |\n",
      "|    std                | 0.979       |\n",
      "|    value_loss         | 0.899       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 505       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.98     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 4.59      |\n",
      "|    reward             | 1.4054505 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 0.693     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 505       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7        |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 7.98      |\n",
      "|    reward             | 0.6805626 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 505        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.99      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -22.7      |\n",
      "|    reward             | -1.3274841 |\n",
      "|    std                | 0.979      |\n",
      "|    value_loss         | 15         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.97     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -6.02     |\n",
      "|    reward             | -0.205167 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 0.821     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.99     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 7.94      |\n",
      "|    reward             | 0.7137201 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 507        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -6.62      |\n",
      "|    reward             | 0.32569936 |\n",
      "|    std                | 0.981      |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 507       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7        |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -4.66     |\n",
      "|    reward             | 1.9656359 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.79      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 507       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 9.1       |\n",
      "|    reward             | 1.0441148 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.89      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2018-04-04 to  2018-07-03\n",
      "A2C Sharpe Ratio:  0.28589513453414617\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_252_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 692         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 2           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.17450483 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006582331 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.000126    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 0.5741618   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005420512 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.000146    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    reward               | 0.35549602  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.21        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068691503 |\n",
      "|    clip_fraction        | 0.0905       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.13        |\n",
      "|    explained_variance   | 0.00582      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.42         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00692     |\n",
      "|    reward               | 0.20777953   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.39         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004899893 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.00646     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.47        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    reward               | 0.21457884  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.13        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2018-04-04 to  2018-07-03\n",
      "PPO Sharpe Ratio:  0.01948590810006932\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_252_23\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 243       |\n",
      "|    time_elapsed    | 34        |\n",
      "|    total_timesteps | 8304      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.05      |\n",
      "|    critic_loss     | 14.1      |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 8203      |\n",
      "|    reward          | 2.0526638 |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2018-04-04 to  2018-07-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-07-03\n",
      "======Trading from:  2018-07-03 to  2018-10-02\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2018-07-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_315_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 507        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | -0.647     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -8.28      |\n",
      "|    reward             | 0.23009427 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 2.18       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 511       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | -0.365    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 4.19      |\n",
      "|    reward             | 1.1341604 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.87      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | -1.5489401 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 5.36       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 516         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.02       |\n",
      "|    explained_variance | -0.112      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -13.9       |\n",
      "|    reward             | -0.21025267 |\n",
      "|    std                | 0.986       |\n",
      "|    value_loss         | 3.87        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -11.7      |\n",
      "|    reward             | 0.70495504 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 4.08       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 0.792      |\n",
      "|    reward             | 0.96390265 |\n",
      "|    std                | 0.989      |\n",
      "|    value_loss         | 0.219      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -17.5      |\n",
      "|    reward             | 0.29735932 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 6.25       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | -22        |\n",
      "|    reward             | 0.12003267 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 14.1       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 518      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -4.78    |\n",
      "|    reward             | 1.914805 |\n",
      "|    std                | 0.979    |\n",
      "|    value_loss         | 0.762    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -19.3      |\n",
      "|    reward             | -2.3749847 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 7.63       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.03    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 19.8     |\n",
      "|    reward             | 0.939375 |\n",
      "|    std                | 0.987    |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 519         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | -29.6       |\n",
      "|    reward             | -0.84618974 |\n",
      "|    std                | 0.99        |\n",
      "|    value_loss         | 19.1        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | -2.7162848 |\n",
      "|    std                | 0.991      |\n",
      "|    value_loss         | 3.76       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 520       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -4.11     |\n",
      "|    reward             | 1.0228336 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.06      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 520         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.07       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 5.45        |\n",
      "|    reward             | -0.41304603 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 7.76        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 520        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 5.17       |\n",
      "|    reward             | 0.14372762 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 1.7        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -10.4      |\n",
      "|    reward             | -1.1831579 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 9.11       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 518       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 2.04      |\n",
      "|    reward             | 2.3942943 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 3.77      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 2.7        |\n",
      "|    reward             | -1.7777938 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 0.235      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 517        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -27.7      |\n",
      "|    reward             | -1.0163026 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 19.4       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2018-07-03 to  2018-10-02\n",
      "A2C Sharpe Ratio:  0.5537102211041391\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_315_23\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 682          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 2            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.036711924 |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005936137 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0401     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.71        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    reward               | -0.01893349 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053054066 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.00181      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    reward               | 0.3982357    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 633          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045189112 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | -0.00867     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.29         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    reward               | -0.24603537  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.35         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063852053 |\n",
      "|    clip_fraction        | 0.0797       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.13        |\n",
      "|    explained_variance   | -0.00346     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.98         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    reward               | 0.54523844   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.34         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2018-07-03 to  2018-10-02\n",
      "PPO Sharpe Ratio:  -0.017626018868247235\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_315_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 238        |\n",
      "|    time_elapsed    | 35         |\n",
      "|    total_timesteps | 8556       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -1.83e+03  |\n",
      "|    critic_loss     | 559        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8455       |\n",
      "|    reward          | 0.27547413 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2018-07-03 to  2018-10-02\n",
      "======Best Model Retraining from:  2010-01-01 to  2018-10-02\n",
      "======Trading from:  2018-10-02 to  2019-01-03\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2018-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_378_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 487        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -13.1      |\n",
      "|    reward             | 0.09658058 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 4.54       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 480       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.597    |\n",
      "|    reward             | 1.7851256 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 1.92      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 477       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -12.3     |\n",
      "|    reward             | -2.710952 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.9       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -14.9      |\n",
      "|    reward             | 0.06554392 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 5.77       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 10.3       |\n",
      "|    reward             | -2.6574628 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.8        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 3.79      |\n",
      "|    reward             | 0.5044955 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 478        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 3.9        |\n",
      "|    reward             | -1.1127619 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.392      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 480           |\n",
      "|    iterations         | 800           |\n",
      "|    time_elapsed       | 8             |\n",
      "|    total_timesteps    | 4000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.1          |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 799           |\n",
      "|    policy_loss        | 5.05          |\n",
      "|    reward             | 0.00025063477 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.2           |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -8.29     |\n",
      "|    reward             | 1.4349855 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 6.68      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 484         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.07       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | -16.8       |\n",
      "|    reward             | -0.28686953 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 9.32        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 486        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -17.6      |\n",
      "|    reward             | -1.3472452 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 6.5        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 488        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -20        |\n",
      "|    reward             | 0.91774493 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 11.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 489         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -31.5       |\n",
      "|    reward             | -0.08797392 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 26.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 490       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 4.64      |\n",
      "|    reward             | -2.896719 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.08      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 491         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 15          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 3.58        |\n",
      "|    reward             | -0.41243023 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 1.33        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 492           |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.09         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | 22.3          |\n",
      "|    reward             | -0.0051945243 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 13.9          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 492        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -16.5      |\n",
      "|    reward             | 0.43755385 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 8.1        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 492        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -0.991     |\n",
      "|    reward             | 0.03888902 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.711      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 493        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -8.84      |\n",
      "|    reward             | -0.0398385 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 1.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 493         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | -14.6       |\n",
      "|    reward             | -0.26610273 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 4.85        |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2018-10-02 to  2019-01-03\n",
      "A2C Sharpe Ratio:  -0.2970841586388141\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_378_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 681         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.08996567 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00872108  |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | -0.0962     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.89        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    reward               | -0.06776339 |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 3.4         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007372088  |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.08        |\n",
      "|    explained_variance   | -0.00316     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.11         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    reward               | -0.119722456 |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 4.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006008314 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.0044      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.9         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    reward               | 0.2823984   |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 4.48        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052158865 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.0177       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    reward               | 0.37200806   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.26         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2018-10-02 to  2019-01-03\n",
      "PPO Sharpe Ratio:  -0.32822947165228694\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_378_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 232        |\n",
      "|    time_elapsed    | 37         |\n",
      "|    total_timesteps | 8808       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 1.37e+03   |\n",
      "|    critic_loss     | 176        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8707       |\n",
      "|    reward          | 0.11482468 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2018-10-02 to  2019-01-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-01-03\n",
      "======Trading from:  2019-01-03 to  2019-04-04\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2019-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_441_23\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 499           |\n",
      "|    iterations         | 100           |\n",
      "|    time_elapsed       | 1             |\n",
      "|    total_timesteps    | 500           |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.1          |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 99            |\n",
      "|    policy_loss        | -10.7         |\n",
      "|    reward             | 4.4088305e-05 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 3.33          |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 503       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -2.72     |\n",
      "|    reward             | 0.7026428 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 502        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -9.14      |\n",
      "|    reward             | -2.5453196 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.74       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 502       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.15     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -5.47     |\n",
      "|    reward             | 0.3306611 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.888     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 503        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | -0.0154    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 10.9       |\n",
      "|    reward             | 0.21205552 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.21       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 504          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.15        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.48        |\n",
      "|    reward             | -0.035145655 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.577        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 505        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 2.61       |\n",
      "|    reward             | -1.2723042 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.174      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 506        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 9.25       |\n",
      "|    reward             | 0.40809375 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.2        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.18     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 2.51      |\n",
      "|    reward             | 0.5204542 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.17     |\n",
      "|    explained_variance | 0.0323    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -2.24     |\n",
      "|    reward             | 2.0708666 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.17     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -6.08     |\n",
      "|    reward             | 1.4642726 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.794     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 507        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.16      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 9.18       |\n",
      "|    reward             | -0.6234515 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -1.23      |\n",
      "|    reward             | -0.5863114 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.111      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 508         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.16       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -11.5       |\n",
      "|    reward             | -0.16172242 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.71        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -11.3      |\n",
      "|    reward             | -0.4831726 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.15       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 508       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.14     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -25.2     |\n",
      "|    reward             | 0.9981719 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 10.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.16      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -8.78      |\n",
      "|    reward             | -2.9568965 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.26       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -5.96      |\n",
      "|    reward             | -1.9491472 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 2.54       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -30.5      |\n",
      "|    reward             | -2.7391753 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 35.9       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 507         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.2        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 4.47        |\n",
      "|    reward             | -0.62921584 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 2.16        |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-01-03 to  2019-04-04\n",
      "A2C Sharpe Ratio:  0.5015923855362412\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_441_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 662        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 3          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.03239181 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 619         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008422378 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | -0.0584     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.41        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    reward               | -0.48329714 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007298773 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.0115      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    reward               | 0.21908662  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00427295  |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | 0.0276      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.38        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    reward               | -0.68332916 |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 4.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006463228 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | 0.0415      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | 0.18876816  |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 3.67        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-01-03 to  2019-04-04\n",
      "PPO Sharpe Ratio:  0.45150742444367314\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_441_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 233        |\n",
      "|    time_elapsed    | 38         |\n",
      "|    total_timesteps | 9060       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 485        |\n",
      "|    critic_loss     | 2.52       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8959       |\n",
      "|    reward          | 0.45101056 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-01-03 to  2019-04-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-04-04\n",
      "======Trading from:  2019-04-04 to  2019-07-05\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2019-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_504_23\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 506       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0.095     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -9.92     |\n",
      "|    reward             | 0.2382331 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 500       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.808    |\n",
      "|    reward             | 1.4301094 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.45      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 488        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -9.9       |\n",
      "|    reward             | -2.2219946 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 4.95       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -21.4      |\n",
      "|    reward             | -0.0891466 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 10.9       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 485        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 11.3       |\n",
      "|    reward             | 0.30565643 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 3.41       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -1.65      |\n",
      "|    reward             | 0.74588245 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.306      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 485       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13     |\n",
      "|    explained_variance | 0.185     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 0.153     |\n",
      "|    reward             | 0.3622526 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.924     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 484         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -1.84       |\n",
      "|    reward             | -0.58066463 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.234       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 485       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.14     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -19.4     |\n",
      "|    reward             | 0.7593527 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.66      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -1.42      |\n",
      "|    reward             | -1.4779955 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.705      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 484         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | 6.07        |\n",
      "|    reward             | -0.15150116 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.36        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -18.2      |\n",
      "|    reward             | 0.69976044 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.02       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 485        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 22.5       |\n",
      "|    reward             | 0.29849142 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 11         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | -0.0047   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -7.21     |\n",
      "|    reward             | 0.3935791 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.02      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 483      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.1     |\n",
      "|    explained_variance | 0.0221   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 2.92     |\n",
      "|    reward             | 0.764648 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.356    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 1.85       |\n",
      "|    reward             | 0.19676986 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.314      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -33.8      |\n",
      "|    reward             | 0.40133053 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 27.6       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 2.67       |\n",
      "|    reward             | 0.60746956 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 0.286      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 481        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 8.56       |\n",
      "|    reward             | 0.39208487 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.6        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 482         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 3.45        |\n",
      "|    reward             | -0.95411813 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.29        |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-04-04 to  2019-07-05\n",
      "A2C Sharpe Ratio:  0.09584034226398572\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_504_23\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 673          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 3            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.044571705 |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007107695 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.134      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.1         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    reward               | 0.16980138  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 626          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067959176 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | -0.00269     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    reward               | 0.56537294   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.85         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062822048 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | 1.7037125    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.29         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060231676 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.14        |\n",
      "|    explained_variance   | 0.0107       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 0.57186717   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.2          |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2019-04-04 to  2019-07-05\n",
      "PPO Sharpe Ratio:  -0.15780667483691968\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_504_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 231        |\n",
      "|    time_elapsed    | 40         |\n",
      "|    total_timesteps | 9312       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 270        |\n",
      "|    critic_loss     | 158        |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 9211       |\n",
      "|    reward          | 0.19787735 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-04-04 to  2019-07-05\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-07-05\n",
      "======Trading from:  2019-07-05 to  2019-10-03\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2019-07-05\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_567_23\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 483         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -12.8       |\n",
      "|    reward             | 0.097877786 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 4.2         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 487       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -1.96     |\n",
      "|    reward             | 1.0835388 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.69      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 474       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -13.9     |\n",
      "|    reward             | -2.358341 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 4.35      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 474         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -18.2       |\n",
      "|    reward             | -0.40178797 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 10.4        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 474       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 8.15      |\n",
      "|    reward             | 2.5880764 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 2.78      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 475        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 0.644      |\n",
      "|    reward             | 0.40163568 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 1.01       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 475         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.1        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 18.2        |\n",
      "|    reward             | -0.34456837 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 5.07        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 476       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -7.37     |\n",
      "|    reward             | 1.584391  |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.24      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 477      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 13.8     |\n",
      "|    reward             | 1.328538 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 7.75     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 475        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 10         |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 16         |\n",
      "|    reward             | -1.3650162 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 5.4        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 477        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 8.57       |\n",
      "|    reward             | -1.2181532 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.51       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 13.9       |\n",
      "|    reward             | -0.6998016 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 4.46       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 480         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.389      |\n",
      "|    reward             | -0.36745146 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.232       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 481       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 10.7      |\n",
      "|    reward             | -4.417482 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.26      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 482       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.14     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -9.68     |\n",
      "|    reward             | 1.8364936 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.81      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 14.6       |\n",
      "|    reward             | -1.2576611 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 5.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 483         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.15       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | -0.973      |\n",
      "|    reward             | -0.28738037 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.897       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.16     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 15        |\n",
      "|    reward             | 0.5419337 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 483      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.16    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -23.7    |\n",
      "|    reward             | 1.602457 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 13.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 483      |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.15    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 5.87     |\n",
      "|    reward             | 2.150767 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.73     |\n",
      "------------------------------------\n",
      "======A2C Validation from:  2019-07-05 to  2019-10-03\n",
      "A2C Sharpe Ratio:  -0.1710229441047188\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_567_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 644         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.080894776 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073092524 |\n",
      "|    clip_fraction        | 0.0685       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | 0.00769      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.2          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    reward               | -0.74019414  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.06         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009249114 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.00904    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.4         |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    reward               | 0.24170758  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 608         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007430463 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | -0.00113    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.99        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    reward               | -0.23914059 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007445386 |\n",
      "|    clip_fraction        | 0.0649      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0092     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    reward               | 0.12662262  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-07-05 to  2019-10-03\n",
      "PPO Sharpe Ratio:  -0.25437726016693446\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_567_23\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 231       |\n",
      "|    time_elapsed    | 41        |\n",
      "|    total_timesteps | 9564      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -13.7     |\n",
      "|    critic_loss     | 2.31      |\n",
      "|    learning_rate   | 0.0005    |\n",
      "|    n_updates       | 9463      |\n",
      "|    reward          | 1.1875563 |\n",
      "----------------------------------\n",
      "======DDPG Validation from:  2019-07-05 to  2019-10-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2019-10-03\n",
      "======Trading from:  2019-10-03 to  2020-01-03\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2019-10-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_630_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 486        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0.00464    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -11        |\n",
      "|    reward             | -0.1912717 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 2.97       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 477       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.281    |\n",
      "|    reward             | 0.5718878 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.01      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -8.81      |\n",
      "|    reward             | -1.4865466 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 2.96       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 479      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -1.58    |\n",
      "|    reward             | 0.520968 |\n",
      "|    std                | 0.984    |\n",
      "|    value_loss         | 0.74     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 481        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 6.43       |\n",
      "|    reward             | 0.39718834 |\n",
      "|    std                | 0.98       |\n",
      "|    value_loss         | 0.663      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 481         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7          |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | 0.178       |\n",
      "|    reward             | -0.25160164 |\n",
      "|    std                | 0.981       |\n",
      "|    value_loss         | 0.0264      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | 4.29       |\n",
      "|    reward             | -1.3021547 |\n",
      "|    std                | 0.983      |\n",
      "|    value_loss         | 0.52       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 481       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 22.2      |\n",
      "|    reward             | 1.7971301 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 13.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 9.16       |\n",
      "|    reward             | -2.1502745 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 13.7       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 484         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.06       |\n",
      "|    explained_variance | -0.00656    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 2.6         |\n",
      "|    reward             | -0.18495981 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 10.2        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 485        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 0.00161    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 2.61       |\n",
      "|    reward             | -0.8857175 |\n",
      "|    std                | 0.992      |\n",
      "|    value_loss         | 0.388      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.05     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 5.23      |\n",
      "|    reward             | 1.0810689 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 0.938     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -3.62      |\n",
      "|    reward             | 0.89709336 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 0.624      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 481       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 3.11      |\n",
      "|    reward             | 1.8581934 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.59      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 482      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | 5.54     |\n",
      "|    reward             | 2.305125 |\n",
      "|    std                | 0.999    |\n",
      "|    value_loss         | 1.32     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 483        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -8.36      |\n",
      "|    reward             | -0.2065174 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 2.41       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 484       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -1.14     |\n",
      "|    reward             | 0.7441216 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.337     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 484         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | 2.53        |\n",
      "|    reward             | -0.37273973 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 11.4        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 485         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | -16.9       |\n",
      "|    reward             | -0.25220826 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.93        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 485         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 9.03        |\n",
      "|    reward             | -0.49724853 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.47        |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2019-10-03 to  2020-01-03\n",
      "A2C Sharpe Ratio:  0.5797029991075294\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_630_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 676         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.11639265 |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004689269 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.00351     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    reward               | -0.14735171 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 624         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006965812 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | -0.00572    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.02        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    reward               | -0.7410693  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006270056 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.0301      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.7         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 1.0163536   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008710255 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.22        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    reward               | -1.3332536  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.08        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2019-10-03 to  2020-01-03\n",
      "PPO Sharpe Ratio:  0.5366403872984487\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_630_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 231        |\n",
      "|    time_elapsed    | 42         |\n",
      "|    total_timesteps | 9816       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -394       |\n",
      "|    critic_loss     | 11.9       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 9715       |\n",
      "|    reward          | -3.1515832 |\n",
      "-----------------------------------\n",
      "======DDPG Validation from:  2019-10-03 to  2020-01-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-01-03\n",
      "======Trading from:  2020-01-03 to  2020-04-03\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2020-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_693_23\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 454          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.16        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -10.9        |\n",
      "|    reward             | -0.083673276 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.97         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 463       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.13     |\n",
      "|    explained_variance | 0.0218    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.861    |\n",
      "|    reward             | 0.5985983 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 470        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -8.87      |\n",
      "|    reward             | -1.8315921 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.65       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 472        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -11.5      |\n",
      "|    reward             | 0.33058646 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.61       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 474      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.11    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -8.76    |\n",
      "|    reward             | -0.78799 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 476         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | -0.302      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -18.7       |\n",
      "|    reward             | -0.19673328 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 10.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 465       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -4.19     |\n",
      "|    reward             | 0.1729882 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.522     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 468         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0.0436      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | -4.41       |\n",
      "|    reward             | -0.23304598 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 1.69        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 467        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -4.5       |\n",
      "|    reward             | 0.83769834 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.35       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 467          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.09        |\n",
      "|    explained_variance | 0.0195       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 3.79         |\n",
      "|    reward             | -0.026048616 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.551        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 468       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -3.76     |\n",
      "|    reward             | 0.5118826 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 5.42      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 469        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 1.62       |\n",
      "|    reward             | 0.59726036 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.168      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 470         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.06       |\n",
      "|    explained_variance | -0.0176     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 4.59        |\n",
      "|    reward             | -0.51689255 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 0.816       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 470        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -1.34      |\n",
      "|    reward             | 0.26541463 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.0613     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 470       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 9.87      |\n",
      "|    reward             | 1.0630655 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 4.68      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 471        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 19.5       |\n",
      "|    reward             | -0.4662319 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 10.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 471       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -6.85     |\n",
      "|    reward             | 2.6671247 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 472         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -22.5       |\n",
      "|    reward             | -0.20515065 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 11.6        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 473       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -5.91     |\n",
      "|    reward             | 1.1945244 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 0.949     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 474        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 21         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -1.05      |\n",
      "|    reward             | -1.3128244 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 0.216      |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2020-01-03 to  2020-04-03\n",
      "A2C Sharpe Ratio:  -0.09692460144305706\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_693_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 661         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.042368997 |\n",
      "------------------------------------\n",
      "day: 2516, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 544887.56\n",
      "total_reward: -455112.44\n",
      "total_cost: 1167352.61\n",
      "total_trades: 9713\n",
      "Sharpe: -0.364\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067211073 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | -0.0416      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.78         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | 0.6908744    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 3.45         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 609          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050889626 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | 0.00127      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.78         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -0.058977216 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 4.08         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00522155  |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | -0.0075     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.52        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    reward               | 0.078860074 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007053771 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | 0.00526     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    reward               | 0.22578064  |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 3.23        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-01-03 to  2020-04-03\n",
      "PPO Sharpe Ratio:  -0.08122791690514908\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_693_23\n",
      "day: 2516, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3372278.30\n",
      "total_reward: 2372278.30\n",
      "total_cost: 49065.54\n",
      "total_trades: 5273\n",
      "Sharpe: 0.838\n",
      "=================================\n",
      "======DDPG Validation from:  2020-01-03 to  2020-04-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-04-03\n",
      "======Trading from:  2020-04-03 to  2020-07-06\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2020-04-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_756_23\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 465         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -13.1       |\n",
      "|    reward             | -0.13698405 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 3.21        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 469        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | -0.0636    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -1.1       |\n",
      "|    reward             | 0.90708244 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.31       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 471        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | -0.00686   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -7.21      |\n",
      "|    reward             | -1.8664143 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 2.3        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 464       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | 0.143     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -4.66     |\n",
      "|    reward             | 0.2566701 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.502     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 462         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -10.9       |\n",
      "|    reward             | -0.47007048 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.84        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 462        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 6.24       |\n",
      "|    reward             | -1.2299476 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 4.01       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 463       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 2.44      |\n",
      "|    reward             | 0.2512682 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 464       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 2.94      |\n",
      "|    reward             | -2.152958 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 0.399     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 466        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -19.6      |\n",
      "|    reward             | -0.3746367 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 8.11       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 468      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.11    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 18.6     |\n",
      "|    reward             | 0.5873   |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 20       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 469        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.14      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -2.3       |\n",
      "|    reward             | 0.95221156 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 467        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 6.03       |\n",
      "|    reward             | 0.75757474 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.961      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 467       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.16     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 7.57      |\n",
      "|    reward             | 1.9909745 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 467         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.16       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | -5.35       |\n",
      "|    reward             | -0.10128164 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 468       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.14     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 5.06      |\n",
      "|    reward             | 2.2444797 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.45      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 468         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 17          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 2.19        |\n",
      "|    reward             | -0.19183575 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.375       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 469        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 22.8       |\n",
      "|    reward             | 0.96791786 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 9.25       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 468        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 4.29       |\n",
      "|    reward             | -1.5669814 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.424      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 468          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 20           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.13        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.00946      |\n",
      "|    reward             | -0.057544336 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.148        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 469       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.16     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -36.3     |\n",
      "|    reward             | 10.167507 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 53.4      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2020-04-03 to  2020-07-06\n",
      "A2C Sharpe Ratio:  0.3811164847579358\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_756_23\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 3         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 0.4216089 |\n",
      "----------------------------------\n",
      "day: 2579, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 500775.70\n",
      "total_reward: -499224.30\n",
      "total_cost: 1160336.55\n",
      "total_trades: 9936\n",
      "Sharpe: -0.317\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006093772 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0463     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.13        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    reward               | 0.44469735  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 589          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063467193 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | -0.00852     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    reward               | 0.00498488   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 4.24         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063936953 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 0.00599      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.51         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    reward               | 1.7717822    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.01         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 574          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064067817 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.14        |\n",
      "|    explained_variance   | 0.0127       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.09         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    reward               | -0.25384587  |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.44         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2020-04-03 to  2020-07-06\n",
      "PPO Sharpe Ratio:  0.27405341593893645\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_756_23\n",
      "day: 2579, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1544695.48\n",
      "total_reward: 544695.48\n",
      "total_cost: 998.41\n",
      "total_trades: 7737\n",
      "Sharpe: 0.335\n",
      "=================================\n",
      "======DDPG Validation from:  2020-04-03 to  2020-07-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-07-06\n",
      "======Trading from:  2020-07-06 to  2020-10-02\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2020-07-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_819_23\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 510          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.03        |\n",
      "|    explained_variance | -0.264       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -10.4        |\n",
      "|    reward             | -0.022983994 |\n",
      "|    std                | 0.987        |\n",
      "|    value_loss         | 1.95         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 506        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7         |\n",
      "|    explained_variance | -0.0162    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -0.729     |\n",
      "|    reward             | 0.55508256 |\n",
      "|    std                | 0.98       |\n",
      "|    value_loss         | 0.841      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7         |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -3.25      |\n",
      "|    reward             | -1.7666117 |\n",
      "|    std                | 0.982      |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0.0424     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | 2.76       |\n",
      "|    reward             | 0.70990545 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 1.21       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 511         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.02       |\n",
      "|    explained_variance | 0.0132      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -3.95       |\n",
      "|    reward             | -0.61919886 |\n",
      "|    std                | 0.985       |\n",
      "|    value_loss         | 0.656       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 511        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | -0.04      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -4.96      |\n",
      "|    reward             | -0.8819991 |\n",
      "|    std                | 0.985      |\n",
      "|    value_loss         | 1.29       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 511        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -3.77      |\n",
      "|    reward             | -1.7970557 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 0.385      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 512       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 5.5       |\n",
      "|    reward             | 1.0444801 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 513       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -6.21     |\n",
      "|    reward             | 1.2054727 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 0.877     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | -0.00186  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -20.7     |\n",
      "|    reward             | 1.7602133 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 16        |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.02       |\n",
      "|    explained_variance | -0.053      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -2.04       |\n",
      "|    reward             | -0.35268426 |\n",
      "|    std                | 0.986       |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | -0.00571   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -23.1      |\n",
      "|    reward             | -1.3114947 |\n",
      "|    std                | 0.989      |\n",
      "|    value_loss         | 12.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | -0.00185    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 6.34        |\n",
      "|    reward             | -0.28979295 |\n",
      "|    std                | 0.988       |\n",
      "|    value_loss         | 3.29        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -6.15     |\n",
      "|    reward             | 0.6958652 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.38      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 517       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.05     |\n",
      "|    explained_variance | 0.00126   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -85.9     |\n",
      "|    reward             | -2.814182 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 131       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0.013      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 1.62       |\n",
      "|    reward             | -1.1813403 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 518        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 2.96       |\n",
      "|    reward             | -1.9870394 |\n",
      "|    std                | 0.991      |\n",
      "|    value_loss         | 0.419      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 0.0208     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 7.88       |\n",
      "|    reward             | -1.5516196 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 1.47       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 520        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -4.08      |\n",
      "|    reward             | 0.99308145 |\n",
      "|    std                | 0.983      |\n",
      "|    value_loss         | 0.724      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 520        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.99      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -9.76      |\n",
      "|    reward             | -3.0058153 |\n",
      "|    std                | 0.981      |\n",
      "|    value_loss         | 3.36       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2020-07-06 to  2020-10-02\n",
      "A2C Sharpe Ratio:  0.21536188620749777\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_819_23\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 674          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 3            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.009726611 |\n",
      "-------------------------------------\n",
      "day: 2642, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 340274.41\n",
      "total_reward: -659725.59\n",
      "total_cost: 974532.14\n",
      "total_trades: 9989\n",
      "Sharpe: -0.510\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007516265 |\n",
      "|    clip_fraction        | 0.0872      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0283     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.76        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    reward               | -0.03084759 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 624         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006161739 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | -0.00201    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.29        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    reward               | 0.19656467  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053903847 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.12        |\n",
      "|    explained_variance   | 7.7e-05      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.24         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00498     |\n",
      "|    reward               | -1.3408854   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.75         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005736182 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.13       |\n",
      "|    explained_variance   | 0.00569     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.4         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    reward               | 0.011028185 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-07-06 to  2020-10-02\n",
      "PPO Sharpe Ratio:  -0.04980601641998189\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_819_23\n",
      "day: 2642, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2569200.63\n",
      "total_reward: 1569200.63\n",
      "total_cost: 1126.20\n",
      "total_trades: 5285\n",
      "Sharpe: 0.604\n",
      "=================================\n",
      "======DDPG Validation from:  2020-07-06 to  2020-10-02\n",
      "======Best Model Retraining from:  2010-01-01 to  2020-10-02\n",
      "======Trading from:  2020-10-02 to  2021-01-04\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2020-10-02\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_882_23\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 519          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.08        |\n",
      "|    explained_variance | 0.154        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -12.6        |\n",
      "|    reward             | -0.102504306 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 2.89         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 519      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -1.88    |\n",
      "|    reward             | 0.459454 |\n",
      "|    std                | 0.995    |\n",
      "|    value_loss         | 0.644    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 519        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -3.91      |\n",
      "|    reward             | -1.4362165 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 0.927      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 519         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | -0.0107     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -7.36       |\n",
      "|    reward             | -0.05879658 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 1.25        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 519         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -5.41       |\n",
      "|    reward             | -0.32241353 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 517         |\n",
      "|    iterations         | 600         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 3000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 599         |\n",
      "|    policy_loss        | -2.73       |\n",
      "|    reward             | -0.70085436 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 3.15        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -6.45     |\n",
      "|    reward             | 0.3572251 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.78      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.07       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 6.9         |\n",
      "|    reward             | 0.077934146 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 1.42        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 11.6       |\n",
      "|    reward             | 0.47625887 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 2.63       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | -12.7      |\n",
      "|    reward             | 0.22660281 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 6.36       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 506         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | -0.0261     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -19.8       |\n",
      "|    reward             | -0.18796423 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.95        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 507        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 9.73       |\n",
      "|    reward             | -0.8793224 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.43       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 507         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | -0.0853     |\n",
      "|    reward             | -0.17815162 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.0568      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 6.27       |\n",
      "|    reward             | 0.09973744 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 1.27       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | -0.000802  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 4.69       |\n",
      "|    reward             | -1.5059079 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 3.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0.0356     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 62.9       |\n",
      "|    reward             | 0.21017794 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 116        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 29.4       |\n",
      "|    reward             | -1.3781079 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 13.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 510       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 3.04      |\n",
      "|    reward             | 0.7053831 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 510        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -4.64      |\n",
      "|    reward             | 0.98833686 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 1.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 7.08       |\n",
      "|    reward             | 0.11634121 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 1.65       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2020-10-02 to  2021-01-04\n",
      "A2C Sharpe Ratio:  0.3254642612507611\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_882_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 676        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 3          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.50044304 |\n",
      "-----------------------------------\n",
      "day: 2705, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 625518.12\n",
      "total_reward: -374481.88\n",
      "total_cost: 1321761.48\n",
      "total_trades: 10408\n",
      "Sharpe: -0.166\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 640         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005633635 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | -0.138      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.35        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    reward               | 0.33479896  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008489862 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    reward               | 0.4885827   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 625         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007373143 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.028       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    reward               | -0.34698996 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008161208 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 3.37        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    reward               | 0.17841157  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.09        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2020-10-02 to  2021-01-04\n",
      "PPO Sharpe Ratio:  0.30177704853692416\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_882_23\n",
      "day: 2705, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3982045.21\n",
      "total_reward: 2982045.21\n",
      "total_cost: 998.81\n",
      "total_trades: 8115\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "======DDPG Validation from:  2020-10-02 to  2021-01-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2021-01-04\n",
      "======Trading from:  2021-01-04 to  2021-04-06\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2021-01-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_945_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0.496      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -8.98      |\n",
      "|    reward             | 0.39376104 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 2.25       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.33      |\n",
      "|    reward             | 1.3693149 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 2.01      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 516       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -10.9     |\n",
      "|    reward             | -2.143763 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 4.03      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 3           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -22.4       |\n",
      "|    reward             | -0.40084144 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 8.83        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -15.4      |\n",
      "|    reward             | -0.8506298 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 4.17       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 513       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 9.39      |\n",
      "|    reward             | 1.2778642 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 12.4      |\n",
      "|    reward             | 1.0123776 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 4.61      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 514        |\n",
      "|    iterations         | 800        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 4000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 799        |\n",
      "|    policy_loss        | 2.49       |\n",
      "|    reward             | 0.93758917 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 0.191      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 514         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 8           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | 30.9        |\n",
      "|    reward             | -0.56767946 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 23          |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 512        |\n",
      "|    iterations         | 1000       |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 5000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 999        |\n",
      "|    policy_loss        | 23.7       |\n",
      "|    reward             | -3.6811512 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 22.8       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 511       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -80.1     |\n",
      "|    reward             | 0.1304249 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 183       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 510       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.05     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | -2.04     |\n",
      "|    reward             | -3.322677 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 2.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 510      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 16       |\n",
      "|    reward             | 0.524016 |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 8.96     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 509       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 14.7      |\n",
      "|    reward             | 4.7966514 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 7.07      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 509         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 14          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | 5.71        |\n",
      "|    reward             | 0.024026513 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.3         |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 509       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -25.3     |\n",
      "|    reward             | 4.2925763 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 21.4      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -5.25      |\n",
      "|    reward             | 0.79038477 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.47       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 508        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -22.3      |\n",
      "|    reward             | 0.28188342 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 8.33       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -22.7      |\n",
      "|    reward             | -0.5395163 |\n",
      "|    std                | 0.994      |\n",
      "|    value_loss         | 8.48       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 509        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 15.3       |\n",
      "|    reward             | -1.4622419 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 7.86       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2021-01-04 to  2021-04-06\n",
      "A2C Sharpe Ratio:  0.17528597584197356\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_945_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 680         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.071366794 |\n",
      "------------------------------------\n",
      "day: 2768, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 493150.14\n",
      "total_reward: -506849.86\n",
      "total_cost: 1115445.22\n",
      "total_trades: 10404\n",
      "Sharpe: -0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 638         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005997162 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0195     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    reward               | -0.01473266 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005965207 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.0144      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.66        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    reward               | -1.4976952  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 4.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 625         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006546428 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.0452      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | 0.6612669   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 618         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006386431 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.14       |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    reward               | 0.045914028 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2021-01-04 to  2021-04-06\n",
      "PPO Sharpe Ratio:  -0.04617839757243758\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_945_23\n",
      "day: 2768, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2137611.56\n",
      "total_reward: 1137611.56\n",
      "total_cost: 998.75\n",
      "total_trades: 5536\n",
      "Sharpe: 0.482\n",
      "=================================\n",
      "======DDPG Validation from:  2021-01-04 to  2021-04-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2021-04-06\n",
      "======Trading from:  2021-04-06 to  2021-07-06\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2021-04-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_1008_23\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 512          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.08        |\n",
      "|    explained_variance | -0.114       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -5.7         |\n",
      "|    reward             | 0.0006726674 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 1.34         |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 514      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.1     |\n",
      "|    explained_variance | 0.254    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -6.34    |\n",
      "|    reward             | 0.623209 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | -0.316     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -5.1       |\n",
      "|    reward             | -1.4366541 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 1.5        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 515       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -3.48     |\n",
      "|    reward             | 0.1529921 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 0.292     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 515         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -6.26       |\n",
      "|    reward             | -0.39646932 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -0.0651   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -11.8     |\n",
      "|    reward             | 0.7396745 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 4.5       |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 515          |\n",
      "|    iterations         | 700          |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 3500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.09        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 699          |\n",
      "|    policy_loss        | 3.33         |\n",
      "|    reward             | -0.019035034 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.597        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | -0.113    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 14.2      |\n",
      "|    reward             | 0.6240729 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.93      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 515        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 8          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | -0.0254    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 1.34       |\n",
      "|    reward             | 0.31891772 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 0.388      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0.0668    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 11.4      |\n",
      "|    reward             | 1.1396999 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 514       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | 0.077     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 24.1      |\n",
      "|    reward             | 1.5448208 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 14.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 513        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0.0268     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 15.1       |\n",
      "|    reward             | -0.2198464 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 3.81       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 513         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | -0.283      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 9.2         |\n",
      "|    reward             | -0.89940435 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 2.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 513        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 0.836      |\n",
      "|    reward             | -0.8371311 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.653      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 513       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -7.8      |\n",
      "|    reward             | 1.3040833 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.29      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 513        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -9.35      |\n",
      "|    reward             | 0.48202345 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 2.14       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 513        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | 19.9       |\n",
      "|    reward             | 0.41660228 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 9.08       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 513       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 12.6      |\n",
      "|    reward             | 1.8930647 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 4.43      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 512          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.08        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 17.9         |\n",
      "|    reward             | -0.097019725 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 6.83         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 511       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 19.4      |\n",
      "|    reward             | 1.7766217 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 10.8      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2021-04-06 to  2021-07-06\n",
      "A2C Sharpe Ratio:  0.11291230994679172\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_1008_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 668        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 3          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.07807331 |\n",
      "-----------------------------------\n",
      "day: 2831, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 892665.76\n",
      "total_reward: -107334.24\n",
      "total_cost: 1438620.20\n",
      "total_trades: 10846\n",
      "Sharpe: 0.024\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072447513 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | -0.00216     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.55         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | -0.59544384  |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 4.15         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003956615 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.07       |\n",
      "|    explained_variance   | 0.00648     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.12        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    reward               | 2.928178    |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 4.94        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064014443 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.08        |\n",
      "|    explained_variance   | 0.0616       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.53         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    reward               | -0.4652111   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.28         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065133655 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | -0.0119      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.76         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | 0.3472224    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.79         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2021-04-06 to  2021-07-06\n",
      "PPO Sharpe Ratio:  0.16357045398743542\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1008_23\n",
      "day: 2831, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5321503.20\n",
      "total_reward: 4321503.20\n",
      "total_cost: 998.92\n",
      "total_trades: 5662\n",
      "Sharpe: 0.849\n",
      "=================================\n",
      "======DDPG Validation from:  2021-04-06 to  2021-07-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2021-07-06\n",
      "======Trading from:  2021-07-06 to  2021-10-04\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2021-07-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_1071_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 496        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -8.99      |\n",
      "|    reward             | -0.0247479 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 3.02       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 497      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.05    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -1.14    |\n",
      "|    reward             | 0.58135  |\n",
      "|    std                | 0.991    |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 500        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -10.1      |\n",
      "|    reward             | -1.7382421 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 2.35       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 503       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -2.95     |\n",
      "|    reward             | 0.3310781 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 0.345     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 503         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -7.65       |\n",
      "|    reward             | -0.37206092 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.6         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 503        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | -0.102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | 16.9       |\n",
      "|    reward             | -3.4858968 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 7.54       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 502       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | -3.83     |\n",
      "|    reward             | 1.0813761 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 2.52      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 502      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.04    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -4.04    |\n",
      "|    reward             | 0.51925  |\n",
      "|    std                | 0.989    |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | -0.0928   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -0.557    |\n",
      "|    reward             | -0.632077 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 0.446     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 496         |\n",
      "|    iterations         | 1000        |\n",
      "|    time_elapsed       | 10          |\n",
      "|    total_timesteps    | 5000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.01       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 999         |\n",
      "|    policy_loss        | 3.61        |\n",
      "|    reward             | -0.90332526 |\n",
      "|    std                | 0.983       |\n",
      "|    value_loss         | 0.672       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 496         |\n",
      "|    iterations         | 1100        |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 5500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.05       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1099        |\n",
      "|    policy_loss        | -24.9       |\n",
      "|    reward             | -0.97863436 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 20.4        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 496        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0.0685     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 0.0704     |\n",
      "|    reward             | 0.98953265 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 0.212      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 496        |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 13         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | 10.2       |\n",
      "|    reward             | 0.44078028 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 2.76       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -13.1     |\n",
      "|    reward             | 1.5318545 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 5.46      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 499       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -12.9     |\n",
      "|    reward             | 1.0118145 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 3.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 499       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -10.3     |\n",
      "|    reward             | 1.2135103 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 2.83      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 499      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 13.2     |\n",
      "|    reward             | 2.001375 |\n",
      "|    std                | 0.997    |\n",
      "|    value_loss         | 5.9      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 500        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 0.0368     |\n",
      "|    reward             | 0.17903918 |\n",
      "|    std                | 0.991      |\n",
      "|    value_loss         | 0.152      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 500        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | -4.04      |\n",
      "|    reward             | -0.2022336 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 0.486      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 501        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | 4.35       |\n",
      "|    reward             | -0.4400875 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 1.49       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2021-07-06 to  2021-10-04\n",
      "A2C Sharpe Ratio:  -0.03435576353069919\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_1071_23\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 665          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 3            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.034840252 |\n",
      "-------------------------------------\n",
      "day: 2894, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 408823.05\n",
      "total_reward: -591176.95\n",
      "total_cost: 1172472.15\n",
      "total_trades: 10980\n",
      "Sharpe: -0.373\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 610          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069212597 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | -0.0831      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.4          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | -0.7683755   |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.49         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066866744 |\n",
      "|    clip_fraction        | 0.0666       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.11        |\n",
      "|    explained_variance   | -0.00153     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.14         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    reward               | 0.30118296   |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.55         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004197777 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.12       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -0.09224102 |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008044173 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | -0.01       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.63        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    reward               | 0.29513055  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2021-07-06 to  2021-10-04\n",
      "PPO Sharpe Ratio:  -0.1126823671154853\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1071_23\n",
      "day: 2894, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3285351.20\n",
      "total_reward: 2285351.20\n",
      "total_cost: 998.93\n",
      "total_trades: 8681\n",
      "Sharpe: 0.689\n",
      "=================================\n",
      "======DDPG Validation from:  2021-07-06 to  2021-10-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2021-10-04\n",
      "======Trading from:  2021-10-04 to  2022-01-03\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2021-10-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_1134_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 504        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 0          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | -0.00269   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -13.8      |\n",
      "|    reward             | 0.47918946 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 4.56       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 503       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.05     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 6.69      |\n",
      "|    reward             | 1.5157979 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 3.27      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 504        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -28.3      |\n",
      "|    reward             | -1.9444346 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 18.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 504       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -22.3     |\n",
      "|    reward             | -0.504428 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 9.84      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 505        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -9.51      |\n",
      "|    reward             | -0.5605484 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 6.81       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 504       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | -0.212    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -1.16     |\n",
      "|    reward             | 2.0066593 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 0.282     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 505         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 6           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -2.31       |\n",
      "|    reward             | -0.43957976 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.838       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 506         |\n",
      "|    iterations         | 800         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 4000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.04       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 799         |\n",
      "|    policy_loss        | 23.9        |\n",
      "|    reward             | -0.09175493 |\n",
      "|    std                | 0.99        |\n",
      "|    value_loss         | 15.7        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 507       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | -32.3     |\n",
      "|    reward             | 0.8114281 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 26.9      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 507       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -45.2     |\n",
      "|    reward             | 0.6070085 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 85.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 507       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -16.4     |\n",
      "|    reward             | 1.6661723 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 9.3       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 506        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | -13.7      |\n",
      "|    reward             | -1.6468713 |\n",
      "|    std                | 0.986      |\n",
      "|    value_loss         | 4.68       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 501      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.01    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.467    |\n",
      "|    reward             | 1.075991 |\n",
      "|    std                | 0.983    |\n",
      "|    value_loss         | 0.567    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 500       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 14.6      |\n",
      "|    reward             | -3.212916 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 5.86      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 500        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 38.2       |\n",
      "|    reward             | 0.31045082 |\n",
      "|    std                | 0.984      |\n",
      "|    value_loss         | 18         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 499       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -8.94     |\n",
      "|    reward             | 2.037467  |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 7.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.02     |\n",
      "|    explained_variance | -0.000659 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -52       |\n",
      "|    reward             | 8.299041  |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 100       |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 497         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.01       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -8.84       |\n",
      "|    reward             | 0.050230812 |\n",
      "|    std                | 0.984       |\n",
      "|    value_loss         | 3.97        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 16.8      |\n",
      "|    reward             | 1.7155335 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 6.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 498       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.05     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 17.5      |\n",
      "|    reward             | 1.4433857 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 5.24      |\n",
      "-------------------------------------\n",
      "======A2C Validation from:  2021-10-04 to  2022-01-03\n",
      "A2C Sharpe Ratio:  0.03957296932116534\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_1134_23\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 665        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 3          |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.25993922 |\n",
      "-----------------------------------\n",
      "day: 2957, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 536761.90\n",
      "total_reward: -463238.10\n",
      "total_cost: 1263973.04\n",
      "total_trades: 11232\n",
      "Sharpe: -0.228\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007026685 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | -0.0178     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.38        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    reward               | 0.4759022   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005505529 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.11       |\n",
      "|    explained_variance   | 0.00703     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    reward               | -0.3172621  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007392859 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.1        |\n",
      "|    explained_variance   | 0.047       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.09        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    reward               | 0.5437691   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 3.01        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 608          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067229494 |\n",
      "|    clip_fraction        | 0.0847       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.1         |\n",
      "|    explained_variance   | 0.00819      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.6          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    reward               | -0.10428849  |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 3.03         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2021-10-04 to  2022-01-03\n",
      "PPO Sharpe Ratio:  0.0688097056738186\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1134_23\n",
      "day: 2957, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4034065.83\n",
      "total_reward: 3034065.83\n",
      "total_cost: 998.57\n",
      "total_trades: 11828\n",
      "Sharpe: 0.767\n",
      "=================================\n",
      "======DDPG Validation from:  2021-10-04 to  2022-01-03\n",
      "======Best Model Retraining from:  2010-01-01 to  2022-01-03\n",
      "======Trading from:  2022-01-03 to  2022-04-04\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2022-01-03\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_1197_23\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 497         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0.336       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -7.25       |\n",
      "|    reward             | -0.06282103 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 1.13        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0.245      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -0.593     |\n",
      "|    reward             | 0.11537793 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 0.768      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -2.58      |\n",
      "|    reward             | -1.5047419 |\n",
      "|    std                | 0.996      |\n",
      "|    value_loss         | 0.748      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 483       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | -0.055    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 1.8       |\n",
      "|    reward             | 0.5819803 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 0.881     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 485         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.09       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -10         |\n",
      "|    reward             | -0.51760256 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 2.24        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 467       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 0.634     |\n",
      "|    reward             | 3.0267603 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 0.497     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 471         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.07       |\n",
      "|    explained_variance | -0.062      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | -16.9       |\n",
      "|    reward             | -0.24999854 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 7.22        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 475       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 7.18      |\n",
      "|    reward             | 1.0254275 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.55      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 477         |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -6.91       |\n",
      "|    reward             | -0.30731177 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 1.7         |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 479          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.07        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | -1.35        |\n",
      "|    reward             | -0.120422654 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.484        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 480       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | -3.62     |\n",
      "|    reward             | 1.0374672 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.95      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 1200       |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 6000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1199       |\n",
      "|    policy_loss        | 3.7        |\n",
      "|    reward             | 0.85427356 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.8        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 478       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.09     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -6.65     |\n",
      "|    reward             | 1.6270734 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 1.25      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 479        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.1       |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | 14.3       |\n",
      "|    reward             | -0.5505049 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 7.32       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 9.33       |\n",
      "|    reward             | 0.17215386 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 4.12       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 479         |\n",
      "|    iterations         | 1600        |\n",
      "|    time_elapsed       | 16          |\n",
      "|    total_timesteps    | 8000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.1        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1599        |\n",
      "|    policy_loss        | 12.9        |\n",
      "|    reward             | -0.28903052 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 4.27        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 480      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | -43.5    |\n",
      "|    reward             | 1.576104 |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 53.7     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 480        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 33.3       |\n",
      "|    reward             | -2.9731975 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 30.8       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 481      |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.06    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | -2.83    |\n",
      "|    reward             | 1.56239  |\n",
      "|    std                | 0.993    |\n",
      "|    value_loss         | 1.56     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 482         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 12.1        |\n",
      "|    reward             | -0.38852763 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 2.31        |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2022-01-03 to  2022-04-04\n",
      "A2C Sharpe Ratio:  -0.24456352596878608\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_1197_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 654         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.042167213 |\n",
      "------------------------------------\n",
      "day: 3020, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 574550.67\n",
      "total_reward: -425449.33\n",
      "total_cost: 1285857.27\n",
      "total_trades: 11422\n",
      "Sharpe: -0.183\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004739072 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | -0.0238     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.971       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | -1.1580129  |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00547299  |\n",
      "|    clip_fraction        | 0.043       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.08       |\n",
      "|    explained_variance   | -0.0123     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.53        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    reward               | -0.50270283 |\n",
      "|    std                  | 0.998       |\n",
      "|    value_loss           | 4           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006327972 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.07       |\n",
      "|    explained_variance   | 0.00551     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.68        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    reward               | 0.050080836 |\n",
      "|    std                  | 0.991       |\n",
      "|    value_loss           | 3.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005840717 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.06       |\n",
      "|    explained_variance   | 0.00121     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    reward               | -0.23977356 |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 3.15        |\n",
      "-----------------------------------------\n",
      "======PPO Validation from:  2022-01-03 to  2022-04-04\n",
      "PPO Sharpe Ratio:  -0.34757745690527647\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1197_23\n",
      "day: 3020, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3436803.77\n",
      "total_reward: 2436803.77\n",
      "total_cost: 998.80\n",
      "total_trades: 9060\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "======DDPG Validation from:  2022-01-03 to  2022-04-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2022-04-04\n",
      "======Trading from:  2022-04-04 to  2022-07-06\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2022-04-04\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_1260_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 485        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -13.5      |\n",
      "|    reward             | 0.00853833 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.97       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 477       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.12     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.26      |\n",
      "|    reward             | 1.1643804 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.09      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 485        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 3          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0.0117     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | -13.2      |\n",
      "|    reward             | -2.1622548 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 5.51       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 487         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -18.1       |\n",
      "|    reward             | -0.14631571 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.72        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 488         |\n",
      "|    iterations         | 500         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 2500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.11       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 499         |\n",
      "|    policy_loss        | -13.7       |\n",
      "|    reward             | -0.85852206 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 4.84        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 487      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.12    |\n",
      "|    explained_variance | 0.00311  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.864   |\n",
      "|    reward             | 4.205392 |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.09     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 489      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.09    |\n",
      "|    explained_variance | 0.00509  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -36.1    |\n",
      "|    reward             | 1.723927 |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 25.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 490       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -15.2     |\n",
      "|    reward             | 0.5495596 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 6.69      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 492        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | -10.8      |\n",
      "|    reward             | -1.4741515 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 2.05       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 493       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 4.11      |\n",
      "|    reward             | 2.5655327 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 0.491     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 494        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | -48.4      |\n",
      "|    reward             | -2.4366148 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 59.1       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 495         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7          |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 4.77        |\n",
      "|    reward             | -0.43109688 |\n",
      "|    std                | 0.983       |\n",
      "|    value_loss         | 6.94        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 495         |\n",
      "|    iterations         | 1300        |\n",
      "|    time_elapsed       | 13          |\n",
      "|    total_timesteps    | 6500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1299        |\n",
      "|    policy_loss        | 11.5        |\n",
      "|    reward             | 0.112631224 |\n",
      "|    std                | 0.983       |\n",
      "|    value_loss         | 3.27        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 496        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -26.7      |\n",
      "|    reward             | 0.84534764 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 19.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 496        |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 15         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | 1.67       |\n",
      "|    reward             | 0.79065794 |\n",
      "|    std                | 0.989      |\n",
      "|    value_loss         | 1.24       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 497        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | -7.02      |\n",
      "|    reward             | -1.3226076 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 1.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 495       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.02     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 41.8      |\n",
      "|    reward             | 2.1615622 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 40.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 495        |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 18         |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | -18        |\n",
      "|    reward             | -0.2818955 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 49.9       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 494         |\n",
      "|    iterations         | 1900        |\n",
      "|    time_elapsed       | 19          |\n",
      "|    total_timesteps    | 9500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1899        |\n",
      "|    policy_loss        | 1.43        |\n",
      "|    reward             | -0.18361482 |\n",
      "|    std                | 0.987       |\n",
      "|    value_loss         | 0.129       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 494        |\n",
      "|    iterations         | 2000       |\n",
      "|    time_elapsed       | 20         |\n",
      "|    total_timesteps    | 10000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1999       |\n",
      "|    policy_loss        | -11.4      |\n",
      "|    reward             | -1.2193503 |\n",
      "|    std                | 0.987      |\n",
      "|    value_loss         | 2.73       |\n",
      "--------------------------------------\n",
      "======A2C Validation from:  2022-04-04 to  2022-07-06\n",
      "A2C Sharpe Ratio:  -0.3192224654927889\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_1260_23\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 655         |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 3           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.00959137 |\n",
      "------------------------------------\n",
      "day: 3083, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 445785.62\n",
      "total_reward: -554214.38\n",
      "total_cost: 1243829.19\n",
      "total_trades: 11612\n",
      "Sharpe: -0.289\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005601016 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | -0.0603     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    reward               | 0.4951337   |\n",
      "|    std                  | 0.995       |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 606          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067075593 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.07        |\n",
      "|    explained_variance   | -0.00246     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.48         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    reward               | -1.1122001   |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 4.24         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 601          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041629616 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | -0.00319     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.64         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    reward               | -0.3691343   |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 5.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005395917  |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.06        |\n",
      "|    explained_variance   | -0.00651     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.39         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    reward               | -0.013290224 |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 5.06         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2022-04-04 to  2022-07-06\n",
      "PPO Sharpe Ratio:  -0.3639035024053221\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1260_23\n",
      "day: 3083, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3133026.40\n",
      "total_reward: 2133026.40\n",
      "total_cost: 998.79\n",
      "total_trades: 12332\n",
      "Sharpe: 0.612\n",
      "=================================\n",
      "======DDPG Validation from:  2022-04-04 to  2022-07-06\n",
      "======Best Model Retraining from:  2010-01-01 to  2022-07-06\n",
      "======Trading from:  2022-07-06 to  2022-10-04\n",
      "============================================\n",
      "turbulence_threshold:  27.90730730085542\n",
      "======Model training from:  2010-01-01 to  2022-07-06\n",
      "======A2C Training========\n",
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/a2c/a2c_1323_23\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 469        |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 1          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -11.6      |\n",
      "|    reward             | 0.17720635 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 3.9        |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 467        |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 2          |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -13.2      |\n",
      "|    reward             | 0.76445717 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 4.71       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 476       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -10.1     |\n",
      "|    reward             | -2.075319 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 3.41      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 482        |\n",
      "|    iterations         | 400        |\n",
      "|    time_elapsed       | 4          |\n",
      "|    total_timesteps    | 2000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 399        |\n",
      "|    policy_loss        | -6.63      |\n",
      "|    reward             | 0.01871372 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 1.78       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 5          |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | -10.5      |\n",
      "|    reward             | -0.6238619 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.16       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 487      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.09    |\n",
      "|    explained_variance | 0.108    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -10.8    |\n",
      "|    reward             | 6.78261  |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 5.24     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 488        |\n",
      "|    iterations         | 700        |\n",
      "|    time_elapsed       | 7          |\n",
      "|    total_timesteps    | 3500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 699        |\n",
      "|    policy_loss        | -3.18      |\n",
      "|    reward             | 0.54843855 |\n",
      "|    std                | 0.995      |\n",
      "|    value_loss         | 0.83       |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 490            |\n",
      "|    iterations         | 800            |\n",
      "|    time_elapsed       | 8              |\n",
      "|    total_timesteps    | 4000           |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -7.06          |\n",
      "|    explained_variance | 0.0191         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 799            |\n",
      "|    policy_loss        | 11.7           |\n",
      "|    reward             | -0.00070007326 |\n",
      "|    std                | 0.992          |\n",
      "|    value_loss         | 3.53           |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 491        |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 0.00391    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 0.719      |\n",
      "|    reward             | 0.14164856 |\n",
      "|    std                | 0.99       |\n",
      "|    value_loss         | 0.672      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 489       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -5.55     |\n",
      "|    reward             | 1.4119956 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.12      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 489        |\n",
      "|    iterations         | 1100       |\n",
      "|    time_elapsed       | 11         |\n",
      "|    total_timesteps    | 5500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1099       |\n",
      "|    policy_loss        | 21.3       |\n",
      "|    reward             | 0.40579554 |\n",
      "|    std                | 0.989      |\n",
      "|    value_loss         | 11.3       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 490         |\n",
      "|    iterations         | 1200        |\n",
      "|    time_elapsed       | 12          |\n",
      "|    total_timesteps    | 6000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1199        |\n",
      "|    policy_loss        | 14.5        |\n",
      "|    reward             | -0.48301426 |\n",
      "|    std                | 0.988       |\n",
      "|    value_loss         | 8.83        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 490       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.04     |\n",
      "|    explained_variance | 0.109     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | -1.9      |\n",
      "|    reward             | 0.2377061 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 0.576     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 490        |\n",
      "|    iterations         | 1400       |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 7000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1399       |\n",
      "|    policy_loss        | -12.6      |\n",
      "|    reward             | -2.7954302 |\n",
      "|    std                | 0.989      |\n",
      "|    value_loss         | 6.27       |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 487           |\n",
      "|    iterations         | 1500          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 7500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.01         |\n",
      "|    explained_variance | -0.00338      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1499          |\n",
      "|    policy_loss        | -34.9         |\n",
      "|    reward             | -0.0043225037 |\n",
      "|    std                | 0.984         |\n",
      "|    value_loss         | 30.4          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 1600       |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 8000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1599       |\n",
      "|    policy_loss        | 1.19       |\n",
      "|    reward             | -0.1490396 |\n",
      "|    std                | 0.988      |\n",
      "|    value_loss         | 0.696      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 484        |\n",
      "|    iterations         | 1700       |\n",
      "|    time_elapsed       | 17         |\n",
      "|    total_timesteps    | 8500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1699       |\n",
      "|    policy_loss        | -31.4      |\n",
      "|    reward             | -0.3944518 |\n",
      "|    std                | 0.991      |\n",
      "|    value_loss         | 18.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 485       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.03     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -9.55     |\n",
      "|    reward             | 1.2352649 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 28.1      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 485        |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 19         |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 7.13       |\n",
      "|    reward             | 0.17630768 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 1.02       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 484         |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 20          |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.03       |\n",
      "|    explained_variance | 0.00087     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 12          |\n",
      "|    reward             | -0.96553415 |\n",
      "|    std                | 0.988       |\n",
      "|    value_loss         | 3.43        |\n",
      "---------------------------------------\n",
      "======A2C Validation from:  2022-07-06 to  2022-10-04\n",
      "A2C Sharpe Ratio:  -0.14290229333286486\n",
      "======PPO Training========\n",
      "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ppo/ppo_1323_23\n",
      "-------------------------------------\n",
      "| time/              |              |\n",
      "|    fps             | 637          |\n",
      "|    iterations      | 1            |\n",
      "|    time_elapsed    | 3            |\n",
      "|    total_timesteps | 2048         |\n",
      "| train/             |              |\n",
      "|    reward          | -0.012147618 |\n",
      "-------------------------------------\n",
      "day: 3146, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 358453.11\n",
      "total_reward: -641546.89\n",
      "total_cost: 1296875.95\n",
      "total_trades: 11963\n",
      "Sharpe: -0.382\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005767622 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | -0.00569    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 1.6926763   |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076978724 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | 0.00912      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.73         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    reward               | 0.57103205   |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 3.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004978025 |\n",
      "|    clip_fraction        | 0.0722      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.09       |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    reward               | 0.38237774  |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 2.68        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 583          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076773134 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.09        |\n",
      "|    explained_variance   | -0.0355      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    reward               | 0.50076675   |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 4.95         |\n",
      "------------------------------------------\n",
      "======PPO Validation from:  2022-07-06 to  2022-10-04\n",
      "PPO Sharpe Ratio:  -0.23905497391716898\n",
      "======DDPG Training========\n",
      "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
      "Using cuda device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1323_23\n",
      "day: 3146, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3386049.53\n",
      "total_reward: 2386049.53\n",
      "total_cost: 997.50\n",
      "total_trades: 6292\n",
      "Sharpe: 0.646\n",
      "=================================\n",
      "======DDPG Validation from:  2022-07-06 to  2022-10-04\n",
      "======Best Model Retraining from:  2010-01-01 to  2022-10-04\n",
      "======Trading from:  2022-10-04 to  2023-01-04\n",
      "Ensemble Strategy took:  26.64127467473348  minutes\n"
     ]
    }
   ],
   "source": [
    "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
    "                                                 PPO_model_kwargs,\n",
    "                                                 DDPG_model_kwargs,\n",
    "                                                 timesteps_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "-0qd8acMtj1f",
    "outputId": "9f0cbf89-5f4b-4691-9e43-daa093ebceae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Val Start</th>\n",
       "      <th>Val End</th>\n",
       "      <th>Model Used</th>\n",
       "      <th>A2C Sharpe</th>\n",
       "      <th>PPO Sharpe</th>\n",
       "      <th>DDPG Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.269732</td>\n",
       "      <td>-0.064986</td>\n",
       "      <td>0.350089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.079306</td>\n",
       "      <td>-0.075124</td>\n",
       "      <td>-0.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.285895</td>\n",
       "      <td>0.019486</td>\n",
       "      <td>0.006096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.55371</td>\n",
       "      <td>-0.017626</td>\n",
       "      <td>0.358259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>378</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>A2C</td>\n",
       "      <td>-0.297084</td>\n",
       "      <td>-0.328229</td>\n",
       "      <td>-0.362581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>441</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.501592</td>\n",
       "      <td>0.451507</td>\n",
       "      <td>0.654183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>504</td>\n",
       "      <td>2019-04-04</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.09584</td>\n",
       "      <td>-0.157807</td>\n",
       "      <td>0.144054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>567</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.171023</td>\n",
       "      <td>-0.254377</td>\n",
       "      <td>-0.16838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>630</td>\n",
       "      <td>2019-10-03</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.579703</td>\n",
       "      <td>0.53664</td>\n",
       "      <td>0.664165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>693</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.096925</td>\n",
       "      <td>-0.081228</td>\n",
       "      <td>-0.01568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>756</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>A2C</td>\n",
       "      <td>0.381116</td>\n",
       "      <td>0.274053</td>\n",
       "      <td>0.319479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>819</td>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.215362</td>\n",
       "      <td>-0.049806</td>\n",
       "      <td>0.216875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>882</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.325464</td>\n",
       "      <td>0.301777</td>\n",
       "      <td>0.463227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.175286</td>\n",
       "      <td>-0.046178</td>\n",
       "      <td>0.341642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1008</td>\n",
       "      <td>2021-04-06</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.112912</td>\n",
       "      <td>0.16357</td>\n",
       "      <td>0.201567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1071</td>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.034356</td>\n",
       "      <td>-0.112682</td>\n",
       "      <td>-0.026017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1134</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.06881</td>\n",
       "      <td>0.222518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1197</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.244564</td>\n",
       "      <td>-0.347577</td>\n",
       "      <td>-0.230611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1260</td>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.319222</td>\n",
       "      <td>-0.363904</td>\n",
       "      <td>-0.300059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1323</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>DDPG</td>\n",
       "      <td>-0.142902</td>\n",
       "      <td>-0.239055</td>\n",
       "      <td>-0.075959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
       "0    126  2017-10-02  2018-01-02       DDPG   0.269732  -0.064986    0.350089\n",
       "1    189  2018-01-02  2018-04-04       DDPG  -0.079306  -0.075124   -0.072008\n",
       "2    252  2018-04-04  2018-07-03        A2C   0.285895   0.019486    0.006096\n",
       "3    315  2018-07-03  2018-10-02        A2C    0.55371  -0.017626    0.358259\n",
       "4    378  2018-10-02  2019-01-03        A2C  -0.297084  -0.328229   -0.362581\n",
       "5    441  2019-01-03  2019-04-04       DDPG   0.501592   0.451507    0.654183\n",
       "6    504  2019-04-04  2019-07-05       DDPG    0.09584  -0.157807    0.144054\n",
       "7    567  2019-07-05  2019-10-03       DDPG  -0.171023  -0.254377    -0.16838\n",
       "8    630  2019-10-03  2020-01-03       DDPG   0.579703    0.53664    0.664165\n",
       "9    693  2020-01-03  2020-04-03       DDPG  -0.096925  -0.081228    -0.01568\n",
       "10   756  2020-04-03  2020-07-06        A2C   0.381116   0.274053    0.319479\n",
       "11   819  2020-07-06  2020-10-02       DDPG   0.215362  -0.049806    0.216875\n",
       "12   882  2020-10-02  2021-01-04       DDPG   0.325464   0.301777    0.463227\n",
       "13   945  2021-01-04  2021-04-06       DDPG   0.175286  -0.046178    0.341642\n",
       "14  1008  2021-04-06  2021-07-06       DDPG   0.112912    0.16357    0.201567\n",
       "15  1071  2021-07-06  2021-10-04       DDPG  -0.034356  -0.112682   -0.026017\n",
       "16  1134  2021-10-04  2022-01-03       DDPG   0.039573    0.06881    0.222518\n",
       "17  1197  2022-01-03  2022-04-04       DDPG  -0.244564  -0.347577   -0.230611\n",
       "18  1260  2022-04-04  2022-07-06       DDPG  -0.319222  -0.363904   -0.300059\n",
       "19  1323  2022-07-06  2022-10-04       DDPG  -0.142902  -0.239055   -0.075959"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "X4JKB--8tj1g"
   },
   "outputs": [],
   "source": [
    "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9mKF7GGtj1g",
    "outputId": "99c5e5f8-2e3f-49c3-e5a6-4e66ed92e40a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.5949256259904039\n"
     ]
    }
   ],
   "source": [
    "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
    "\n",
    "df_account_value=pd.DataFrame()\n",
    "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
    "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
    "    df_account_value = pd.concat([df_account_value,temp],ignore_index=True)\n",
    "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
    "print('Sharpe Ratio: ',sharpe)\n",
    "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oyosyW7_tj1g",
    "outputId": "0e54f2d5-6057-4a14-c94a-5f2af26ad171"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_value</th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>datadate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.002810e+06</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.007755e+06</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.013057e+06</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>2018-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.013965e+06</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>2018-01-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_value        date  daily_return    datadate\n",
       "0   1.000000e+06  2018-01-02           NaN  2018-01-02\n",
       "1   1.002810e+06  2018-01-03      0.002810  2018-01-03\n",
       "2   1.007755e+06  2018-01-04      0.004932  2018-01-04\n",
       "3   1.013057e+06  2018-01-05      0.005261  2018-01-05\n",
       "4   1.013965e+06  2018-01-08      0.000896  2018-01-08"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "wLsRdw2Ctj1h",
    "outputId": "0e2b0bc2-840c-47fd-87d4-01201d8e4e3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df_account_value.account_value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "ab0971b8-10b0-4fb1-a151-71a1de89cdf2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Backtest Results===========\n",
      "Annual return          0.095640\n",
      "Cumulative returns     0.578842\n",
      "Annual volatility      0.181324\n",
      "Sharpe ratio           0.594926\n",
      "Calmar ratio           0.381305\n",
      "Stability              0.771573\n",
      "Max drawdown          -0.250822\n",
      "Omega ratio            1.111783\n",
      "Sortino ratio          0.835972\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.910380\n",
      "Daily value at risk   -0.022417\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiHhM1YkoCel",
    "outputId": "c233f613-67a3-4882-8710-c1839247590e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1259, 8)\n",
      "Annual return          0.059583\n",
      "Cumulative returns     0.335290\n",
      "Annual volatility      0.217954\n",
      "Sharpe ratio           0.375375\n",
      "Calmar ratio           0.160661\n",
      "Stability              0.685042\n",
      "Max drawdown          -0.370862\n",
      "Omega ratio            1.077914\n",
      "Sortino ratio          0.516270\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.893140\n",
      "Daily value at risk   -0.027135\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "df_dji_ = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "stats = backtest_stats(df_dji_, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhJ9whD75WTs",
    "outputId": "8ae25787-8400-4357-ecc0-af7538689cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_dji:              date           dji\n",
      "0     2018-01-02  1.000000e+06\n",
      "1     2018-01-03  1.003975e+06\n",
      "2     2018-01-04  1.010116e+06\n",
      "3     2018-01-05  1.019008e+06\n",
      "4     2018-01-08  1.018490e+06\n",
      "...          ...           ...\n",
      "1255  2022-12-27  1.339089e+06\n",
      "1256  2022-12-28  1.324351e+06\n",
      "1257  2022-12-29  1.338253e+06\n",
      "1258  2022-12-30  1.335290e+06\n",
      "1259  2023-01-03           NaN\n",
      "\n",
      "[1260 rows x 2 columns]\n",
      "df_dji:                       dji\n",
      "date                    \n",
      "2018-01-02  1.000000e+06\n",
      "2018-01-03  1.003975e+06\n",
      "2018-01-04  1.010116e+06\n",
      "2018-01-05  1.019008e+06\n",
      "2018-01-08  1.018490e+06\n",
      "...                  ...\n",
      "2022-12-27  1.339089e+06\n",
      "2022-12-28  1.324351e+06\n",
      "2022-12-29  1.338253e+06\n",
      "2022-12-30  1.335290e+06\n",
      "2023-01-03           NaN\n",
      "\n",
      "[1260 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_dji = pd.DataFrame()\n",
    "df_dji['date'] = df_account_value['date']\n",
    "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "print(\"df_dji: \", df_dji)\n",
    "df_dji.to_csv(\"df_dji.csv\")\n",
    "df_dji = df_dji.set_index(df_dji.columns[0])\n",
    "print(\"df_dji: \", df_dji)\n",
    "df_dji.to_csv(\"df_dji+.csv\")\n",
    "\n",
    "df_account_value.to_csv('df_account_value.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HggausPRoCem",
    "outputId": "615e8d79-f3d7-47e9-c886-3cd18e4535f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_result_ensemble.columns:  Index(['ensemble'], dtype='object')\n",
      "df_trade_date:          datadate\n",
      "0     2017-10-02\n",
      "1     2017-10-03\n",
      "2     2017-10-04\n",
      "3     2017-10-05\n",
      "4     2017-10-06\n",
      "...          ...\n",
      "1356  2023-02-22\n",
      "1357  2023-02-23\n",
      "1358  2023-02-24\n",
      "1359  2023-02-27\n",
      "1360  2023-02-28\n",
      "\n",
      "[1361 rows x 1 columns]\n",
      "df_result_ensemble:                  ensemble\n",
      "date                    \n",
      "2018-01-02  1.000000e+06\n",
      "2018-01-03  1.002810e+06\n",
      "2018-01-04  1.007755e+06\n",
      "2018-01-05  1.013057e+06\n",
      "2018-01-08  1.013965e+06\n",
      "...                  ...\n",
      "2022-12-27  1.582652e+06\n",
      "2022-12-28  1.564768e+06\n",
      "2022-12-29  1.584028e+06\n",
      "2022-12-30  1.580730e+06\n",
      "2023-01-03  1.578842e+06\n",
      "\n",
      "[1260 rows x 1 columns]\n",
      "==============Compare to DJIA===========\n",
      "result:                  ensemble           dji\n",
      "date                                  \n",
      "2018-01-02  1.000000e+06  1.000000e+06\n",
      "2018-01-03  1.002810e+06  1.003975e+06\n",
      "2018-01-04  1.007755e+06  1.010116e+06\n",
      "2018-01-05  1.013057e+06  1.019008e+06\n",
      "2018-01-08  1.013965e+06  1.018490e+06\n",
      "...                  ...           ...\n",
      "2022-12-27  1.582652e+06  1.339089e+06\n",
      "2022-12-28  1.564768e+06  1.324351e+06\n",
      "2022-12-29  1.584028e+06  1.338253e+06\n",
      "2022-12-30  1.580730e+06  1.335290e+06\n",
      "2023-01-03  1.578842e+06           NaN\n",
      "\n",
      "[1260 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print(\"==============Compare to DJIA===========\")\n",
    "# %matplotlib inline\n",
    "# # S&P 500: ^GSPC\n",
    "# # Dow Jones Index: ^DJI\n",
    "# # NASDAQ 100: ^NDX\n",
    "# backtest_plot(df_account_value, \n",
    "#               baseline_ticker = '^DJI', \n",
    "#               baseline_start = df_account_value.loc[0,'date'],\n",
    "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "df.to_csv(\"df.csv\")\n",
    "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
    "df_result_ensemble = df_result_ensemble.set_index('date')\n",
    "\n",
    "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
    "\n",
    "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
    "print(\"df_trade_date: \", df_trade_date)\n",
    "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
    "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
    "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
    "print(\"df_result_ensemble: \", df_result_ensemble)\n",
    "print(\"==============Compare to DJIA===========\")\n",
    "result = pd.DataFrame()\n",
    "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
    "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
    "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
    "print(\"result: \", result)\n",
    "result.to_csv(\"result.csv\")\n",
    "result.columns = ['ensemble', 'dji']\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBQx4bVQFi-a"
   },
   "source": [
    "GRAPH ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Get Baseline Stats===========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1259, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1259, 8)\n",
      "Shape of DataFrame:  (1259, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (1259, 8)\n",
      "Shape of DataFrame:  (1259, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "df_dji_ = get_baseline(\n",
    "        ticker=\"^DJI\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "\n",
    "df_dji = pd.DataFrame()\n",
    "df_dji['date'] = df_account_value['date']\n",
    "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_dji = df_dji.set_index(df_dji.columns[0])\n",
    "\n",
    "########################\n",
    "df_ixic_ = get_baseline(\n",
    "        ticker=\"^IXIC\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "\n",
    "\n",
    "df_ixic = pd.DataFrame()\n",
    "df_ixic['date'] = df_account_value['date']\n",
    "df_ixic['ixic'] = df_ixic_['close'] / df_ixic_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_ixic = df_ixic.set_index(df_ixic.columns[0])\n",
    "\n",
    "########################\n",
    "df_nya_ = get_baseline(\n",
    "        ticker=\"^NYA\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "\n",
    "df_nya = pd.DataFrame()\n",
    "df_nya['date'] = df_account_value['date']\n",
    "df_nya['nya'] = df_nya_['close'] / df_nya_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_nya = df_nya.set_index(df_nya.columns[0])\n",
    "\n",
    "########################\n",
    "df_rut_ = get_baseline(\n",
    "        ticker=\"^RUT\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "\n",
    "df_rut = pd.DataFrame()\n",
    "df_rut['date'] = df_account_value['date']\n",
    "df_rut['rut'] = df_rut_['close'] / df_rut_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_rut = df_rut.set_index(df_rut.columns[0])\n",
    "\n",
    "########################\n",
    "df_gspc_ = get_baseline(\n",
    "        ticker=\"^GSPC\", \n",
    "        start = df_account_value.loc[0,'date'],\n",
    "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
    "\n",
    "df_gspc = pd.DataFrame()\n",
    "df_gspc['date'] = df_account_value['date']\n",
    "df_gspc['rut'] = df_gspc_['close'] / df_gspc_['close'][0] * env_kwargs[\"initial_amount\"]\n",
    "df_gspc = df_gspc.set_index(df_gspc.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "#Ensemble\n",
    "with open('./pkl_results/ensemble.pkl', 'rb') as file:\n",
    "    ensemble = pickle.load(file)\n",
    "\n",
    "#EnsemblePRED\n",
    "with open('./pkl_results/ensemblePRED.pkl', 'rb') as file:\n",
    "    ensemblePRED = pickle.load(file)\n",
    "\n",
    "#A2C\n",
    "with open('./pkl_results/A2C.pkl', 'rb') as file:\n",
    "    A2C = pickle.load(file)\n",
    "\n",
    "#A2CPRED\n",
    "with open('./pkl_results/A2CPRED.pkl', 'rb') as file:\n",
    "    A2CPRED = pickle.load(file)\n",
    "\n",
    "#DDPG\n",
    "with open('./pkl_results/DDPG.pkl', 'rb') as file:\n",
    "    DDPG = pickle.load(file)\n",
    "\n",
    "#DDPGPRED\n",
    "with open('./pkl_results/DDPGPRED.pkl', 'rb') as file:\n",
    "    DDPGPRED = pickle.load(file)\n",
    "\n",
    "#PPO\n",
    "with open('./pkl_results/PPO.pkl', 'rb') as file:\n",
    "    PPO = pickle.load(file)\n",
    "\n",
    "#PPOPRED\n",
    "with open('./pkl_results/PPOPRED.pkl', 'rb') as file:\n",
    "    PPOPRED = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph = pd.merge(df_result_ensemble, df_dji, df_ixic, df_nya, df_rut, df_gspc,  left_index=True, right_index=True)\n",
    "Graph = pd.concat([A2C, A2CPRED, DDPG, DDPGPRED, PPO, PPOPRED], axis=1, join='inner')\n",
    "# print(\"result: \", result)\n",
    "# result.to_csv(\"result.csv\")\n",
    "Graph.columns = ['A2C', 'A2CPRED', 'DDPG', 'DDPGPRED', 'PPO', 'PPOPRED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABL4AAAHPCAYAAABdpBPPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hUZfbA8e/MZNIb6YWEHorSmyII2FGxV1SsrK6ia/3ZXbtrd+27rqKiIlYsWEAQUHqR3klCSEjvyaTMZOb3x829Mzcz6ZMEwvk8D8/c+972TiDAnJxzXoPD4XAghBBCCCGEEEIIIUQ3Y+zqCQghhBBCCCGEEEII0REk8CWEEEIIIYQQQgghuiUJfAkhhBBCCCGEEEKIbkkCX0IIIYQQQgghhBCiW5LAlxBCCCGEEEIIIYToliTwJYQQQgghhBBCCCG6JQl8CSGEEEIIIYQQQohuSQJfQgghhBBCCCGEEKJbksCXEEIIIYQQQgghhOiWJPAlhBBCCCGEEEIIIbqloyrwtWLFCqZPn05CQgIGg4EFCxa0+h4Oh4OXXnqJlJQU/Pz8SEpK4tlnn/X+ZIUQQgghhBBCCCFEl/Lp6gm0RmVlJcOHD+f666/n4osvbtM9/vGPf7Bo0SJeeuklhg4dSmlpKQUFBV6eqRBCCCGEEEIIIYToagaHw+Ho6km0hcFg4Ntvv+WCCy7Qxmpra3nkkUf49NNPKSkp4fjjj+f5559nypQpAOzatYthw4axfft2Bg4c2DUTF0IIIYQQQgghhBCd4qgqdWzO9ddfz8qVK/n888/ZunUrl156KWeddRb79u0D4IcffqBv3778+OOP9OnTh969e3PTTTdRVFTUxTMXQgghhBBCCCGEEN7WbQJfBw4cYN68eXz55ZdMmjSJfv36ce+99zJx4kTmzJkDQGpqKgcPHuTLL7/k448/5sMPP2Tjxo1ccsklXTx7IYQQQgghhBBCCOFtR1WPr6Zs2rQJh8NBSkqKbrympobIyEgA7HY7NTU1fPzxx9p577//PqNHj2bPnj1S/iiEEEIIIYQQQgjRjXSbwJfdbsdkMrFx40ZMJpPuWHBwMADx8fH4+PjogmODBw8GICMjQwJfQgghhBBCCCGEEN1Itwl8jRw5krq6OvLy8pg0aZLHc0466SRsNhsHDhygX79+AOzduxeAXr16ddpchRBCCCGEEEIIIUTHO6pWdayoqGD//v2AEuh65ZVXmDp1KhERESQnJ3P11VezcuVKXn75ZUaOHElBQQFLly5l6NChnH322djtdsaOHUtwcDCvvfYadrud2267jdDQUBYtWtTF704IIYQQQgghhBBCeNNRFfhatmwZU6dOdRu/9tpr+fDDD7FarTz99NN8/PHHZGVlERkZyYknnsgTTzzB0KFDATh8+DC33347ixYtIigoiGnTpvHyyy8TERHR2W9HCCGEEEIIIYQQQnSgoyrwJYQQQgghhBBCCCFESxm7egJCCCGEEEIIIYQQQnQECXwJIYQQQgghhBBCiG7pqFjV0W63c/jwYUJCQjAYDF09HSGEEEIIIYQQQgjRRRwOB+Xl5SQkJGA0Np3TdVQEvg4fPkxSUlJXT0MIIYQQQgghhBBCHCEOHTpEz549mzznqAh8hYSEAMobCg0N7eLZCCGEEEIIIYQQQoiuUlZWRlJSkhYvaspREfhSyxtDQ0Ml8CWEEEIIIYQQQgghWtQOS5rbCyGEEEIIIYQQQohuSQJfQgghhBBCCCGEEKJbksCXEEIIIYQQQgghhOiWjooeX0IIIYQQQgghhDhyOBwObDYbdXV1XT0V0U2ZzWZMJlO77yOBLyGEEEIIIYQQQrRYbW0t2dnZWCyWrp6K6MYMBgM9e/YkODi4XfeRwJcQQgghhBBCCCFaxG63k5aWhslkIiEhAV9f3xatrCdEazgcDvLz88nMzGTAgAHtyvySwJcQQgghhBBCCCFapLa2FrvdTlJSEoGBgV09HdGNRUdHk56ejtVqbVfgS5rbCyGEEEIIIYQQolWMRgkniI7lrUxC+ZMqhBBCCCGEEEIIIbolCXwJIYQQQgghhBBCiG5JAl9CCCGEEEIIIYQ4Jk2ZMoU777zTbRugd+/evPbaa10yL+E90txeCCGEEEIIIYQQx7xvvvkGs9ms7a9fv56goKAunJHwBgl8CSGEEEIIIYQQ4pgXERGh24+Oju6imQhvklJHIYQQQgghhBCttqNwB3//7e+klqZ29VREF3M4HFhqbZ3+y+FwtGqelZWVzJw5k+DgYOLj43n55Zd1x6XUsXuSjC8hhBBCCCGEEK32yoZXWJezjr5hfblv7H1dPR3RhaqsdQx57NdOf+7OJ88k0LflYY377ruP33//nW+//Za4uDgeeughNm7cyIgRIzpukqLLSeBLCCGEEEIIIYRHh8oPEWwOpod/D914TmUO63PWA3C44nBXTE2IVqmoqOD999/n448/5vTTTwfgo48+omfPnl08M9HRJPAlhBBCCCGEEELHZrdx/4r7WXRwEb1De/PdBd9hNBix2q38/be/szZ7rXbu4UoJfB3rAswmdj55Zpc8t6UOHDhAbW0tJ554ojYWERHBwIEDO2Jq4ggigS8hhBBCCCGEEDrvbnmXRQcXAZBels6+4n0MjBjI3qK9uqAXQHZFdldMURxBDAZDq0oOu0Jr+4GJ7kOa2wshhBBCCCGE0PnuwHe6/XU56wDYXrDd7dzimmIsVkunzEuIturfvz9ms5k1a9ZoY8XFxezdu7cLZyU6gwS+hBBCCCGEEEJoiquLyanMAeBvw/4GwLrsdTgcDlZnr9bOu3fMvYSYQwDIrmx/1pfVbuXbfd9SWFXY7nsJ0VBwcDA33ngj9913H0uWLGH79u1cd911GI0SFunu5HdYCCGEEEIIIYRmV9EuAJJDkjkh/gRAKXd8es3TLMlYAsDrU1/n2uOuJT44HoD/bfsfv6a3b1W/T3d+ymOrHuOqn67Sxoqqi7DWWdt1XyFUL774IieffDLnnXcep512GhMnTmT06NFdPS3RwY7sIlwhhBBCCCGEEJ1qd9FuAAZFDCIqIAqAwqpCVmSt0M4ZFTsKgH7h/dhbvJcfU3/kx9QfmdxzMv4+/m167h9ZfwCQVZGF1W4l35LPWV+fxfj48bx3xnvteUtCAErW19y5c5k7d642dt9992nbNTU1BAcHa/vp6emdOT3RQSTjSwghhBBCCCGEZk/RHgAGRw7WAl/l1nKt/PHXi38lzC8MgCk9p+iu/WD7B2RVZOnG8ix5vLD+BTLKMpp8brhfuLa9LnsdC1MX4sDBmuw10phcdKiamho2bNjAjh07OO6447p6OsLLJPAlhBBCCCGEEEKTVpoGQN+wvgSbg/Ez+WnHevj1ICE4Qduf1HOS7tp3trzD5T9erhu76/e7mLtzLg/9+VCTz8215Grb9y6/l7/y/tL2i2uKW/9GhGihn3/+mVNOOYXp06dzySWXdPV0hJdJ4EsIIYQQQgghBAAOh4P0snQAeof1xmAwaFlfAH3C+ujOD/EN4e7Rd+vGSmtKdftbC7YCsCV/S5PPVjPKACqsFVrpI0BWeZanS4TwigsuuICysjI+/fRTzGZzV09HeJkEvoQQQgghhBBCAErWVZWtCpPBRFJwEgCRAZHa8YaBL4Drj7+e4dHDPd6vrLZM244Pim/0uTa7jfyqfAAWXriQ3qG9dcczKzJb/B6EEMKVBL6EEEIIIYQQQgBo2V49Q3piNimZL1H+zoyvlB4pHq9Te36prHZlJcYtec4sLwOGRp9bUFWA3WHHx+BDYnAiU5Km6I5nlkvgSwjRNhL4EkIIIYQQQggBQGpJKoAu48rX5KttN+zppQrz1Qe+CqsKASWgpTpceZht+ds8Xq+WOcYExmAymhgTO0Z3vGHDfCGEaCkJfAkhhBBCCCGEwOFw8N2B7wAYFj1MG6+0VmrbSSFJHq9tmPGVb8l3uxZgxk8z2FGww+36AyUHlPuHKvcfHTuaQJ9A7bhr43shhGgNCXwJIYQQQgghhGBz/mZ2Fu7Ez+THJSnOle1uH3k7UQFRPDvx2UavDfUL1e3nVeUBSpP6hlYdXoXFasHhcGhju4t2AzA4YjAAwb7B/HTRTzx24mMAWKyWNr4rIcSxTgJfQgghhBBCCCH4I1NZRfHU5FOJ8I/QxgdHDub3y35ner/pjV4b6qsPfKkZX54CVull6UyYN4EnVj+hjamBr4ERA7WxyIBIEoISlPvYJPAlhGgbCXwJIYQQQgghhGBD7gYAxsePb/W1PgYf3X6epfGMr+8PfE+do46v930NgN1hZ0/xHgAG9RikOzfIHAS4l0wKcaz48MMPCQ8Pb/Kcxx9/nBEjRnTKfI5GEvgSQgghhBBCiGOcxWphW4HSeH5s3NhWX29z2HT7RdVFgOfAV0OHKw5TZavCbDTTO6y37ligWenzJYEvIURbSeBLCCGEEEIIIY5x3+z7BpvdRnJIMj2De7b6+uMij9Ptq6s6qqWO1x9/PcOihrldB5BRngFAz5Ce+Bj1mWNqg3vp8SWEaKtWBb6ee+45xo4dS0hICDExMVxwwQXs2bOn2euWL1/O6NGj8ff3p2/fvrz77rttnrAQQgghhBBCCO9xOBzM2TEHgOuOvw6DwdDqe4yIGcFrU1/jjpF3AO4ZX8dFHsfjEx53u85qt5JZngl4XjFSLXWsrqvGZre5HRdHCIcDais7/5fLAgktm6aDF154gb59+xIQEMDw4cP56quvAFi2bBkGg4ElS5YwZswYAgMDmTBhgi7msWXLFqZOnUpISAihoaGMHj2aDRs2aMdXrVrFySefTEBAAElJSdxxxx1UVjqzFXv37s3TTz/NzJkzCQ4OplevXnz33Xfk5+dz/vnnExwczNChQ3X3VC1YsICUlBT8/f05/fTTOXToUJPvdc6cOQwePBh/f38GDRrE22+/3aqvVXfi0/wpTsuXL+e2225j7Nix2Gw2Hn74Yc444wx27txJUFCQx2vS0tI4++yzmTVrFp988gkrV67k1ltvJTo6mosvvtgrb0IIIYQQQgghRNuU1JRoPbmm9228gX1zTk0+lUj/SAAKq5WML7VEMcgcRFxQnNs1FbUVHCpXPsA3FfgCqLJVEeIb0ub5iQ5ktcCzCZ3/3IcOg6/nWIQnjzzyCN988w3vvPMOAwYMYMWKFVx99dVER0dr5zz88MO8/PLLREdHc8stt3DDDTewcuVKAK666ipGjhzJO++8g8lkYvPmzZjNZgC2bdvGmWeeyVNPPcX7779Pfn4+s2fPZvbs2cyZM0e7/6uvvsqzzz7Lo48+yquvvso111zDSSedxA033MCLL77I/fffz8yZM9mxY4cWhLZYLDzzzDN89NFH+Pr6cuutt3LFFVdo82rovffe45///CdvvvkmI0eO5K+//mLWrFkEBQVx7bXXtvrLfLRrVeDrl19+0e3PmTOHmJgYNm7cyMknn+zxmnfffZfk5GRee+01AAYPHsyGDRt46aWXJPAlhBBCCCGEEF0suzIbgKiAKPx9/Nt1LzXwlVWRxU2/3qSVPAabgwnxDSHEN4Ty2nLt/LLasiYDX74mX3yMPtjsNiqtlRL4Em1WWVnJK6+8wtKlSznxxBMB6Nu3L3/++Sf/+c9/+Nvf/gbAM888w+TJkwF44IEHOOecc6iursbf35+MjAzuu+8+Bg1SFmEYMGCAdv8XX3yRGTNmcOedd2rHXn/9dSZPnsw777yDv7/yvXX22Wdz8803A/DYY4/xzjvvMHbsWC699FIA7r//fk488URyc3OJi1OCxVarlTfffJPx45WFJz766CMGDx7MunXrGDdunNt7feqpp3j55Ze56KKLAOjTpw87d+7kP//5jwS+Wqu0tBSAiIiIRs9ZvXo1Z5xxhm7szDPP5P3338dqtWrRUVc1NTXU1NRo+2VlZe2ZphBCCCGEEEKIRqiBr/ig+HbfKyLA+dlwbc5abVvN3EoOSWZH4Q5tvLy2vMnAl3ptaU2p9Pk6kpkDleyrrnhuC+3cuZPq6mpOP/103XhtbS0jR47U9ocNc/aii49Xvify8vJITk7m7rvv5qabbmLu3LmcdtppXHrppfTr1w+AjRs3sn//fj799FPteofDgd1uJy0tjcGDB7vdPzY2FoChQ4e6jeXl5WmBLx8fH8aMGaOdM2jQIMLDw9m1a5db4Cs/P59Dhw5x4403MmvWLG3cZrMRFhbW4q9Xd9LmwJfD4eDuu+9m4sSJHH/88Y2el5OTo/3GqWJjY7HZbBQUFGh/kFw999xzPPHEE22dmhBCCCGEEEKIFsqpzAHwWIrYWmoz+oYaC3yV1ZRxuEIJmDTWVD/QJ5DSmlJZ2fFIZjC0quSwK9jtdgAWLlxIYmKi7pifnx8HDhwA0CXnqKWG6rWPP/44M2bMYOHChfz888/885//5PPPP+fCCy/Ebrdz8803c8cdd7g9Ozk5Wdv2dP+mntlwvLkx9br33ntPyxBTmUwmt/OPBW0OfM2ePZutW7fy559/Nntuw98MR30DusaaJj744IPcfffd2n5ZWRlJSZ6j/0IIIYQQQggh2i67wnsZX419xlMDX0mh+s91RTVFWgP8CH/PlUTqtZU2CXyJthsyZAh+fn5kZGRopYyu1MBXc1JSUkhJSeGuu+7iyiuvZM6cOVx44YWMGjWKHTt20L9/f29PHZvNxoYNG7Tsrj179lBSUqKVXLqKjY0lMTGR1NRUrrrqKq/P5WjUpsDX7bffzvfff8+KFSvo2bPppW7j4uLIycnRjeXl5eHj40NkZKTHa/z8/PDz82vL1IQQQgghhBBCtEKORfm85o3AV2PU4FVsoL4aKKs8S9turH9XYH05m2R8ifYICQnh3nvv5a677sJutzNx4kTKyspYtWqVtsJiU6qqqrjvvvu45JJL6NOnD5mZmaxfv17rXX7//fdzwgkncNttt2mN5Hft2sXixYt544032jV3s9nM7bffzuuvv47ZbGb27NmccMIJHvt7gZKZdscddxAaGsq0adOoqalhw4YNFBcX65KMjhWtCnw5HA5uv/12vv32W5YtW0afPn2avebEE0/khx9+0I0tWrSIMWPGeOzvJYQQQgghhBCiY+VW5lJeW84bf73B0kNLAe8FvnoG9ySzIlPb9zf542NUPnr28O+hO1c9L8QcgsnouQwryEcJmkmPL9FeTz31FDExMTz33HOkpqYSHh7OqFGjeOihh9xKCxsymUwUFhYyc+ZMcnNziYqK4qKLLtLaNA0bNozly5fz8MMPM2nSJBwOB/369ePyyy9v97wDAwO5//77mTFjBpmZmUycOJEPPvig0fNvuukmAgMDefHFF/m///s/goKCGDp0qNZ4/1hjcKh1hy1w66238tlnn/Hdd98xcOBAbTwsLIyAgABAKVPMysri448/BiAtLY3jjz+em2++mVmzZrF69WpuueUW5s2b1+JVHcvKyggLC6O0tJTQ0NDWvD8hhBBCCCGEOOKpzdvjgzsu60qVWZ7JRd9fRJWtShvzN/nzw4U/eKXP16HyQ9z6262kl6UDEB0QzdLLlOCaxWrhgu8u0Brqj4kdw4bcDSQGJ/LLxb94vN+dv9/JkowlPDL+ES4f1P4ggmif6upq0tLS6NOnj7ZSoRAdoak/a62JExlb89B33nmH0tJSpkyZQnx8vPZr/vz52jnZ2dlkZGRo+3369OGnn35i2bJljBgxgqeeeorXX3+9xUEvIYQQQgghhOjOFqYu5PSvTufsb85m9eHVHf68BfsX6IJeVw++mqWXLfVK0AuU1Rlnj5yt7fcN66ttB5oD+emin/j78L8DsCF3AwChvo1/cG3Y46vaVs37295nb/Fer8xXCNG9tbrUsTkffvih29jkyZPZtGlTax4lhBBCCCGEEN1eviWfJ1c/qQWiHvjjARZfshhfk2+HPK+wqpAv936pGzu337mN9tdqK9dG9QN6DNAd8zH6MDZuLO9seUcbC/MLa/Re6kqRFbVKE/zHVj3Gz2k/89vB35h37jxvTlsI0Q21KuNLCCGEEEIIIYR3lNaU8q91/8JiszCgxwAi/CMoqi5ibfbaDnvmbUtuo6i6SDfWL6yf15/jGvhK6ZHidnxs3FiuGXKNtt9UxldSiLIS5NaCreRU5vBz2s8AbC/cjrXO6q0pCyG6KQl8CSGEEEIIIUQnSy1JZeLnE1l0cBEAT5z4BKf3Oh2AJRlLOuSZBVUF7Cjc4Tbu7+P9Pk2uTez7hHleFO24yOO07aYyviYnTQZgY85Gt1JQKXcUQjRHAl9CCCGEEEII0cm+O/Cdtn1pyqUMjR7KqcmnAvBr+q+UVJd4/Zlb8rYA0D+8P9+e9y1B5iBuG3Gb158DEO4XrpVPesr4AugZ0lPbbirw1Su0F33D+mJz2Pjftv/pjm3O39z+yQohujUJfAkhhBBCCCFEJ3I4HCxKVzK97hl9D4+c8AgA4+PHMyhiEBXWCj7c8aHXn/tX3l8AjIwZSf8e/VkzYw23DL/F688BMBqMLLxwIb9f9juB5kCP5yQGJ2rbAT4BTd7vkpRLAMgoVxZSU0spP9rxEZXWSm9MWQjRTUngSwghhBBCCCE60eHKw2RWZGI2mrls4GUYDcrHMqPByI3H3wjAiqwVXn/u1oKtAIyIGeH1e3vSw78HUQFRjR6P9I/UtpsLXl0x8Aqt1xfAw+MfJjE4kezKbH5J+6X9kxVCdFsS+BJCCCGEEEKITnKo7BBv/vUmoJTwNcyGGhU7CoADJQewWC38d+t/+cfSf7Ais32BsDp7HbuLdgNwfOTx7bqXtxgMBm27uVUlzSYzd4++W9sfFj2MiYkTAciqyOqYCQohugWfrp6AEEIIIYQQQhwLKmorOG/BedgcNgB6h/Z2OycmMIbYwFhyLblMnj+Z6rpqADblbWLF5St0waLWSC9Lp8pWRYBPAL1Ce7X5PXjbiye/yK/pv3LloCubPffU5FO5aehNmAwm4oLiiA2MBSDXktvR0xRCHMUk40sIIYQQQgghOsH729/Xgl5AowEodbVDNegFUFJT0q7Mpp2FOwEYFDEIk9HU5vt421l9zuLVqa8SZA5q9lyDwcA/Rv2D2SNnA0qQECDfkt+qZ6aWpnLegvP44cAPrZ+wEJ3sww8/JDw8vMlzHn/8cUaMGNEp8zkaSeBLCCGEEEIIITqYw+Hg57SfdWO9w3p7PPf8/ud7HFeDV69ufJW7l92tlS62hNrYfkjkkBZfc6RTA195lrxWXffMmmdIK03joT8f6ohpCXFUMBgM2q+QkBDGjBnDN998ox1//PHHteNGo5GEhASuuuoqDh06pLvPlClTdPdSf91yyy0enxUUFMSAAQO47rrr2LhxY6e8Vwl8CSGEEEIIIUQ7WO1W53adlU93fcoza54htSRVG99bvNctYyshKMHj/U5JPoWFFy50G99RuAOL1cIH2z9g8cHFXPnjlWzO29zs/OrsdSzJWALApMRJLXlLRwW11LG5wFdNXQ2/Z/yOtU75fSquKe7wuQlxNJgzZw7Z2dmsX7+e4cOHc+mll7J69Wrt+HHHHUd2djaZmZnMnz+fbdu2cdlll7ndZ9asWWRnZ+t+vfDCCx6ftWPHDt566y0qKioYP348H3/8cYe/Twl8CSGEEEIIIUQb/ZL+C+M+HcdF31/EA388wOyls/nXun/x+Z7PmbV4FgVVBQCsPqx8mJzScwqXplzK2LixTa6umByaTJhfGACXD7wcgD3Fe0grS9POsTlsvLn5zWbnuClvE0XVRYT5hTEuflxb3+oRR834KreWY7FaGj3vxl9v5I7f7+Db/d8CSvad8C6Hw4HFaun0X639vXQ4HLzwwgv07duXgIAAhg8fzldffQXAsmXLMBgMLFmyhDFjxhAYGMiECRPYs2ePdv2WLVuYOnUqISEhhIaGMnr0aDZs2KAdX7VqFSeffDIBAQEkJSVxxx13UFnpXLG0d+/ePP3008ycOZPg4GB69erFd999R35+Pueffz7BwcEMHTpUd0/VggULSElJwd/fn9NPP90t86qhOXPmMHjwYPz9/Rk0aBBvv/222znh4eHExcUxaNAg3n33Xfz9/fn++++14z4+PsTFxZGQkMCkSZOYNWsWa9asoaysTHefwMBA4uLidL9CQ0M9Pqt3796cccYZfPXVV1x11VXMnj2b4uKODUZLc3shhBBCCCGEaKOFqQux2W3sK97HvuJ9umN5ljy+2/8dNw69kYPlBwEYGDFQ61HVnK+mf0WeJY+y2jLm75lPgaWA9NJ03Tm5lc03dldLJMfFjcNsNLfo2UeDYN9gAn0Csdgs5FnyPJaOltaUsiV/CwCL0hdx2UD3bBXRflW2KsZ/Nr7Tn7t2xlq3lVGb8sgjj/DNN9/wzjvvMGDAAFasWMHVV19NdHS0ds7DDz/Myy+/THR0NLfccgs33HADK1euBOCqq65i5MiRvPPOO5hMJjZv3ozZrHxPbdu2jTPPPJOnnnqK999/n/z8fGbPns3s2bOZM2eOdv9XX32VZ599lkcffZRXX32Va665hpNOOokbbriBF198kfvvv5+ZM2eyY8cObTELi8XCM888w0cffYSvry+33norV1xxhTavht577z3++c9/8uabbzJy5Ej++usvZs2aRVBQENdee63Ha8xmMz4+PlitVo/Hc3Jy+OabbzCZTJhM3ukTeNddd/Hxxx+zePFij5lk3iIZX0IIIYQQQohjSpWtiqLqohafX1BVwC9pv3Co/BCbcjfx7NpnsVgtLNi/gGWHlgEwOGIwkf6RRAdE8+qUV7lr9F0A7CraBUBmeSYAPUN6tvi5cUFxDIseRg//HgAUVxeTVqpkfA2PHg5AWW1Zo9e7zl+9X3ejvqfGGv8vOrhI2+4X3s/teE1dTcdMTBxxKisreeWVV/jggw8488wz6du3L9dddx1XX301//nPf7TznnnmGSZPnsyQIUN44IEHWLVqFdXVykITGRkZnHbaaQwaNIgBAwZw6aWXMny48r344osvMmPGDO68804GDBjAhAkTeP311/n444+16wHOPvtsbr75ZgYMGMBjjz1GeXk5Y8eO5dJLLyUlJYX777+fXbt2kZvrDGpbrVbefPNNTjzxREaPHs1HH33EqlWrWLduncf3+tRTT/Hyyy9z0UUX0adPHy666CLuuusu3ft0VVNTw9NPP01ZWRmnnnqqNr5t2zaCg4MJDAwkPj6eZcuWcdtttxEUpF+M4u233yY4OFj366OPPmr292TQoEEApKenN3tue0jGlxBCCCGEEOKY8UfmHzzwxwPU1tUy75x59O/Rn4KqApYdWsZ5/c7D1+SrO99itXDut+dSaa0kpUcKe4v3AnC44jDLM5dr53169qfaaolGg5FVWasA2FOklEmpga+kkKRWzznCLwKAopoiUkuVvmEjokewJX8LpTWlOBwOLTPEk/wqZdXD6IDoRs85Wg2MGEhqaSrbC7ZzUuJJbsfXZq/VtqtsVQDU1tVqYyXVJcQGxXb8RLu5AJ8A1s5Y2/yJHfDcltq5cyfV1dWcfvrpuvHa2lpGjhyp7Q8bNkzbjo+PByAvL4/k5GTuvvtubrrpJubOnctpp53GpZdeSr9+SkB148aN7N+/n08//VS73uFwYLfbSUtLY/DgwW73j41V/uwNHTrUbSwvL4+4OCWw6+Pjw5gxY7RzBg0aRHh4OLt27WLcOH35cn5+PocOHeLGG29k1qxZ2rjNZiMsLEx37pVXXonJZKKqqoqwsDBeeuklpk2bph0fOHAg33//PTU1NXz33Xd8+eWXPPPMM25f26uuuoqHH35YNxYTE+N2XkNqqWpTf395gwS+hBBCCCGEEN2atc7Kq5teJdwvnC/2fKFlSc3fM5+7Rt/F9b9cT3pZOkXVRfxt2N901+4u2k2lVenRowa9AF3Qa3zceMwmfQnhwIiBABwsO0hZbRnZldkA9AxuecaXSs34stltbC/YDsDwmOGwE+ocdVRaKwn2DW70+gKLkvEVFRDV6mcf6YZFDePntJ/ZVrDN7ZjD4WB9znptXw18uTa3L6mRwJc3GAyGVpUcdgW73Q7AwoULSUxM1B3z8/PjwIEDAFrpIjgDMuq1jz/+ODNmzGDhwoX8/PPP/POf/+Tzzz/nwgsvxG63c/PNN3PHHXe4PTs5OVnb9nT/pp7ZcLy5MfW69957j/Hj9eWnDUsUX331VU477TRCQ0M9Bqp8fX3p378/oDS637dvH3//+9+ZO3eu7rywsDDtvNbYtUvJiO3Tp0+rr20NCXwJIYQQQgghurUv9n7B3J1z3cYXpi0kMiCS9LJ0AObvns+sobN0HybVUsXG9Anrw0MnPOQ2HhkQSUxADHlVeSw/tJw6Rx2+Rl+iA1ufdeXv40+ATwBVtiotgDYoYhD+Jn+q66oprS3VBb7sDjtF1UVaoEvL+GrDs490Q6OVTJltBdvcMt/SStN0Ja0WmwWr3Up5bbk21pqSV3F0GzJkCH5+fmRkZDB58mS342rgqzkpKSmkpKRw1113ceWVVzJnzhwuvPBCRo0axY4dO9oUAGqOzWZjw4YNWnbXnj17KCkp0UoFXcXGxpKYmEhqaipXXXVVk/eNi4tr1XwfffRR7b2PGjWqdW/Cg9dee43Q0FBOO+20dt+rKdLjSwghhBBCCNFtPfTHQ/xr3b90Y7OGzqJ3aG/Ka8t5a/Nb2nheVR5LMpbozlUbwzfmjVPeoG9YX4/H1Kyv3w7+BkBiSCJGQ9s+gkX4R2jbvkZfEoISCPVTVk0rrSnVnTtv9zymfjGVhakLAWfgKyag+dKjo82giEH4GH0oqi4ipzJHd0wNaKqqbFWUVJfoxkpq9Pui+woJCeHee+/lrrvu4qOPPuLAgQP89ddfvPXWWy3qR1VVVcXs2bNZtmwZBw8eZOXKlaxfv14rYbz//vtZvXo1t912G5s3b2bfvn18//333H777e2eu9ls5vbbb2ft2rVs2rSJ66+/nhNOOMGtzFH1+OOP89xzz/Hvf/+bvXv3sm3bNubMmcMrr7zSrnn07duX888/n8cee0w3brFYyMnJ0f1quFJjSUkJOTk5HDx4kMWLF3PJJZfw2Wef8c477xAeHt6ueTVHMr6EEEIIIYQQ3VKdvU5rbh7oE8jiSxeTVZ7FwIiBjIsfx6xFzv43anbWoysfZWzcWML8wsipzGHxwcXa9RabBYDnJz3Pl3u/ZHDkYJJDkt0fXG9QxCD+yPqDpYeWAtAvzL25ekv18OuhNXBPDk3GZDQR5hdGniXPLfClBvoe+OMBTk0+VctwigrsfqWOfiY/+ob1ZW/xXvYU7yE+OF47VmGt0J1rsVrcMryKq/UfzkX39tRTTxETE8Nzzz1Hamoq4eHhjBo1ioceesittLAhk8lEYWEhM2fOJDc3l6ioKC666CKeeOIJQOndtXz5ch5++GEmTZqEw+GgX79+XH755e2ed2BgIPfffz8zZswgMzOTiRMn8sEHHzR6/k033URgYCAvvvgi//d//0dQUBBDhw7lzjvvbPdc7rnnHk466STWrl2rlVK+9957vPfee7rzzjzzTH755Rdt//rrrwfA39+fxMREJk6cyLp167ySOdYcCXwJIYQQQgghuqXMikxt1b4/r/gTs8lMaKSSJTUubhxB5iCtf9fzJz/Pk2ueJK00jeWZyzmv33k8veZpqmxVhPiG8P4Z7/Ps2meZedxMTu91Omf3PbvZ5w+K0JchpUSktPm9qH2+QCmvBAjzVRpVl9bqA18mg4k6Rx3gzFjzM/kRYg5p8/OPZOqiA3uL9zIlaYo2rgb8IvwjKKouospWRWFVoe5a135fovszGAzccccdHvtwgbPZumrEiBG6sXnz5jV5/7Fjx7Jo0aJGj3tavbDhM3v37q0bu+6667juuusAuOiiizze9/HHH+fxxx/Xjc2YMYMZM2Y0OpeGz23JPQEmTJigu3bZsmVN3qclz+poUuoohBBCCCGE6Jb2F+8HYHDEYLfm80aDkT6hzobKfcL6cFbvswClNNHhcLA5fzMAT5/0NIMjBzP37Lmc3ku/IlxTGga+BvYY2Ja3ATQS+PKrD3xVOwNfFqtFC3oBfL7nc0BpbN/RK6d1lZQeSkDRdfEBgIpaJeMrJlAp8ayyVZFZkak7x7XfV0fJLM/k892fY62zdvizhBDuJPAlhBBCCCGEOKqV1pTyxZ4vtFX7VPtLlMDXgB4DPF7n2hA+wj+CU5NPBWDV4VXkVOZQWlOK0WBkQsKENs2rZ0hPLTgFzgBNWwSbnXNV56MFvlwyvtJK03TX/Zz2MwBDIoe0+dlHOjWguKdoj25cDWpFByhN/XMtuWzI2eDxnI503S/X8czaZ3h/+/sd/iwhhDsJfAkhhBBCCCG8yuFwYHc03S/Hm+5Zfg9PrXmKdza/o5vD+pz1APQP97xq2eCIwdq2wWBgQI8BhPiGUFNXw09pPwGQHJKMv49/m+ZlNBh59IRHASX4khic2Kb7AEzrM42+YX15csKTjI4dDThLHfeX7OfxVY9z3S/XsbtoNwBmoz7DbWTMyDY/+0inZsBlVmTq/typPb7UjC+7w87P6UogUO231hmBr1xLLgC/pv/a4c8SQriTHl9CCCGEEEIIr6myVXHpD5cS6R/J/874n1uJobcdKjvE2uy1AMzZMYe7Rt+FwWBgwf4FrM1Zi4/Rh4mJEz1e+7dhfyOzIpOz+yj9uowGI8dHHs/q7NUs2L8AaDxo1lJn9j6T6IBowvzC2lVqOCJmBN9d8J1uLCpAaVavZnUBZJRlADBj0Ay+2veV1sNsVEzHN5DuKlGBURgwYLPbKK4uJjIgEnAGtWIDY92uGRw5mAOlBzol8KVqmJEohOgckvElhBBCCCGE8JrtBds5WHaQTXmbeHPzm2zI2YDNbuuw5313QB8MUjOe1IytW4bd0mSp4ytTXuG0XqdpY8dHHQ9Aelk6AP3C274So2pU7Civ3Kehi1MudithzK/KB+C8/ufx+ImPYzaaiQ6Ibldj/SOd2WjWgl1qdhW4Z3y5Ur9uHR34qq2r1bbVIGR30dUNy0X3560/YxL4EkIIIYQQ4iiy+vBqDlcc7uppNMq1z9IH2z/g+l+v55t933TY85ZnLtft37XsLpZmLGVT7iaAVjWjB2fgS5UQnNC+CXagIHMQNw+72W28X1g/UnqkcFafs/jpop/4YvoXbqWP3Y0a3Mqz5GljanN714UBVOrCAxXWCrIrspm3ex67Cnd5fV5qIBKgrLaMgqoCbl9yO0sylnj9WZ3FbFb+LFksli6eiejuamuVwLHJZGrXfaTUUQghhBBCiKPEyqyV3PLbLfQJ68OC8xdgNHT9z7E35W4iKiCK5NBkAHYVuQcPNuZu5LKBl3n1uR/v+Jj1uevZXbQbAwbmnzufG3+9kayKLP7x+z8ApcRN7f/UUr1Ce+n2PZXJHUlGxIxwGxsY4Vw9Mi4orhNn03ViAmPYWbhTF/gqtyrZXCG+Ibpzn534rJYhVlhVyNnfnI3NYaNPWB++v+B7r87LdT52h517lt3DprxNLMtcxrZrt3n1WZ3FZDIRHh5OXp7y3gIDA7vtiqGi69jtdvLz8wkMDMTHp32hKwl8CSGEEEIIcYRLK01jS/4Wfjjwg7a/NnstJyac2KXzembNM3y+53N6Bvfk54uVPlNqxtfLk19mXc465u+Zz97ivV59bkFVAS9ueFHbHx07msGRg/n83M8559tztPGRMSNb/YE8Pihet3+kB74i/CPcxhoG744F6u+Ta6mjWsboGvjqG9aX6f2mU1BVAEB1XbV27GDZQewOu1cDyq7zAdiUt8lr9+5KcXFKQFUNfgnREYxGI8nJye0OrErgSwghhBBCiCPYobJDzPx5JiU1Jbrxb/d/26WBr4raCj7f8zmgrKZXUl1CqF8oB0oPAEoPpeHRw5m/Zz5ppWlU26rbvDpiQ0sO6svEbhtxGwDJocn0Du2t9efqGdKz1fcONAcS4BOgNSKPCXLvD3Wk+eDMD7hv+X0UVhcCx3bg679b/8tlKZcRGxSrlToGm4O189QgmOuYyu6wU1JT4jGY2FZ5ld0zMGQwGIiPjycmJgar1drV0xHdlK+vL0Zj+wPREvgSQgghhBDiCPbBjg90Qa8Qcwjl1nJWHV5Fnb0Ok7F9vU/aIrU0lZc3vOw21jOkJza7DZPBRFxQHCaDiR5+PSiuKWZf8T6GRg/1yvNd+yP9Y9Q/GBM3RtuPC4rTAl9t7c/lY3B+TAoxhzRx5pFhbNxYnpn4DLf8dgsAvUN7d+2EuoBrA/un1jzFq1Nf1bK5XDO+Qn1DAfAz+WE2mrHa9UGbfEu+VwNfDTO+XHk7u6wrmEymdvdfEqKjHd3fZUIIIYQQQnRzqSWp2raP0Yf/nfk/QswhlNaUsrNwZ5fM6bqfr2NF5grd2G8Zv/HAHw8AShDCx+iDwWBgeMxwAL7e97VXnl1nr2NL/hblnud9zU1Db9Idd+1plRiU2KZnuGYYHC29i8L9wrVttd/asWRc3Dht+4+sP0grTdP2g8xBWjDrjN5nAMrva8PeX6DvyeUNmeWZAMQEuGcOdvSKkkIIhQS+hBBCCCGEOIKpH5xfm/oaX0//miGRQxgfPx6A1dmrO30+qSWpFNcUu43P3TmX9TnrAX2frBuPvxGABfsXUFhV2O7nHyg9gMVmIdAnkH5h/dyOuwa+2prxZTIcfRksKT1S6B/en0mJkzwGdLq7+OB4tl27jZExI7E77MzdORdQsr18jD7MP3c+r0x5hfP7na9d0ymBrwrl+9c1K1HVsHxZCNExJPAlhBBCCCHEEaraVk1elfJBfHTMaPqG9wWcK/ktP7Sc3UW7O20+KzJXcP535+vGPPWTcg0+jYgZQWJwInWOOg6VH2rX8x0OB1vztwIwNGqoxzLPAJ8AbTs+ON7teEuoWWSn9zq9Tdd3BbPJzDfnfcPbp73d1VPpUtP6TAPgx9QfAUgOUbLf4oLiOL3X6boMPtcyVnVb/X7zBofDoQWuJfAlRNeRwJcQQgghhBBHqKyKLEBpxB3mF6aND4oYBMDWgq1c+sOl5FTmdMp83vzrTbexEdEj3MYarowYFRAFQH5VfpufvTB1IZPnT+aJ1U8ANNovrIdfD23bz+TXpmfNGDSDD878gKdPerpN13eVo6UssyNNTZoKgM1uA5ou+4wOjNa2x8aNBZQeX95SVF2ExWbBgIHRMaPdjpdUl3jtWUKIxklzeyGEEEIIIY5QaoZUUkiSLqgxsMdA3Xn7ivfpsqw6Qk5lDruKdunGxsaNZfbI2Xx34DvdeMOAU3SAEmBoS1Chpq6GL/d8yfPrn9eND4wY6PH8c/qewx9Zf3BC/AmtfpbKZDRpgRBxdIkLimNI5BCt/11Tjf7vHXMv/cP7axmJSw8t9VqpY1ltGVO+mAJAsG8wSSFJ2mqhySHJZJRneCwZFkJ4nwS+hBBCCCGEOEIdLDsIQM+QnrrxcP9w3X6FtaLD57KtYBugBBbO73c+l6ZcSmxQrMdze4f11u2rGV8FVQVszd/KW5vf4p4x95DSI6XJZ1rtVm789Uatmb2r/mH9PV7ja/LllSmvNPd2RDd2StIpWuCrqYyv5NBk7hh1BwCrslYBtLscV7W9YLu23Se0D2aTmbnT5lLnqGPuzrlklGdQWlPqlWcJIZompY5CCCGEEEIcodSAz5DIIW7HLh94ubZdVF3UYXOw2q0cLDvIvuJ9AIyPG8/skbMbDXrdPfpuzuh1hm5MLSkrqCrgqp+uYtXhVTy28rFmn/3Rjo+0r8GEhAm6Y556iwkBcEryKdp2r5CW/TlJCk0ClMBXnb2uXc/PqshiacZSbf+G428AlCzFIZFDtBU4i6sl40uIziAZX0IIIYQQQhyBHA4Hf+X9BcDImJFux+8fdz9F1UUsPri4QwNfz619ji/3fqntD+gxwO2c6IBorX/X9cdf7/E46Ht8taTsccnBJQA8esKjXDbwMkbNHYXVbgWUZu5CeNI/vD8nJZ5EniWPlIimswpV8UHx+Bh9sNqt5Fpy27wiKMBZX5+lbZ/b91xO7XWq7rga+JLm9kJ0Dsn4EkIIIYQQ4giUWZ5JQVUBZqOZ46OOdztuNprpH66U+7Ulc6TOXqcFkZqirqKo8hT4ennKyyQGJ/LqlFc93iMyIBJAW+EOaDawUG2r1lasPCnxJOU1QXl1bWAvREMGg4F3T3uXb877psULHPgYfegZrJQUqyXGbWF32HX7apmvK8n4EqJzSeBLCCGEEEKII9DOIqVH0aCIQY1+eI/wjwAgozyDp9c8rZUFOhyORu9rrbPyU+pP3P/H/Uz4bAKHKw43OY+GKzF66ss1MmYkv1z8C6f1Os3jPdSMr/SydG2sqYytjLIMxn46FpvDRrhfOAlBSpDs6YlPc+WgK/lw2odNzlmItlDLZzPKMtp8j4bBrEj/SLdz1B59kvElROeQUkchhBBCCCGOQFkVWYCyomNjevgrmU9rs9eyNnst8/fM58pBV7IicwVfTP+CUN9Qt2vm75mvWyHxz6w/uWzgZR7vX1NXo5VR3nD8DUQFRHnMYGmOpxUnm2rsvfLwSm37uMjjtBUtw/zCeGj8Q61+vhAtoX6vZZS3PfBVUFWg21ezHV2pGYsS+BKic0jGlxBCCCGEEEegrHIl8JUYnNjoOWrGl6t5u+eRVZHFt/u+9XjNwtSFun2TwdTo/XMrcwHwM/lx56g7uWbINc3O25Me/j04If4E3VhTgS/XlfWuPe7aNj1TiNZqLOPrx9QfOevrs7TS26Y0DHx5ChSH+YUBEvgSorO0OvC1YsUKpk+fTkJCAgaDgQULFjR7zaeffsrw4cMJDAwkPj6e66+/nsLCwrbMVwghhBBCiGOCmvHVM6Rno+d4CnypymvLdfsOh4Nn1z7L9sLtuvEKa0Wj98i1KIGvuKA4LeuqrW4feTs+Bh9tzk0GvsqUwNcj4x/hxIQT2/VcIVoqOTQZgIPl+h5fD/7xIFkVWTzy5yNNXl9TV8N3+7/TjXkKfKmZmqU1pW49wYQQ3tfqwFdlZSXDhw/nzTffbNH5f/75JzNnzuTGG29kx44dfPnll6xfv56bbrqp1ZMVQgghhBCiu7E77B6bzKuBr6Yyvjz1D1JV2ap0+6mlqczbPU/bHx8/HnAPkLnKqcwBIC7QvVSxtYZFD+OHC39g/rnzAaiuq6baVu123ld7v2JZ5jIAkkIbL/MUwtvUjK/M8kwWH1zM/N3z2VO0RzueXZnd5PVv/fUWP6f/rBvzVOqoNrevc9Q1+f0nhPCOVvf4mjZtGtOmTWvx+WvWrKF3797ccccdAPTp04ebb76ZF154obWPFkIIIYQQolups9dxxcIrKK8t573T39MCPXaHXVtZrqnVD8P8wkgKSdKVBqosNotuX+3VpRoaNZS12WubzPhSA1+xQbEte0PN6BnSE4fDgclgos5RR1ltGf4+/s45Wy08sfoJbT85JNkrzxWiJeIC4zAbzVjtVu5edrfbcU+BWldzdszR7af0SNGCXK58Tb4E+gRisVkoqSnRSh+FEB2jw3t8TZgwgczMTH766SccDge5ubl89dVXnHPOOY1eU1NTQ1lZme6XEEIIIYQQ3c3q7NXsLtpNVkUWD/zxgDZ+7/J7ceDAaDB6bAyvMhgMHBd5nMdjDVeXcy0tfHXKqwSbg4GmM77UUsfYQO8EvkCZs9p0X51TTV0NDoeDHEuO7tym3rsQ3mYymposLa611zZ6zGLVB5qvGHgF88+dj9Hg+SO3Wu4ofb6E6HidEvj69NNPufzyy/H19SUuLo7w8HDeeOONRq957rnnCAsL034lJUmKsxBCCCGE6H5c+wHtKVZKqmrqalh8cDEAFw24CLPR3OQ9zu9/vsfxfEu+bl8NMk3uOZnTep1GiG8IoGR1/W3R3/h89+du99BKHb0cgFIzXEprStldtJsTPj2Bf637l/Y8gGl9puFjlEXoRedqahVVaLw33baCbbr9U3ud2uSfXzUTbG/x3tZNUAjRah0e+Nq5cyd33HEHjz32GBs3buSXX34hLS2NW265pdFrHnzwQUpLS7Vfhw65p24LIYQQQghxNDtQcoBFBxdp+zV1NVTZqsiuUPoI+Zv8eeyEx5q9z8TEibw25TW38byqPN2+mlmiBp3UjK91OetYnb2aj3d+7HaPjgp8hfopGV8rMlfwR+Yf2Bw2Ptv9GYvSla/HhIQJvHCytEYRnc91wQhPmY6eyorBGfiakDCBOWfOcVvFtCE18PXk6ifdVpEUQnhXhwe+nnvuOU466STuu+8+hg0bxplnnsnbb7/NBx98QHa25+aAfn5+hIaG6n4JIYQQQgjRXZTVlvHgHw9id9g5JekUfAxKZkhpTSmHKw4DSlP7lq6keEqy8x6qAkuBbsU4NVNFC3z5BuvOz7Pk4XA4dGMdUeoIMDp2NABzd87VBRK+3vc1APFB8V59nhAt1cOvh7atBmhdqYtONKQ2wR8XN44xcWOafY66uATAlvwtrZ2mEKIVOjzwZbFYMBr1jzGZTABu/7AKIYQQQghxLJi3ax67inYR4R/BvWPv1ZX+Ha5UAl9NNbVvyGAwEGgO1I3ZHDZd/yB1W800UUsdVTV1NZTVOnvrVtmqtGu8nfF1+8jbCfQJxOawuZWIgfea6QvRWq6N5tVedK7UwHRDaqnywIiBLXrO9cdfzzl9lb7XmRWZrZ2mEKIVWh34qqioYPPmzWzevBmAtLQ0Nm/eTEaGkp754IMPMnPmTO386dOn88033/DOO++QmprKypUrueOOOxg3bhwJCS3/x1wIIYQQQoju4kDpAQCuPe5akkKStA/bJTUl2gfr1gS+ALfAF0BJdYlzu2Hgyxzidr5rj63cSiXbK8AnwGMAoD3MRjP9e/QH8FjmFRcoTe1F11CbzoMSHL568NW6454yvqpt1doqrIMiBrX4Wf3Dle+BzHIJfAnRkVrdLXLDhg1MnTpV27/7bmWZ12uvvZYPP/yQ7OxsLQgGcN1111FeXs6bb77JPffcQ3h4OKeccgrPP/+8F6YvhBBCCCHE0UcNMKnBLTUYVVpTSnal0g6kteV+QT5BbmPFNc6VHZsrdQSl3FHNWFHLHOOC4lpcctkaajBNXSkv0j+SwupC7ZlCdIWGGV93jr6TMXFjyCzP5KUNL2nfn64OlBzA7rAT4R9BVEBUi5/VM1hZQVICX0J0rFYHvqZMmdJkieKHH37oNnb77bdz++23t/ZRQgghhBBCdEtaVleQEvjylPGVGJzYqnsGmd0DX64ZX2rgq7FSR3AGu8AZnPN2fy9Vw+c/edKTbM3fyoGSA1oPMCE6m67Hl28ofiY/Tk0+lVVZqwDPpY5qFlhySHKrnqWuINlYw3whhHfI+sBCCCGEEEJ0IqvdSn5VPuDM+FIDX2W1ZVrWU3RgdKvu66nUsaimSNtuWOoY6BOI0WDUMlWKqovIszhXgmxLr7HWaFg+GRkQyeyRszvkWUK0lPr9Afo/o+r3QVZFFg6HQ5cFqX4/t/Z7tmdIT+36KlsVAT4BbZ22EKIJHd7cXgghhBBCCOGUW5mL3WHH1+hLhH8E4Pyw/fuh37Xgk+sH8JYI9Gm8x1dJdYlb4MtgMNA3rC9B5iCm9ZmmzM2SS0FVAQdKDpBVrmSxtDbzrKUaBr5cM22E6CqupY6uweT4YKX0uMpWpWVPqgqqCgCIDmhd4CvML0wLdhVYCto0XyFE8yTjSwghhBBCiE6k9fAKjsdoUH4OrX7Y3pq/VTvP9QN4S/j7+GvbySHJZJRnaD2+Pt39KXWOOgZFDCImMEY77+NpH1Ntq2ZF5goACqsKufj7iymqLtICXp2V8dXaQJ8QHaGx7zs/kx/B5mAqrBUU1xSTXZlNv/B++Jp8tWB1azO+ACL8I8iqyGJH4Q7e3PwmM4+byXGRx7XrPQgh9CTjSwghhBBCiE6k9ghybV5vMpjczgvzbV3ga2fhTm17er/pgDPj67eDvwHKKpKuJVohviFEB0ZrmWdZFVkUVRdp29CBGV9+zsCXn8lPyrzEEcHH6MwNqXPU6Y6pffQ+2/UZl/14GY+tegxoe8YXODMd71txHz+l/cTVC6/mqdVPcdOvN2G1W9v0HoQQehL4EkIIIYQQopMUVxezu2g3oM+kGhw5WHdekDkIs8ncqnvPGDwDgCsGXqE1pFd7fJXVlAHQJ6yPx2sjApTA1/6S/W7HOirw5drcPtwvvENWjhSiPXqF9tLtB5uVlVA/3/M5AAtTFwIuPb7aEPhSv/dUNoeNL/Z+wdqctazLXtfq+wkh3EmpoxBCCCGEEB3Earfy7b5vmZg4kWDfYC787kKteb1rxtf4uPFcM+Qa5u6cC7St7O+SlEsYET2CQRGDWJ65HHBmfJVbywEIMbuv5AgQ6R/pcdxsNBMVENXqubSEa6lj/x79O+QZQrTFh2d9yPaC7ZySdIpuPMhXyfgyGUxaNli1rZp8S9ua20PTve3UTDIhRPtI4EsIIYQQQogO8vy655m/Zz4nxp/IuPhxWtAL9BlfBoOBKwddqQW+Gva/agmz0axljqmBs5KaEursdVTZqgAI9g32eK1a6thQUkiS1ofM21wzvoZFDeuQZwjRFqNjRzM6drTbuJrx5WpbwTZt4Yg2ZXw18r0HznJjIUT7SOBLCCGEEEKIDlBbV8v8PfMBWJ29mvW563XHXTO+AF1mldnYujLHhtQP00XVRVRYK7RxTx/cQVm9LsAnQAuQqa497tp2zaMprsG946OO77DnCOEtao8v195fyw4tA5Tv2dYuSAFNB77Sy9JbfT8hhDvp8SWEEEIIIUQH2JK/Rbdvs9t0+w1XS3Rt7t7eptbh/uEAVNmqtCwzX6MvvibfRq9x/QDuY/ThykFXcmH/C9s1jybn6FLOKavYiaOBp8Dxmuw1gJLt1ZY+dT38Gy91TC9Nb/X9hBDuJONLCCGEEEKIDpBTmeM2dtXgq/h016cAxATGNHptewNfIeYQfAw+2Bw2zl9wPtB4maNKzWYB+Ozsz9wa7ntbsG8w/zzxn5iNZiIDPPcYE+JI4vo9otpbvBeAqMC29cJrKvCVUZ7RpnsKIfQk40sIIYQQQogOkGvJdRubmjRV226qnLFhdlhrGQwGLetL5dpTyxP1AzzAoIhB7Xp+S12Scgnn9z+/U54lRHs1FTyOCWg8kN2UxhaWAKi0VmKxWtp0XyGEkwS+hBBCCCGE6ABqxpe6kuI/T/wn4+PH8/RJT/PZ2Z95vCYpJAmAKUlT2v38hitDNtbfS3VC/AkADI0a2qaSLSG6u6a+h9q6+mlSaFKTxwurCps8LoRonpQ6CiGEEEII0QHUjK87Rt3BpJ6TSAhSeno1leH0wZkfsCJzBdP7TW/38xuWUDUX+HpiwhN8ve9rZg6Z2e5nC9EdeSp1VEUHtn5FR1AWeXAtgW6osLqw2eCYEKJpEvgSQgghhBCiA+RWKoGv+KB4EoMTW3RNXFAclw28zCvP7+HXIPDVTI+vhOAEbh95u1eeLUR31DB4PDZuLOtzlNVaowPaFvgCuG/MfRwXeRzrc9bz7f5vdcck40uI9pPAlxBCCCGEEB0gz5IHQGxQbJc8v2Ggy4CULwrRHg0zvs7qfZYz8NXGjC8Ak9HE9H7TmdZnGgnBCWwr2EaVrYr1Oeu1VVmFEG0nPb6EEEIIIYTwMmudVfvAGhvYNYEva51+ZchKa2WXzEOI7sI1mGw2mjkl+RRtv2GGZVv4GH24ZfgtvHXqWySHJANI4EsIL5CMLyGEEEIIIbwsr0rJ9vI1+ro1me8s1XXVun2LTVaHE6I9XDO+QnxDiAqI4tbht3Ko/BCDIwd79VmRAcpqj1LqKET7SeBLCCGEEEIIL1P7e8UExnTZComjY0ez+ODiLnm2EN1RXFCctl1UXQTA30f8vUOeFekfqXuOEKLtJPAlhBBCCCGEl6krOnZVfy+AywZehtFgJKMsgx9Tf+TBcQ922VyE6A5CfUOZkDCBVYdX4Wv07dBnScaXEN4jgS8hhBBCCCG8TM346qr+XqD0ILpy0JUA/N/Y/+uyzDMhupOXJr/EyxteZkrSlA59ToR/BCAZX0J4gwS+hBBCCCGE8LIjIePLlQS9RIeoLoVtX8Gwy8AvpKtn0ylCfEN4fMLjHf6cML8wAEprSjv8WUJ0dxL4EkIIIYQQwsu0wFcXZnwJ0eF+uBN2fAOWIph8X1fPpltRF8UorS3F7rBjNBi7dkJdqM5eh81hw8/k19VTEUepY/e7RwghhBBCiA6iBr7iAuOaOVOII1h1KWyZD1kb9eOVBXB4M+xcoOznbuvsmXV7auDL7rBTXlvetZPpQg6Hg2t+voYzvjqDnYU7u3o64iglgS8hhBBCCCFa4ffVL7Ftx5cej23e/hm3z53A1vytwJFT6ihEqxWlwlvj4du/wccXgLVKGa8ug7fGwX8ng8OujBXs77Jpdle+Jl8CfAIA2FGwA4fD0cUz6hp7ivewrWAbRdVF3PX7Xcfs10G0jwS+hBBCCCGEaKEDBxZzx96PmLHhSXJzt+qOVVcVc83G51hmd2Zn9Azu2dlTFMI7vr8DyrOV7ZoyOLBU2T64EiwNVhosOgB2e+fO7xigZn3d/NvNLNi/oEvn0lV+z/hd2z5ceVia/Ys2kcCXEEIIIYQQLbRyjzPT6+2l9+iOfb3sYd1+dEA04f7hnTEtIbyrthIyVivbA85QXnf9AA4H7PzeeV78CDD5gq0aSg+1/7l2O+z/DWoq2n+vbkANfAG8svEV3bGFqQu56qeryKnM6eRZda6Vh1fq9tPL0rtmIuKoJoEvIYQQQgghXBw+vIHvlj6AzVqNwyWLxWG3syh3g7b/a3U2tTVKdldB/i4+yl6hu0+/8H6dM2EhvC1zPdhtEJoI429WxrI2wo93wZbPlP0pD8HMBdCjj7L/072wYU77nrv9K/jkYvj8SudY1iaoyGvffY9SroGv6MBo3bEH/niArflbeXXjq508q86lBvbUVS7TStO6cjriKCWrOgohhBBCCOHi8cW3spoqHvlsIQDD7WauH3g5fxxcwhajVTuv0mjg7/OmssNRTaXRACaD7j6hvqGdOm8hvCZjjfKafKIzsFWaBbt/dJ4zbhYE9ICEkVCwB/YtUn4NvRT8gt3v6XCAweA+7mrjR8pr2gol66voALw3FUJ7wt072v++jjKB5kBtOyYwxuM5ldbKzppOp7M77BRWK2W1Y2PH8lvGbzyx+gmGRg1lYMTALp6dOJpIxpcQQgghhBAuVlOl299itPJ/e+fyda3S72iUw5dL/RIBWGeoUYJe9aaXOz+EJocmd8JshegAmfWZjcknKFlfANZKqMxXtu8/CIERyvbwK/TX/isJNnygH9u3GJ6Jg21fNf1c14DZD/+A7d8o22WZYK9r/fs4yrmu5hjoE8hbm99iznZ9Vp3ZaO7saXWaspoybHYbAGPixmjj729/v6umJI5SEvgSQgghhBCins1a7XG81iVT5Z3LfuXiEX/THb8ncjxrLl7MM/0u582cPM4NSGLW0FkdOlchOkzONuU1fjiY/SHIpcwuZggEhDv3+0yGqBTnvsOulES6+vQSpQ/Ytzc3/dwilzK27V/Bytec+97oIXaUKakp0bb3l+zn3S3v8srGV7DanZmn3TnwVVBVACgln6NiRmnjuwp3ddWUxFFKAl9CCCGEEELUy875S9t+c+D1bLt2G6/0c/Ybiq1zEBgYxXGDLmI8/gD8o8corjv3fwQFx2Ew+TC5qprnwkfpypSEOGpU5EFFDmBQglwAYS6rk8YP159vNMJ1C8GvkdLeGmfWEn4hjT/XXgfF9YGvM58FnwD98cIDLZp+dzKtzzRtO7cyV9u2WC3attnUjQNf1UrgKyogisGRg7l/7P0AOHB05bTEUUgCX0IIIYQQ4phkqchj+ZpXdFleh3I2AdCvzsDkE+4GYEif07Tj8UZfbfvlC77m2eTzuHbaO86bGur/e+2QD2biKJWzVXmN7O8sPVTLHQF6jnG/JjgGek3Qj9lqlNd0l1X5fD30/lKVHYa6WjCaYfwtMOYG/fGi1JbNvxu5dsi1XJJyCQAWmzPYpWZCQffN+NpRsINZi5Ss2ciASAAm9ZwEQL4lv8vmJY5OEvgSQgghhBDHpPcX387sPXN49AtnVkVG4W4AknycH9AT4p0f9GsdzlUew8KSmT71GcyumV1q4OsY7EckuokDvyuvcUOdY65ZW0Mu9HxdUJR+vzRTea3IcRk7BAtuBVut+/UFe5XXHr3AaIJBZ+uPF+5vfu7djNlk5vx+57uN51qc2V/dNfvpjb/e0LajApQ/W9EBSsmtxWbRZb0J0RwJfAkhhBBCiGPSJyXKKnE/2gq44cMx5OftYN7h5QD0CYzVzjMYnf9lPj4grumbGk3Kq0uATIijRskhWPeesj3sMuf4wPogVNRACIr0fG1Qg1UHSw4qr1Ul+vHNn8LW+e7XZ65XXhNGKq/JJ8Kwy4H6/nrFB1vyDrodTyXTrmWPVbYqt+PdgeuquJW1yqIhgeZAAupLYPOrJOtLtJwEvoQQQgghxDGpFz7a9npDDZf+eDmpJgexdQ6unPCI7tyvJvyLqwP7cPe5HzZ9U63UUTK+xFFo2xdQVwO9ToKUs5zjY26AC96FG39t/NqGGV8l9c3oq0vcz83ZBq8OheUvOscy1iivSeOVV6MJLvovXFq/imF1aaveSncR6OMh8OWS8VVt87wgx1HPuZ4IA3oM0LbVrC8pdxStIYEvIYQQQghxTMrFptsvNBnwcTh4fcLTxCeM1h0bOOAc7r/0e4KCm8n4MkjGlziK7V6ovA67DFxWMsXHF0ZcCQE9Gr/Wx0+/31jGF8C6/0BpBvz+tLJfZ3NmfCWfqD9XbZpfU9ait9DdBJmD3Ma6a+BrX/E+fkr9CYfDQVn973dSSBI3Db1JO0cte3TtcyZEc3yaP0UIIYQQQojupbamnCKj8sF+mimCn+uKADjBEMyQQRe0/cbS40scrQr2QdZGwAAp05o93U3DBR3KDiuvnjK+GircD7UVSvP7mMH6Y/5h9fc5NgNfzZU6Vtd1j8BXTV0NM3+eSYW1An8ff0prlAy//xv7f7qvgRr4klJH0RqS8SWEEEIIIY45uXnbAfCzOxgeOUQbHxLaq303VvuBScaXONr88oDymnImhMQ2fa4nx10E/uHOfTXwpWZ8TXsBJt3rfp3DAfm7lO3oQc4+eSot4+vYLHX0NfriY9Dnq3THjK/v9n9HhbUCgA+2f0BJTQkAYX5huvPUFR6Lq4s7dX7i6CaBLyGEEEIIcczJLdwDQKzDQC/XwFfsqPbd2CCBL3EUqi6D/b8p22c+27Z7BEXCvXvh2h+U/YYZX+G9YNzf3K+rKYO8+sBXzCD34/5q4KvcPavsGGAwGAgwB+jGXANf3aW5/R9Zf2jbW/K3kFmhrAoa5qsPfPXwU8pti2uKqa2r5f4V9/Pd/u86b6LiqCSBLyGEEEII0e2VlqTzy4onqalvkJ1TcgCAWKMfyXEjtfOO63NG+x4kPb5EWx1aB1/Pgt+f6/xnF6Uqr4FRENmv7ffx8YPQRGW7cB+8O8nZ5N4/DIJjwDdEf42l0CXwNQQ3asaXw66UQx6DGja4L3XJfqupq+ns6XQINYNrUIQ++BnqF6rbD6/PKiypLuGLPV/wU9pPPLJSvxiJEA1J4EsIIYQQQnR7by+azX1pX3LjvKnY62xklqYBEO8bRs/EEzjHJ4oLfWOJjR3evgdJxpdoi72/wofnKKsqLv+XMxDUWYqUQHC7gl6qkHjnds5WsNQ3IQ8IVxrmN+zhVVkI+buV7WgPGV/mADDWl/odo32+PDW4V3WXUke1tPH+sffrxpvK+EovS++MqYluoNWBrxUrVjB9+nQSEhIwGAwsWLCg2Wtqamp4+OGH6dWrF35+fvTr148PPvigLfMVQgghhBCi1f6oUFaY22K0snrTu6SWK1ko/UJ6YTT58K+rfufJK3/DYGznz4Wlub1orU1z4bPLoK7WObbtq86dQ2F9xleEFwJfvu7N2AFn/6+GgS9LARSnK9uR/d2vMxiO+ZUdG2Z8AUxMnAh0n+b2asZXhH8Ekf6R2rjZZNad55rxpQbLhGhOq/9lr6ysZPjw4bz55pstvuayyy5jyZIlvP/+++zZs4d58+YxaJCHaL4QQgghhBAdwIazN9DWrFUcsJYA0C/6eO8+yCiljqKFai3w2eXw/Wxlf+TVcMG7yvbGOVCa1Xlz0TK++nbcMwLCldfogfrx4nRn0C84xvO1ap+vYzTj67io49zG+oUpQcoqWxWOo7z3mdVupaxW+b3t4d+D6MDoRs91zfhyLfmskx82iCb4NH+K3rRp05g2reXL2/7yyy8sX76c1NRUIiIiAOjdu3drHyuEEEIIIUSbWK0Wcl1+3Pt26Tbtx799E0/07sO0Ukf5ECaasecn2PuLsp0wCqa/DnYbrH4LcrfB4sfgkvc77vnpf0JNBax8DTJWK2PeyPgCJbtLbWoPYPJTShYBghusGJmvLDSBb4jznIaO8Yyvh8c/zOUDL2fRwUW8u0UJjvYNdwYpa+pq8Pfx76rptZsawDJgINQ3lKiAqEbPDfcL165xDXxV2aoI9g3u0HmKo1eH9/j6/vvvGTNmDC+88AKJiYmkpKRw7733UlXV+OoTNTU1lJWV6X4JIYQQQgjRFjk5f2E3GDweS4gf7d2HSY8v0VKH1imvRjNcOU/JFvTxg2nPK+Npy5VVDO11sPVLyNrk3Wd/eA7Mu9wZ9PINgeQTvHP/639WGuWrgly2U85yNsAH2PNz/TnO8jY3/vV9nuoXp6CyEH59GDLWeme+RziDwcCAHgPoGdxTG+sb5gx8He19vkrqg6RhfmGYjCbuHHUnBgxcknKJ27lqqWOdo07X46vSWtkJMxVHq1ZnfLVWamoqf/75J/7+/nz77bcUFBRw6623UlRU1Gifr+eee44nnniio6cmhBBCCCGOAYdytwAQV+cgx+QMgI1x+GHy8fXuw7QeXxL4Es3IrA98XfguhMQ5xxNHg8kXKvOV1RZ/vEsJgoUkwN07lZ5X7bV1vn7/tMdh3M2N9+dqrdghcN4b8PmVyn6Cc+VU/ILhH1tg1Ruw5AmoyFHGgxovb9NlfNnr4I2RShAsewtc96N35nwUMBud/a6SQpIwG81Y7dajvs9XcY3S30vN5hoYMZA/r/yTEHOI27l+Jj8CfQKx2CxU2ZzJNJU2CXyJxnV4xpfdbsdgMPDpp58ybtw4zj77bF555RU+/PDDRrO+HnzwQUpLS7Vfhw4d6uhpCiGEEEKIbiqraB8AA3yCuS6oP1MMIfz3+Nt44eyPvP8w6fElWqLWAjnblO2kcfpjZn+IH6Fsf3mtEvQCKD/sbALfHt/8Ddb/Tz82/ErvBb1UrsG8nmP0x0xmGDEDzC7PbCrwpfX4KoXMDc7Mr0PHRsaXqrTWWdoX4R+hlTcezRlfiw8uZmXWSkDp76UK9Q3F0EiQ1/U8lcVq6ZgJim6hwzO+4uPjSUxMJCzMuQzp4MGDcTgcZGZmMmDAALdr/Pz88PPz6+ipCSGEEEKIbqykOI3//XYXP1TsB6OBRL8I7rnk2459qPT4Ei2Rv1vp5xUYCWFJ7sf7TFIywtTgmCpzPUT0aftzKwth6xfu465BKm8JTXBuu2Z8uT5z2gvO5v6BLSh1/PNVmOLSByzAPQDSnQ2OcK6IaTAYCDAFUE65LvPpaJJamsrdy+7W9tWMr+aE+4WTVaFf/EFKHUVTOjzj66STTuLw4cNUVFRoY3v37sVoNNKzZ88mrhRCCCGEEKJt7HU2rvz2PD6yHKDIqGQN9AxObOYqLzBIxpdogsMB27+GuRco+zFDPJcuTroHhpzvPq72BVtwG7w2DJb9q3XPP7AUcIA5CK79EXwCYPL9rbtHSwVFQ4CyuBmJjfTSix6kP78xx12kBJWrS2HJk85xS6HyNT1GjIgZwbunvctPF/0EODOf8ix5bb5nV64ImVGWodsPNresOf1FAy4iOiCakTEj6R/eH5DAl2haqwNfFRUVbN68mc2bNwOQlpbG5s2bychQ/tA++OCDzJw5Uzt/xowZREZGcv3117Nz505WrFjBfffdxw033EBAQCOrdgghhBBCCNEOO/d8S6ZJP5bo0gy6w2g9viTjS3iw9l346gZnqZ5r4MeVbxBc8I5zf9S1ymvuDqjIg82fQMlBWPYcFB9s+fP3/6a8jpulZJU9kgNTH2r9+2gJowluWwf37AE/915NAESnOLd9mqj4SR4PJ9+nbLsGOOw259fyGHFS4kkkhShZgsmhyQAcLGvFnwEXD/zxABd9f1GXlUrmVuZq2xH+EZyafGqLrrts4GUsvWwpH0/7WFsBUgJfoimtDnxt2LCBkSNHMnKkkq569913M3LkSB577DEAsrOztSAYQHBwMIsXL6akpIQxY8Zw1VVXMX36dF5//XUvvQUhhBBCCCH0Vuz5xm0sMXpIxz9YVnUUjamzwcoGn4GiBzZ+vm8Q3LQUzn8bhl2ujFXkwuHN+vP+mtuy5zsckP6Hst1vasuuaa/g6KbLKP2d7XCoKW/6XknjPY9bCls/r26iV2gvADLKM5o5053D4WBh6kL2l+xn9eHV3p5ai+RYlIUNrhx0JcsuW8apvVoW+HIVZA4Cmu7xlVWR1ebgoOgeWt3ja8qUKU2mQ3744YduY4MGDWLx4sWtfZQQQgghhBBtsrp0DzSoIEuMG9XxDzZK4Es0Yv9vSoN6V1Hu/Y51eo5WfhXsV/Yr8yF7s/6cA7/DKY80//ziNCjLAqMZeo5r/vzOMmombJkPo69v+jxPfcIAKgsgsp/353UUSA5pe8aXa18wm8PmtTm1hprxFRsY22gj++aoga/GVnW02q2c9fVZAKy7ah0BPlJ1dizq8B5fQgghhBCi+6mz1fLf769h05aPu3oqHuXaawFIdKk4DPXURNzbJOPr2GMpghUvQUV+0+epKxCOuhYGnav092ppACo4RnmtKYODq5TtwefVP7+FGU/pysp5JI72/gqO7TH9dfi/VIjq3/R5gRHO4FdYEsQPV7Z/fRCsR2dz9/ZSSx0PlR9q9bXFNcXadpeVOlrqA19BsW2+R6CP8me5sVLHzPJMbbu05tgqixVOEvgSQgghhBCtNm/xHbxRvJlrN7/Y1VPxqLQ+eWBqSDtWwGsLaW7ffTUWXFnyJCx9Cl7qD6vebLy/W3G68ho1AK74FG5d3fIAlF8I+Pgr26m/K6/9TlFeq4o9X9PQru+V1z6TWnZ+ZzEYwK9lTc2Z8YXSlP/WNRBcX0KZtRHW/bfj5ncEU0sdD1ccxlpnbdW1JdUl2nZRdRGpJanU1tV6c3rNUgNfcYFtX1W0uVLH1JJUbbumrqbNzxFHNwl8CSGEEEKIVvstd0NXT6FR1ppKLPUrOd409SVmh4/g0zEtKAXzBmlu3/FKs+D3Z2Hlv519ocqyO251vzobvH8mPBMH3/7d/fgml6zHRQ/D1vnK2Pd3QPYW5zE18NWjd+vnYDA4s76UAeg7RdmsLm3+z1tRGuyrbz0z/MrWP/9IERyjBO78gsE10FF4oOvm1IV6+CmrOjpwUGGtaNW1rhlfC/Yv4PzvzuelDS95dX5NcTgc5FQqPb7alfFlbjrj60Cp889GV2W2ia7X6h5fQgghhBBCHHBUKx/Gj0Cl9WU/BoeD8PDe3Hx+C5t/e4NRMr46TEU+/PEyrHVZ7XDTx0rj99+fgV4nwelPKT2xGio+qPyeRNRnAG7+DDI3wFn/Ah/fpp+btwMOrVG2d32vrIJYnK4EYAoPgKNB0GmBS3Bs+9dw028QM9gl8NXGLMTgWCipb2IeNQDCetYfcCjBr8CIxq/d/5tyXu9J3acfltFl2damVoTsxkxGE/4mf6rrqrHYLPSgR7PXZFdk88zaZ7TVEAH2lyg95ObtnscD4x7AaOj4/JhcSy41dTWYDCZiA9se+FIzvhoL/KWWOjO+XPuaiWOLZHwJIYQQQohWqbPVUmI8MoNeAGXlWQCEOsDUXFDD27QeX5Lx5VW1Fphzlj7oBVC4Xwl6ARxcCf87BVKX6c+pLoP/Tob/nAyVhbDxQyU4teF92LOw+We7rqJYWwGvHQ8fnQt/fQJzL1DGE8fA3bugYePs2grYMk8JTFUVKWM9erXsPTcU5JLxlTASTGbwC1X2LUVNX1tS3/w8bmjbnn0kOvNZ5/YxvLJjcxlPDX2y6xOWZy7n631fezy+q3CX1+bWFPU5/cL74Wtq+9/TCUEJAKSXpXs87lrqKIGvY5cEvoQQQgghRKtkZK7S7dvrumZFsMaUlCmBrzBHFwTnpMdX80ozYfE/oSKv5dfs+EYJcqmOuxAu/ci5Hz9CWa0QYPs3+mv3/KT0waopg00fwbLnncdSlyuv+5fA/KudWVmuGq6iqPruNiUDyzdYyRwLTYAr5ymljIPOhfPfUs47tM5536BopV9XW/iHOrcT67PaAsKV1+b6fJXUNz/vjAUeOkvscXDRe8p2ZUHXzqULqc3dG+tx1ZDN3vTf12uy17R7To1ZmbWSQ2XKn8VdRUrga1DEoHbdc3DkYEAJcHnq4aWWU4KUOh7LpNRRCCGEEEK0Surhtbr96poSAgOjGjm785ValIBKmKEL/qurln/aJfDVqIX3wN5fIG0F/O335s+vKlb6eQFMeQiiByr9rfzD4NTHwBwI426GtGUw90Ll3nY7GOt/xr/dJbNlyRP6e6cth6xN8MlFyr61Cq5ukAmTtanp+Z36GCSNVbb7TYV/bFH6jRWlOq/Pq8+iaWuZI0Ds8cprUAyMmKFsB0QowbeqZjK+SusDX+HdKPAFzvLO5jLeujE148tia1ngq9bedAP7PEsrAtKtsCl3E7f8dgsmg4nNMzdrga8hkUPadd/YwFh6+PWguKaYfcX7OD7qeO1YbV2tfvXKOgl8Hask40sIIYQQQrRKWoNSmCovf+jcs28hD346ldzcrW26vtSSD0CosZPLHMGl1FECXx45HEpgCuDwppY1JZ9/DRTsBXMQjL4WjrtAyXQyGGDSPXDC35UgV6+J4BsCFbmQ/ZdybU2Fs/TR1yXTatzflAyxolR4b6pzfP9vsPY/zv30P+szvgxKDzFVQH0vJYMJhl7qPmeDASL6QmAk1NUoPcVA6fXVVmNuULLcbt/ozBpTAz8NM762fwMv9IUD9YHF7pjxBcrXF47tUsf6jK+qxlYdbaCspszjeJhfGKBveu9NKw+vBKDOUYfD4eBAifK9n9IjpV33NRgMWtbXzsKdumMFVfpMQMn4OnZJ4EsIIYQQQrRKWnmGbt9S5d0PnVeuvJ8fbQX8a9Gtbbq+tFr54BbWsN9SZ5Dm9k0r2Kff3/ur5/PqrEqW16aPIf0PJcB0zTcQEtf4vX18oc/JynbqciXItu4/UFcL4cnwfwfgkg9gxhdw5nMw7Xn99dH1JVc/3+/M1lr+gvI65ga44B1IGAWXzIHLPobJD8CspY03lTcYIGm8sp1WX1IZe1zj82+Ob6AS9HMteVQDcA2Dz9/NVoJBcy8AazVU1mfxhCe3/flHItfAV0et6nmE03p82Zw9vqx2K7MWzeKVja+4nV9eW+42FukfyewRswEorSntkHnW2JxliGW1ZZTVlmnPbq/BEUrgS80iUzXMXpMeX8cuKXUUQgghhBCtklZTrPvxaVVNidfufejQaqz15YKbbG27b2n9fMLNwV6aVStIc/umHVii38/aAPY62PEt5O+BsTdBSKySdbX4Med5wy6D5BOav3/fyUrD+gNLIX83bJ2vjPc/XVn57/iLneeOvRFWvQHFacr+FZ/BD/9QAm27foATblP6c4GSIdajl740Uw2yNSVpvNJjTNWewJcnAS4ZX3t/hfIcGDUTXBud76sPLvoGOwNl3YUa+KqrURYSaGv/tKOYuqqha4+vFZkrWJO9hjXZa7h79N2689WA07Q+06iyVvHQ+IcINAeyJX8LACVe/PvcVY7F2WsrpzJHa8avzr89BkUqQevdhbt14/lV+bp9KXU8dkngSwghhBBCtNihQ6vZY7ACzsbxlmrvlcZ8ve5lbbvYAGWlhwhtZXlWVlV9jy9zF3wIlub2elUlSmnjkAvA7A+761dRHHCmEpDJ3AC7f4Svb1TGi9OUhuXr/qu/z4Q7Wva8PpOV1/Q/9ONqT6yGIvo4A18RfWHI+c7AV5/JYKtSeolFtbEcS834UsW0r5+RGzWQlb0ZVtRnp/XorT9n0aPKa0QfZw+67sI3SFlJ01alZH0dg4GvgPrMVtceX67ljA6HA4PL77ua8XXFwCsYFTtKGw/3CwegpLqkQ+aZUebMFM4oz9Ca7Hsj8DUkQvm+2lu8F6vdirl+oYt8iz7wJRlfxy4pdRRCCCGEEC324u/3UmswMNbhR3+78l/JqkZ6xrSWxVLAl2XOn9g7DAbWbP0Ih0ujeJu1mv/7ZDL/nHe6bly1Zfvn/GRTSi/jQhK9Mq9WUTO+7JLxhd0O866Eb2+Gla9B/l44WL8i6CmPAAYoOahkZ6l2fgefX6WMq0ZfD7EtDBhFpYDJpbfbiKvg4RzoOcbz+ac9oZw/6lolKDToHGU8cwPsW6RsJ45xNspvrYSRSvN9gOQTGy+LbKs+k5RXda7g7KGmUr+WfafSLalZX5WtKLmutcDqt6EorWPm1Ik8repYW+dsYG+1W3Xnqxlfob6hunEt8NUBGV8Oh4ODZc7vabW/FzhLNdujZ0hPgs3B1NprSS1J1cbdMr6kx9cxSwJfQgghhBCiWVarhZ+XP87vDuVD04MTnyYQJbvJ4qWeMKs3v0+Z0UBiHVwf1B+A/zvwOad9OIznvjgXgB+WP8rPdUV8U5tDSYn7h9ZfdilNxPvUGThn4qNemVerSI8vp7XvQkZ9oGvZc/DWWKUENG4oxA9TSgcB9vzsvKauVilVBDj7Jbj+F+W1pYxGfQP3yH5gbqLXW/wwuG8/nFPfCyk0ob7Xl0MpgwRIHN3y5zdk9ocr58G5r8FVX7X9Po3pczKcfJ9+bM3byuvwK8Hk5xxPOdP7zz8ShNUHuItbEcRa/jz8+iC8f3rHzKkTaT2+XMpbXUv6XANiDodDy/gK8dVnx6nN7S02iy5w5g2F1YW6jDQ1OBVkDsJoaH9IwmgwMihCKXfckLtBG1d7fPkYlUI3yfg6dkngSwghhBBCNOvbpQ/yf+lfA9C7zsCA/mcRqH6YqK3wyjN2524GYFxALJeOvxeAOoOBPJOBz6oO4rDbmZPhbIaeV7DL7R6Hq5WsjxkJk/HzD/PKvFpFLSk61gNfmRthyROej51S37tLDVBV5CqvapkiQO9JMG4W9DoRTK3szqIG1ADCezV+nso/TP8MdR5qJmPUgNY9v6G+U2DM9eDXQT3nGisDPekfcM7LSvArNNG97LK7UFfKzHP/+0BTWahkeNXUN3ZXF1WozG/8mqOEtqqjS1DHtYG967jFZqGuvv9gqJ8+4yvEN0QLQnk76yu9NF23v69EWeQiyKf9ZY6qU5NPBeD7A98DSpBvc95mAAaEK9/DkvF17JLAlxBCCCGEaNaG/M3a9lk9lAbdgfV9VCweVglri93lSinMwPAUkpJOYlbIIALtzpXaLvpwBGkm535u8QG3exy2KUG4hB79vTKnVpMeX0pD+LkXgK3avbzu1H9CyhnKdmiC/tgklybcvSe2/fmuwa6G/a5aou9k/X5b7tGZ/ENhxpf6saTxSkBo1DVw1w645U8wmbtmfh1N7ZuWt7Pxc94crWR4rXmnfuAoWAGyztailSobNrf/37b/8Z+t/9GOewqI+Rh98Df56+5jNBg7rNwxo8FKwPtL9itz9/Ve4OvsvmfjY/BhZ+FOlh1axvaC7WSUZxDgE8AZvZW/c6S5/bFLAl9CCCGEEKJZadYSAEY6fLnu9FcBCDAqvZSqXFeQa4c9NiXDZlCCkplyx0Vfsvb67Qys7yW236T/EJjn0jNGlYWSzZAY5eUm4i11rPX4slbDVzfAsn8p+w4HfHGtki3VayJc/gnEDVOOXfCuPrjlGvgymCB5Agw+D/zDYeTVbZ+T633Dk1t/fcIo/f6RHvgCJZh4+pPOffVrDhAc7f3eYkeS5gJfRWnKqpcAhze7H/fQK9DrCg/A6rfAVtOy8ysL4M0x8PH5zZ6qljqqpYT/3vRv3XHXEsPS+rL0UN9QXcN7lVruWOql8nWV2t/r8oGX0zu0tzYe7MWVdyP8I7h80OUAPLLyEX7L+A2AKT2nEOGv/PmXjK9jl6zqKIQQQgghmmSzVnPAUAcYeObUNwkKjgMg0OQHNn0PmbYqLUkn26R8EEvpc5ruWJTRnz24PyOvIlu3X1Z6iHKjco+E+Hb0ZWoPNfB1rGR8bfgAtislsAw5H8qyoPywUl43Y75S3nflPMjZBiln6a8NdVl8IKIP+PjCpR8qQUMfX9rMtWdQUHTrrw+J0++35R5dIdhl3mr537FAfa/F6VBbqaz06GrrfOd2cP3vpWtg2lLoHO8oc86GihyoLoWpDzV//k/3KT3LitOUYJmPX6OnqqWOlY38AMJTxlfDxvYqNeOr2Isr9YJzRcfeob2J9I/k7S1KHzpvNLZ3dc/oe1iwfwGlNaWszV4LwMCIgdrKl9Lj69glGV9CCCGEEKJJBzP+wGowEGB3kJgwVhsPqG+cXWVrf+ArPXMNALF1DkJC9asxDg3tq233rIPzzMqH1Lxq/Spuh3P+AiDC7iCgqzJcjqXm9vY6WPW6c//tE+CTi5Xt2OOcPa3CesLAac7+ZyrX3+fkE5RXo6l9QS+AwdOV16gU92e2hMGgD5615R5dISTWuR3TRRmPXSEoCoJilO283e7HXVe8VHt8ufb2KtcH0DtERY7yuv0b5bXW4l7GaCmC5S9C8UHY85NzvJk+ZK4ZXw4PpZGuwZ7SWmfGlydhvkrGV7mXytdVB+vL2JNDk4kPjtfGvZnxBWA2mekbpvx7saNwBwAxgTFaWee6nHW8s/mdRq8/EtXZ61ifs549RXu6eipHNQl8CSGEEEKIJm1O/QWAFHwxujQBVzMNLHUtLN9p4K+tn3DGB8fz/g/X89FfbwGQZPR3O+/6M9/gpuCBfHfya/x8wzZGRY8EILe2THdeRt5WABLpwl5GWsbXMVDqmLmh8aBB/PDmr3ctSew9yTtzAogeCLM3wk2/tf0eDcsdjwYBPZzbMYO6bh5dIbaRcseKfMja5NyvLgNrFVSXOMfKczp2bq7BqOpSyN0Bz/WEH+/Sn7fkSfj9afjPJKU/nqoir8nbq38P7yzcSX6Ve5DMNSNXzeTq4d/D7TyAYF8lEOXtwFdOpfI1TgxOJC7ImZmo9ifzJjXwpYoOjMbfx/nvipptdjRwOBzcuOhGbvj1Bi754RLe2vxWV0/pqCWBLyGEEEII0aTFh/8E4OTI43TjWvlIGxsG37vhX2SbDLxWtIHF9hIAkupLbVwFBkbxj4u/om8fZdWumDCleXmeXV+2sv7wKgCGBMbTZY6l5vZ7lYAo/U9zP9aSvlhhPZ3bvSZ4ZUqaqP7Kao1tdeG70HMczPjCe3PqaDFDIHG00ictwHNgo9tqrM/X4b/QNbKvKXcP1lZ0cOCryqVssLoU0v9UAuMb5yhBMNX+Jc5zXDWT8RUTGKNtP/DHA+6Pd8n4ai7wFeIbAkC5tW2BL4vVQmZ5pm6szl6nBdLC/cKJC+zYwFe/8H66/ZiAGO3fKpXNbvP6cztCrb2Wjbkbtf1lh5Z12VyOdhL4EkIIIYQQjSotzWCtQ+kdc/qwG3XHoutLVrIaZF61VJ7JvYQsKSjBw5l6veKUbJw0Qx01Lh8S11QeAuDEpMker+sUallcZzTM7io7v4f/nQZ/vqLsD7tCfzwkHoZd1vx9gqKUhuxnPN22JvQdKWoA3LQYUs7s6pm0nMkMs5bC5XO7eiadT+3z1TDwVVWkvKqZmDVlUJqlP6ejM75KDzm362ogY41zf9lzzu2gKM/XNxP4Sg5N5urBymIQOwvdG/y7Nrcvqla+Ho1mfJmbz/jaW7zXY1/H9TnrOePrM5j2zTR2Fe7Sxl3vFeoXqsv4snfADwgaBr6iA6MxGvRhj8MVh73+3I7QsG9bvqXpPwuicRL4EkIIIYQQjVq+8V1sBgP96wz06T1Fd2xg0kQA9jiqsdd55yfoSQ0+tHg8p+cEIuscWA0Gtu9ZAEBu7lbSTWB0OBh3fDtWBGyv7t7ja+f38MU1kLle2Y8eBIPOUZrZq+7ZrS9jbMpJ/4AJt3t/nuLYElOfjdqwx5eabaUGVqvLIL/BOZX5MG8GvH+mPijlLaX6DCgtswtg1w+we6GyXdPIDxCaKXUEOKuPsnCEGihJCErggv4XAA0yvmqUr0eEn+ceiGrvr8YCX1vzt3Lx9xdz06Kb3I59ufdLbTXIvcV7tfGSmhJAye4yG826ssOyNv7QpClDIvX97YLNwQyOGMz4+PHaWHpZutef2xEqa/WBr6LqoqMmW+1II4EvIYQQQgjRqJ8PLQXg9B7HuR3r02syvg4HFUYDWYfXtuq+1hrPK5DFRQxo9lqD0cgos5KxsOmg8iEyLXM1AL3sRrfm+J2qO/b4stdB+krl1+/PKmNRKTDqWrjmW/ANhMs/UcbPfa3Lpim6r/15FVRbm/ieCqv/nq/M02dbVpUor2rgqywTfrpX2TbVL6KQvwf2LIRDa2DB3706bwBKDun364NDhNQHh+dfDYfWuQfIVM1kfAFE+OsDWUG+Qc4ejG3o8VVRW+Hx+OKDiwHYVrCtyWwk115jakP9cA9l7I09pz2iAvSZcwaDAbPJzP/O+B+n9zodgPTSdK8/tyNU2pSvcaR/JCaDCQcOLWtPtI4EvoQQQgghhEdzfryRP1H+433a0Jlux83mQPo7lGb3u9J/b9W9D3kIlPWsg0H9prXo+pH1P9XfVnIAgMPF+wBINAW2ah5e1x17fC28Gz48W/mVvwv8wuDGxXDe687MrpQz4JF8GH1dl05VdD+LduRw2ivLeWbhrsZPCqgP/Djs+sb1DTO+XPVWMlZ1GWDlue2aq0clBz2PX/I+DDhTmfMPd+ob2oOzR10LMr4aBr5CzCHOHoy2Kj7Z+QlX/3Q1B8uUuTTX46uxTCzX4NWq+p6KqoKqAm27sMq54q6aBea6kuRJCScBcNnAFpREt8H4uPEex3uH9gbgxQ0vMmvRrA7JOPMmNbgY4htCpH8kIOWObSWBLyGEEEIIoXP48AYem3carxSuA2BmYF9S+nsOSKX4KT9dP1DYxIfSBupstWxN/VU3FmF38NN1W/BvYVPuhLA+ABTVKWU8WeVKVkWCh6yCTqVmfNm7ScZXnQ12fKsfO+NJCAh3P9fH19njTAgvmbcuA4Dle5v4wO/jC371gRWLM+jiDHz1dr+mlxJ8ocIl2GWtBFvbVqltVF79343xI/TjUSlwzktgNENefZN71ybsQdHKawsyvgJ9AvFzKTcO9g3WBb6eX/88W/K3kFWh9DdrGChThZiVwFeF1XMmlmugaH3Oet0x1ywvXcZXfeArzM+52MS/T/k3C85fwJSkKc2+t7Z4btJznBh/Iq9NeU03Pix6mLa9JnsNX+39qkOe7y1q4CvIHERUoPJvraeVO0XzJPAlhBBCCCE09jobt/96I9/WKh8GI+wO7rno60bP71H/YbOshauAOex2Lp87lkczf9KNnxKQiMHY8v+ahgYpK5mVOpR+J4ctSlZEQlAXrugILqWOR3DGV852+GAaHFja/LmZ65RV5vzD4Yxn4MznlBJHITqYw+GguLKWP/YpmUQZRRZKLLWNXxCoZMToAl9q9ldInNvpJJ/o+T4WL5eSqYGvQec6x3z8lfmGJ8PQS5zjSeOcATI1e7IFgS+DwaDL4go2BxNoVrJfPWU1NbuqYyM9vlzv5VpyZ7FadKWPrtlf6nmugS8/k59bE3pvig6M5r9n/JdTe52qGx8ZM1K335Ulj7V1tdTUeQ6yrshcwU2/3sTqw0oJf5A5iOgAJRAqga+28enqCQghhBBCiCPHivX/Zq/RGbQZagrBaGr8v4wh9auAVbj0kamyFLFi41tMHXcnvn4huvNLSw+yx+X+r/abQVrRLq6Y8hytERoUC0CZQbnXYWsZGCAxrHer7uN1anN7HOBwHHkZUA4H/Hin0px+7oVw/CUw/d/gF+z5/P2/Ka8DTocJszttmuLIsTa1kNAAM4PjQ5s/2QscDgdPL9zFL9tzGNcnApvdoR3bllXKpAHRni8MjITiNKh0Bl20jK+GmaTXfNv4AgyWQgj1UgC9KA0q6leNHDgNfn9a2U4a7/y74YS/w5bPwRwApz8BEf2UlSbr6oN8LSh1BOjh14OcSuVZIb7OUscD9eXgDc/1pNnAl0sDfrVpPehLG8EZ+Pp237e8tOElAMJ8w+hqrsE3gC35W7pkHrV1tZy/4HzyLHkkBCdw49AbtcUIFh9czN3L7gZgbY7SEiDIHERkgBLYLbAUeLynaJpkfAkhhBBCCM2qg84soHC7g7+PvbfJ84Pr+7ZU1Dn707z8w9Xcm/oFL3zr3r8lN3+Htj3K4cupE+5n1nkft7ohfViIcn6ZQckiO2xXfnKeEDmoVffxOoPLf6+PxKyvXd87V2QE2P4VbP1cf86B32HDHCVIdlDJOKDPyZ03R3HEWLwzl8v/u4aL3l5Far73G5F78vayA7z/ZxpZJVV8+5dSmmc2KUGiDenFjV/oKeNLbW7vGviKHw79TnGe31CVlzK+yg7D6yOU7eBYiBkMEX2V7fPf1M/nuoVw0xJIGAn+oRCd4ix1tBQqJcfNiAhwli8Gm52ljmmlabrz/E3+2rGG1Ob2ldZK7B7+/nLN+FJLGME9C0kNfD226jFtrGHQqavcP/Z+bTu1NLVL+nztL9lPZkUmtfZa0svSeXTlozgcDnIqc3joj4fcznfN+Mq1dEAfumOABL6EEEIIIY5BDrud+b/ewYbNHwLKKovvfT+TedVKP52X+17OH9dv57jBFzd5n5D6kpnVthJ+WfEkAPOrlX5b82vcVynLrW9C37fOwAdXr25VeaOrsFClWbXNYKCsLIO8+tskxA5v0/285kgOfNXZ4Lcn3MczN+j3516gZIUteRIy6htYJ53Q0bMTR5hqax33f70VgCprHY99t6OZK9pvTWohL/66x2389lOU1V7/vWQfmzKK+WhVOme9toJP17o0jg+qX82vPNs5pmV8hTvH6nsl4Rei9NdqyFuljof/cm4njVOyQf++Gm7f6N5sv/dJEDtEPxYYCRgAhz6Y14gIP5fAl28wA3sMxGgw4sChOy8pNAlDI5moasaXA4fHPl/NBb5SeqQASuDMYrVgdPn7MMgc1Ox76AxXD7mabddu0wJJh8oPNXOF9zUMRgJ8susTLv3hUqrrqt2OBZmDiK8v41ez+gC2F2zn1C9P5YcDP3TcZLsJCXwJIYQQQhyD1v71Hk/n/M71W14mNW0p//xqOq8XOz+ojR7cstW21MBXpdHAfWlfsnHLR7rjebnbdfs5pcoH1WSfYEw+vm2ev79/OGaH8oFub9oS7AYDfnYHkREpbb6nV7gGvo60BveZ66DogNKv68rPnStQpq90nqNmyAD8+Yryag6CqAGdNUtxBMgqqeKSd1dRVOnsqbXyQAF55cqH8j055WQUWhq7vM1+2a58qL9gRAJ7n57GfWcO5JkLj+eWyf2ID/MH4KK3V/HP73ewO6ecf/28G0ttfTZUYH3gZ9lzsOEDJWPRtdQxeYKyPf4W5dVg8Jz15Y2MrwW3wecznPtnPa+8mv2VgFtLmHyc82tBny+1FA6U7Kr+Pfpz+8jb3c5TVzb0xM/kh69R+Xu5otZD4KuRUkc1eNQrtJeWTZZdma0F0qDx8smuEh+sBJKyK7KbOdP7UktT3cZeWP+C9jWdNXSW7liQOYiEYKU0V12gAOCpNU+RZ8njoT8fwuHQBziFngS+hBBCCCGOQStSnc3lL15+Bz/YnB+sxuNPZFTLAkjBAfoPjt/s0Ae+1u7Ul9HlVBwGILadqy8ajEbC6hOqdh5W+qDEO4xtziDzGq3HF52f8VVdpnzYb0zaH8pr3ylKv6EHDirBr9IM5YN6USqUesh+6H/qkderTHSY8morV/9vLduzlCDHnacNYHhSOA4HXPzOKkY+uYgzX1vB+W/9SWVN8yV4rbEpQwlUnTo4Fl8fI7dN7c9V43vh62PkXxcPc/tjWF5tY8Ffyt8pWiYXwI93Q20FOOqDzwE94Kov4W/LIeUM53mugS9PpZJt4XDA5k+c+yfcCmGtK+XWaCs7Nt/n67x+5zE+fjzn9TuP05NPB+DG42/kzN5n6s7rFdqryfs01efLNeOrylZFbV0tJdUlzNk+B4AxsWMYHDEYUFZNVLPCfAw+nN///GbfQ2dKCHIPJHUWTxlfKl+jLzMGz8DH6Oyt6Rr4yq7MxuFwYHfYdc35dxW1fGXlY5EEvoQQQgghjkEry53/8ba5fJpcPv1b/nPVSk+XeBTs+mET2Fqtz0zYWbBVt59brXyojAtopEF1K4TV/1d2d4lSPplo8ty3plPpSh07MePr0Dp4vhcs8VDKqEqvD3z1maS8+oXAyfU93DZ/At/8DYrrS8ci+sLdu+DC/8C0Fzpu3uKI89Kve0grUFboG9YzjKtP6MX0YUp2zKGiKootVgCKLVZ+2ta6bJntWaV8suag8sHdrvxSWWpt7DisBFZG93Jvvj45JZrf75kCgNEA156oBHA+Xp2uZLvYrc6Tw5Kc2V4mP6VxvF8wJIzQ3zTY5e+hmPpSQ0sTfcRaomGpZFjPtt9Lnd/cC5XAdBMG9BjA/874H89MfIZw/3BAWe3xxZNf5P0z3tfOSw5JbuQOCrUk0WLTZ/TZHXa3YFhJTQlrstdQVltG79DeXDbwMm3lxJ/qf7gS6hvKpms20SesT9PvtZNpGV+V3s/42lO0h8t+uIxf0n/xmImVWqL8Xj454UnWzljLtD7TMBlM3DHyDj6a9hFRAVFaYA6U35O4wDiMBiM1dTVsK9jGz2k/636PVh1e5fX30Z1I4EsIIYQQ4hhz+PAGUk0OjA4Hj8adoo1H2B1ERPRvVQliSP3qiqr0+oSnsPoPtDsr9T9Nz7UqH2xjQ9rxYbBeaH1/nh9tSiPlhEZWKutUhi7K+Pr+duV5f77q+bi1WgmOAfR2aVQ/9SE4p76kMWebsioeQNwwZdW74Vd4b4U7ccTbfKiET9Yqff4+vWk838+eSFSwH5eNTdKdd8lo5fv3lcV7OVhY2aJ719kdnPvGnzyyYDv/XZHK8Y//yknPL2X1ASUYvjatiDq7g7hQfxLCPQexe0cFMW/WCXxy43juPmMgAWYTu3PKWZ9eDP1OdZ5oNDa+oqOrk++DgWcrWVn96v8ubG+pY2mGfr89ga+gGOf2r4/oj615F145Dgr2N3kLg8HA0Oih2n5UQFQTZ0OgORAAi1Uf+KqwVmj9wtTgWGlNKZkVSi/HYdHD8DH6aIGvrfU/9EgMTmy0p1hXSgxSsvA6IuPrq71fsatoF/ctv4/xn43X9eUCZ7BtZMxIAs2B/GvSv1h22TJmDZvF8VHHA2gZXqB8vc0ms9aX7KqfruKBPx7Q3bPhyppCTwJfQgghhBDHmJXbPwVgOH4M6+38sJiIh0bPzQgJ9hwUmeoXB8BuRw12lxXJcuuU1Rfjwvu2+lkNhRr1AbqEoLh237PdOqPHl8MBhzdDjUv2RXlOo6cDykqOdTXKinIN+3WNvg58/MFWDWkrlLGGzbdFt5WaX8HGg0UcKrJw00cbqLM7OGdoPCf1dwZIQv3NPHvhUALMJj66YRwPTBtETIgf2aXVPPnDTp5ZuJNJLyzlqR93enxGja2Olxc5m9Y/9/NuLLV1ZJdWM3dNOgDz1ylltmceF+vpFpoT+0UyoX8UYQFmzqg/d316ESSOgsuVv9soz/Xc2L6ew+Hgt525FEePgyvnwVnPOZvjVzRfVtik0gaLerQn8OVS7kb9352aX+6HskxY8niztwnwCSAmQAmiDYse1uS5gT5K4KvSqg9oqmWL/iZ/LQBTUlNCZrnyfhODlUDSyNiRuhUce3rhhxwdoSN7fBXXOLMGq2xVrM9xrqRbW1erZWr1qO+RaTQYtSw91ejY0dp2sFlZbVP9GrtSe7IVVXtpUYZuSgJfQgghhBDHmJW5SubPST2GkJw0QRsP8rTCWTOCgjx/SD0hYQJ+dgcWo4H0DCWY4rDbyTUoWVCxkQNb/ayG8uqqdPuRgTGNnNmJdD2+OqjZ8Ko34L+T4Y3RkFsfaKguafq5aplj70nu/bqMJlB7uu1bpLxK4Kvbs9bZeejbbZzy8nIufmc1k174nYKKGgbHh/L8Je7BkRnjk9n11FlMTokmKtiP/84cA8CS3Xm890cah4qqeP/PNMqqrbrrDhVZmPLiMt5edsDjPFLzKymoqGHxrtz65zTdg8rVgJhg7R4A9JuqvNqqoKS+X52HjK//rkjlpo83cNcXm52Dkf2V14K9LX6+G2sVbP5MPxbansCPy/dyg8CIpoUB9gUXLOD3y37XBaU8CTAr2XYNSx3VjKIe/j20e7hmfKlBmVDfUOacOYdTkk5hcs/J3Dj0xhbNr7O59vjydmP4w/W9LFVqVtmW/C1csfAKQAl2uTb/b2h6v+natpox1zust9t5ExKVf8OLq9tZotvNSeBLCCGEEOIYkpP9F3/UKT+5nzjwQgJdenRZ21CaZzT5eBxPjBzIcQY/ADbt/xGAsvJMqozKf+Bjoo9r9bMaCnAtKwSG9j6t3fdsN9egUkeUOhanw9Knle2KXHjnRHhznP4cT825U5cpr2p/r4ZiBuv3owe1Z5YCmL8+g1NfXsbunLLmT+5EDoeD53/ZzUn/Wspna/VleUG+JuZcN5ZgP8/f166G9wyjZw/3ksSCcn1m0rI9eWSXKqtB9osOcjs/raCSJbtyqbM7OC4hlIFxLVz1EKX0UblH/QqEvkGgBhPydyuvAT34dUcOk15YypZDJQD8e8m++rm59CRUe3yVHnJmi7XWytdhj3PhEBJGQnA7AvJTH3Juuwa3Xfn4tehWIb4hzZY5gjPjq2Gpo7pyY1JIEuH1i5PctewuthcoK/e6ZiMN6DGAf5/yb9489U2Oi2z/3/UdISk0CaPBSIW1goKqArfja7LXcOkPl7Iic0Wr760Guk5LVv5NUksbr/7pavYVK3/2wnzDMBoaD8ckBidybt9zCfcL18pHLxlwidt5JyWcBOizzIQ7CXwJIYQQQhxD/rf8IWoNBsY4/BiScoHu2LDgJM8XtUFc1BDGhSlZROtyNwKQm78DgHC7A/+m+u600KOTnmOSIYg3B17PnOH30L/fGc1f1BnUDzMd0dz+z9eUkifXD0wFe/TnfHUDvDUeSuqDGoUH4NBa5Zr+p3u+r/qhH5Syx55jvTrtY8kv27N56Ntt3P/1Ng7kV/LeCs8ruFVb63TN3b2dddKYZXvyeWfZAfLKawgwm/jHqc7S15NTookL82/RfQwGA9OOdy8vLqys1e3vy1OCUn87uS9L7pnCuD4RuuM1Njsfr1YWVTh9SNNljg31qQ98pRe6BGlC6u+hBr78w7l57kYOFVXxzE+7sNsdWGqd35u2uvoAdUA4hNVnOubuaNU8NH/NdW6f8gjctLR9K6L26A1X1GeQVZU4x20uX2NTywJfLaUFvhpkfGWUK3+fJIUkMSVpijaulkQeqSWNjfEz+ZEUovybd6DUPRvxyz1fsrtoN7ctuU1rRt8SFqtFKzscE6dkRWZVZLkF15rLvAN4ZuIzLL98ORH+yvfM0OihulU6YwNjtZ5gkvHVNAl8CSGEEEIcQzZWKSUYMwdegcGo/FfwixOe5vrgAdx81jtee05k1EDG1WdgrastVMoci5SfdMdhaurSFuvf7wzenrmGySfczZgR13nlnl6hZqJ5M+PL4YA/XoGNc5T9md/pj4+8GgIjle205cqH/g/PdV4H0P80CHPvEQPAcRc4t/3Dwdyy4IfQ25ZZyi2fbNJlUq1LL9SCWtXWOr7ccIjnft7F1JeWMf65Jfy8LZtXFu/lhOeWsHhnbofOz+Fw8MpipZRvYGwIi+46mTtPcwa+pg1t3UIGd52ewttXjeKXOydpKzE2zPjaXx/4UssS37xyJANjQ5g+PEHLAFNXczxtcOsCX70jleuLKmsprV9tkuD6YNz+3wAotAdq59fa7OzM1mfgZRa7lEzHKUEEcra3ah6aIJeMqn6nKk3220v9IYFrFpprVqex+ey81tBWdbRa2JK/Rcv8yihzBr4uSbmEc/ueq13jY/TR+n4dTfqGKb0mD5S4B75q65zBxR9Tf2zxPdVsr1DfUFJ6KD/8ya7IZmnGUt15an+vphgNRressOcnPc+Gqzfw80U/8/m5n2v3Ka4u7rTg+dFIAl9CCCGEEMcIe52NDIOS6dC/50na+OCB53P3xd8QFOy95vBmcyDDBl+Cr8NBoclA2sHfyS1NByDWFNj0xUc79YOKt5rbV+TBJxfDkieU/RFXKb26TntC6cV161o4/y1IHK2/ruQg/HgXbP5E2T/h1saf0aM3DJ+hbE+80zvzPgZ9vUnpdzS6Vw9eunQ4RgMcKqoiraCSvbnlTHz+d+77aiv/WZ5Kdmk1+eU1/P3TTby+ZB+5ZTXM+ngDmcWWZp7SNpZaG0/9uIttWaX4+hiZ97cTSIoIxGAwsOC2k3jmwuOZPqx1ga9AXx/OHhrPoLhQooKVJtsFDTK+1MBX//rAV0yoP7/edTJvXDmSPlHB2nlGA6TEtrzMESDIz4fYUCXjaX9+fbljuD5zdXeJM9BeUFHDXxn6zJhUtUwSILa+LC+3PvDlcCgLPhQegD0/Q52+f5kbtbH9lfOVZvv1csuq+W5zFjW2NvydoPb2qiqGXx5USp0rXUo0ays8XtZW6qqO8/fM5+qfrmb20tkUVhXyS/ovACSHKllxaqYRwKAegzAZvfMDjc7UL7wfgMeMrgqr8+u6LHNZi++5u0jJNOwZ0lMr/8yuzGZjfeazqiUZX56YjCb8TH70DOlJVEAUPepXM66117pl6QknCXwJIYQQQhwjcnI3U2sw4ONwkBA/uvkLWmju6Ae5ITiFZed8zRRDCA/ETATAzz+MkQalB9C6PQvIqW/4G+vbtv/wHzWMXs74+u0JOLBE2T73VSXIZTAoAao7t0FMfT+uEA9BCzVDbOwsZ+Pvxkz/N1z9DYz7m3fmfQxJK6jkzaX7mL9e6YM0e2p/LhndkzG9lRKlDQeLeev3/RRU1BDoqw8Q+Jv1H8kW7eiYrK83l+7ng5VK2eU5Q+OJCHKuijoiKZyrxvfSmmi3RWSwEoByzfgqrbKSV7+vBr5cpcQ6x3r2CMTXp/UfT49PUP4+0QJaJ9+nO761yPmeskqqWJOmX/3uQJ7L6oWx9cGc3O2w7j14Ihw+mg5vjIJ5V8CatxufiK3GGZBqUCr8yILt/OPzzVzyzmqsda38e0HL+CpSnr/iRSjLch6v8W4PObXUsaxWue/6nPX84/d/YK//+yw5RAl8qUEjgLHxR2dptJrxlVqqBL6+2PMFL6x/AYfDQWltqXbevuJ95FQ2s3IuUF5bzlub3wLg5J4nExMYg8lgwmq38tvB33Tnqn3S2ivQHIi/ScnQlZUdGyeBLyGEEEKIY0T6YWU1x2S7EZOPbzNnt9yI42dw18VfExmVwhszV3HVNGfJ5NhwJSjzVfYKVpQoPwmPDTz6SmJaxds9vg6uVF7PexPG3NB4z6AeTayGF9uCBtM+vtD/VP3KlAKAzGIL17y/llcW7aHaWkd6QSUOh4PP12WwNrWQm+du4KVFe6my1pEQ5s+kAUrJ28ikcABWHyjk1x3KB+f36ldDBPjpjkksu3cq/75iBPedqax0unR3Xoe8hzWpzvK4myf39fr9o+oDX/9eso8/9yn9jNILlKBSTIgfIf7uq8YOjg/VtntFti0TVO0Ztia1/kN/ZD+Y+rB2fFexsxTQ4YCFW5VG48N6KgGzA/kuGVNxQ5XX7C3w073uD1v7n8YnogajfPwh0NnHrM7u0EpYt2WVsi6t+eCEpdbG2f/+gxs+XK/0HmtI7V8GUFPe7P1apL5MTs34crUlf4u2rWZ89Q/vr42NjB7pnTl0MvW9ZFZk4nA4eGrNU8zdOZetBVspaxBQzCzPdLv+UPkhSuoXHXA4HFz+4+VkVWRhMpi4ZMAl+Bh9tKyvWrs+E9LX6L1/g13LHYVnrQ58rVixgunTp5OQkKCkxS5Y0OJrV65ciY+PDyNGjGjtY4UQQgghRAukpy8nL9dzf5r0AqVhcy+f1pUTtceE/ucBsMdoZ5dRCQSNSJrcac/vElqPryb6rdhqYc8v+ibVnlQWQHF9c/TB05s+N8YluJV0gr4Bfpj3Fi7ojqqtdWxIL1IyPaqsVNTYtGO1NjvXvL+OP/YV8PrS/Qx69BemvLSMB7/ZxgPfbOPy/65hb64zePL3qf3xMSlf+2E9wwH49q8sqq12+kYFMaFfJN/PPok5141lSEIocWH+nD8ikbPr+2utPFDAvHX61Rbby1pn1/poLb1nMoPiQpu5ovXUUkeAq99fCzj7ZyVHeA5quQa+GjunOeP7Kr3t1qcXORcLiErRjpcQxHEJoYzppe+pdNFIJSCRml9JYUUNBRU10KMPmAMbz9Zs6nu6tD7wFZqoC07vydEHplIL/p+9sw6P4lr/+Gd2N+7uThKCu7uXQt1dbr23dut+e3urv3p76y5UKVCk0BanOAQNECXu7ivz++NsVkgCCSTBzud58uzMmTNnzqxl5zvv+33rOBZ/7C9if0E1Kw8UU1ivCDHNlhKbghZdIXzl7YCXo2HzR5aIr7b4cc6PuOhEFK+fsx9DAocQ5RnFqNBRJz6Hk0CLKFVUV0RJgzV9tE5fZ4l4a/EuOzKaKrcml9nzZ3PzipsBIYK1VL58aPhDBLkJv7oYrxjLPi2eX9BaCDsRWoSv0oZSDCYDPx78kaK67vULPN3otPBVV1fHwIEDeffddzu1X1VVFddddx1Tp07t7CElEolEIpFIJB2gsiKTS1fdxdTfr2TuZ/3ZsNX+91qLj0m0a2CPzal/30t5Mngy0UaFCCM8FzaLEYP/0WPHPym0XPS25fFl1IuL5/Wvw7zLYdnDRx8rd5t49E9sO/LDliCbyoyeofZil9fpVXGtp7nv+2Qu+WAjMY8tZeh//uDSDzZaRJT1aSVktiFWfG9Oa2yhf5gXd0/uxRXDrc/7wAj7tN4LBoehKAoDwr2Z3Nv+cxjj78YNY6JRVXh20T4Kqxq76vQ4VFRDk8GEh7POYgjf1bREfNnS4lcW5uPS5j4tVRlPhH6hnrg6aqlq0HOwyCwCBSRatlerbgyK8ObZ8/oyZ0AIgyK8uX9agiUNNaWgmplvrmXsSytZvLfQvsJpi79WC0dLX26J+DqigMT6tBK79UOFNXy1Mcs+0uwI/kqxRv0l51S0nkfxfutyVwhfyx6GxkpY9hAuDm2/Vg4aB3r79rasK4rCl+d8yaILFlnEsNMNP2c/nLXOqKjsLN5paS9vLKfBIETbFuHqSOHrr2yRfn6o4hCVjZXsKxM3lgb4D+DqpKst/VrSKQEGBQyyLNua558oLdF3+8r28fGej/nPpv9w/e/Xd9n4ZwKdLgFxzjnncM4553T6QLfddhtXXXUVWq22U1FiEolEIpFIJJKOkZG9jkaNEF2ytPDl/q8YO/xuy/adDfmggX5BXefv1REun/k2l/foEU8ybXl8GZqheB/Mv01UYSsWF0ls/xwmPgKe7ZiKp64QjxEjjn1cW6FLXw/ugcLgHqTwdQQmk4pRVXHQalh1sJjf91n9ewwmlZSCag4W1RDj78Zbf6UBcP3oKHIrGvirnVTE1y8bSPwR5uxh3i4kBnlYBJkLBrVTVdPMM3P7sD+/mi1Z5Yx9eSVh3i48ODORcB8XhkTaRyytSy3h8V/3cMXwSO6a3KudEQV784Rf0YBwLzSa4/fxOhoezvaXlkaTaon4Cm9H+NJqFDycddQ0Ghgff3wp0DqthqFRPqxLLWVzRpmIIvO1+k/V4Uz/MC/6hXnx7lVWw/k6c1RfTZOBFluy/y5JYU5CLOSZBWdXXyEIWXYqEeK1tnXaJmXifYJPNMU1jVQ3GDDZVNGMDXAjo6SOrzeJz+SwKB9+vmNMq2FUVWX1Qet7bGd2JbNcvKHWxmOqwJp62CXCV6PVz6q9iC9/F/82PeCOrDp4OqEoCqHuoWRUZbCjaIel/XC1eI00ioYIjwi2FG5pJXy1+IIB7C7dzcJ0UWm3r799WrltxNegwEGkV6WzvWg7F8Vf1GXnMShwEIvSF5FcnExlUyUgqku+vv117hp0F07a1qL02UaPvEs///xz0tPTeeaZZzrUv6mpierqars/iUQikUgkEsnRySs/ZLdeaLRGjFRVZpFqrug4NOmyHp3XWYfF48ssfFXmwM83wkeToPSgVfRqYWM7mRSGJtg3Xyz368BFku1FqXsg2F7sOLU2Fj9ZLNtTwKDnVvDPeTupaTxGlbw22JxRxk1fbCWt+Pgu+FVV5c5vdzDkuT84XFbHmoPWiJwB4V7Em03YN6SVcv8PyezKqQRgzsBQ3rxiEK9cMoAPr20tHrdl3q4oCl/fPIIZfYK4fWIckcfwsVIUhTsnC9HGaFLJLq/nnnk7ueh/f/P+6nRLvwd/2sW1n24hp7yBD9ektxonOaeSaz/dzMM/76K2yUB6iYhYiw/svjTnMXH+dtFuRdWN5FW2CF/tn/fSe8bz3lVDmNk36LiPPcqc7rglyyxO6BxRz32dT7iQVDWMfmGtC2q4OekI9bJPISyoasTg6m9tcLEXG1GNUHG47UkUiSis7w97MOK/fzHjjTXcM28njXoT4+P9eWauvSCy7XAFFXXNHCistqs0WVjdSHWjNdU2OacS3I4iCjbVgKmLCmkAru1Uo/V38W+zvcc4sASyN3X5sKHuoQB2VRcPV4nX2NPR03LeRwpfu4qt4uNdf93FhjzhxdjXz/51jvCwfiYGBQzig2kfsPCChYwMGdll59DisbandA86jVWA/nzv53x/4HuajE3oj1WR9Ayn0xFfnSU1NZVHH32UdevWodN17HAvvvgi//73v7t5ZhKJRCKRSCSnN7+v/TfBPr0Y1F+kVeSb71L3N+nYozFQqlgvhtbu/BhVUYgxKvjZ+N9IugFbc/u1/wcr/3P0/pv+B1Fjofds+/aM1dBQIao1xnTQF+2KebDtU5j0OCx5oNNT7wneW51GZb2e33blM76XP5cN77j/WFltE//4chs1TQZ2Zlew4v6JBHh0LpphQ1qZJcJr4qurLe2vXTqQi4eG88m6DJ5fksJfKcXsMAsSN4yJZliUD4qicNkwMd/5d46huLqR99dkcO2o9isiBno685GNof2xGB3n12b7/604yJwBIXi5OvDzdqvRdnWjAaNJRWsTyfXB6nTWmQ3mk0I8yTALX3EB3ZPmCCJ666WLB7AhvZSc8gYWJOdZjPrDvNtPhYvwdSXiOP29WmgxuN+SaRWQ8uOv4vnGYBy0CglBbQt+vYI8yD8ipbRS8cYi8bj4QOJsOLjU2qE8HfzbiLAzC9oLC7wBMKlwoLAGrUbh3+f1bbNi5fdbc3j59wM4ajVsfGwKfu5OpBXbp0DmVzXA7Jsga539zu5BUFsEqKCvA6fjEDX/flcY5VdZ309utWVtdvVzaft92e0Up4hUzMy14OAGD6WCY9e9j1t8vg5WWH3TsqqzAPBy8sLXWby3bIWvJmMT6VWtBWeAsWFj7db7+PUh2C2YAJcAwj3CURTFLv2xK4j1jsXD0YOa5hr2l+2327axYCPv73qfgQED+WDaBydUufV0plsjvoxGI1dddRX//ve/SUjo+A+sxx57jKqqKstfTk7OsXeSSCQSiUQiOYvYuvNTHsr8mWt3vGRpy68XF/PDPEVqRY1Goboqh+KivfwnS6RhTPaK7/nJnm20mNsX7LYXvQL7CNP5Fi78CMJHiMiwH662RIxYyFwrHuNndLzSYu/ZcM0vInVy6jPiQnHCQ8d/Ll1MRkkte/Os2RwWT6ZjsC2rnAve28DQ5/+kxpyiVlGvZ9abazvlhWUwmvjv0pQ2t/UOEcLBoJZKjBllNBlMBHs688zcPq0uGIdE+jCrXwgL7xrLJUO7LpXUSaclsA0xz2hS+WRdhkXE8nF1sIgp+ebIKhARbVuzrBfpy/cVklkqxJQY/+6P/Av3FiLWK79bhYT2Uh27in6hXigKlNY2UWLOW2ypKBnp69qm6AS0+bqVqDbG/y4+MPdtGPcAhAwUbWVtCB5NtVCRBcABk72QOybOj9gAd0K9XOgT4kmsvxtXjxTVBF/+XVRnbDaaWLqngFu/2mYpbJAQJF6r8tpm6HshjD+iymT8DJE2DceX7qiqsOIJ2Pm1SI0241pT2GZ3P+eTJHwtvMv6Xaivg4+ntv0aHCeRHpGt2lpSHb0cvfB1EcJXWYNVECyubzvdefs121tFxrk6uLLkwiV8OevLTotOqqqy4dWLSXl+FIbFD0L+zjb7aRQNgwPbrqy5IW8Ddfo6/s7/m21F2zp1/DOJbhW+ampq2LZtG3fffTc6nQ6dTsdzzz3Hrl270Ol0rFy5ss39nJyc8PT0tPuTSCQSiUQikVhZl77YslxfLyI78porAejl0xtfszH3tb+cy9Tfr6RBoxBnVLhrzhc9PdWzj5aIrxZ/Lv9EmPFfuOl3mGhjZp80F675GSLHCPFrzcv247Rc7MVMOL55BPaGR7NhypPHt383sGK/faWxQx0Qvr7fks1lH24UKV9mRsb44ufmSFldM9d8upnpr6/h+6NUQkwpqGZffhU/bMshpaAadycdXi72Pk0tqYohR0QnTUho29uoO/n0+uGMiPYlwMMJDycdT8xOAkR6XEtEUO9gT0slxMNlVuEio7SOsjqrcfamjHJLqmNMN0Z8tXCkkb1Ooxw11bErcHHUWkz7W6ooZpWJcz6amf/sfsHE+rvhqNXQx1xhMl9vEznl4gPuATDtGYgzF2lr8fKyxVxlsVj1pgL7a9dhUUI40WgUltwzjt/vm8CdbXiyPbVwHyv2F7F0jxCehpvN9+uajTQaTDD1KZj9f9YdIkdbo7waO2ENlJ8Mbw0SkaFt4FqV32b7SUl1NOrFDQRbSlLgr+e67BBTIqe0aqs3iM+Th5OHRfBrifj6cNeHzJ4vonMDXALwcBCvQZh7GI5ax1ZjAThqHXFoyxfuGFRXVjC27k+SDCnotn2MYelj7fY9UviaHTO7VZ8XNr9ARWNFq/azgW4Vvjw9PdmzZw/JycmWv9tvv53ExESSk5MZObLr8lolEolEIpFIzhYKC5P5vM568fXX5jeprSkgzSiiPkJ9EwhD/MjO0KqWfgNdgnA8nnQYSefQmH9itwhXQ2+AMXeDsxfETYHp/4GrfwFHV9E243nRL93mpnBtCRTuEcvR445/LtpudzbpFJsyRNTEuQOEmX9qUS15lQ1c+sHfvPHHIfRGkZ6bXlLL2JdWcvmHG3n81z2YVLhgUChbnpjKpsemMu+WUbx/jfDZSiuuJbW4lsd+3cPvewtaHbOqXs/F7//NBe9t4MWlIsLmvmnxbHpsKucPCrX0c9KJqLpADyc7u7RBEUf4PPUA/cO9+PH20Wx4ZAobH5/KxETh8ZRdXm+pBtgr0J1os2fYNZ9uZn1qKUXVjSxKFsLFiGhfRsX6WsZ0dtAQ4ulMdxNlk7aoKLD72RntRlx1JYnmdMZrPt3M9sMVFjEw6ijCl06rYf6dY/jjgQmMND9XWU02/W09vvzMhvnlbUQb1QpBN1/1Y0JCAP8YZzU0HxZtHUNRFBx1GsK8XXjsnN54OusYHOnd5twGR/qgM6evVtSbhUzb7+/IUdZqj+abHx3i98egIhOW/Mu+3Rw95lFbirO29fvkpKQ6lh4Ckx6cPOH2Ddb2lu/WLiDcI5yRwW3rEj5OPq1SHd9Ntnoy+jj78NmszxgWNIyXxr/U5hjHQ0OzkR+35pB92P69VltwqJ097CtGXtvnWl4c/yJuDvbv/bTKNB5d92iXzfN0otP/CWtra0lLs/7QyszMJDk5GV9fXyIjI3nsscfIy8vjq6++QqPR0K9fP7v9AwMDcXZ2btUukUgkEolEIjk65eVpzN/wPD+UbAOt9cr88eyFkL0QtAoaVSUqdDhhez3YY7S/sxvdRkqHpBtoifhqMKebRdt4vigKjL3Hvn+LX1BTNegbwMEFNr0HqBA2FDyCu33KPYHBaGJrpnhOrh0VxZLdBRRWN/L1xsNszapga1YFjjoNd03uxfur08mrbLCYo4+I8eWNywfZRV6NiPHl7SsHU1TVyIHCGn7Zkcs93yez9B4PO6P55fsLqW8Wht16owFHrYZLhobj4qjlufP7YTCpzOlvrarpoNUQ4O5EsTllLsa/+6Ok2sNRp8FRp7GkCtY0GthxWHyu4wLcMKlWYfuaTzfb7Xv58AgGR3pz7tvradAbGRTh3W0VHW1JCLaKMzH+brg69oz4mhDsYfFuu+KjjTibhcxo/6NHm3m7OuLt6kiEOSrtYI2N6ONsY4rfUimyLINWmKsiVqluTEkM4MLB4XyyPhOAgebU2SO5bWIct06IZWN6GVd9Yn3tBkV4ozeamJgQgI+bIyU1TZTVNhPi5QKONqmqvrHgEyVErIqsjgvkxqbWbWHDYMh18Ns9ONcU8uGsD1FReX376+wuERFXbaUEdjtF5kIgQX0huB/cuwveGii+W2uLRRGPLuDREY/yc+rPDAkcwr/WWAXBQNdAS8RXdXM1Nc32Eao+Tj709u3N57M+75J5tHDTF1vZmFHGFX4ZvASUqp74K9V4G8tA3wgOrYXJAQEDiPOKw0Xnwj8H/xONoqGXdy92lQgT/tkxs8moyuDh4Q+32vdsoNPfQtu2bWPy5MmW9QceEKaZ119/PV988QUFBQVkZ7cfZiyRSCQSiUQiOT5eWnozy4zldqKXLTpV5cGgCQQE9iXBM5rfK+yFrxj/Pj0xTYli48elc4GgY9zwdfIUFRiNTeJizisctn4mto3/19H3PcnUNOq54fOtRPm58uJF/TlcVt+mkbiqqvywLYe6ZiNeLg6MiPYl2NOZwupGO6P233blc/GQcBbtsqZbDYrw5sWL+reZbnjeQBGxZTSp5FXWsymjnAU783hwZqKlz5Ld9lFg5w8KxdtVpCR5uTjw3lVDWo3rf4oIXy24Ourwd3eitLaJzWbxsFegB7EB7ny7ufW11/h4fy4aEoaiKKy4fwKHy+oZGNG6smF3kGjz+h/N1L6rsY2c0htV9EbhBXe0iC9bWp6fFYdNvGJ5q9m851oivqpyWosPjZUAVONK3zAvUYDg9tFoNQruTu1fciuKwqAjIr5+vXOM5b3uZxa+yltSVxNmwfBbhJiuKEL8ylgN5W2Ice3hekTKYtxU4QuYtV6sV+czJEh8Jmwjv+K84zp+jK4iP1k8BvVlS2Y5Hs6+JPkniuq4eTug1zRY8aQQ/ZLmHPdhevn04tERj5JXm2fXHugaiLezN9Ge0WRVZ/F3/t92232cuz4adG9eFYbMDSx0/IZ9VVGgg3ynOFya9uOmNFFVmIlXRFKr/Ry1jvx6/q+oqGjMN1/ivOMswtfIkJG8NP6ls9bcvtPC16RJk1Bt7iwcyRdffHHU/Z999lmeffbZzh5WIpFIJBKJ5KxnuaGMlhwsL5PKDJdwfmoSP9RfiDyPiUNux9NLGCsPCB8HFfZGuDEhI3p2wmcrik1al2/MsY3pFUVELlTlQF2J8LVpqhKiWcKs7p3rCfLVxsNsP1zB9sMVrDpQTEW9nqfm9GFyYgCxAe5U1etZvr+QRcn5rE8T6VjXjIpEo1EI93GhsLqR0lprBMqBwhpu+WobzQYTQ6N8+Pn20R26UNNqRLXFTRnl/JlSZBG+GvVGS3rlx9cNI8TLmaSQY/sHG0zWiqhBnp2rGtldRPi6WJ4rRYEBEV54Ojvw4bVDue3r7XZ9JycGWp63rqia2Ll5Wo9lOsp1Y1czKSGAd64cTEKQB9d/toXCalH0oKOVLAdH+BDq5SyqPJr1nsziSgxFNcQHeYBbgPhMGhqgpkC8CF4RoNFSX1WKKyLia7L5/TUs2rf9g9ng6qhj2b3jefCnXVw4OMzu/e7rJgTaZXsLGBPnh06rg3OFz1duRT3l9b4MACjP7NCxAGi2rxqJR4g4F09z2m91vjC+VxS7SoZBrkEdP0ZXUJpq8SEr8RnCFR9tRKMo7B88EMfSg1CwC6rzYPP74u/ZqhM+ZKBLIFpFi1EVEaKBriKibEL4BLL2Z7HYxlsTul74qm82cM/XG/nC4X0iNSUM1AhBU+8WTJG+lFg1h4LDBy3C19ZNa/Fcfg/Fg/7J+PNvRlEUFBux1rZ6ZJBr0FkrekE3e3xJJBKJRCKRSLoOf+u1OJE4oLURWKYOv9ciegH0Sziv1f5hocO7dX4SM7ZCl09M+/1scRMeTnwyFVa/IJYDkzpezfEkYDCa+Gy99YK7ol4PwH8W72fq62u45pPNjHtlJQ//vNsiel02LJwHpgtRKtQmGshBqzAwXETc7MmrQqdReOHCtqO82mNyYiAaRYhn2WX1GE0qP23Loclgwt/diWlJgfQL80LbgXS/Rr31w3aqXCxG2BjEJwV74uksfPzairAbHXeSKvCB3fPbkm7YEyiKwtyBoSQGe/DLnWO4d2o8b10xqMPG+hqNwqx+IuXVoIjn9t5N7kx/Yy01jXohDrl4i847vxYpd8sfB6CiXLy/FRfvo0Z4tUdSiCdL7hnPP8bH2rW3CF/ztuTwk01kJMCcd9bzXrIQaKjohPBVe0RFwpZU6hbhS19nSd0sqrMWo+jxz8HuH8HQCNHj+bFxOCYVDCaVN5LN//fK0kTUVxfioHUgwsP6f7RF+JoUMQmA1bmr7fp3tfC1OaOc2TU/E6kpsWs3uQdT7Sxen8oC4ftVUtOEaelDJKqZjN/5AKWlrX3ebKP0Ws7lbEUKXxKJRCKRSCSnCQab6w4DKkEuAZZ11yO8Ttzcrb5QM7U+zBv+NLo2fEEk3cCREV8dwfb12/uLeAzu33Vz6gb25FVRVtfcppCkqrA+rZSaRoOlbUSML69cMtDS31b4Sgrx5Iax0Zb16X2CSAzuXCEGHzdHi+Azb2s213+2hacWCo+gkbG+nbpwb6mo5+p46giPtr5lw20M08OPqKKYGORhl254Mnh6Th/83R3tUk57kjBvF+6fnsD5g8I6td8As/h6p//nJM/4kd2qEA4enb+HJ37dg97RHC247jXxuPkDABqqRVShk3vHorw6im3l0Q/XpHPtp5u589vtqKpKZb2ew6o5CqszEV919qIKTub3lYOL1cy/WqQau9t6ivU0lYcBUOOm8tvuQktzhmr+31aWZikqAAh/xC4gyjPKstwS5TYkcEibwpG3k3eXHLOFtMws7tItbNWu9QzFYBbkmkvFa711XyrDlYOWPgdXfNhqv2jPaMuyFL4kEolEIpFIJKc8jQ0VlNsIDNdGz+HKKS9zoWMQ7yfd2uY+3w57kju9BvDyFX/Sr8+lPTVVia3w5RPdsX3aMmk+BYWvyvpm7pm3k++3ZLPBHMU1Lan13B21rS8zLjhChAjztgqxScGezB0QSlyAG4oCt0yIPXL3DnHpUHFx+P7qdEuUGcCYTkZAPXluEreMj2HBXWOP3bmHuGFsNBMSAnDQKpxzhBl/C1eNjOSXO8f0iIn90bhpXAxbn5jWobTSU4n4ICH0bC51IsO5r6V9ye4Cvt2czc4WzUjraN2pthhDnUgJdPXq2ki7/EqrmKMC61JLWbrHWqwhRzXf/GishKaa1gMciaHZ4kdmIWSQddnT/Bk1C1+vTHiFJN8kPp/ZtebtHaJCCF/7Grw4UFiDk07DHZPiyFTFe18tSxPp4S3UdaKy5VHwcrJ64bVUstRqtMyNnduqr+YE5JSqBj11TdYbA00GIzVpG3BRmqlyicBkM7aTbzhOwUJEdi1PYeOhPFLW/IBGsaYSa9uoNhrmHsZlCZdxVe+r7M7rbOTUqm8skUgkEolEImmT/EKrX9dnA+9n2IAbUDQanrvyz3b3GdD3cgb0vbwnpiex5XgivlzbuGA+BYWvn7blsmhXvp35/Nhe/lw6NIJ/fLUNAGcHDQvuGsvhsnru+GY7cweGMijCm8uHR9iNZR/x5YFOq+H7W0dTXNNI39Dju0ib2TcYjQIm8/XgwAhvZvQJ4uIh4Z0ax8fNkSfOPbWKQXg6O/DVTSNoMhhxOiKF8Lnz+7IwOZ+HZiQeV6pdd3CqpIh2hrgAdzSKECX25Ve32l6tmtMmjc3Wxqx1wpMP8PYNaLXPiXDD2BhWHRRq2+Gyekt7Wa04fh3OGNGgxSSEL6djRPrVm8UhRQv3JkPOFoidZN3uEQxFe4WHGTAocBA/zv2xq06nc1SKog3fHRTfpzeMjeaRWb35a3cWpjoFTVM1lNi8RnXF4B3R1khgMoFqBK1D29ttcNVZU2MdNNb+lydezqd7P7Xr62grgHaCV5cf4IM1GSR5G1mYsBzNkGu5aYXKkMK94AD60GFo0q2iXq/+I6iqjIfd/6VP8x4OfzOTf2nEdgNadBhxri9odRxFUXhq9FPHNcczjVPjW1EikUgkEolEclTyS0TKVoJJw/BBN53k2UiOisl6Fx+/Xh3bp7H1RTZBfVu3nWTWpdlHVXg465jRJ5hgL2cOPj8LjaJQb67c2DvYk73/nomLg7ZNEeTIVEeAAA8nAjyO30zexVFLmI8LOeUiUub8gaHcNK6D4uNpwpGiF8B1o6O5bnR0z0/mDMPZQUuUnxuZpXWWiEZbqmjDKL9oHw7N4vPr59+16WQTzYb9/5xnX6gkq6zOvKTQoHHD3VQjvkNafLrao8Xfyy0AvCPFny1u5vkfmQ7ZnSR/J7wQo0Zb2wxNFvFtTbH4nmiJ5hzaK5T8XX6Ec8Tr017El8kEH0+C5nq4cxNojy6BXJJwCd8f/J4hgfbVXkPcQ7hj4B28v+t9wtzDCHELYVbM8RUfmbcxjcW6x0iqz4ZkIPlrNjR+y3UOWQB4RA0CY6kQVWMm4BTYiwB/I1W446XUkqRYRbF9nhMYWL0Kj6aitg4lMSOFL4lEIpFIJJJTDJPRgOaIH+crM5YAEOtwdqcrnBYU77cue0e138+W0MGt244VvdFDLEzO49vN2Tw4I5G/zWLAfy/sR2ZJHdeNjibYS6QstggyXi7WiDdXx/YvN2yFr95dmBIX6+9uEb6i/HqumqHkzCAhyJ3M0joOFLZOHaxWWwtfhoocXE21oEBIUEir7SfKoAjvVm2Hiqxzq1dccaemY6mOLYKWWzuRaW7+5n5dkzZ4THK2woI7xPINSyCoH5RnwMeTLV3y9G64OGiJ8RfPfZSfG9tMCYRrS0V0rYMbNNe0Nu1vofSQqAAJQkxrLyrMTKJvIksvWoq/i3+rbXcOupMLel1AsFswGuX40hyNJpUBzckkOWbbtS9xfJy+GpHe6RTaH3rPgv0LYZR4fhSNliz3IQysXWu3X3PCHNi2Cj9jO+cvAaTHl0QikUgkEkmP0dhQwZLVT1PRhhdHCwX525ny5SCenTfD0lZaksLCRlHR6/J+MtrrtKKj6V4Dr4DZ/2dd1506hQj+sziFLZnlXPbhRgwmlVAvZ64aEcmTc/oQeQLCkpeLA29dMYh3rxpsZ+J9orRcIIMUviSdp60qmS0oLVUdbWguy8YTEYHl6dP11TTbioA8aCPK1apmAbnJJmpUVWH9m5Cy2H7H6jzx2F5kWIsg1lMRX6nLrctfnAsvR9mJXkaNA6DQO8TDUhQj3MeFh/S387TPy3D7ekiae/Q5526xLpurVR6LCI8IXHQubW4LdQ89btELoLpBzwzN9lbtLaIXIATAwN4w6RFwtt4UCL3idXJ8RmHEGvUZOvQcALypwdhYC0BacQ1NBqN1vJTFUJxy3HM+E5ARXxKJRCKRSCQ9xI+rHuHVko24Zs7ngdApXDL1/9Dq7D1CXv7rHsq0Cr80F/Csue2btU/RrCgMNDkwdMB1PT5vyXESPKDjfbUOMOIW+P1RkSoZM6H75tUJ6psNlNY2WdbDvF14+8rBXebf1Nmqex3B29UqooX7SOFL0jnij1YR08Ub9PZNSuVhXBXzZ8TZu8vn4+ygxcvFgaoG64EPFddalqtafMdsha/sjfDnM2L5WRuxp+pUE77+aHeTydmHD5qFqNPHJiI03McVPTpW1MXzXFBf8vTuhEH7UWo5m63LDRVdMOkTo6pBzwTt7vY7THkSPILa3BQQHg/3LkdVVb7/5Uc8vP2ZFRRKjeqCh9JARWEmaUXVhCy5gRXhVzDXJwcOLLF60v3rULtjn+lI4UsikUgkEomkh0guE3dc6zUKzxeuInbvN3Z+XarJxN+GKjDf2TYamjGpBn6sPgAahZt7X4WikQH7pzyDr4WdX8M5L3d+3xuXwZaPYPp/un5enUBvNKEAe/PExbSbo5b5d44lNsDNrorgqUi0nzXiy9mhtR+WRHI0EsyVHVsI83Yhr7KBCF8XtC7ecIQdn0uDjam4U/dUsTzyM3fIJuKr0ugk8rhsUx3LM63LRr3V1N1crXFrhQuR1Y18si6D1OJaPrhmKBX1zQS6+otYop5IdWyogILk1u0RI+HiT/nfjkb+b8UhAEbFWiPpwswp0kU1jaw6WMyGXXU86QBUHm49FkDuNuvykRUtTwJVDXoSMYuRwf1h0NVCaNz1PVzzCwQmHXMMRVG44hJr4ZoiTQAeajbVBRloVr5DlKaYqPy3If+IHX+4Bq74Dty7tgjD6YAUviQSiUQikUh6iFR9FTYZClTU2P8qzcpeS4PGGklTXp5KbX0JNRoFF5PKxBH39dBMJSfE3LfMd+2DO79vxAjxdxLJrajnio824eygZWqSMLseF+9PYvCp4Tl2LOYMCCE5p5IRMb4neyqS05BYf3vh66ubR/D1xsNcOzqKbctToR0P8QadJy7HME4/XibE+zN/Z571WHprGlu1JdXRRvhqrrMu15dbo3yqRcr8vAMm/nh9DTWNohDHMwv38cO2HJ4aqudm6JmIrzxzup9vLAy9Af54GsbeC9OfAyC1WBj6zx0YytyB1gg1f3dHnHQamgwmXltxEAdTgthwYAnk77T3SzTqoSzNun6SI74WJufx4PfbSHU2R+9d/xu4+IjlqU8f97hFjpH0asqmMScZN6Wp/Y65W1Dn34Jy3YLjPtbpyql9u0YikUgkEonkDKG+vpTDGhMAvU3iJ1iDvtauz+6M3+3Wn1p2E1sPLQAgCm0rw3vJKYpGe3yiVw+TWVrHwuQ8VFW1a3/gx13kVjSQVlzLh2syABgd2/XeRd2FTqvh2fP6Mrt/1xuNS858HHUaBpoN5R+f3Zu4AHeePa8vcQHuOHtYxdQm1YF81bre7NR9n5GXLh7A2ocm8/plA1ttq2lL+LK9qVJvE71lTnUswM8iegH8sE1UCfxoe411H5OpaybfHi2RWOHDYfTdQgSa8pRlc2apEO/mDLD/HCuKQriPOOe9edXsVONZbBwFqJA8z/4Y5Zn2VXYbKrv6LDrF/B15uFNvbXDsmpsJdQGiAqWasxk3Q3mbfd4xXECqQyKGmccRiXwGIH89SSQSiUQikfQAaZl/oSoKviaVcJ0HB0xVNDTXYTIaSEldRGjgQL48vMzutuQG6tlQ8BcAkQ7dk0IjOfs4VFTDk7/uZUuWuECqbTJw9UhRfbK+2cDWrNYXThcPDe/ROUokJ5MPrhlCXkUDw6Ltowbdva0pYg04kq/6E6qYPy/tVUrsAhx1GiL9XMkotd4smZwYwLbDFdQazB5fjTY5mFXW6DBL2qKqWlIdC9S2oyHLMf+fMRlEWqBrN0ZN5m4Vj2HDxM0CG19DVVXJLBHCV6x/60qaAyO8SS+xRrX9aRzCHO0ma/XGFkoP2q+fxIgvVVXZnVuJuyIqzjYqzjh30c2sgKRxkPs2ETXJuKoNYA4cX2wcyRyt8DjLDJxB8C0f4+DieJSRzlxkxJdEIpFIJBJJD5BdsheAOMUZF4344dloaGDFhv9yxeZnmPDbBaRq2r/DHuUqo1ckXcPj8/dYRC+Al5cdsFQASy2qRVXBz82R7/4xkig/V547vy8ezl1XdVEiOdUJ8XJpJXoBuAXHWZa9lTpKtVaxy9m7+03DB0f4EO3nynkDQ/nw2mFcPTLKkupobBG+Gqsga511p5aIr8ZK0AuxqEBtOzpNj45GnTkKqbvTHc0i1Q8FAXyyLoOy2iY2ppeRV9nA80tSqGkyoCi0WTn2zkm9sHEFYK8aLRYK99hHqpUcIXz1kMdXWnENl7z/N6sOFFvacisaqKjX44kQvpq0rQW94yVpyHiaVR2e1KFTTNSrTqwY/zOh132KUVVoVB245aKZeJylohfIiC+JRCKRSCSSHqGkVtxpD3TwwFnrCAZoMNSzs3CrXT8/o0ofnTvr1Dq79ijv2B6bq+TMJa24lm2H7aMeqhsNPPDjLu6bGs9Bs2l2YrAHY3r5s+ahySdjmhLJKUmgrw9XNT/OBw5v8ItxAheP7AXbNwDg5BnY7cf3cnVgtc1n8sEZCby4UQhDjbWVuAF8fzXU2Bju15VB+kr4+x0AylQPmrAKIDqNwug4PxqajWw7XEGd4o4zNUJA6y4aKizC2nObjNSRwvNLUlp183DS4aRrXaCiV6A7r1wykNSiGr7fmkNGQygmrTMafR2Up4N/vOjYIny5BYjj9VDE15d/H2bb4Qpu/GIr25+chp+7E7tyKwFwNwtfel3XCV/OLq7s8R5P/6pVABx06seMqdMxGE3c6vcFGo3CB6GnT7p6dyCFL4lEIpFIJJIeoLhB/MgPdPLGqIo70g2GBgqbrD/Efx33GlGR4/jnd63FhqjAAT0zUckZzYr9hQDEBrgxZ0AohVUN/LgtlyW7C0gvrmVMnD/AaWNkL5H0JNF+bvxt6sfQpg/Ro+PGIBsvrW5MdWwPnVaDg6sXNEJzXSVu+gb7aC8QEV9fP2RZzVED8HNz5LXLBvLH/iKemtMHZwctC5PzROqk6owf2HuGdSVVefDzjQDUOgZQ1+jSqkuLef0cG1P7I7nEnH69KbOcXTl6qr17412WLLzD/ONF5FfGatG51zTYNa/HhC/b4gM3fL6Vn24fze7cKhzRc652EwDNWvf2dj8uAmc9BD8I4ctrzvOAeH98es8FXXqc0xUpfEkkEolEIpH0ACVNlQAEugVRaU63aDA2kWuoBQ281/sf9IqbAUCCexgbalPt9o8KHdmT05Wcoaw7JNKebhgTzXWjo9mRXcGP20SltwOFNdQ1CyPo3lL4kkhaodEo3DYxlg/XZODprAMvG+87N/+TMidnd19oBGNDFRTta93hiLZcNZAYfzcmJQYyKdEapdZiGF9pdCIKoNm++MoJU1MEX8y2q7KYRWth67rRUTx2ThJGVcXNsXW015H4uYnotQLvIUL4ylgFg66EvG1QVwxOntB7jhC+MlYLg3sX7645p3Yor2u2LO/Jq2LVgWJ25VTyvsObTNWKapX1SusUzhMhKGksJdPeRuPsRuyAMV069pmA9PiSSCQSiUQi6QFKDCJ1McA9DGedMwANxmbyEHeGwwP7W/reMv0dznOwXpB4mlS8vWN6cLaSM5G6JgPbDgtvr3G9xEX64AhvHj2nt6VPTnkDGgXGx/d89IpEcjrw4IxEHp6VyJc3jQDPMOuGkxDxBeDu5QOAf+VuOCzSLrN8xvKs/jrR4cBiu/45agDRbRjGh/sIIabS6CQamrpY+NrykZ3oBXCw0btVt+fO74eLoxZ3Jx2KorTafiQ+rkL4OuQ+SjSk/SmivVL/EOvx08HdJg3119uPa/qdoaS6kTglDx8XLc40caiolqK8TIvoBaB36PqbCwHjrsdv2CVdPu6ZgBS+JBKJRCKRSLqZ/QcWsEMRd4ADvWJw0YkLjILmSurMDr1hIUMt/T08w3jusmVoVBWAKBxQNPJnm+TEWLQrH71RJdrPlRjzha+iKNw+MY5bJ1g95CYnBhLq3Tr9SCKRgINWw52TejE40sc+4supa1PXOoqrj03U1B9PA5DuEE+J6t1m/1w1wPL5tyXA3QlHrYYaVdyYaTfiqzIblj0CZekdn+TBZbDu/1o1V5hcCfRw6vg4beDrJgpvpDgkgaM71JfB4vugSBSUIWIU7+2yMbw/tExEfXUjg6r+5C+nh9ipXk6y063s3buDuca/7PrEhAV36xwk9shfUBKJRCKRSCTdSHNTDddtfNKyHuDbC1cHcdGRpjYCEGhUcXL2sttPq3PE1/xbPdLRu0fmKjmz+WrjYQCuGRXVKpLiyhGRDI3yoU+IJ/dNSzgZ05NITj9cfKzL7t1f1bEt3MKSeER/i13bYv0w/jQN4UfDRPRe0Xbb2hO+NBqFMB8X6sxVItv0+DI0wZv9YfMHsPYIIatwr4im2vUDmG/aWPjtXuuyXzz0mk6u5xA+NMxlZKwfn1w3DIA3Lx/UkVO2w8ec6lhSr8KM50HRwI4v4eBSALJ1kby6vozRje9gdDeLTWl/dvo4HcVoUhnZvNmy7qzo8SrZznnajXb9nN28u20OktZIjy+JRCKRSCSSbmR/6m802dRdD/BPwtksfJWb2yM0zm3u669oKcVElFv7Br8SSUeorG8mpaAagIuHhLfaHuPvxi93SF8YiaRTKApc+YOIggruf+z+3UCEnxs/GCfTpHXnFc+fWBd6E7/u9gXgYcNtJF4yloF+JnhFpMsXqT5tCl8AYd4u1Faaha+2Ir5SV1iX87bZb9vwJuz5SXhpeQRD7ETRbmiC2iKxfPc2S8XFhz7aRElxGSNjfJnWJ4jMF2d3KLWx1fmbUzQ3Z5ZhvOQGtDlbYNd3lu2LCryAcgrwozr+Inx2/g+2fgI6Z0ia0+njHYuK+mYClXK7tkmaZOI1efYdnaSPYk8iI74kEolEIpFIupFdh1dblj1MIrLL5YgfvDHObZcZj3HwBqBvyLDump7kLOFQkbiIDfdxsURISCSSLiBxFoy89aQdfmC4NyNifFnQPJybvD/j4XT7CsCVDXpw9aV2yn/5wDCHA2oE0X5tC18BHk7UYr4R05bHV7VNFUt9o/22yhzrsq2hfovopXWkzCmCRr0Rk0lld24lAMOjhUh3PKIXwLSkILxdHcitaODPlCIYfafd9l8PNlmWywLNPmDZG+GHqyFz7XEd82gUVzfRSxEilynpfADO0WwBoNx3kLWjSd/lx5a0jxS+JBKJRCKRSLqR3RUpAIzEmc/HvgSAi+MRwpdnVJv7PjH3az7udzfjh9/b5naJpAWjSWXFvkLKapva3H6wUER7JQbJKAOJ5ExCq1F44cJ+AKxPK6XMXFFwYIQ3AFUNQmD5QXMuLxmuonewJy7tVEv0d3ekrsXjq61Ux/oy63J1LhiabdZtRDFbE/uaQgD0LoGMeXkVQ/7zB5d9uJG6ZiOOOg1xAW2LcB3FxVHLZcMiAFi2p0BE3sWLCsmG8FGkl9RZ+hZ4DrTfOWvDCR27LUoK8/BVajGhoOk1BQCtIlI/HUJsogK72WdMYo8UviQSiUQikUi6ieamGjbrKwC4feBdJCaItApnR0+7fjH+/drc38srklFDb5PG9pJj8t3mw9z69XZu/Xp7m9sPFomL2IRgKXxJJGcacQHu+NlEckb7uRLiKQSsqvpmdudW8uafhwDh8dceAR5O1HGUVMe6UuuyaoIqc5SXyQg1Rxe+spo9aTKYqG82su2w+L+YEOSOTnvi/98mJ4qqjevTyjCZVLj0C5jyFLsGPGXXr9JwRLRrecYJH9sWo0ll9/pF4liOwRDQ2267e1iidcVXVmruSeSvKIlEIpFIJJJuYs3Wd6jSKAQaVQb3u8rS7nKEkX10yPCenprkDKPFuH67+YLSlo3pZXyzKRuQEV8SyZmIoiiMiPG1rCcEeeDlIqodVjXoeWrhPmoaDQR7OnPB4LB2x/F3d6L2qBFfpfbrFVnQUAGfTgeTwdpuW/HRLHylNbSO7IpqJ+WyswyJ8sbFQUtpbRMHCmvA0Q0mPMjGWvuCA9WNeiGKtdBS+bELUFWVG9/5jZvKXhPrvWaCd6RdH8UvHm5aAWPvgxEnLz32bEQKXxKJRCKRSCTdxMKM3wCY69Ubrc56p9nFyduy7KiqhIYM7empSc4w6puNlmWjyb6iWkukh1ajMDLWF4lEcuYxZ4C1CEqMvxverkL4qqzXk2aO+Pzw2qG4O7Vf387f/RgRX/X2pu2UpcP6NyDPHGmqMY9dnQvN9aBvRE1ZCAhT/QdnJDDvllGW3cN9XDpziu3ipNMyyvzd9vveAuqahAj3d3qZXb/qBgP0vRDuMwtepYeE+X4XkFFax8DihbgpTWQ7JeB30SvgHgxamygzvziIHAnT/w0OXXPuko4hhS+JRCKRSCSSLqa8PI2cnA2sN4mLjfOG2Jvtujh7W5YTVAc7UUwi6QjJOZU89NMuMkpqUVWVynqr105BVYNluaHZyM7sSgAW3jWWEC95sSWRnInM7h/MNaMi0WoUZvQNxtMc8ZVVVkedWRhPPEaqs0h1NEd8lRyET6bBnp+tHVpSHSNGise87ZC5zrrdZAB3c5TVwaWw4U2UrPUAFKs+/GN8LKPj/PjyphGcOyCEOyf2OrGTtmFcfAAAb69MY+abazlYWMPf6WUoCszoI+ZU3Wg2lPcKBycvMV/btMwTYFtmGZfrVgMQOftB0DmBRgNDb7B28m4/zVTSvbQv90okEolEIpFIOk1x0V7OW3oFdRoFFIUBJh2xMVPs+ri4+FiWY51kBI6kc+zMruCyDzeiN6os2pVPvzAvy4UtwL9+3IUKvH/1EPblV9NsNBHq5UzfUM/2B5VIJKc1iqLw/AX9efLcPjg7aDlgLmixJ68KgEAPJ5wd2ja1b0GkOtpEfOVuFX/9LwFArS9FAfKDpxCasxkOLLaPDHP0gOH/gFX/hbX/Z5f+WO/oYzn+xIQAJiYEdNGZCybE+1uWcysaeH7JfgCmJAbSJ9STFfuLqDYb/aMo4N9LCHelqRDU94SPn5KaxuVKKSY0aJLmWjfMeglc/YTYJm9ynTSk8CWRSCQSiUTShazb/bkQvczMChrRqo+zs1XsivGI6JF5SU5f6psNrDpQwpI9+ezKqSK/qgHVnM3YZDC18vXanCnSkR7+eTd9w4Sf3Kg4PxRFQSKRnNm0iEs+rkJkKaoWqXwRvq7H3NfXzZF6xbntjSYTan05CnDdeh/+dMIqeml0GEMGk9L7bhIGTcBx0/tQkmK3+36Pccd1Ph2lV6A7kb6uZJfXA7AuVUSnTUoMQG8UX5jVjTY+ZH7xQvgqS217QKNeRL0F9RVC2TGozdkDQKNHFK6ONs+1RguTHj2OM5J0JTLVUSKRSCQSiaQLyai0T5sY1+fKVn1sUxv7BEtje8nReWnZAe76bgdL9xSSVylEr9n9g/n65hFcPTKSe6b04ufbR3P9aPs0mr8OFLN4l6i01ltWc5RIziqGRftgcw+GiA74aWk1Cg4u7USGNlaiUUVkabYaRL6jTVXCwdfyn6C3mLPEgVkf7aZq+mt2u05oegNXH3uj+a5GURS+vGkEU3oH2rUnhXha0j4tEV8gIr4ASttJddz4HnwwFn4/tmhV22TAs0aMow1O6vzkJd2OjPiSSCQSiUQi6UL21+WBzcVGdOSENvv9y28k+XUFjB56Rw/NTHIqYTSp7M2rItDT6ai+W3qjiUVm8crXzZGn5iQxLMrXEr0xPt6aLpRW3NqMOqO0Dui66mkSieT0INDDmZExfmzMEAbvHYn4AnBw94MqmwbFnB5p9veqVl1oxoEVmrHcQKbYFjGCdX+VAJBRUsc7OTE8aTNEvurHGM92Ism6kBh/N+6dGs/KA8WWtsRgD8rrhAeixeMLwD9BPLYX8bVvvnjc/AEMuwkCEts9bkpBNfFKLgBOIf2O/wQk3YaM+JJIJBKJRCLpIoyGZg6ojQB4m1ReiDwfRdP2z60b5nzC45cvaXe75MzAaFLZllVOQ7MRVbVWW/x8Qybnv7eB0S+uZNXB4nb3X3WgmMp6Pf7ujmx9YhoXDg5v9wI2Psga1RXiZX+RGeXXsYteiURy5nDNKBEF6uKg7bCnlrenB58bZlobHMzfHebUxRxVRFR9Wjva0iXTpS/pJXWW9a+3FtqNaUBHYA8IXwADwr3s1j2cHSwRXzuzK1lzSAh0+MWLx5JDIq3xSFytnmEcWn7UY+7Lq6KvJkusBPY+nmlLuhkZ8SWRSCQSiURygpQU72Pe+mfp5deHWo2Cp0ll1TXb0Dn0zA99yalJo97IP77cxvq0Uktb31BP3rh8EL/uzLO0vfVnKpMTA1vtX1LTxCO/7AbgvIFhaDVH95mJD3K3Wfag2WCizBzpENnBaA+JRHLmcO6AEMb2mo6zg/aYxvYt+Ls78YLhakZGuNKn4Ffh42UyQf5OAHaZYgHIMfjwv6DHKSwu4qvPRbRTbIAbro5a9uZVU+/qj2uz9bvvGF9fXYaiKHxwzVBu/2Y7V42MBKx+ZyCKf3x503DSitw5z8UXpaEcsjdBzHj7gerLrMv5O456zKqMrQzQZGJUtGgjx3TZuUi6DnmLUSKRSCQSieQEeXH57Xxcc4BHskRqxEyXcCl6SViUnG8negHsy69mxhtr2ZdfbWlLzqlk9lvrWLK7wK7v8n2FVNTriQ9058GZCcc8nqezg2W5UW/E393Jsu7qKO93SyRnI96ujh0WvQACPJzQo2NRyD3mFhW2fgLr3wBgtxpn6ftKXj++0k+1rI+N8+eqESLK7BHdg+jR8m/9tQBcMjT8BM+k48zqF8zqByfx9Jw+ACQEuXPLeOFJVlrbxLlvr+feH/ZQGDxR7HBwWetBbIWvvO1HPV7fgl8ByA+bBZ4hJ34Cki5HCl8SiUQikUgkJ8g2g31VvTlJV52kmUhOJX7angOIqIsrhkfw9pWDibZJORwR7cuT5woj5P0F1Ty5YI/d/luzyi37d1S4CvQQYtfU3oHM7i8uwFwdO37RK5FIzm783UV0VGEdoDF/7yx7yLJ9jymWkTG+rfYbEePLA9MTOG9QKK6OWn4rjyS+8Ss+N57Dvn/PJNynZ6NOo/3dLIKfoig8cW4fnpnbx67PWtNgsXB4fesBbIWvymyoLbHf3lQLn0yHpQ8R2JgFQEPMTCSnJvLWj0QikUgkEskJEoyOCkS1q0gjDO5/zUmekeRkU1LTxNasChQFnjq3D8Fmz63aRgOP/yoErgdmJDAq1o8ZfYKZ8OoqKur1VDXo8XJxwGRSWZkivL9GRLe+yGyPX+4Yw9rUEi4ZGo5WUXBz0jKhg94+EolE0hIpWlqnBycPaLDe2MkyBXFQDWfN5YNYsDOPV5cfBOB/Vw+xCO0A5w8KZd6WHEDB29UBN6dTQ3a4emQULy07QJPBBMD6Sm8uB6jKte/YXA/6erHs6idEsNJD4G7zXXpwKeRugdwtxKguoIBHUAySUxMZ8SWRSCQSiURyAqgmE4UYANCoKu9MflMa1p/FqKpKdaOelAKRyhjj72YRvQAuHhrGtaOi+O+F/RgV6wdApJ8rfm4iyiK7TFxsXfXJJmqaDDhoFQZH+nT4+BG+rlw9MgonnRadVsM/xseSYGN6L5FIJEcjwBw1erCohjK91RvL6BbEpObX0WgdCfVy5o6JcfQN9STUy7mVcf7VI6Msy9UNbRjHnyQcdRoW3DWWc80i3dpi83dzfRnoG6wdG0S0LRoHCOorliuz7Qcr3m9Z9FDEvj6hcUhOTU4N6VUikUgkEonkNKSyIpNzF8yl2uzau/aCxXh5R5/cSUlOKp+sy+S/S1MYFiXEqqRgT7vtTjot/7mgdbn7cB8Xyuqamfvuep6YncSmDHHh9czcvrjIVEWJRNJDtER8ldQ0UezoiJ/5Pk66GgooxAa4oSgKigLz7xyDqtLKQ6xfmBdxAW6kl9QxNKrjwn1PkBTiyXtXD2HHi39RUKVi1LmiNdRDdT74mYWrljRHN3/wNot4RwpfudvsVpvR4ewt/b1OVeTtSIlEIpFIJJJOkJ7+B81NNQBs3vuNRfQC8PSMPFnTkpxkVFWl2WDiv0tTANh2WKQHJYV0LNrK1v+mZYwwbxeuGRXV3i4SiUTS5bREfAHU4mJZ3lwtIlQvGxZhaXPStV8t8sfbRnPT2Bj+fV5rof9UIDbADVCocw4SDbbpji3Cl6sf+BwhfDVUQPpKTLlb7cYr1QSAjPY+ZZERXxKJRCKRSCQd5Oult/FKyd/c6NaLBy75lWZDo912meJ4dlLXZOCC9zaQWlzbalvvIyK+2iPEq3UV0Pgg9xOem0QikXQGPzdHIn1dyS6vp1a1Cl8ZqohmuriD1Rn93J14+ggz+VOJWH93NqSVUaYNwJNMIXyZTKAaoV5E3BpdfNFaIr4Oi8d5V0L2xlYRRJ5qTc9NXtJp5K8ziUQikUgkkg5QU53HKyV/A/B5XRoA5fXWKk8eJvWkzEvSPZjaeT2rGvSc/+567v5uh6XP4t35bYpeAAMivDp0PEMbx5PeXBKJpKdRFIWHZyUC0IjV42uHKZ6tT0zDy8XhZE2tSxERX5BnMhcPqc6Dby6ENwdARSYAy9KbeXWT2furJeIre6NljFzVnwZVPEe1Dn49M3HJcSGFL4lEIpFIJJIOsG3fPMtyqCjgSHmjtdz5RyOf6ekpSbqJN/88RL9nl/PMwr0s2Jlnaf/y7ywG/nsFu3KrWLy7gNjHl/L5hky++Puwpc9z5/e1LA+M8CbQo3UkV1tcN7p1SmN8oIz4kkgkPc+cAaF8ev0w4pR8S1uZR5JdGuTpTmyA+H5NazJ7kJVnQMZqqMmHZPH/vkT14ucMs2RSlSuqPdpQoPryy9Bv2OsylJpz3umpqUuOg04LX2vXrmXu3LmEhoaiKAoLFiw4av/58+czffp0AgIC8PT0ZPTo0Sxfvvx45yuRSCQSiUTS7exL+YWcnA12bTkVhyzLpRoV1WSiorkKgH/6DKJfn0t7dI6SE8dgNJFWXIOqqnZtb/6ZSn2zkS83Hua+H5L5fks2BwqreXX5wVZj/Pu3/aQUVOPmqGXrE9O4bnQ0T8/pQ1KIJ+9cMbjDc4kNcCfjhdnobDzjBkV4n9D5SSQSyfEyNSkIvYM1VTvU98yKQE0K9kBRYEetOeIrfaV1Y3k6ACWqN0X4UOYQIlIgDyy2GyNf9ee8GVPo98hK4gdP7KmpS46DTgtfdXV1DBw4kHfffbdD/deuXcv06dNZunQp27dvZ/LkycydO5edO3d2erISiUQikUgk3U1pSQpXbHmW2StvRzWZLO05NVbj22ZFoaIyg3J9HQC+LgGtxpGcWuiNJjJK7NMRP16XybTX1/Lp+kxL25as8lb7Pjp/D7PeXEdtkwGAh2Ym8t5VQ+z6fHXzSEs0xE3jYlh273gi/VxbjXU0NBrFLuUxXqY6SiSSk8gPgfey2jiQOU3PE+7jcuwdTiMCPZ25fWIcqarZs6y2qFWfYrwBhWWMEQ1/20d1VTkE4ul8ZqR+nul0Wvg655xzeP7557nooos61P/NN9/k4YcfZvjw4cTHx/PCCy8QHx/Pb7/91unJSiQSiUQikXQ3uYU7LMs5uX9b2xvtBZGikn1UGIW5vY9bUM9MTnLcvLcqjSmvreHrTda0xFeXHwDg+SUp3PXdDoqrG3lxqWiL9HXl6Tl9uHiIvZHzkEhv7prci3MHhHD/tAQUBV65ZABDo3y6ZJ7T+4j3UlupjxKJRNKT6AP6cYP+EfaqsWec8AVwxfAIMtQQjKrS5vYS1RuAL2tHiobC3XbbVbfA7pyepAvp8aqOJpOJmpoafH192+3T1NREU1OTZb26uronpiaRSCQSiURCbYNV4NqdsZzIyHEA5BrrwKZqe2F5KuWqiADy8+hYlSvJyePNP1MBeGrBXi4bFo6TTouniwOV9XoAluwuYMnuAkBUNfv65hFE+bmhqipXjYzk4veFCNovzGpWf8/UXtw4LrpL7/i/cGF/ZvUN5vxBoV02pkQikRwPY+L8mLdFmLq3eGKdSYT7uILOmSw1mDiloNX2EtULf3cnUmvDqQ4cgWfxFrvtvm6OrfaRnJr0uLn9a6+9Rl1dHZdddlm7fV588UW8vLwsfxERET04Q4lEIpFIJGczlfXFluW9xckAGA3N5GpEClqSSahfRVWHKVdEm49nZM9OUtIpVFXF1dGqWq46UEJZbZNF9LIlyNOJb28ZSZSfqPilKApDo3z44dZRzBkQwr1T4y19FUXp8jSXAA8nLh4ajk4ra1BJJJKTy9yBoSy5ZxyvXDyAc/oHn+zpdDlajUJcgLs13fEIah38SAoRKee7I69utb0yela3zk/SdfTof9R58+bx7LPP8sMPPxAY2H5Y4GOPPUZVVZXlLycnpwdnKZFIJBKJpKuxNQ8/1alqKLUsp9SLilYFhTswKAo6VWWgq4jEyajKoN5sRO7rE9vzE5V0mJKaJuqbjZb1bVnlHCysAURK4xc3Drdse3x2Er2DPVuNMTLWj3evGoKf+5lT1UwikUiORd9QLy4bHoGTTnvszqch8UHuzDNOaXObg0eAiAoDtjiORnUUN0S+MkxneOP/UL1kgM7pQo8JXz/88AM333wzP/74I9OmTTtqXycnJzw9Pe3+JBKJRCKRnJ58vekwfZ5ezh/7WxvHnopUNlZalktMzQAczF4DQC9VS7Sn8F76rV54RQUYVdzdQ3p2kpJOcajI3tT+uy3ZrDC/HxODPRgV60dsgBu9gz04p598LSUSieRsIT7QnTWmgbzu9yxfGaaz1tjfss3f09XibZZb2UDWlWt5Q38x7xgupMnZX/6/OI3oEY+vefPmcdNNNzFv3jzOPffcnjikRCKRSCSSk0h5XTPNBhPBXs48vXAvqgq3fLWNz28YzuTep7YZbGVzlXXZnMp4qHgXAAlO/kT49obi9dSao73GOgejaGRa2qnID1uz2ZtXTVWDSGnsG+rJvvxq6puNfPF3FgBDIn1wdtDy1wMTMaki9UUikUgkZweDI0VhkrfzEoAEhioHmaDdw3pjX4I8nYnwFRFfueUNFBjDect4MTH+bmy4bwKOOvm//3Sh08JXbW0taWlplvXMzEySk5Px9fUlMjKSxx57jLy8PL766itAiF7XXXcdb731FqNGjaKwsBAAFxcXvLy82jyGRCKRSCSSU4ui6kb+/ds+Kuv1vH/NULxc2vc1Siuu4ZIPNmI0qbxz5WBssxxv/GIrAPdM6cUDMxK7e9qdpq62kJT6QktMfI1GQd9Ux4EaEd3V27sXkUGD4IB1n3ERE3t+opJjUlbbxCO/7LFrm9EnGK1GYXeuVdwcGSsKLimKglZqXhKJRHJWMTjSG51GwWASP1a2q4lMbXqVUtWLSz2crBFfFfWU1IoCfMGezlL0Os3o9Ku1bds2Bg8ezODBgwF44IEHGDx4ME8//TQABQUFZGdnW/p/+OGHGAwG7rrrLkJCQix/9957bxedgkQikUgkku7mkV92s3RPIX+nl/Hwz7uoqGtut+/jv+6lsl5PTaOBGz4XQle0nysDw603vN5emcbmjLJun3dneXT+RezS2Buef/r7baw0iQrTvUNGEBYyzG77mIE39dj8JB1n5YHiVm39wz35/tZRzOgTZG0LkzdiJRKJ5GzF1VFH/3D7/wPpahhVuBPk6UykOeIrv6qRe79PBkQREsnpRacjviZNmnRUg9ovvvjCbn316tWdPYREIpFIJJJTiOpGPetTrYbvy/cV8WfKnzx3fl+uHhll19dkUtmdW9lqjEfPSaJXoDuz3lxruav67qo0Rsb6devcO4PR0MxqtaZV+/sVyaAoeJpU+iaej4OTm2Wbr0nFwzOsB2d5arE3r4pwHxe8XU+9ku5/prT2lOsX5oWro45nzuvLnrwqZvYNxkFWT5RIJJKzmmlJQezMrmzVHujphL+7E+cNDGXRrnxLe0sUmOT0oUc8viQSiUQikZy+rD1UgsGkEhvgxuTEQBbvzqeouomXlh5g7sBQPJ2taY+5FQ006k12+696cBIx/kIsWnDXWEpqmrjxi61sSCulpKbplLlzmpu3uc12kyLy3/64fDWurv4AzNT6sNxYwaOxl/TY/E41tmaVc+kHG0kK8WTZveNP9nRakVIgRMxege6kFQtz+0APZwDCvF3Y+NjUkzY3iUQikZw63Dwuhg9Wp1PTZLBrD/IU/zNeuWQAgR5OGFUVT2cHrh0d1dYwklMYKXxJJBKJRCJpxXur0sgoqeOCwaG8uFQYWk3vE8Rj5yTxxOwkZry5lrTiWn7cmsM/xsda9kstFmJD72APJiYGEObtYhG9QETcAAyK8CY5p5Lf9xVy7aiT8wMyNe13souSmTr2UQAO5ayz2+5vVCk1mz5N0XhaRC+Ap+Z+w/W5m+nf99Kem/ApxvdbcgBIKag+yTNpjaqqlNQIL5YXL+rPk7/u5fzBoSd5VhKJRCI5FXF20LLqoUnsy6/m1eUH2Jsn/q8Fmm/MOTtoeXJOn5M5RckJIoUviUQikUjOcvRGE/f/kEyotwuPz04ir7KBV5cfBOCXHbkARPm5ctuEOAA0GoVLh4bz4rID7MiuoFFv5NlF++gX5kWt+W5pQpAHj52T1O4xh0f7kJxTSXZZXTefXftctOEhAP7n4Mr4EfdwqMRqhN7LqBCh82SVKn78jg8eabevl1ck/b0ie26ypyAV9VafN6NJ7dJqiEXVjSzYmcfVo6Jwd+r8z9XaJgMNeiMgKjkuv39Cl81NIpFIJGce/u5OTEwIYMHOPKvwZY74kpz+SFMDiUQikUjOcrZmlrN4dwEfrc3gQGE187fn2m0/b2Ao3986Cl83q49T7xBPAFYfLOGyDzfy/dYcnlywl0NFIuIrPtD9qMf0MY9VXqc/ar/uornJ6uW1OmMpAIdqRXGeRwLHMv+GZAIcPSx9xg+4oUfndzpQZq5uBVBW13SUnp3nyQV7eXHZAR78cddx7d8S7eXupMPVUd7nlUgkEknHiA8Sv1/cnXTHdeNFcmoiX0mJRCKRSM5CVFXlr5RissrqKLep0DjrTWu6X99QT64eGcWVIyJQFPtonqRgIQrVNxvZnVtlad+QJkzwk8zCWHv4ms3QK+vbrw7Z1WRnr6e6toC46KkUFO20tB9uEtUlD+mrQQsJwcNQNBp8nLyhKY9Ek4agoAE9Ns9TnW1Z5WxIK+NAoVU8LK5usvhnnSiNeiN/7BfG9L/vKyS3oh5/dyecdJpW78P2aBG+ThX/OIlEIpGcHiQGid83wV4y2utMQgpfEolEIpGcRaiqyo/bcnhtxSGKa9qP0nFx0DL/zjE46bRtbm9PUCiqFmO2eHm1hyXiq4eEr4b6cq7663aqNApsfY4BJgdL3PsuUwNVlVnkmk81PmoyABMSLuS7LXu5NuqcHpnj6UB9s4FLPtjYqr3kKO+lzrL2UInd+j++3EZeZQNTegfy1hWDOzRGsRS+JBKJRHIcTEgI4LrRUYzr5X/szpLTBpnqKJFIJBLJWcS7K9N45Jc9bYpe4+P9CTXf4fz3eX3tRS9DM8y/DT6ZBg0VKIpiERWmJQUxPNrH0tXf3ZEgz6MLDj7miK+Kup4RvtIy/xKil5ndGmuKZaNGYePuLwEINKr4+AovswF9L+fvG/dy/pSXemSOpwPfbspus72ourHLjvHJ+kwABoQL8fRAYQ01jQYWJudjNKkdGkNGfEkkEonkeHDQanju/H7M6Bt8sqci6UKk8CWRSCQSyVnCFxsyee2PQzii51Ltar7ot4s+PiYALhgUylc3jWDDo1PY8OgULhseYb/z8sdg9/eQuxU+PxcOreCjq/pz3egoXrt0IBG+rpaufUO97FPSdn4Lr/eFLR9Dcz0Avm4OAHZplt3JofxNAPgZ2xZOHsr8GYB4rVub2yXQ0Gzkw7Xpdm0tvm9Hix7sDKsOFLMlsxxHrYYPrx3KNaPsCwhkltbyd1op/1udRk55fZtj7M+v5rnF+wFrRS6JRCKRSCRnLzLVUSKRSCSSM5zth8uZtyWHn7fnMkQ5xHt+PxFSuw/SYFjsbP6Y8SrnDQyziFVh3i7WnU0mqM6F7V9Y24r3wXeXMnjQ1Qy+4H8ABNtUPhoV62ft21wPSx8Evflx6YPg4kNEzFS8mU5lowcGowmdtnvvxaVWHAJgmlskPzTmtNtvpF+/bp3H6Uij3siF//ublAJR5SrC14WLh4RTVN2Et6sD769O75KIr2aDiSd+FZU1rxsdRYiXC89f0J9HZvXmyo83sTevmmmvr7X0/2htBlufmIbDEe+dn22KM/i7S+FLIpFIJJKzHRnxJZFIJBLJaUhZbRPfb8mmtLb9SJtGvZG3/kzl4vc38vP2XCZqdvGj0/NC9DLjnrGUCzdehvanayHTamxPRRbsnQ+vxsKb/cFkgMgxMPUZCBko+uxbAPoGAGL8rZFSNwZlwNcXwoK7YPMHQvSypaECp/0/87LDxwBUNnR/ZcfU+gIA+vn3x8smXS7OaI1MSzJpuWH2x90+l9ONbVkVFtFLUeCJ2X24b1oCL17U32IC/FdKMY1643Efo6pBz9I9BeRXNeLprOOBGQmWbR7ODiQFty6WUFmvp7CqteCWWVprWZ6WFHTcc5JIJBKJRHJmICO+JBKJRCI5xaltMuDqoEVj9qj6dWcuTy/YR02TgT4bD/PrXa1N6Bv1Rqa9vobcCiFMXR6YzXM1b6JTDZBwDsx+Fda9Bts/FxFcxfsg5TfwioTEWbDjazA0WAd0C4SZ/4WwITDufnijn4gES18Jvc/lvEGhZJTWMbNvMM6/TIDKw/Yncf7/IHocfDodakXFvpnabcQbcqmoa+72yJxMUyNoFXqFDKMmZ4mlva+zP+l6YaY+zisBRSPvCR7JrtxKy/K7Vw5hVj+r78k5/YN5+XdnCqoaWZSc3ypFtqPRfLd/vZ2NGaK6ZmKwB66O9j9Rp/cJ4idzJJdOo2Awi5e5FQ12abYAh8uE0PrdP0aSaK4+KpFIJBKJ5OxF/rqTSCQSieQURW80ce/3O+n/7HJu+2Y7JpPKoaIaHvhxFzVNBgD2F1RbDMezSuuY/dY65m3JZuWBYovo9dyACl6qfxYntQl6TYPLvgLvCJj1EvSeA47u4GSOqKnKhi0f2YteF30M9+8ToheIsJ+kOWI57S8AnHRaHpnVm0Geda1Fr9DBMPBK8ImCe5LhqTJInA3AOZotrX2+muuhMgfUjhmZHwujoZky8y+e4IB++Jus23wdrdUnQ9zDuuR4pyt786r4ZXsupiMM5JNzKgF48twkzh0QYrfNSafl/EHieduTV4XRpFJZ38wjP+9m+utr6PvMcv5OLz3qcU0m1SJ6AcT6u7fqM71PEEvvGU/qf89h1zMzGB8vqm3lVthHE+qNJrLN3l8xAdKvTSKRSCQSiRS+JBKJRCI5ZVl5oJiFyfmoKvyxv4iP1mXw1cYsVBXG9fLnyXOTAFixvxCAbzcfZn9BNY/N38Od3+4A4O5xYVxX/AqKoRHiZ8BlX4NOGJLj4AxXfAuPZsMDKTDmHuvB+14EI26FqU/DgMus+7QQPlw8bvsUNn8EVXnQXAc5wkQerRMoGiGqXfQxtERSObqCVgfB/QEIUiqoqD9C+PrhGnizH3x1fpeIX+XlqZgUBY2q4uMTxxsjnyLepOHLQQ/h6+xr6RfsHXPCxzpdUVWV277ezr9+2kXs40u59tPNNDQbMZlUi/A1KMK7zX0jzRFXX286zOgX/+KjtRn8sC2H1OJamgwmHp+/hyZD+2mQeZUNduttCVaKotAn1BMHrQY3Jx3hPsKHrkXcbSG3ogGDScXFQUuQh3OrcSQSiUQikZx9yFRHiUQikUhOQTJKarnt6+0AOGgV9EaVl5YdsGy/c1IcYT4uPL8khW1ZFVQ36tmVW2U3xgUOm7g7Z72IwPIMg0s+F8LTkWi04OQOM/4D0/4NZWngHy8iu9qjxecLYNlD4i9qHAT1FW1Dr4f+l4KztxjrSNwDAfBXqiipPUL4yjaLZ5lroCpXRKedAKUVaQD4mkCrc2RA38uZ3/dyAHLK9oM52CjEr/cJHed0pay2if8uTbEToNallnLD51u4ZlQUJTVNeDjp6Bfm1eb+Eb7WYgjFNU38b7Wo/BgX4EZOeQNZZfWsOlDMrH720WKqqvLVxsM8s2ifXXus/7EjtVoKMBwpmmWUCH+vKD9XS2qwRCKRSCSSsxsZ8SWRSCQSySnC7txKftqWw4dr0jn/3Q2W9l/vHMv5g0It6xMSAhgd50eUnxuxAW4YTCq/7ylkS2Y5APdMjefpsS68qX0b5yIR+cXY+4S4dSw0GghIOLroBeAb17rt8HrIWC2WI0ZCxAgxVlu42QhfNTYG/YZm0NdZ18szjj3nY1BSmQVAgNL6fp+TzioEBgf2P+FjnY78b3U683fkAeDioOWeKb1wcdCyObOcf87bCcDFQ8NxdtC2uX+4TxtiKvDm5YO5bnQUAMv2FrbavvJAcSvRCyDSr+3x2jrmkamOe/KE+NtbentJJBKJRCIxIyO+JBKJRCI5BdiXX8UF723A1l7J392Ruyf3ol+YF/936UASgjxIKajm2fP6otSVwKoXuDJ8Iv8tceThX3bjQT0PuyzkmujrUTa+Z3+AAZd27YRtTeBDBkFBslguPSgeI0cffX9zxFcAlfaVKevL7PuVp0PsxBOaamlNDgD+2tapb15mAQ7A3SOk1fauRlVVssrqifR1RXuKRCT9biNK/WtGAv8YH8s5/UO4+pPNlNc14+Gk48ax0e3uH+rd+nl1d9KRFOJBszGET9Zn8ldKMXqjCQez0X1GSS0frbUXNUO8nLl6ZCS926jgeCQtqY5pxbUYTarluWxJyxwc6XPMMSQSiUQikZwdSOFLIpFIJJKTiKqq7Miu4JavtmNSRZpX/3AvIn1d+ce4WLxcHQBw0Gq4a3Iv644/PAApv3GD43xe4D1UNFylW8W16m/w7W/Wfi3VGF26QQi49lfY8RWc8wr8eB1kbxTtXhHgdQyjeEuqY/URwtcRRuhdEfFVJ6pI+ju0jngbNfhWrs1YRqJf0gkfpyMs3l3AP+ft5P5pCdw7rY0U0B6modlIUXUjAHMHhnLVyEgAkkI8+fG20SzbU8BFQ8MtqYVtcWRF0ZaxdFoNgyO8cXXUUttkILu8nrgAd/RGE5d8sNFS1OCeKb2oatBz//QEvF0dW43VFv3DvfB01lFa28zmjDLG9PJHVY/tRyaRSCQSieTsQwpfEolEIpGcRJ5auJdvzFUZAV6/fNCxL9q3fgIpQtxyaK5ipnYbvxtHcFNYDhSZ+3iGQ+QoOP89YWLfHcRNEX8A/glW4Sti5LH3NUdauSpN1FbbeJPVHSF8lZ2Y8HXw0GLerUwWU3TybbVd0Wh4+NKFJ3SMzrAutQSARbvyTgnh6/ut2RhMKoEeTrx9xSAUmxTXXoHu/HNq5+cY6OHEQzMTAdBoFGID3NibV016cS1xAe6kFtXaVfK8dnQ0AR5OnTqGk07LuQNCmbclm0W78hnTy5/DZfVU1utx1GlICjl21JhEIpFIJJKzAyl8SSQSiaTHWbK7gBeWpqA3mrhtYhw3j4tBVVUe+nk3RdWNvHn5IPzcO3chfDryV0qRRfSakBDAuF5+xxa9qvJgyb/smp6PT2dG76sI+n2taLj8G0g81z4dsbvxibYuD7vp2P2d3DHqXNAaGjDVFFnbj0x1PLgEPpsFdCAtUOcEkx8X3mJmftr5P8tygGtgW3v1KAeLhPl6ekkdeZUNR42k6m725Fbxn8X7AZicGGgnenWWxf8cx+qDxVw2PAInrdYSqQgQF+DO3rxqVh4oZkJCAHvzrULnxISAToteLYzr5c+8Ldmkl7Q8p+Ix1t8NR520sZVIJBKJRCKQwpdEIpFIepRGvZGHf95FXbMRgP8s3s/WzHImJQbw8/ZcAK77bAv3To1nf0E1I6J9GdPLv1vnZDSprNhXSJPBxPmDQk9IAOgopbVNfL3pMAA3jo3mmbl9O7ij2UPL0R2u+Ba+Oh//3D+4qGCNaHf2gsTZPSt6AfQ5H/5+B4ZcB9FjO7SLyTUQbfVhQutTwGQU1SVbIr5iJkLJAagtskaSdQQXHzvhq1Jfa1keGD2t4+N0AyaTSmpRjWV93aESrhgRedLm8+n6DEwqjIzx5em5fU5orH5hXu1WfYwLECmm328VXmstJvk3jInmmRM4rp+7SIssM0ePZZaKoggxHagKKZFIJBKJ5OxBCl8SiUQi6VFWHyymrtmIm6OWqUlBLNqVz+/7Cvl9n9Vge19+Nbd+vd2y/uNtoxkR0zpNrStIK67hzm93cMgcibM7t4r0klqmJQVy9cgoNF1sQN7QbGTVwWLumbcTg9nJfu7A0GPsZUNZuniMHg9RY8HJE5qqwSB8mpj0uBCQehq/OHg449jVIG3QeIZA9WFe07yN8eO1aG9dbfH4avSKxfmqH+DwBmiuO/pAADlbYOO7UFdi12xSxXN8r+9Q+vS+oMNz6w5yKxqoNwu+AOtSS0+a8FXbZGDJngIAnjy3D25O3feTsEX4AiF+DYsSfnODIrxPSGT2bxG+aoXwdbhMVHiMlsKXRCKRSCQSG6TwJZFIJJIe5bfd4mL76lFR/GtGAkkhnvy8PYf0kjpCvJy5dFgEb/+Viquj1iISrEst6Tbh6z+LUzhUVItGAZMKn23IBGDNoRLqmo3cPjGuU+M16o38vD0XjaLgoFW4ZGi45eJebzRx8ft/s7+g2tLfiWYGFi2A/CaRInjodwgbAl7h1kFNJji8HsJHWM3e/eJA6wB9LxAG8wAzX4RRtx/vU3HidFLE0Ex8kOxv7iRSKUZbkAyNVULAAj7cVsVlkyGkVwejtJy9hPCVtQ42fwjDbwGNhgaTEEX8XYM6NbfuILVYRHs5O2ho1JtYn1ZqV5GwK1FVlf0F1fQKdG/TfH53TiV6o0qYtwv9w9uO1OoqBkV6263vNBvQtxch1lH83ESKZFWDHr3RRFaZOeLLTwpfEolEIpFIrEjhSyKRSCTdyut/HGL74XLunhzPwAgvVqYUAzBnQAhOOi13TIrjtgmxHC6vJ8TLGWcHLRPi/YnwdWXlgWIem7+HLZnl3TK30tom1qeJCKP5d47lkZ93U9tkwMfNgb151by07AC7cirJLq+nT4gnj89OYn9BNWPi/NqNVPlobQav/3HIsu7qqOPcASEAzNuSbSd6gcrP/h+jXbJBrG7/XKT3KVqInQSTHoMlD0DhbrE96TwwmCsg+saKx1kvi/TAyhwYfHVXPTU9ghI/nSejvuWjw7NxVvSw/nXIFCmbZaoHv+8t5MaxMR0bzC3AurzsYfE8jb2HetUACrg4tq7o2NMUmqsnjonzZ2tWOVUNevbmVTGwGyoQfrXxMM8s2sdtE2N57JzWFStbxKcjRanuIMzbhZX/msiU18RrazSpeLs6EHuCkVleLg5oNQpGk0pFXbMl1VFGfEkkEolEIrFFCl8SyVlGWnENpbXNjIr1O9lTkZwFpJfU8vZfqQBsyijnmpGRNOiNRPi60N8m2kOjUex8eYZFi+iu4ebH5JxKmgzGNiNXjpfK+maeWbQPo0llQLgXgyK8WX7/BEBcmM94Yw3pJXUs2ytSMPflV/OT2YPsvauGWMQsW7LL6nlnZapd29ML96LVKORW1PP8khQAnprTh+tHR5G24Rd6r9xg7VxyQDyqRkj/S/zZkrLIuuxnjkRzdIUr5x3v03DSeercJMr/50Eo5ZgOraDFmWyzKYlIcypoh3A9wgcuZRGMvYcG1WgWvk5+lb/iaiFaBns5Ex/ozo7sSgqqGhkYceJj/7G/iA/XpPPfC/sT6evKOyvTAFh9oKRN4Su5RfgK9z7xg3eA2AB3+oR4WoTfwRHeJ5xGrNEo+Lg6UlrbRG5lA/mVDQBE+7ue8HwlEolEIpGcOciSNxLJGUhhVSMfrkmnqkFv1/79lmxmvrmOKz7axKaMsnb2lkg6R1WDnheXpfDt5sOsTy21tDcbTLy07IBl3WhS+XKjMHO/YFBYh7x94gLc8Hd3pMlgYsfhyi6b89ascib/32qW7C5Ap1G4d2q83XatRuHDa4eRGORhabO9Rl95oLjVmMXVjUx4dRV6o4qDVuHrm4XBelldM7d/s90ievUKdOf60VHotBp6l68SOw+4XKTqaZ3gsq/hvHfA0Xps3ALB6wh1JKD3CTwDpw5xAe5UquJcFbNx/xP6mzioRmLslPB1hJhfLVJqG1QTAC5OHkfu0eMU1wjhK8DdCVdHce+xQW844XFVVeWu73aw7XAFV3y0kW83H6a0VhzrUHFNq/8F9c0GSxRlT0R8tRAbYBW3h0T6dMmYLT5fG9PLMKng5+ZIwFlQEVYikUgkEknHkRFfpxlVDXo0Cng4Oxy7s+TMoCoXjHporgWfaDjGxVt5XTMXv/83eZUNHC6v54UL+wOQUVJriW4B+GJDloz6Os3ZkFbKrtxKrh8d3a3G1Mfif6vT+HBNhmX9g2uGMKtfCM8s2scf+4uEiHTNUN5bncbO7EqmJQVy1+ReHRpbURQmxAcwf2ceqw8VMzruxN+zRpPKHd/soKJeT3ygO8+e15exbVSN7BXoztJ7x/PQT7vQaBSuGhnJDZ9tobrRQHJORav+G9Ktot8VwyMZG+dPtJ8rWWbDbU9nHSFeLvz3gr7otn0MigYKWlIY58KUJ0VlQ19zal/COXBgsUhpjJ0Ihmb4ZKpIe5z+H/AIPuHn4lRAo1Go0ZiFL7NIVaCKSL/apk6IQtojPgPVedBQSQMmQMHVqXt9rDpCiVn4CvR0wsVRRC/amt0fLwcKa2g2iOeuol5vEVkBVFVEd01MsKaCfrspm6oGPVF+rgzuhjTL9hgY7s3i3QWEeDlz+fAuCHMDfN2E8PXqciGa9gn17JGqrBKJRCKRSE4fpPB1GlHVoGfa62twcdCy4v4JlnLgkjMYfSN8ONFS5QzPMLj2VwhIbHeXL//OIs+c7vHd5mzun5ZAgIcTb/+VSpPBRLCnM4XVjfyRUkRBVQMhXi49cSaSLqSgqoE3/0jlh205AMzfkcc/xsWwLq2UlPxq3r5yMH1DRVpXd18AqqrK8r2Fdm1v/ZXGpoxy5m3JBuCDa4YyrU8Q0/oEUVHXjLerQ6fmNTFRCF9/pRTz8MzeJ2wEnl5SS2ltEy4OWhbdPc4iQLSFVqPw+uWDLOtrHprM4P/8QXpJHTnl9by24iAz+wZzTv8QNqWLCJpbJ8Ty+GyRWvbLHWOoazIS5OWEo1Yjznv5E8KE3ZagvuB9RHU/9wAYdqN1XecIN68QYri/fYTa6U691hNs9J8yVbx/y+qaT2BUFSoP02B+u7g4d02E0YlQUiM8vgI9nHE1v+8aukD4+iulyLLcYpwf5efKwHBvFu3K5/rPtjCzbxDXjIqiV6A735k/m3dMjEOn7bng/+vHRNM31JNBkd6WiLcT5chx+oSc/JRWiUQikUgkpxZS+DqN+H1vgeVu8a8787jyJJVAl/QgmWusoheICIY1L8Mln7W7y/J99iLE5R9t5B9jY1iZfAgFVz6+bhjPL9nP5sxyRr+4kgemJ3DnpJ69+JEcm6p6PVqtgrtNJJfJpLJwVx5PL9xHTaM1EiatuJZH5++xrD/+6x5qGg34ujny3lVDCPZy7rZ5vvHHIbLK6nHUafjj/glMf30tKQXVpJh9fG6bEMv0PtZqej7m6AyaaqGuGHxiWlcCTPlNpPY110LoYCYmBODioCWtuJZ3V6Zx77QTE31avI36h3sdVfRqCx83R2ID3MgoqeM/i/ezYn8RC5Lz+fG20fydIT6rtlFpfu5O+Nl6qteWwKb3Ww/sHd2xCTi4nHGiF0Cjg7e98IWIziqvPRHhC2iopN789nI9BYQvS6qjh5NF+OqKiK+MEmHq/tDMRC4dGk56SR19wzzZm1vFol35ACzfV8TyfVaBzEmnYc7A0BM+dmdw1GkY00Z05Ylw5NdHYvDJT2mVSCQSiURyaiGFr9OI+TvyLMvfbDosha8zHZMJtn4ilh3cYPRdsPYVyFwnclfaiJjJLK0jrbCCq3VruezqW7ljQS7VJfmMXnoru52LKNCEEMK3XD8mms1mf5fX/ziEu5OOm8Z1sHKapNt5b1Uab/55CF83R364dTTR/m7c9d0OluwusOvn4azjqpGRfLgmA61GYVwvf9YcKmF3bhUg3g9PLtjLJ9cP65Z5Hiqq4W2zgfaVwyOI8nPjrSsGsXh3AQVVDUxNCuKOiXGtdyw+AN9eAlU5EDIILvwAAs3m2ymL4YdrrH01DniHDOCFGf/H/UsKWJicx73T4lmYnEdKQQ33T4/vkOG9yaTy2h8HWbK7gAa9EBrsUrwMTZD6BxTuEYJb/HRRVbENEgI9yCipY8V+q4hw2YcbAXBz1FoM+dtk78/CuD5sKDTVQOkhUcFRc3YLz82OXtBoXS+1RHw1ndC4+tpCDObvSheXkyt8mUyqxXcr0MMJFwfxE6wrhK/MMiF8xfi7EejpTKCnELtHx/nZGcrbMqV3oJ2wfrpy56Q4iqobySqtQ6tRGB8fcOydJBKJRCKRnFWc/r94zhJWHSy2CBUA+wuqqW0ynBE/WiXtsPI5SF0hlq/4BqLGwt9viyiZ0kPWdMfk7+D3R8GvFz/6/JvrtSt4SvcN/PINi5KuxX/Px5YhQ0wF8MkUZg26hoen3cVrK7MwmlR25Vb2/PlJ7GgyGFm+r4ggDyeLV01RdRP/nLeTj64baid6zewbxK0T4hga5YOqqgyO8CHM24X+4V48u2gfX/ydZem7I7u1F1VXsTVLfCf1Dvbg2fP6AnBO/xDO6X9EtcPSVChLh17ThA/Tb/cK0QugIBn+NwpG3gFDb4BlD9vva9JD3nYmRv4B9KOwuhGD0cT9PyRjUmFffhVxAe5cPCSc/uFWD6f6ZgObM8oZFeuHi6OW3/cV8t6qdLuhB7UIX4V7Yd6VUJVt3bjxXRh2M4y7H7ztvYjig9z5fV/bz8nN42Ptv5dVFTa8BTWF4OwJa/9PtA+4AhJmwKJ/wohb2x7sLELvZBULa1VnGhHm5J1OdZzyJKx83rLaUGl9TV1cTq6n4c/bc9Ebhceiv7uTTaqjgeKaRv69aD83jYtmaNRRhFMgt6Ke1/84xL1T44nyE2bxWaVC+Ir2c7PrqygKn1w/jD9Tinh+cQrNRpNl23Wjo7vq1E4qgyN9WHT3OExm/8oTrRQpkUgkEonkzOPsvsV8GrA5o4wh//mDGz/fio4mxsU9zdioZ1BUA4/8vJunFuylulF/7IEkpxeGJthqTmccfTdqzCTQOUGEqBJH+iowGmDzh7DgDmisgrzt1O5eyBVac5U4Q6Od6MW5r4OHSGvRJH/DnaGpvH7ZQACKq08sqmLVwWLu/HY77/yVekLjnM18symbe+bt5PKPNgEwINwLJ52GPXlVTHxlNQCOWg0r/zWRD68dxtAoEb2iKAqz+gVbRJ8HZybSK9DdYvhcXtdsiTLpalqqLE7vE9S+Z1dzPXx+Dsy7HD6bKUSmnE3C2P3W1eAZLvptfh/+N1Kk87YQOsQiCnlnLgFEdMyO7Epaiv2tSy3li7+zuPTDvwEhIB4uq2PCK6u48YutfLBGiF3r02xShs2MjTenXK36rxC9nDxh8LUQN0W0b/sU3uwPX8wR52GmV6B7q7FauNk2crKuVIjVfz4jzm/NyyLay8EVBl4uilVc/5swtj/LMdmkIbb4e4F4/3aK8Q/CAylCWAQazO8nrari4OB2tD27lWaDiUfmi0IGIV7OOOo0dub2/1uVzpI9BVz8/kZLAZI9uVUU1zS2GuvOb3cwf0ceV328GRBp0RX14ndAlJ9rq/6h3i5cNzqaBXeN5ZWLB+Co0/DPKb26pFDEqYRGo0jRSyKRSCQSSZvIcKFTlMfm7+ZAYQ055Q2U1zXipS1hUmQeKx2bwRFG+cxjyZ5rAXGBfOmwrqmOJDlBmuvFhe0xKi8ek9Q/oKmKRpcgLjs4HSX1b767ZRRuCbMgcy3sXwiqCZY/ZrfbfzQf24/jnyhSIsOGwdAbhXD2wTix7dByAvqNBWjz4qozPPbLHgqrG1m6p5DJvQPpF3byq6d1J6lFNXy8LoMhkT5cPDQchy7wR1t9sNiy7Oqo5ZVLBvDZ+kx+3JZridK4d1o8sQHtiy4A7k46ltwjXuMZb6zlcFk9hwpr8O/ldMJz3JJZTn2zgdLaZr7emMUuc0rlkCgfqMoD90DQHlFxduc3UFcilvO2wQfiPUevaRA6GKY9A/Nvsd9nxvMiwtE3xpzy+ymawl0kOpdzsNGX348w0wdo1JtoNpg45811ZJijXwCL19jmjDK7/t6uDng6O4iKqZlrReM1v1jF5cx1QqjKWif+/i8epj0LI24hzuY16BXojk6jcKCwhpl9g/ByMZ+/qsK8KyB3a+sncsw/wfnM/ox0Fo2rNcqpDKvwVVmvR280dfwzpijgGQou3gA0JH8NEaG4qqCcxHTS7PI6VLNY+9VN4j1m8fjSG6lssN7AeujnXZzbP4Sbv9zGiBhffrxttN1YLanMeZUNbEgr5Q9zym2gh9NRq7v2CfWkT6gnlwwNlwKRRCKRSCSSswopfJ2CFNc0Mm9LjmV9YuD/2OGXS7JJBcSP1SK/PSgVBlR05FY0nKSZSuwwGeHjydBYDXdvOTHxa+/PAHxdM5TdFeIi/vFf93BR3BgmAmT/Lf7MbDUlMFxzyLp/9Hi4YXHrcYP7w3WL4Kvz4NByAke9AGApmnA81DTqKay2CmfztmTz3wv7H/d4pzI1jXpSCmq44fMt1Dcb+XFbLj9sy6G20UCYjwufXT+8QxeU+/KriPB1FcILYDSpJGdXAnDF8Ajum5ZAsJcz90yNp7C6iYZmYWR/6dBw+4EMTWBobCWitHhexQd6cLisnrdXpjIkygedRjnuIgafrc/kucX7W7V7OusY2bAO3rhJRDJ5R8LVP4nHlN+s4mzcFEhfKZYd3GDiI2J5wGXgFQEaLWz7DDQ6kWLoaBO5Ej4McjYz3fkgBxtH89mGzDbn+Hd6qZ3oBZBb0UBJTRPpJXUoiqhi98GadN6+YrC5w1bh6eXqJwTiFmLGi7/FD4jIr+ZaWPoguPgQl3ghiiK0rSfOTSLc24VfduRxxySzn1llNnwwHhorreNdMx+ixkD2Roie0NGn/ayh2cdq2J+pBtttS86pPLpvWluY/bwazJ9HF/XE5neipJvN5/uHeREfJP432FZ1LLOJypy/I8/i6ZmSb+/Npar2J3L1J5styx01dZeil0QikUgkkrMNKXydgmzOsHp5RbhXscMvF4Bymx+rxQ4a5sS+zR+Zt5BXKYWvU4KCZCg5IJZT/4B+F9lvb6yGLR+JfiYTnPcOuPram9TrG2DZI7DvVwAWGsdYNi1MzmdhMnzt0I/x2r0AZJiCOb/5eWb39mJ41qUAqHHTUC75tP15Ro0BF1+oLyVix6t4MpDqRjca9UacHTpX4Q4gq7Tebv3PlKIzTvgqh+0EJQAAecNJREFUqm7ky7+z+HrTYUs1Ra1GQaso7DQLVqnFtaJSZhvpQwajiTf/TCU5pxI/d0cWJuczd2Ao71wpxJeUgmpqzJ59/72wP1rzZz3cx9USHdKK+nLhS5W7VUQiDb1BRCYV7YNRd4CTB4nB7vyZUsSmjHJ6P/U7oV7O/PmviThoNaQW1ZIU4sGO7AoctBoGhHu3e/4Vdc28sDTFri3Uy5kHZyYyPj4A118vF436evEZWP8mjLsPFt4FJgP0uxgu/BDydkD6XyK1L9jmPRJljmiJaOdcYyZAzmZGa/bxLtbol1Gxvmyy+b480vwfhB/iee+uB6BvqCcPzUzknqnx1vf6xvfEY9yUtg3mB10thK8WfrkZl6A3+P7Sd6l0CmFyYiAAj57T29pn0/v2otfY+yB2shi/JY1SYofGN5oJTW8wQnOANcYBdttW7CvsvPDl7A1AvSJeUxdOrtjTUnUxxt+abuni2GJub7Bsn5QYwOqDJZY+NU0Gahr1eJhF8qPdpHjhDPvelUgkEolEIukqpPB1inGwsIZ/ztsJwCVDw0lyns+b1us6dKrKAJzYoTSz2qmYPlEvUlj++kma7WlEcx2UHBSeOq6dvIBqjwNLIX8H9J4DoYPEeguHltsLX8118NX5on8Li7WQvQkSZsL571Je10zah9cxoloY2meYgil0TST9ieks2VPA8r2FpBXX8rXLM9TlvYK3Usv9zXdy3sjePHluH/h6FJRnoFz4viXNp020DjDkWtjwFk5b3uUPJx+uan6ckpomQryc+WBNOmN6+TMksmMV0FqqicUHupNaXEtRdVOHRbQNaaW8uvwgr1020C597FTjld8P8suOXLu2H24dhU6r4aYvtlp8iK75dDML7hxrZ7IO8MyifXy7Oduu7bdd+Rbh67fd+YCowKY9VjRGYzWsfgk2vWdt++Mp8ddCXQloHblF483KoOGkFInXKL+qkUNFtfy+t5AP1qQzu38wK/YVoSjw/a2j2jXVXn2oGINJJTHIg9/+OY5duZUMivAW6We52yDD7Cs3/BbY+rEQilrEopBBQvTSOkDkSPHXWWImwNpX6d+0Ey1GjGj54Joh+Lg6WjzRAH7aLl6jGH83rhsdxb9/ExFqBVUiInF6UjCKoljfm4dWwIHFIsps/L/aPnboYBh4FRibxee3PAOK9jKy9i8Y8mDr/g2VQvgG8ImBW1dZoo8k7ePl4kC2GkS2McjSduWICOZtyWH1wRKeOLeTA7akOrZEfBk66RXWxWSW1gIQG2AVvlzN78Oc8gZqmgwoihCvxry00m7fwqpG3J10vPHHIRbvaS3uAtw9uRcRvq39vSQSiUQikUgkUvg65Xhm0V7L8sy+wXy4eRto4KmQqfQJH4tOK3x6bv37cSo0CqkuJkZWfAtM7dD4BqOJt/9KZVx8ACNiukgAOpUxNMHCu2HPT4AqUqpuXQ1u/sc3XmOVqKJYmmq9sF//Jvj1ghKbiJjUFSIPqiWaa+P/xEWziy/0vxS2fAgpi8S2nV9TMf5ZfvngWW5pFqJXlimIpw03MnVAMFqNwnkDQzlvYKhl+MNlY/nP4v3M8nXl6Tl9hLH4DYvFxbljBwych98C27+ExkqClApu0C6nuOZS9uVX838rDsGKQyz+57gOeXW1VBMbFOFNYXUjNY0Gcivq6RV47LSbljSdZxft4+ubj0MQ6SF2m6teDo/2wWBSifFzY2iUD4qisO7hyWzKKOPmL7dhNKnc8tU2/vrXRNycdNQ2GXh20T5+NgsyWo1iMa4GKK1twkGr4VdzWtPFQ8LMG1Lhj2fA1QdmvQxO7qIa4K55UJZ27Alv+QgAb2Dp6H9yk/d5rDJHkWSW1vLDViHCLd1j9cp64te9/H5f2yl4f+4X/mPT+wThqNNYo2/qyuCbi8Vy6BCY/apI80tdLtr8E+CKb1v7fnWWiJHg6o9nfSmzNFtZYhrFzL5CxPrqphFc99kWS1dnBw2/3zceJ53WIny1ML2PVVRh2SOw+QOxPOoOCExq+9gaDVz4vljO2QKfThfL+Ttb922ogJejres3r5CiVwfxcrW+R1wdtSy/bwL1zUbmbcnpfGVHsER8NSgtqY6mo3Tufloiumw9+lpSHVuitsN9XAj1duGViweQXlrLXynFpBXXMv2NtTx6Tm/eXmn97E9MCMDPzZH5O8V3h6VCqUQikUgkEomkFVL4OoXIKa+3pO3cNiGWUGUjBzUmdKrKzBH34eUdbem7NvE8nvluFvP1eejJxmRSO+TbMW9rDm+vTOPtlWlkvdTZW+inGbUl8P2VVnNpRQtVOfBqHIy9F6Y+23Zq09FY+3+iSpstJr1V9HLygqYqaCgXkSF+cfD3O7DqeQDed7sdxfUibg3dhiZ/u2UIn7fjaLH3fttwAa8bLgNgxfgY2iLKz41Prh9u36h16LjA4B0B9++DHV/C8scJVsopqWkitajG0uX9Nem8d9WQYw6VaRa+YgLciPR1ZV9+NYfLji181TYZLMt648m9KD0aTQajxTfqnSuHEOzlbLfdzUnH1KQgFt09lus/20JhdSMfrknnrwPF7LPx57lgUCiPz07ikg82kl0u0kOnvb6GSnM1Nn93J6bEuouIrs9nQ53Z7L62BC78AFa9IAontNDnfJGGFzkaFt8noosmPw5fzoXDGyzdlJSFfPTP57j1q22sOljCR2szqajX46jT0GywPu8HCmv4fks2Fw0Jx1Fn/VxU1jfzZ4owz7YTjgAOrxcpfVonuPQLIfRe9YNoqy0B31jQdsG/GZ0TDP8HrHmJq7V/Yky6AOWPp6BgFxOu+I6B4V4Wo/3h0b4WjzNbHpnVm6QQ83uypsgqenmGW/3GjkXECLhhKXwxW6RtAugbxfwURQhjLQT2FWb/kg5hG/HpoNUQ4etKdpn4nDQ0G9vbrX0sHl/ivexqOnkmX7VNBoshfd9Qq3F/S1XHFiYliPfLZcNFsZpDhTWkFYtIsZeWHbD06x/mxTtXDcZRq7EKX5He3TZ/iUQikUgkktMdKXydQiww/4AdHetDZcUdXFEiqpBN1/nZiV4txHvHQkkezQ4VlNY2Eejp3KrPkey3uRDPKa8/s1Mj1r8uRC9HdxF14uAKX10A+jrY8BZUZMElnwtT7WOhbxTi1oEl1jadM1y7QES3lGfCkOtojpxA0VuTiKjbi5qzBcXNH/54GoA9ur68mtsHU+4hdsc/yTvDl6Hd+pFluDLVE22/Cxg24FFiF6dyzcgoEoJOsDrk0XByF2IJEKhUklzdSFaZ1a9rc0Y5qqqKaLJ2aGg2svJAMf/QLuHGrQ8zhigu5A6LsHM0NqZbq+wdj7dYT5BZWsfk/1sNiCqAQZ7tV0YcEO7N03P7cP8Pu+wiM0AY1j85pw/uTjrWPjyZf3y5lT9Tii2il6LAV+MqcHwlAjjiAj11OXw4wSp6Xfql8Miyfd9e8pl1ee5bwljdYPb+q8zGwVBH/3BvVh0ssVQ5vH1iHN4uDuRWNLA1q5w9eVU8On8PRdVN3DvNajT+8/ZcmgwmkkI8GXBECifZ5jTDIdeBTxSWk3Hx6fpIp8RZsOYlhruXMOSSJHjZ7JW18T28XK2+WbYea7dOiOWjtRm8d9UQzh0QYh0rY7V41DrBHRs6V4giZCCgQE0+pP0pfNYSZonvEtsosPPf7fw5nsUE2fz/qjJXOGwRhhr0xmN+F7XCXPCh0byPs86li2baMRqajVz58SaSQjyZmBBAs9FEtJ8rsTYeX66O1p9gDlqFOyfH2Y3h4+bYaty3rhjEnAGhlpTo3+4eR7PRhL/7iVdtlUgkEolEIjlTkcLXKUJOeT2v/XGIaKddOGrns9QgDGydTSr3T2/bwys2sB+UrKPCsYmCqsYOCV9ZNhXPNqSVcsWIyK45gZ6msQqqciGob/t9MtaIx9n/B7GTxPKj2bDnR/jtXti/UFSd63vB0Y+lb4D3RogUrhbu3Cwulr3CrMbcwGvLUvCviuQW3V7Wrf6d+oxGZqkmKvHg/NrHMCGiD5amNjCm791cc/FI+OVmkk1xbJr4NbdP7csYYGViWKefkuPCQ1RPC1QqySqrs/jQgEjDG/fyKn65Y0yrKCcQ1UcX7yqgqqGZe50X4FJXxyBymaAZR3Z5LACrDhTTbDQxs29wq/0XJOdZlouqj7+qZFehN5r4dtNhfN2dmNU3GJ1G4b4fki3bPZ0drBfeqipSDr2jQGe9OD2nXwj//m2/RdACmNU3mBcv6m930d4n1Is/U4rN+wTz8KzexKy+BzvR6/JvRIru/oUiUhFg0uPHfr/6x8MtK0W1x3lXQm0hFB8gwsf6GsQFuHHnpDiL4Pjmn4fYkyciUr7cmMU9U3uhKAqqqvKd2ZvsmlGRKA0VYoDqfNj5tTVqKnLU0efUFXiKipYODaU4lFpTwtn5Dec51ZGpxJCjBnHhYPNnR1X514wErhwRaTUUb64XYnhLKuaoO47uh9cWTu4QkChM/Jc9ItKLUxYJz7WWKLBzXoGwY0dLSuw5MhXYNiKqyWDqnEDuKgRQvflj5xA9rkvm2FG2H64gOaeS5JxK5m0Rn6EpvYPsvgdcbc4vPtCDEC97ca68jRTPcb387XwAj/QTlEgkEolEIpG0RgpfJ5nyuma+3XSY1/44hLumAk3kt+wwpxk5qirfjH2JkNChbe4bGzYa9r1PnqNCRU01wtGnfUwmlb35VZb1TRllrYSvDWmlLN5dwKOzett5rpxyzL8NDi2Dq3+B+Gmtt9eVQfE+AHY5D2Pp0hSaDCYmJgYwedBV4qJ1w1vi4r3P+faVFY/k4DJ70QvEhe8R++RXNvDJukxm0gsAn/JkDpU2gQ6WGobj6+7C21cOYn9+Nc8vSeGbTYdJumAK/9f8BMmmOL7pFUKPYxa+Aqjkyw0ZFmHO2UFDo95EXmUDTy7Yy8fXDbW7YEsvqeWcN9fRbDThRzUeWAXVK7UreTN9HJsyyrjxC5FmuuXxqRZhtlFvZPoba8gpt1YjLalp7PZTPRafrc/kRXM60R2T4pjZN5hdOZWW7RcPEcIL+gb4+SY4uBTcAuDc16AyB1x8cB58NU+d24fHf92Do07DsnvHE+7TOqry5uhSHMb54x8YwmXDItAqWNMT3YNE1FbiOeAXL1JmNQ7g4AJDr+/YyQT1EY+BSUL4SllIRK/7rccfF2snIlw3OpqDhTUs21tIeV0zyTmVDI704e/0MjJK63B30nGx5yF44zpRudEWRSMqhXY3bv4iQsvYBId+t7ZX5XAJbzPCLZqCK/8iZPMLonJq3k6cXH2IufAj8B8N1QXwyVSotgquxE0+vrmEDhHfIbZ+aweWQlmqefvg4xv3LOeK4RF8uzmbMG8hADnbpNw2NHey6qx7AFzxHYbizZD5K1rnnhWIWop+tOCk03C5OYWxBVthr1dg6+Ied0/uZVfh0d1Jh28bUWASiUQikUgkkqMjha+TzI2fbyG74ADj/Rewzz+LEsX6Q/+dvneQmDCn3X0DA/vjYjLRoNHwz63n4rtZ5b6Ic7hw2qsAqKrKxvQyUgpruGBQKFUNemoaDUQ77aZMH87uvNYm6K/8foBduVW4OWp5ck6frj/h46W6AEwG4U3VWC1EL4BvL4b4mTDndfAyCxO1JfDuMABqPHpx0VepliiC7zZn890tIxnW5wIhfKX9CV+dB9ctal/82v2jeGzx7xp8jaVvTnk9Xq4OeDo78NXGwxhNKkrUcCiCJCUbf61IK9to6sP/rh7CiBhf+oR48urygxworOHiDzYCImqtT0jrCzNVVdmQv4HqpmomRkzEzaEDxvWdwS0QFQWdYsKXGkrxIkk5zJ3nTedfC9NoNpj4M6WI5fsKmdXPKswtTM6n2ezLFavYVxkbrd3P7YU1XGFTbW93bhXT+gjh62BhjUX0ivN3paq0gNJaL/RGk6gSeBJoNpj4bEOmZf2X7bmW1KHJiQE8cW4SURTATzfAvl+tO9aVwI/XWdcjR3Hx0DjOHRCCSVWtqUxGPfz+KORsBidPvA5v4J99zocRX4ntpWlQUwBaR7h3lxC5AAJ7w+3rj//EgvqKiot/v8Oov99hnkMfrtU/ytwBwVBfLiqcVufjq9Hx/jVDuff7nSxMzmfRrnwGR/pYvL0u7ueN84JLWoteQ66HvheCZ2gbB+9iFEUcpyIT1r3WanOkIYtIl1x7D77mGtj5jYjK3POTveildYKoscc3l7AhsOs7+7Yc8/vdPdicDinpLE/N6UOIl7Plu0an1eCo1dBsNNGgN9Lp5Nne52LQF0Im6JSe/bmTWWIVvvqFeXLf1AQSg+1Tam0jviJ8W6diDov25a9/TWTqayJ6OcTLuXPpnhKJRCKRSCQSQApfJ5X9+dV4GZ7EkFBGMgDiB+2rMZfi4x7MyCG3HnV/jVbHqOYI1jrlYlQUyjUKi3JXcaF5+7rUUku1swMF1QyP8SXJZT250YtJqtOxNed5apsMuDuJt4HRpHKgUJibf7s5mzsmxeF3sn1DVBVWvwRrXxWRJUNvgPJ0+z6py+H9MaL6nbFJVMRrrATglcpJGE0qkxIDqGrQszO7kks+2MgD0+K5J2YCZK4Vf6/1hsu+bJ2ypW+EdHNp+Zt+F9E+AQmoqso3m7N5asFeovxc+fXOsZZ0lvPHD8e4LBhdXSEhlFPrEsqll95qqaLp7erIrRNieecIH6gjjY7X563n+U3Pk1crLtYDXQN5a/Jb9PPvd+LPawtaHSZXf7T1JQQqFURQzK9Oz8DGj5n7+F+8tr6Ed1am8fySFDvha8U+azXAu/qrcAhhsp69ES/q8KSWaqwRDLvzqphmNkbPqRDiiUaBxYO34LLuBW5u/heltVNapfr0FAuT8yiqbsLXzZEmvZHimiY+XpsBwKAIH3qlfQErnrTfadbLwidu8/vWtu8uhxuX4nykqfni+0V0oS37F1qX9/4iHiNHWUWvrmDAZbDtc+FrhxAlf7/EH48d7wvvuTH/hO1fCVHpH39x3sBQFibn8/mGLA6X1VuKDszWbIKmavCNg6t/ElVL+14EHkFHO3rX4xUuhK8WfGLs1/f81HqfiizxmHWEgBjc//irTYbapDHGz7SmTgLMelGY3Us6jbODlrunxB/RJoSv+uMxuAeMZm88naaHhS9z2vgLF/bnqpFtWwo42xRhaCsyFLDzBHNyODk3BiQSiUQikUhOdzr9K2rt2rXMnTuX0NBQFEVhwYIFx9xnzZo1DB06FGdnZ2JjY/nggw+OZ65nHPNXfcROH2Hw7WtSCTPCPT6DmTXh6WOKXi24+L2C8dDDXKkdD0ClavUWWnmg2LK8Yn8RWzLL8fX7C4AUNwMatZl9edbUx8zSOprMVd4a9EY+XW9zQXmi7PwWFtxpNZXuKFs/gTUvCWNvkx62fmwRogyOXpB0HnhFCs+vBbcL766NwlT6i8gX+Fo/hcmJAXx6/XA+vHYoY3sJ35fX/0xlXtJ7Is0RRDrYyudbHz9vmxDT3INE2lj4UAoaddz0xVaeWiB8hg6X1XPOW2upatAT7uPC1D7BaCOtFRfdL3qbCX2jqGmu4ct9X7Iscxlj+9YwpXcgOrNXy11mU+OyhjLya/NpMDTwxPonLKKXq86V4vpibv/zdv6/vfsOj6LqAjj8291skk3vjYRQQu8E6b0XAQEFBSkqts+GHewdFBQURMGGWBAFRBFEQapUgYROQk9IISG9t53vj0k2WdIhJCGc93l42J29M3tncxl2Ts49NzQhtHKfYTm0DoV1vka75WfExJ+DbXN4pI/ar0sJGSTl160Ki0vnVHQKOq2G4NcG0dctfwx5tVU/J8BfE2P2HseKjLOCbK/R7eth2PkeAM9b/Fwjdb6S0nNYGxTBgs3qFLWHezfivh5qwf/oZHX6Zfv6TmotuKKc/KHTfTBsDtzzEzTPz8yMOw3fjwNj/k16aix8O6ow6GXlYH6chIsQcxIOLlOfd5hClfJuB7PCzQI1AbrLsDc/WLd7oZrFmJkIvz1GrybuOOdPcd5yKoadp68A0PLy7/n9u1ddqbTro9Uf9ALzVRLb3QOjrlphtWjgyzI/8JpwXv15hO1Rn3d7HJwbqFNUr5VnK7B2Uh8Pftv8tVZjijUX167gFwIbjkaRnp1bTuvico3qPtUd+CpYKKShW+lZukVXYu5QyqqMRTO8SlqtVAghhBBClK/Sga+0tDTatWvHokUVW7Hq/PnzDB8+nF69ehEUFMRLL73Ek08+yerVqyvd2bokMj6B/WnfAjAEN7bfd4yN9x/lwVHLK3UcRxs9KUZXrmQ2BSBRKfyt+K4zV0yPkzJyWHXwEjm6wsCYv/VxU0FrgFPR6rQ8Q34dleV7LnIsIol3/jhBRGJhPaZKS49XA1LBP8Dy0XB6c8X2y81WM72AvIDBhdudG3DApid9U97i79ZzUSb+VHxf1wCWx6tTNe/t6o9Oq8HD3pofpnfl6YHqZ/X6b8e53Hxa4T5he8BoND9OQZZIg54cvpRESHQKE7/Yx9aQWCx1WjrUd8JCqzEFbaZ1b0BmXjo5BbWD2ownqX5nziWd44G/HmDegXm8sOMFHtx8H+N6x/Dm5ASWP+rOs4OacTbxLCN/HcmQ1UPo/ENn4jPjcbJyYueEnWwZv4W2bm1Jykrinj/uYXu4OvUlJD6EpKwkEjITCE8Jr9jnehWNnRr48tQkMLxekalsZ7dga2VhmvLX7q2/WbE/jL9PqNleXRq64GRjCdFHTZ95wSqRMzpa4GSj581R6jTOooGvghUfWxkSTNuiFBe+2HEORblqRcMb7PXfjzFjZTARiRm42FpyT5f6PDOoKa+MaIFep8HGUkf7evYQnV9M/X/74NkQeHh7YVZPs2FqIfrRn6pZidFH1Ol1P4yHeQFwPn+RhY5T4eljEFCkJt3HbWFxV3WFQFsPaDmq6k9Sq4Mpa8EzP1Nw3xJ1WiVXTZkK34vlxe18NdW8pmADTRT2MQfUc2t3d9X3rzJSLhc+Hv0pNOwN96ws3JZ6GdDAc2fg8QPqtuQIeMtFzVizcoRBb6nTSX3aX3s/9NbwwN/w6G613t+oheoUx/v/KrteoKi0gunCH20KZebqo5XevyYCXzl5RtN1rqzAF8CP07uw8J4ONPdyKLMdQJt6UsheCCGEEOJaVPqb4LBhwxg2bFiF23/++efUr1+fBQsWANCiRQsOHDjAvHnzGDduXGXfvk7Izc3h7Z/HcN4A9nlGXhz56TUfy9GgZmf8e0EPTSBRC4rRSGxqNqdjUtFo1FXl/jwWjYZcwq2yKYh3ehqOc/hSEtO/PcD+83EkZ+bSy/1TIpzC8E/qydaYkdy+UA38ZOTk8e6YNtfWyeNr1GytAuuehKeOgK6c4Xf8V0i9TI6NJwPDp9NV24ZX7+qOplFf7nxdnVr00HcHCfRz4OowaozfMM7tVW88Av3VyjA5xhy0aHm4rx87zlzi0KUIfk/sxoOP7lanShpz4ZcpMO4ryE6Do6vgv68ACDW0Y/Snu0zHr+dk4Nv7b8PJPouQmGhiEi2JTo/gtsZpDPplEA0dG/D9/X+T69WWCevGmDK3ipq5c2bh484z+frY16TkpJi1eTrwaZzyM0sWDljIrJ2z2B25m6e2PkU9u3qEpYShQWPKCvhx+I+4WLswZ/8cJjSbQPd6FSg67uwPwAudrXBNLJJNFnca9izG37kNV1LVwN6sNUe5rYH6eQ5p5aVOKy3I4mvcHyIPQfheBnimEXzXYJIzc3j99+PEpGSRkpmDvbWeS/lTHTtm7TO9lY0mm/VHo3gqpglNPc3r4NxI+8/HA2qwd+VDXXGwVv89Te/ViMEtvchNvYLjqrvUqYIWBnXFRG0JWRcajZoNlR4Pm15Vx3hRvZ9X/1hYwb2r4adJcOqPIvvr4K5vbtwUOWtHNUB3+VhhLaruj6tTiRMvQmwoXAmB7+6g4+B3eazfQD7dqk4pnmSVP+4b96+eWl5l6fEkXPxXnfJc8HNoNlQNuhYUmndvrhY2LymI2mZcyT+/a+HerPBxxynqH1Hliha0//1wJJ/cU7mFA3IVNfCl01RftlR4fDp5RgWDXoenQ9n/prsHuJV7vB8f7MLaoAieGdy0qroohBBCCHFLueG/At2zZw+DBw822zZkyBC++uorcnJy0OuL11jJysoiK6tw2lNycvKN7ma1eu27O/nXEIdGUXjU6w7c3a+9iHxB4Cspzx1LIFejITU1in9OqZlfbeo58uzgpvx5LJr6VieJL1I83MJwkXWHI03PLTUZHHENw6jREOu6i4ZJfpzPag/A78GRjO/kR1tfx9KL6xqNasaFQ34tKGOeuiLi/i8B+MZ6ChON67BKjlAzufrOLD07QlFMUxaXZPTnYkYuFwlk5bdZtPfbZ9b0YHgyWBc+z7N04I69TdDoUvD0DeZIvD17ju1hzek1pOfmZzQZwK4JfHIeDuf0YaFfZzTh+9UpbT/cpU71SyrMoHrumA9a63CUPFss7EK4s1dHvgx5lw3nNqBQeIO9OD9udOTKUXbrcpm/cbJZ0OvrIV/Txq0No9aOIiqtsCj8nP1zAGjg0ICe9Xry/cnvaenaktGNR5vauFi7sGjAIp7a8hQ7I3YSlqLWFFNQTJlSS48s5WLyRc4mnWVL+Bb+uesfPGyuqjd1NVd1FUrX0J8hzXyKIn/NYrL7Ixykt2nTfxcS0JHHHVe+gH9/AhRoNhzcCjO+iD8PeTk4/DqF762jmJL5LBfj0mldz5Hw+HR6ao/S8fhs0zF99UmQDediU29I4EtRFPKMChb54397aCxOBj2RSep0xn0vD8DBUqcGWx3qgV9n6rsY4M9n1BpwoK4qWF7QpONk2Poe5BbJkOz5NPS/qj5YvY6Fga/OD6sBnYLFGW4U5wZFHjeEvrPAMj8bZfOb8G+I+njPpwQOvxMALUbGaHeAEWg/6cb2ryKaDIbHD5qfC6g/s4LAl29+xlpJ15bA+25o90TVM1xnXauayPg6f0WtqdfQzbZKitF3b+xG98blB8iEEEIIIUTJbvg3wejoaDw9zWvBeHp6kpuby5UrV/D29i62z+zZs3nzzTdvdNdqzJ1dX+TArocY7jCQycPfva5jFQS+shRbHPNXeExIvMCqgxp8LEPQWi/jwT+MTGsxiEsJsRQNGUXZJKHe0WoxaJLp7rGN/UW+pPu6bOR8VHsAUrJyGf3pLga28OSLKYElf5nfPge2vw8Tfwan+nB4hbpyImBUNCxO7EqWRQKPWKxT29q4QpcSapllJsF3YyH6CNkaS77K6GP2cnB4IgAe9lYMbOnJhqNRTMqcxVuWy9keMIujufWJTE7F2nMFaTaHeeyf9WV+htsvbSek5XSah6sLAZimpuW73PROzqR8ga1XYaDq69OFhcmtdFZk5RWvT/XI5kdMj+0t7Xmpy0vc5qXW/prfbz73bbyPjPwAiYu1C339+vJ4+8dxNbjSybMT7T3ao7sq0KLX6lnYfyErQ1YSlxnHHY3vINuYzeaLm1kUvIgt4VvM2g/4ZQC9fXszr888DBalFE13zS8mXTTo1fUx2KtmIo648g3zNU25qHiZXh5rfRDHQ0WmO3d7XP3bMz+Ie3wNZKdCyAZ6As01YZy/kkZKZi6Z8Zf43qow6AXgZowHFFNdnKr2y4FLvLD6CF9O6YTeQsvU/EUfAHydDWqm176l8Ofz6sYRH0K9TnBmU+FBKlK7yeCsBrG2v69mcT28XS2ifrXOD6n1vuy9ofmI6pke5+Rf+Lj7E4VBL4AuD6v17M7vgJRIetpeYmgrL7yu7MYt6Ypaz6rZ8Bvfx/JoNGqA9WpFM9H8uhQ+btxfrQno4KsGH73b3vg+iip19aIflXU9ga8zMSnYWFrg41S5BSdMgS/3Kl6FVwghhBBCXJNq+RXo1UGSguyU0n4TOmvWLJ555hnT8+TkZPz8/G5cB6tZxxbdWV3/X+xtna77WE42hRlz9nmQoYXl/+7n4MUAOvkvJ0SvABr25G3mNg9PyIG7rf1YnRHGZb0WP8tTuFqGEVFvK/vzC+02NWoJ1Ro54xDPj30UFm9ayonEkcTn+bD55GViU7LwcLA270hernqzD7BxFiRHmmW9HFMaEIsTS3NHMEG3DWdNCpzZDCd/h5gTcNt06PdS4f4Ran2eD3PGkYAD65/sybvrTxIcnoi9tQWOBj0fjW9P63qOjGrnw91LcxiQOReOAaSisUhE73jY9P6BnoG0cm3F1vCtNHdpTqBHIJ/sW0W6Vs0SuSvkK94dtYpR68aDYoQOk9UC3sd/5aM0W3Q5hYGSomZ2nsldTe/iRNwJEjITOJVwCkdLR2bvLwzs3OZ1Gwv7L8RWX3gT1Mq1FevHrEen1XEl4wq+dr7Y6AtX9RrgP6DUn7lOq2Nii4lm2/RaPYuCCwNRjRwbkZWXRURqBDsu7eCHkz/gbOVMb9/euNu4mx/QtbH5c3tvGPIu9HkBfp6C/vx23rb4hik5s0xNxlofhMz8Jz4dwT9/SmXTYdCoH5zbCifWmtq31Z7jwpU0vtx5jsaaItM++78KW97GSsnEjgwuXEkjN8/IO+tPsuVUDN8/0IX6riWvdlYZL6w+AsD05QeKvdbC20FdvfPfjwo37vpE/fmDej49ngK/zhV7s76z1EUTFGPJQS8AK3vo/GBlTuH6FZ2a1+Yu89fsvWDqOlh1PxxbjeXxVXw+eQ5sXAV7gVZ3qHWtaqtGfeHwT9B6LLQtUods9GJ1Km7b8VU3xVFUK4P++n5uefkLTVhoKvd1JzYli4Ef7UCrgdPvDkenLT04nZyZw12f7aGeswE7KwvTyrUNXSXwJYQQQghRG9zwwJeXlxfR0dFm22JiYrCwsMDV1bXEfaysrLCyqtvLwVdF0AsKM74AbPO0oIfDF8/Q1JBAiE1hoftIHfyWoxaG7urXh/OnV7GPTBo6bibE5RKZWnU6SWujBZ/dsYa7fx1FhE7Lw4dngQfYuy6gS6YVVtkORCX1KB74urCz8HH82WL9fDfnXhbe04EP/jrF9IRnWG31Jpz+q7DB9g+g1Vh11bbgHwH4ofkilgS70KepO618HPnxwa4lfgbt/Zyu2qLg3mA9GUBL15bM6DiDzl6d0Wl1PH/b86ZWdzW9m76ffk6K0+egUXj30HeMGvelutJej6dAqyPTtTFbfzAvOG6hsWDZsGWEp4QzvOFwtBot7T3aA9Cvfj+y87L568JfHIo5xJAGQ5jXZ16J/S4IQLlYu5T4emX42fvRzLkZEakRfDnkS5o6NSXbmM2snbPYGr6Vjw+pmXeBnoEsG7rMfGen+oWPNTo1Y0+jAYMTjPgIFgXSW3cUB3JJzrHAimw6ZucHkFrfqQYsC4LYOgsYOlst2F5EW81ZXtqkzgO9R5efWdZkCPR+Tg0yZSXhqUng8KUk5v4VwrLdFwD459Rl0yqL1yorN6/M17s3doVDy9WC7wYXtb5b4kXYk197z78HFCxWUBEajbrqX21j5wH3bQQrO7AupZB22wlwbDXs+0xdtKCgDl+RVSFrpXZ3Q8s7igfnHLyh/T010iVRNayvM/BVUOOrshlfBQtyGBX1cbti/88U2nT8MiGXUwi5bF6jsbzC9kIIIYQQonrc8MBXt27dWLdundm2v//+m06dOpVY30tUjpPB0vTYOs8CyEWnScTbLoIooI/GjnZOTfgkIQgAraLQvukYLsaFsC/+P4LcIgEt/nnwVuDztG4+Bksre+5068jHCYdMx07RaTlhmwO2cZy/dJR2fr3M+qGE77t6jTgAkhUDbbO+BDR829KTsPh0Fv6VWEJLBb4aDJ2mAQqpDgG8HKwGhKZ29y+hfaGCGyONPg4L27NoraLI0B9Fr9XzTo93aOLcpMT9LC10PNV9JK/uCMXKbQupnCOv5Viz3+y/uuMDMojCmGvLvB5fsC9+NaMaj6Kdezvaubcr+bg6Sz4b+BmbLm6ij2+fEttUNY1Gw7fDviUrL8sUSNPr9MzuNZtRv44iJkMNNh28fJDntz9PUlYSC/otULPMtDqw81Trs034znw6mGtjsLSH7BSCGn3B8NAR+GsuY2XMAEc/GPdl8Wl6Hi3UAuOxp0x/t9OeM73c0joe8iis02TvBVlJtNJc5PeoepyMKqzpdyYm9bo/myOXkopte+32lmwPjaWHr54pVtvhn/fUF/q9BAkX1PpyBTXeKprpdTPw71b26437q6tLpsWoReQLFM0Wq61qc0aauGY2VTTV8epp4+UpWJURYEdorFngKykjB1tLnalmYGmaeVXfQh1CCCGEEKJ0la4am5qaSnBwMMHBwQCcP3+e4OBgwsLUQtuzZs1iypTC1a0eeeQRLl68yDPPPMPJkyf5+uuv+eqrr3juueeq5gxucY5FpjrqjepjvUUSiq06nayDc3Mm9CmsIzbB4I+rW1N6NDdfUXOs+210bDcFSyv1i/q4nq/RxKjldgs3VnWfw/12hatJRcUcK9aP+NjoYtuiFWcmZb8MaJjUpT7Weh3392iIr4crx42Fwaync/5Hqs4RspJMNcF+i1df93Mx0Kdp8eLsOy7t4J2975CarQZGujVyxeD7Hdbea7B02YMGDa92fbXUoFeBOwP9eLbzwyiKBq0+iV7f3kNUUhIf/h3CgI828eeF3wFopnuAoc1a80b3N+joWX72i43ehtEBo00rMlYHW71tsewxW70t68as47c7fqNXPTVYufHCRvZE7WFr+NbChvf9CRN/UetNFaXRmFZ91F3cyZ/Wr/CIxwn1tRYjS69NNfFnGPo+TPgegGa6SLQYAWioi1XbFAS+GvQEYLbllzhgHug6G3v9ga/fggunVlpZaFn9aHfu79mQb+/vzEPJi9D98RRkJKhBuo5TYOCbat8t7dU6dL6drrsPNw2dXl118mpuspqcqBlWFlVU46uUqY4Z2XlEJmYU236uyLVn19krpsdhcenc9s5mJn25j5w89ZqWkJ5ttu8T/QP4+G51Kr4QQgghhKh5lQ58HThwgA4dOtChg7qk+DPPPEOHDh147bXXAIiKijIFwQAaNmzIhg0b2LZtG+3bt+ftt9/mk08+Ydy4cSUeX1SOo0HPk/0DmDGwCdaotZCC3S8SbK1+ke/oPwAHRz8WNLmXSYYGzBj5LQBNGw/DNa9wNcLhnZ4wO66zS2PW3HeY2ZO20qzJCJ4et5pmOepwOXs5hPu+2W+aCgJwOTqSq83Mmc5RpRHjO/ny3GA1Y8RgqeP9cW1YmDuG3XkteTz7CX7N60nPtA/INhTWntpnbE4nf2cWTOhQrLZKTl4Oj/3zGCtDVjJpwyR+DvmZhwZr0FkXBt/6+fVjTJPyi5HrtBoe7tUSi/zPLkV7nF6L5/Pp7u3EuD6DRpeFMceRJePurZLVuWqCjd6GRo6NeKit+UICx64UCWC6NoamgylRkRX0tEouHdPyM4FajCz9TZ39oesj4NIIdFZYKDnc0Ui9SWxpiDc/7pD3wMEXWzL5daw9741pw1dT1WDTmZi0ip5micLj0/lpv5q59eODXTj06iAC/Z0LG1zcpf5dvxvc/xdYWKnT+7o+As+cgCcOmheBvxV4t1XrlBWwdQeb65+OK8S1yDUqZs+NVz0vf/+ypzre/cVeus/ZYipIX+BckedFX9t19grZeUb2nY9n6Q41kzU21Xxxk2cHN2N0+3qV6qcQQgghhLhxKj3VsW/fvqbi9CVZtmxZsW19+vTh0KFDxRuLKvFMflDpoRM9sMtbS6pOi6LR4J8HrZqNBmBA9xcZwIumfTRaLU/4DWFDxHaeCHwaL+8O5b6Pq8YGSCU6KYx/42LZGhLLS8Obk5yRS+/Ey8XaHzU2oq2vIx/c2Y4rGVd4d+8SXAwu3NtsOn8pndmYUziFLBF7Hsx6mjlOqzgTl80x2+7880g3MnIz2Hh+IwoK3by7sSh4EStDVpr2O5d0jrf3vl3svUc1HlVsW1kG1x/Bn+E/A2Dt9TsabY7ptSa2vXG3r9yqXrVRe4/2jG0yljWn1wBwKKaC/yaLBL4AyEkDrQXUCyx/X61ODX7FnuS93gbGdPHHeX24+XH11mpNrORLNNZG07jTcFKz1JvVK6lZJKXnmGU2VsaCzafJNSoMaGRL96xdYDFcXYhh13xwqKfW9UIDk1apta+KKq0O1q2gfpEabe7Na64f4paXnWs0e56ek4edVcW/uuQp+cXtSwl8Hc5fJfiPw5E8MUDNEJ615ig7TxdmeV1OziIzJw9rvY6Q6MI6XttDY3msXwBxqYUZX9N7Xl9NQiGEEEIIUfWqZVVHUT2SrW/nSmhHfKxO8+HdPWkX0BG9vvQV8cYN+pDK5N25WjgBqeTYnqez7Sskxw7nvQ3qa4Mtk0ALv+b1xJosvsgdweDOrXlyQBNSslO4d8O9RKSqU8587XxxtTVwJf+35EsmB7Jwy2m2RzSgW7o6BXZUSx80Gg3v7H2HdefWldAbla3elmbOzUxBHBdrF+5rdR/96leiGDnwRq9n8T3qxBdHl5oFvTo63Mncgc+UsefN5fVur3N3s7sZ/8d4QuJDSMxMLH86pkUJC024Ny95e0lcG0PsSayTztPr0i+QnaIGw9yamLc5DcSpCyPYWerwtrckKiWbM7Gp5lla5TgUlsAXO86Rk2dk80m1ttlc2+/g51XQY4YacNvyTuEObk2LB71udQ16qws8JEUUrm4pRA3IzjMPfKVm5lYq8FVaxldSeg5FC1Pm5GeS5eYZWX3oUrHjRCRm0NjdzizwVVCDMC7//7JnBzXlkb6Ni+0rhBBCCCFqlgS+6pDw+AxysOZiVhsCm/eo8ql5njYekH6JE7b5NxI2v8Gp7gA459dmWmsxlO0ZjQCY26sRzrYaPvhvvinoBfDZ4c8Y3X4eX+86zxP9Ahjc0pO2vo70en+raVrLbQ1duJx2mT/P/1msH08HPo2fvR99fftiobVAo9GwNWwrP4X8xDOBz9DMpfKFuG30NjzU9kGWHf+GHKMa+HrhtheY3HJypY9Vm2k1Wlq4tqC5S3NOxZ9i/fn1TGoxqeydvEso4u/VpuJv6hqg/n1oOcSdUR+PXqzWkzK1yb9ZjDsLIX/Cb4+zOTeTkZo3OBtT8cBXSmYOj/1wiKikTNO2QS09cTm9Sn2ya0HxnXzaV/xcbhVaLQx6q6Z7IQTZV63KmpqVA1R8IYOSAl8HLyZw5+e76RngZtpWELw6FZ1iyjLb+lxfHvnuICGXU9hzNo5TUeYrN8anZROXmsWV/IyvFt4O6MspeC+EEEIIIaqfBL7qEHvrwh/njahH5e/aANILp8flFnkPZ00KwVaWxNXbjf6sGwM6xvLd6f9YfbqwUPYn/T7h6W1PE54SzlfjnHlqYBMcrNXgh7ejgbs7+/H93jAMeh39mrmzMuRLcpVcOnp05LOBn/HjqR/xsfVheKPhxfrWr36/Smd5Xc3awpoP+3xIRGoEE1tMRKupuzcwY5uM5b197/H+/vdxM7gxpMGQ0hs3HwnD54F3e/hqoLrN1q309lcrCHxdzq8pZuVQfKVEl/zAV+if6h/AFuinDeJMbM8KvU2eUeGZnw+bgl5aDWg1Gl7o6QTnStlJawHtywn8CSFqzNWBpJTM3Ertn6vkr+qoKSySP39TKIqC2XTGglUcg8ISAOjVxI2Gbrb4uRgIuZzCK2sLayJqNeBqZ0VsShZnYlJNQTM3+wpmwQohhBBCiGolga86ZM64try17jizhre4Icdv4N4Uwq/easSSPGw1mbzt6sVF5RhDe3uw7dIWSCxs5WHwoK9fX1q4tOBY3DEOXD7AyMbmxdHfHNWa+3o0xN3eiiNx+/ji6BcA3NvyXmz0NkxvM/2GnFdR1xs8u1mMbDSSVaGrCE0I5aWdL9HAoUHpmXJaLXR+UH3c72U1c6vzQyW3LUnzEfDvRxCfH31yaaTW/irKveT3bqKJYOnJyzzWLwBHQ9l1vjadiGbTictYWmhZ8WAXPOytScnMpcmVv8wbWtrDg1sgKlgN5rnLioVC1FYvDm3O8chkU4H5gvp/FXV1xtfn28/y75krxdpdSlAXhPnvghr46lBfzTL1dS5eLqBbY1esLHRsORVDaEwql1PUwJerrWWl+iaEEEIIIapH3U1puQW193Nizf96cFuDG7MCW/16XYpte6rjWvo6LeewlSWhVuqX/m2XthRr90THJ9BoNHTyUlfrWxi0kPjMeLM2Oq2Gxu527Ij8i0c3q3WFvG296ed3awSjqpOdpR0/3f4TPXx6kG3M5pfQXyq2Y58X4Olj4FS/4m9m4wJPHMJUUKdh7+JtHHzgjs+g7d3QoJf6N9BEG8G52DTu+2Z/uW+z8Zi6queUrv4E+rvg52JDSy9bNegG4Nka2k6Apw6rwa624yXoJUQt5+diw9bn+tIpf7pz2rUGvjQWnItNZc6fp0psdykhnazcPLaFqHUBezVRs1o7ljDNemwHX5p4qHUBX117jDyjglYDbnaS8SWEEEIIURtJxpeoMBeXABzzjCQVmXrydcZ+8Ia8DKdS9/t73N9423kDMLrxaJafWE5UWhTLji3j6cCnMSpGdPkZQDl5Oby39z0Amjo35aUuL5W6Gpe4PnqtniENhrArchfhKcVS+aqWRgOP7YOg76D38yW3aT9R/QNw+QQc+YkmmkuAwqGwxDJXd8zMyWPLKfWGdUhrr8IXDv8EMSfA2hGmrlODcEKIm45d/lT+yk51zDMWruq4IzS21HY5eQqfbTtLcmYuLraWdMzP+BrZ1puGrrb4OhuYvzmUi3HpjGjrjfGw+erWD/ZuhMFSV9KhhRBCCCFEDZOIgqgUR0VLUgnb9xuKFxtu7NiYZzs9awp6AQQ4B/Bs4LPMPTCXw7GHuXPdnYSnhPNY+8fo4dOD5OxkUnJScLF24efbfzYFxMSN4WvvC2C2+MAN494MBr9TfjtQi91rdDiQgScJXMaFQ+EJ9GvmUWLzN9cdJzkzF08HKzp6W0HoX2DjBlvfVRv0elaCXkLcxGwt1a8r6dl55bQ0V1Djy0JrwfYyAl8ACzafBmBwS090WjVDVaPR0MbXEYC3Rrc2tW3iaW96bGdlwYtDmleqX0IIIYQQovpI4EtUioPWAij5N+7NFD1ZjvW4kHwBgO+Hf4+dpV2xdgXTHQ/FFBbKn3dgHvOYZ3oe6BkoQa9qUM+uHgCRqZEYFWPtKehvYaXWAos7zf1Ns5gdCocumge+LidnMvevEKKTMk01ez4Y1xbdmukQsqHwWA6+0Pnh6j4DIUQVsrJQr02ZOZUMfOVPddRpdRy5ZP5rmycHNKGTvzNLd5wzXUPc7CyZOaz8IFZjd1vT4wZuNmi1Vb+gjBBCCCGEqBq15C5X3CwC7fxNj7tctaR8f8dmPNXxKW5vdDsbxm4oMegF0NipcbkBlkDPwOvvrCiXp40nFhoLcow5xKTHkJCZwKQNk1h+fHlNd81U8D7Q9jIAQWGJZi9/tu0sqw5eMt2w6nUaeiWtMw96AfR/GfTFMxKFEDcPK736i5C07Dyyc40V3q8g8KUYtcSlZQNqRtf749rwzKCm9G7qjp9LYQH7ad0b4GRTfpF6e+vCadcF2WhCCCGEEKJ2ksCXqJT/DVvK3dZ+LGv/HIvv3sIrXoWF57sH3M5A/4HM7jUbP3u/Uo9hpbMyZRoB3Nn0TtNjd4M7FhoLetXrdWNOQJjRaXV42ao1sSJSI/gn7B+OxB5h7oG5HLx8sGY7565mXTQ0XgLgZFQyiqKgKAqfbj3Dst0XzJp3tYtBu/EF9cnAN2HIe9DzabWg/S0oJTuFjNyMmu6GEFXCWq9+Xfnkn9N0m/1PhYNfBYGv1Ey1JpelTsuSyYFMuK1wgQ4/F4PpcTMvhwr3aVh+PcHH+wdUeB8hhBBCCFH95NeUolJs7Dx4eUJhRk23FuMheisArZuPq/BxJjSbwLLjy/hf+/9xZ5M76ebdjY6eHbG3tCclOwU3g1uV912UrJ59PS6lXiIiNcKs1tdPp36qcObdqtBVBMcEM6vLLGz1tuXvUBH5gS/XkB/pog1gX1pzYlOzOBOTyty/Qoo1H6v7F7JyofEA6PGUWlD/FpWYmcjwX4fjZnBjxYgVVfczEaKGWFkUTn2PS8smLD6NAA/7MvZQ5Snq1MjEdPVvDwcrNFddG3wcCwNfzb3KP2aBuXe145lBTc3qfQkhhBBCiNpHAl/iutSv35Mv2zyBk309LCoxnWxqq6lMbTXV9Hxwg8Gmx1YGWRK+Ovnb+7Mvah/nk85zMfmiafvxuOMV2l9RFN7c8yYAsRmxLBm0pMLvnWPM4ULSBQKcAordjBZMdQRYaPUpnTM+4WRUCttCYkzbHQ16kjJyAIUeObvVjR0m3TJBrz/O/cHeyL342Plw7MoxwlPCGdJgCE2cm5CSnUJKdgqfHPqEWV1m1XRXhbguBRlfBbQV/DdekPGVnK5miHk6FP9/ysO+8P+cek6GYq+Xxs7KQoJeQgghhBA3AQl8ievWpeNDNd0FcR0CnNVpOmcSzhCVFmXaHp4STnJ2Mg6WZU/9KZoltjtyN1GpUWYreZblg/0f8FPIT7zb811GNR5l/qJ7M7C0h+wUPJQ46nGFk1HJbD6p1vyaOaw5PQPcuH3hv9yj24JHTgRYWEOTwSW8083HqBjRoCkeEMyXmZvJW3veKjadcckR88Dj9kvbJfAlbnrWevPFToxKxfYrCHwlpKl/ezoU/8VK10auTO/ZkBbeDlKkXgghhBCiDpLAlxC3uAAnNfB1OvE08ZnxZq+djDtJF+8uZe4fkmA+7XB/9H5GB4yu0Hv/FPITAIuDFxcPfFlYwYwj8EU/SLhAR+1pDl5sTXi8GuiZ2KU+eg1YksMsix/Vffq8AFY3fwZGTHoMD/79ILZ6Wz7p/wluBjf2RO5h08VNhMSH4GLtgredtyno1dGjI718exGTHsOKUyvMjhWRGkFqdmqpi00IcTOwtjDP+MrJq2CNL0UNeMWnqVMdS8r40mo1vHJ7y+vsoRBCCCGEqK0k8CXELa6xU2OgMHNLq9HS27c328K3sePSjvIDX/HXFvhKyU4xPS51MQQbFzWDa/9SOmpP8+HZOAAsLbTYp15Es2ICodZnAFDQoOn+ZLnvW5vFpsey7dI2fjz5I+eSzgEw4JcBjAkYw+rTq0vcZ1KLSczsPBNQs1v2RO7hQvIFszanE0/TwaPDDe27EDeS1VUZX5Utbr9ifwTgWmLgSwghhBBC1G2yqqMQtzgXaxesdIXTfwbUH8BdTe8C4OeQnwlPDi9xv+TsZP48/6dpal0Pnx4AFV4N8nDsYdNjDWVML/K9DYC22nOkZqk3sc42ejQ7PoC4M6ZmeTYeoNNX6L1ro8Oxhxm2Zhhv7XmLM4mF52VUjGZBr+4+3bmv9X20dWuLt60345uON71mobXgi8FfMKXlFJ4OfNq0OurJuJPVdyJCVIF1Z9fxzLZn2HFpB1C8xld2CRlfmTl5/Bp0iSupWaZteUY10wtFDZz5u9jcoB4LIYQQQojaSjK+hBA82OZBNodt5tlOz9LFS83w6ujRkUMxh3hw04OsGbUGG33hDWNkaiSj1o4iK0+9wfSy9eK5Ts+x6/ddRKRGkJaTVuZKgjsv7WTO/jmm53GZcaV3zqsNAC20YWgwokVhFsvgyDqzZhZOPpU97QrLNeYSlhKGo6Uj9pb27I3aS3xmPO3d2+Nr74uFtnKX0uCYYBo6NsTRytG07adTP5GVl4WTlRMjG49kWqtpnE08y8ydM4nPjMdaZ83SwUvLzdzysvXi+dueByA1O5WdETv54ugXdPPphoeNh6zwKG4K8w/OJzYjlk0XN/H7Hb9jbWGeqVVSxteCzaf5fPtZWng78OdTatC3YKojaKnnZGBwK68b3XUhhBBCCFHLSOBLCMHD7R7m4XYPm22b12ceEzdMJCI1grVn1jKxxUTTa/ui9pmCXvc0v4cZHWdgo7fB3eBObEYsZxLP0M69XYnvFZMew//++Z/ZtisZV0rvnGsT0Flhk5dFfU0MzTVh3JG9rng7h3oVPNvKW3BwAd+e+LbU1+0t7RlQfwCvdH3FLHuugFEx8t2J7zgce5j0nHR2Re5iQP0BLOi3AFCzUv6N+BeAj/p+xG1eapabh40H2ydsB9Ri9lff/JdnfLPxrD+3nsg0NVDpZOXExnEbJfglarUcYw6xGbGm5y/ueBFHXQOsvAoD5MtP72RzrPkKjL+dj8TKE0ISOnIw2p4Onm0xKvkBMkXHo30bo5Pi9UIIIYQQtxwJfAkhSuRu484DrR/g3X3vsuLUCrPA14m4EwBMbTmV5257zrQ9wClADXwllB74upB0wfS4tWtrjsUdIzErkTxjHjqtrvgOOgvwaAFRwbTQhDFat6vwtc4Pw/78VQztK7aSZGVEp0Wz4NAC1p9bX7xbGh15ijqNKiU7hbVn1rIvah9v93jbVBctKSuJZceX8fuZ34nJiDHb/5+wf1AUBY1GQ1BMEIlZidjr7Wnv0b7EvlQ26AVq9tfyYcuZ8McE4jLjSMxK5FziOdq4t6n0sYSoLnEZ5hmgJ+NPAiexdC7ctjsGMP8nBbZgaQuWLruZ9tciXuww2/SSomixs5KvPEIIIYQQtyL5FiiEKNWQBkN4d9+7XEi+QHZeNpY6S6DgRhRauLYwa9/EuQl7ovawK3IXPer14OeQn/Gw8eDu5neb2hQU0W/m3Iyvh35N1x+7YlSMxGfG427jXnJHvFpDVDBttOforw1Wtz28U83yKgh82bhU3YmjBrMmrp9oyjzxs/fjs4GfMeXPKbgaXFkxYgV5xjxe3/06Gy9sBCAqLYqXdr7E+rHr2RWxi3kH5nEp9RKg1jFr596O4Nhg03u8uedNziedJyErAYAB/gPQa6u2TpmnrSc/jPiBoauHmvoogS9Rm8Wmq//mvGy9eKv7W5xLOkdo7BVW7LtoajOirQ/NvcxXcP1q/14yLA+Yni8KWlL4oqLDxrKEwLoQQgghhKjzJPAlhCiVk5UTFloLco25xGfG42XrRY4xx7SS49WBr1aurQDYdHETmy5uMm1v79Ge5i7NAYhMiwSgjXsbDBYGrHRWZORm0P+X/uybuM+slpiJpxqo6aY9gZUmR13B0bMVaIoUvC4oYn0dCjKwAHZH7jYFvdwN7jzb6Vn8HfzZOG4jFhoL9Do96GBun7nM7TOXhMwExvw2hpiMGBYfXsy3x78tnGYFvNH9DcY2GUtoQiiP/fMY0WnRZkXrdRodD7Z58LrPoST17OoxrOEw/jz/J1FpUTfkPcqSkJlAYlYiDR0bVvt7i5tPQXakh8GDbj7d6ObTjWMOSXy74V9Tm55u7RjXztdsvzW7rcwCXxlKDIXrZkjGlxBCCCHErUpWdRRClEqj0eBirWZS/X3hbzJzM/ntzG9k5mXiYu2Cv72/WfshDYaYrTJY4Lczv5keR6aqga96dmpNrrwiAauQhJCSO+LVGoCOWnW1wywLB9DqQFOkXk+DnpU8O3ObLm6i5089mbF1BklZSeyL2gfAvS3uZcv4LQyoPwAAg4VBDXpdxdnamf+1V2uXfXPsG1PQ65eRv3B06lHGNhkLQFPnpvTx7WO2r1aj5cXOL1Lfof51nUNZvG3VqaAFn391yc7LZvKfkxm1dhQv7niRrLwsrmRc4cujX/Lwpod5Y/cbHI09Wq19ErXblXS15l/RDFBrvXm2VkmrOlprzbM+jZr0wieKFhsJfAkhhBBC3JLkW6AQokyu1q7EpMcw98BcgmKCTMGpB9s8WKwml06r45Wur5CZl8m6s+sY22Qsq0+v5q8Lf/HCbS+g0WhMUx19bNVVGB9t/ygfH/oYgLDksJJXLfRsZfY0x8oJU8WrJ4Mh5iQ07ndN55djzOG/qP94fvvz5Cl5/BP2D/uj95OSnQJgqtdVESMajWDegXlk5GYA8Hj7x02ZbkWNbTKWg5cPkpKdwqtdXyXAOcAUCLxRCj7vyLRIQhNC+eHkD9zf+n78HfzL2bN8kamRLDi0gN6+vRnRcIQpay4+M56X/n2Ji8nqFLUN5zew4fyGYvuvPr2a7j7dearjU0SnRZOYlcgdAXeg1cjvZm5FBRlf7oaigS/zsVDSqo552fZQUik8RYOa8SVTHYUQQgghbkUS+BJClMnV4Gp6vDlsM6DWqxrTZEyJ7TUaDW/3eJtnOz2LjYUNa8+sJTYjltiMWA7FHOLg5YMA+NipgZjpbaYTlRrFz6E/E5YSVnInDM4ojr5oktR6WZkWjpiq+7g0VP9cA0VReHTTo+yLVrO7fO18ScpKMgW97PX2dPLsVOHj2eptebDNg3wS9AkWGgsG+Q8qsV1L15b8OvrXa+rztfK2UzO+wpPDefnflzkVf4rNFzezbsw6U1bftZp3YB6bLm7iz/N/8tOpn/hs4GdY6az43+b/cTzuOKAGBbeEbTEFBV2sXRjXZBxHYo+wL3ofuyN3sztyt+mYf1/8m/r29RnSYAiBnoHX1T9x87iYfJGlR5YC6qqmBawszINWOSVkfKVmAg7Fj6koatDMxlK+8gghhBBC3IrkW6AQokyu1q7FtjVwbICt3rbUfbQarSmY0tCxIWcSz3Ay7iQLDi4oPIZDA9Pjgil+4cnhgHmtrQIaz9aQH/jCtnifypJjzCE4JpiOHh3NstQOXD5gCnq5G9z5ccSPRKdF8/vZ3/Gx82GQ/yDsLO0q9V4Ptn2QAfUHkKvk0sipUaX2vZEKMr7OJp01bUvOTqbPyj508uzE0kFLS5zCWZ7fzvxmVs/tcOxh1p5ZS3hKOMfjjmOrt+WN7m8wtMFQolKjWHV6Fb3q9TKtXpmdl82KUytYcngJKTkppuPsitjFLnbx06mfeLXbq9zV9K5rPHNRVXLycvg0+FMiUiN4pesrOFo5Vvl7rDi1wvS4IDgOxTO+skrI+ErOzC3lqOq/eVuZ6iiEEEIIcUuSb4FCiDIVzfgq0NK1ZYX3b+HSgjOJZ/j+5PemaY7Lhi7DydrJ1MbP3g+AjRc20ta9LZ8EfcLoxqN54bYXCoMxLoVBJDd3r0qdw+x9s/kl9BdmdZ7FxBYTTdsLbrJHNBrB691ex2BhwNnauVjR/sqqTQGvAg0dG9LDpwdHYo+Qp+Rhb2nP5fTLgBoAXHZ8GQ+2Lbu4fp4xD6NiNP1Mzied59VdrwIwqvEoGjs1Zv7B+Xzw3wemfT7o/QG9fXsDatbZEx2eMDumpc6Sqa2mMqLRCD488CGXUi7hY+djmhKpoPDWnrdo4NCA27xuq5oPQ1yTN/e8yW9n1Xp9IQkhDKw/kMktJ+Ns7Vys7dnEsxyKOUQ/v364Gdw4GXeSZceX4WDpwLTW00qd2huTXljYfrD/YNP2YjW+rgp8KYpCSmZOiTMdyc/4spVVHYUQQgghbkkS+BJClMne0r7YtoYOFZ9a2MK1BevOrWNv1F5AzfS6eupaQeBLQeH9/94H4KeQnzDoDTwT+IzayLmBqb3GpuIZX9l52fwS+gsAHx/6mIH+A5ny5xRau7VmV8QuQC1gb7AwVPiYNyOdVsfngz43PQ+OCWbyn5NNz3889SPT20wvlmlXYG/UXl7c8SLJWck0cGyAhdYCDRoUFNq7t+et7m8RmRbJ/IPzTftMbzPdFPQqj5vBjdm9ZgOQkZtBPbt6dPXuypoza1h/bj2/nv5VAl832PG449jp7Ux13xRFQUFh08VNpOeks+7cOlPb80nn+eLoF+yP3s93w74rNm6e2/4cZxLP8PGhj1l3xzpm7pzJuaRzQP6/bQsDoxqP4sXOL6LXFmYaXslQC9u/2PlFswxEve6qGl9XTXXMyjWSk6egS26F3uG42WuKosPKQouFTmrGCSGEEELciuRboBCiTGk5aabH09tMx83gxohGIyq8fz8/86Lzbga3Ym0aODYosaj9smPLTFliOBUpwm5T8ZpUK0NWmh5b6axYcWoFEakR/HXhL9Jz03G2cq5UBltd0crNfMGAKxlXuJB8ocS2ydnJPLXlKeIz48lVcjmTeIZT8ac4GX8SgLua3YVOq8PP3o9B/oOw1lkzqvEoHmv/2DX1zWBh4MmOT9LZuzN3N7sbUOvLpeekl7OnqIj0nHSCY4JZfnw5Y34bw13r7mLd2XVMWj+Jkb+OZGHQQq5kXOGxfx6j3fJ2PLf9OV7b/RpGxUgf3z5sHb+Vt7q/hbXOmsOxh81qs4E6ls4kqiuwJmUlMWnDJFPQqyDTKyM3g5UhK1l4aGGxfaHk60RROVdlfCVn5gCQGTWelwLn4q8vct1RtNjJNEchhBBCiFuWBL6EEGUaWH8gAI0dG/NUx6fYOn4rvva+Fd7f196XI1OOmLJIhjQYUqyNXqtn+bDl/DXuL8Y1Gcd3w76jrXtbFBQOXT6kNiqS8YWhYoGvjec3mk27S8hK4MujX5q16V6v+y25eqBeq2fpoKW80e0NUybVhD8mEJseW6zt72d+Jz03ncaOjfll5C881+k5Ont1xkJrgaeNJ/39+pvaftT3I/ZP2s+7Pd/FQnv9wYZ27u3ws/cjIzeDLeFbrvt4NxNFUcjOy+aD/z7ghe0v8Pg/jxf+e8hXNDBdEacTTjPi1xFM/nMycw/MNQUxX/r3JfKUPBQUlh5ZSr+f+7EzYqfZvs2cm/HibS/iZnBjTJMxjGs6DoCX/n2JJYeXkJqdCkBQTJDZfuEpau2+N7q9wfJhy6lvX9/02qrTq8jMzTQ9j8uIA0qeYl3U1RlfKfn1vewtbbmn9VCcrIrur8VGVnQUQgghhLhlya9AhRBlauXWitWjVuNt633Nx9BoNHw/7Hu2XdpWZraYj50Pb3R/A1ADHkdij7AtfBtDGgzB0qnwZpkyAlWHYw/zw4kf8Lbz5vsT3wMwsflEDsceNq0w2My5GXc2vZPdkbt5qO1D13xeN7tuPt0AiMmI4b/o/8jIzWD+wfm81+s9U5vEzES+Of4NABNbTKS5S3OauzRnaqupZOdlo9VoiwW4SpsueS00Gg23N7qdzw5/xh9n/+D2RrdX2bFrG0VR2BK2hRwlBxsLG74/8T17ovaYtTl25RirRq3icMxhvj/5PQcuH2B80/G80vWVMj/3HGMOmy9uZva+2SRkJeBi7YKfvR/NXZqbZUU2cGhglvnn7+DP5BaTGdZoGPZ6e7P3GFB/AD+c/IH4zHgWBS9iUfAi+vv1N60g2tu3N/ui9pGdl830NtNNgbLf7vgNDRqGrRlGVFoUW8K2MLzRcNJz0knPVbP6ysv4Wr7nIqPb1yPQX60vVhD4crBWp0c6WztCasEHqyMnVynzeEIIIYQQou6SwJcQolxNnZte9zGcrJ24I+COCrdv69YWgL8v/k1SdhJfDi6SqaW3KXGfSymXeOyfx0jKSjJtC3AK4IXbXuB43HHWn1tPS9eWDGkwBGsLa+5ufvc1nUtdM77peFaFriImPYbNYZt5OedlbPW2KIrCq7teJSY9Bn8H/2JBJ0udZbX0ryDwtSdqDzHpMXjYeFTL+1aXPZF7+PLol+yP3l9qm0H+g9h0cRNxmXH0+9l8+vDPoT/T0bNjqUHlyNRIpv893ZR51dq1NZ8P+ty0KmNb97ZsD9/Ofa3vo7Vbay4kXWDtmbV09+lOZ+/OpfapnXu7Ytu2hm/F3cYdgDsC7uD5Ts9jobUwyxItCJSOaDSCL49+yY6IHQxvNNyU7WWwMGBjUfK/8aLGfbabC3PUc07OUKc62lurx3azKSy4ryg6opMzix9ACCGEEELcEm69+T1CiJtCG/c2psf7ovaRk5cDIz+B1ndCy9Gm1xRFzeTIzM3kqa1PmQW9QJ1aqdPqaOvellldZjE6YDTWFiWu/XbLcjW4svnOzfg7+JORm8Hq0NUArDu3jm2XtmGptWRen3nYlBJwvNHqO9Sng0cHjIqRdWfVAuuXUi5x/IqawRedFq2Oj5tERm4G8ZnxAGwP384jmx8xC3rZWNjQyrUVff368k6Pd1g9ajUf9f2I3+/4HS9bdUVTK50V09tM557m9wDwx7k/SnyvzNxM3t//PuEp4djqbZnWahpLBy81Bb1AXZHzw74f0tqtNaDW3JsROKPMoBeogc+u3l0BmNJyCqAuUBGTHoNeq6e7T3caODYodWp0d5/uAOyN3IuiKFzJVOt7uVq7lpi99u6Y1qX25WKcOuWznpO6SIWHbZHAV65dmechhBBCCCHqNsn4EkLUSvXs6vFQ24dYemQpABeSL9AkcCoETjW1WRi0kBUnV7B08FJOxZ8iNCEUF2sXvhr8FWN/H4uCwuAGg2vqFG4qGo2Gaa2m8eaeN5l7YC67InfhaKkGR6a2mkpzl+Y12r/RjUcTFBPEpoubuL/1/Tyy+RHCksN4qO1DLDmyhGmtpvFsp2drtI8VYVSMTNs4jRNxJ9Br9eQY1YDdwPoD6eDRAReDS6nTORs6NuS30b8RkhBCQ4eGOFk7cTbxLCtOrWBf1D7Sc9Kx0dtwJuEM9ezrYVSMjF47msvplwH4bOBnJS4icT3e6fEO+6P3M7zhcM4knjEVuu/i3QVbvW2Z+7Zzb4e1zpq4zDju++s+MnIzgNLre03qotYJfPnXY8VeOxOjzmsM8FSDXN72hXUA8zIaMKB53coSFEIIIYQQFSeBLyFErfVEhyfYH7Wf4NhgTiecpolzE9Nrf57/0xQU+yfsHw7HHgbUzJMA5wB+GfkLydnJNHJsVCN9vxmNCRjD6tDVHIs7ZrZSX1UHS65FW3d16mtYShgx6TFcTL4IwJIjSwBYdnwZzwQ+w7v73iXXmMtr3V6r9KIFRsWIUTFWSVH+0uyK2MWJuBMApqAXwGvdXsPZ2rm03Uxs9DZmP49Gjo2ob1+fsJQwdkfuJi0njVd2vYKPrQ/O1s6moFcf3z435OfoaevJyMYjgcIVG4EKTWu21FnSs15PNodt5uDlg6btDR0blrFPyT/TM7H5gS93NfDl61gYPHus6yCmdWxfbn+EEEIIIUTdJIEvIUStFuAcoAa+Ek+btv1z8R9e2/Wa6fnBywcJjgkGYFjDYQA0c2lWrf2sC3RaHcuGLePuP+7mTOIZ0/aazvYCdeEDgJTslFJrYf0X/Z+pUHt6bjqPtX/MtJpoWQ5EH2Bh0ELOJ50nJTsFfwd/BvgP4JG2j6DX6avsHPKMeaZAXVETmk2oUNCrJBqNhr5+fVl+YjlPb3vatD0yLZLItEgA3uv5XrUsCtCjXg9+Cf0Fg4WBQf6DKrTPOz3fYczlMaRkp5BjzEGv1dPLt1ep7S0tzANfuXlGLHRaTl/OD3x5qIGvRi6epjYP3NYPO8uq+zkKIYQQQoibiwS+hBC1WhMnNcsrJD4EgK+Pfc38g/PN2gTFBAHqjXdBgERcGyudFfc0v4e3974NgIu1i6lYeU2y1dviaOVIUlYSy44vA0Cr0WJUjKY2BdtBzQj88/yfvN3j7TKzj7Lysnhl1ytEpEaYtp1NOsvZI2dZFbqKl7u8fE3TZVOzU9FqtISnhJOem47BwsChy4c4HHsYW70ta0evxcvWiysZV3Cycqr08YsqCHwVcDe4082nG7sidnFvy3u5vdHtVbrSZmn6+/VnTq85dPLsVOFsO1u9Lb19e1f4Pa7O+ErNykWr1RCTkgVA4/zAl4u1C291fws7SzvsLKXGlxBCCCHErUwCX0KIWq1gitvh2MNk5WWxKGgRoK70N6D+ALMsl8faPVYjfaxr+tfvz4KDC0jJSakV0xwL+Nj6kJSVRGhCKAD3t76fbeHbTNlpOyN2AtDStaVpOuGuiF0lBr6uZFxh08VNfHfiOyJSI9Br9Szot4BjV45xOPYwx64cIz4znme3P0v/c/3p6NmRlq4tuc3rtnL7uSVsC09tfarU12d0nGEqUu9mcKvMR1CiDh4dcLV2JS4zju4+3Xm+0/MEOAdc93ErS6PRlLqyZFW5OuMrJTOXXKO6wIWdlQUO1oWZXWOajLmhfRFCCCGEEDcHCXwJIWq1Zi7NMFgYSM5O5tDlQ+QYc9BqtLzb812zFRx9bH3MVoIU187N4Mb6sevZF7WPQM/Amu6OiY+dDyfjTwJgobXgnub38FTHpxj3+zhTMMzb1pufRvzEjks7eHzL41xIvgBAUlYSr+x6BQ0aHm73MDO2ziA6LRoAZytn5vSaQ/d63U3ZRzl5OXx48EN+OPkDW8K3sCV8CwYLA+vuWIenrWfxzhXxc8jPpb7mZevFuCbjrvejMGOhtWDJoCXEpMeUOU2wLrg68JWcmYMGNZvNYKmriS4JIYQQQohaTgJfQohaTa/V09atLfui97E1fCsADpYOaDVasylijZ0a11AP6yZna2eGNhxa090wk5aTZnr8793/mlYN9LHzMQW+etTrgUajMdX2OhV/iiOxR/gv+j+2hW8DMI0jgOc6PcddTe/CRm9j9l56nZ6ZnWfS3r09z+94HoCM3AwGrhqIu8GdzwZ+RjOXZuQac9FpdGg0GtJz0hn/x3hT4f2mzk1N/QJwtHLkta6vVWndsALNXJrdEnXtrp7qmJKZawqGWesrt5iBEEIIIYS4NUjgSwhR63Xw7MC+6H3svKROZXO0cgTUqVXNnJsRkhDCpBaTarKLohr09evL3qi9NHBoYAp6AfjZ+5keD284HIB69vVMNcAmbSh5bNzX+j6mtppa5nsObTiUuMw4ziSe4e8Lf5OcnUxsRiy/hP7C3c3uZuKGiYxsNJJXu73KrshdZkGv1aNWs/PSTq5kXKGXby9s9bYYLAzX+zHc0rRa81plyRk52FmpX2UMesn4EkIIIYQQxUngSwhR67V2bQ3ApdRLQGHgC2DxwMVEpkbS3qN9TXRNVKPxzcZjb2lP73rmxdCntJyCXqunj28fOnp2BNRMwaKF70Ethu9t620qZD++6fgKvW9BUPWx9o/x2q7X2Bmxk63hW9Fr9WTkZvBz6M/0r9/flFFmb2nPR30/AqjzUw+rW1pWrtnzlMxcdPnBMAl8CSGEEEKIklzTvIDFixfTsGFDrK2tCQwMZOfOnWW2/+GHH2jXrh02NjZ4e3tz3333ERcXd00dFkLcelq6tjR77mhZGPjysPGQoNctQq/VM6rxKJysncy2e9l68XTg06agV4FWrq3Mnt/f+n7e6fEOg/wH8cvIX/C1963U+7sZ3Jjfbz4GCwMx6TF8f/J702vzDsxja5g6hXJB3wWmqZaiavk6m2fMfbLlNInpOQBYSeBLCCGEEEKUoNIZXytXrmTGjBksXryYHj16sGTJEoYNG8aJEyeoX79+sfb//vsvU6ZMYf78+YwcOZKIiAgeeeQRpk+fzq+//lolJyGEqNvcbdzxsPEgJj0GMM/4EqI07/V8j40XNtLNpxtGxWgq1N/Jq9M1H9NKZ0Unz06mFSQLFKws2cKlRbEAnKg6AR72fDGlE5/8c5qjEUlcjEvni53nAMn4EkIIIYQQJat0xtdHH33EAw88wPTp02nRogULFizAz8+Pzz77rMT2e/fupUGDBjz55JM0bNiQnj178vDDD3PgwIHr7rwQ4tZRNOuraFF7IUrTyKkR/2v/Pzp4dKjS1SmLHqu9e3uz1xYPXIyFVqoI3EiDWnriZmdpen4qOgWQwJcQQgghhChZpQJf2dnZHDx4kMGDB5ttHzx4MLt37y5xn+7du3Pp0iU2bNiAoihcvnyZVatWMWLEiFLfJysri+TkZLM/QohbWxOnJqbHDlYONdgTcasrGvgaFTCKfn79ALVmmJvBraa6dUvp1MCl2DZZ1VEIIYQQQpSkUr+WvnLlCnl5eXh6eppt9/T0JDo6usR9unfvzg8//MCECRPIzMwkNzeXUaNGsXDhwlLfZ/bs2bz55puV6ZoQoo5r4lwY+Cpa40uI6tbKrRVetl5k5WYx2H8wfXz70Nu3N6Mbj67prt0ypnVvwF/HozlyKcm0zWApGV9CCCGEEKK4a/r1qEZjvpy4oijFthU4ceIETz75JK+99hoHDx5k48aNnD9/nkceeaTU48+aNYukpCTTn/Dw8GvpphCiDglwCjA9lhpfoibptXpW3r6SNaPX4GjliIeNB3c2vRO9Tl/TXbtl2FpZ8NSAJmbbrGWqoxBCCCGEKEGlMr7c3NzQ6XTFsrtiYmKKZYEVmD17Nj169OD5558HoG3bttja2tKrVy/eeecdvL29i+1jZWWFlZVVZbomhKjjGjg0MD3OyM2ouY4IAbhYF59qJ6qXq5359wQJfAkhhBBCiJJUKuPL0tKSwMBANm3aZLZ906ZNdO/evcR90tPT0WrN30anU7+cKopSmbcXQtzC9Do9jRwbAdDNp1sN90YIUdNcbS3NnktxeyGEEEIIUZJKLz31zDPPMHnyZDp16kS3bt1YunQpYWFhpqmLs2bNIiIiguXLlwMwcuRIHnzwQT777DOGDBlCVFQUM2bMoHPnzvj4+FTt2Qgh6rQVI1aQlJWEt13xTFEhxK3F7aqMLwl8CSGEEEKIklQ68DVhwgTi4uJ46623iIqKonXr1mzYsAF/f38AoqKiCAsLM7WfNm0aKSkpLFq0iGeffRYnJyf69+/P+++/X3VnIYS4JdjobbDR29R0N4QQtYDBUoetpY607DxAVnUUQgghhBAl0yg3wXzD5ORkHB0dSUpKwsHBoaa7I4QQQohaoPcHWwmLTwdg7p1tuauTXw33SAghhBBCVIfKxInk16NCCCGEuCl5OVibHhssZaqjEEIIIYQoTgJfQgghhLgp+bkUTn22tpDAlxBCCCGEKE4CX0IIIYS4Kfm7Fga+JONLCCGEEEKURAJfQgghhLgpFQ18WcuqjkIIIYQQogQS+BJCCCHETcnf1db0WFZ1FEIIIYQQJZFviUIIIYS4KfkXqfElhBBCCCFESSTwJYQQQoibkpON3vTYT4JgQgghhBCiBBY13QEhhBBCiGuh0WgIenUQmbl5OFjry99BCCGEEELcciTwJYQQQoiblrOtZU13QQghhBBC1GIy1VEIIYQQQgghhBBC1EkS+BJCCCGEEEIIIYQQdZIEvoQQQgghhBBCCCFEnSSBLyGEEEIIIYQQQghRJ0ngSwghhBBCCCGEEELUSRL4EkIIIYQQQgghhBB1kgS+hBBCCCGEEEIIIUSdJIEvIYQQQgghhBBCCFEnSeBLCCGEEEIIIYQQQtRJEvgSQgghhBBCCCGEEHWSBL6EEEIIIYQQQgghRJ0kgS8hhBBCCCGEEEIIUSdJ4EsIIYQQQgghhBBC1EkS+BJCCCGEEEIIIYQQdZJFTXegIhRFASA5ObmGeyKEEEIIIYQQQgghalJBfKggXlSWmyLwlZKSAoCfn18N90QIIYQQQgghhBBC1AYpKSk4OjqW2UajVCQ8VsOMRiORkZHY29uj0WhqujtVIjk5GT8/P8LDw3FwcKjp7ghhRsanqK1kbIraTManqM1kfIraTManqM1kfNZOiqKQkpKCj48PWm3ZVbxuiowvrVaLr69vTXfjhnBwcJB/PKLWkvEpaisZm6I2k/EpajMZn6I2k/EpajMZn7VPeZleBaS4vRBCCCGEEEIIIYSokyTwJYQQQgghhBBCCCHqJAl81RArKytef/11rKysarorQhQj41PUVjI2RW0m41PUZjI+RW0m41PUZjI+b343RXF7IYQQQgghhBBCCCEqSzK+hBBCCCGEEEIIIUSdJIEvIYQQQgghhBBCCFEnSeBLCCGEEEIIIYQQQtRJEvgSQgghhBBCCCGEEHVSnQ58zZ49m9tuuw17e3s8PDy44447CAkJMWujKApvvPEGPj4+GAwG+vbty/Hjx83aLF26lL59++Lg4IBGoyExMbHYe4WGhjJ69Gjc3NxwcHCgR48ebN26tdw+Hj16lD59+mAwGKhXrx5vvfUWRdcbiIqKYuLEiTRr1gytVsuMGTMqfP6LFy+mYcOGWFtbExgYyM6dO02v5eTk8OKLL9KmTRtsbW3x8fFhypQpREZGVvj44vrU9vGZmZnJtGnTaNOmDRYWFtxxxx0lttu+fTuBgYFYW1vTqFEjPv/883LPfceOHYwcORIfHx80Gg1r164t1kaj0ZT4Z+7cueUeX1y/6hyfhw4dYtCgQTg5OeHq6spDDz1EampquX0s7/oJ8MMPP9CuXTtsbGzw9vbmvvvuIy4urtxjl3X9LHDy5ElGjRqFo6Mj9vb2dO3albCwsHKPLa5fVYzP+Ph4nnjiCZo1a4aNjQ3169fnySefJCkpyew4CQkJTJ48GUdHRxwdHZk8eXKJ4/hq5Y3Pbdu2lXiNO3Xq1HWf+5o1axgyZAhubm5oNBqCg4PL7a+oOtU5Pt999126d++OjY0NTk5OFe5jeePz33//pUePHri6umIwGGjevDnz58+v0LHLu35evnyZadOm4ePjg42NDUOHDuX06dMV7ru4PrV9fFbk++eaNWsYNGgQ7u7uODg40K1bN/76668qOXe5ftas6hqfFy5c4IEHHqBhw4YYDAYaN27M66+/TnZ2dpn9u5H3R1D+9VPuj65dnQ58bd++nccee4y9e/eyadMmcnNzGTx4MGlpaaY2H3zwAR999BGLFi3iv//+w8vLi0GDBpGSkmJqk56eztChQ3nppZdKfa8RI0aQm5vLli1bOHjwIO3bt+f2228nOjq61H2Sk5MZNGgQPj4+/PfffyxcuJB58+bx0UcfmdpkZWXh7u7Oyy+/TLt27Sp87itXrmTGjBm8/PLLBAUF0atXL4YNG2a6KUtPT+fQoUO8+uqrHDp0iDVr1hAaGsqoUaMq/B7i+tT28ZmXl4fBYODJJ59k4MCBJbY5f/48w4cPp1evXgQFBfHSSy/x5JNPsnr16jLPPS0tjXbt2rFo0aJS20RFRZn9+frrr9FoNIwbN67MY4uqUV3jMzIykoEDBxIQEMC+ffvYuHEjx48fZ9q0aWX2ryLXz3///ZcpU6bwwAMPcPz4cX755Rf+++8/pk+fXuaxy7t+Apw9e5aePXvSvHlztm3bxuHDh3n11VextrYu89iialTF+IyMjCQyMpJ58+Zx9OhRli1bxsaNG3nggQfM3mvixIkEBwezceNGNm7cSHBwMJMnTy6zfxUZnwVCQkLMrnVNmjS57nNPS0ujR48ezJkzp9zPUlS96hyf2dnZ3HXXXTz66KMV7l9FxqetrS2PP/44O3bs4OTJk7zyyiu88sorLF26tMxjl3f9VBSFO+64g3PnzvHbb78RFBSEv78/AwcONPt8xI1T28dnRb5/7tixg0GDBrFhwwYOHjxIv379GDlyJEFBQdd97nL9rFnVNT5PnTqF0WhkyZIlHD9+nPnz5/P555+XeT8FN/b+qCLfP+X+6Doot5CYmBgFULZv364oiqIYjUbFy8tLmTNnjqlNZmam4ujoqHz++efF9t+6dasCKAkJCWbbY2NjFUDZsWOHaVtycrICKJs3by61P4sXL1YcHR2VzMxM07bZs2crPj4+itFoLNa+T58+ylNPPVWhc+3cubPyyCOPmG1r3ry5MnPmzFL32b9/vwIoFy9erNB7iKpV28ZnUVOnTlVGjx5dbPsLL7ygNG/e3Gzbww8/rHTt2rVCx1UURQGUX3/9tdx2o0ePVvr371/h44qqdaPG55IlSxQPDw8lLy/PtC0oKEgBlNOnT5fan4pcP+fOnas0atTIbL9PPvlE8fX1LfNcK3L9nDBhgnLvvfeWeRxRfa53fBb4+eefFUtLSyUnJ0dRFEU5ceKEAih79+41tdmzZ48CKKdOnSr1OBUZn6X9m6isq8+9qPPnzyuAEhQUdF3vIa7PjRqfRX3zzTeKo6NjhfpT2e+fBcaMGVPuda+862dISIgCKMeOHTO9npubq7i4uChffPFFhfovqlZtG59Flfb9syQtW7ZU3nzzzUodX66ftV91jM8CH3zwgdKwYcMK962q74+u5f5d7o8qrk5nfF2tIL3RxcUFUKOx0dHRDB482NTGysqKPn36sHv37gof19XVlRYtWrB8+XLS0tLIzc1lyZIleHp6EhgYWOp+e/bsoU+fPlhZWZm2DRkyhMjISC5cuFDJsyuUnZ3NwYMHzc4LYPDgwWWeV1JSEhqNplKp8qLq1LbxWRF79uwpNs6GDBnCgQMHyMnJua5jF3X58mXWr19f7DeJovrcqPGZlZWFpaUlWm3hf0cGgwFQM7ZKU5HrZ/fu3bl06RIbNmxAURQuX77MqlWrGDFiRKnHrcj102g0sn79epo2bcqQIUPw8PCgS5cuJU7ZFdWjqsZnUlISDg4OWFhYAOo4c3R0pEuXLqY2Xbt2xdHRsczjVOb/9w4dOuDt7c2AAQMqVCKhpD5D4bmL2udGjc9rdS3fP4OCgti9ezd9+vQp9bgVuX5mZWUBmGXH6nQ6LC0ty7zmixunto3Pa2E0GklJSan0dVCun7VfdY7PpKSkKhkL13J/dC3373J/VDm3TOBLURSeeeYZevbsSevWrQFM07w8PT3N2np6epY5BexqGo2GTZs2ERQUhL29PdbW1syfP5+NGzeWGUSKjo4u8b2L9u1aXLlyhby8vEqdV2ZmJjNnzmTixIk4ODhc83uLa1Mbx2dFlDaGc3NzuXLlynUdu6hvv/0We3t7xo4dW2XHFBV3I8dn//79iY6OZu7cuWRnZ5OQkGBKM4+Kiip1v4pcP7t3784PP/zAhAkTsLS0xMvLCycnJxYuXFjqcSty/YyJiSE1NZU5c+YwdOhQ/v77b8aMGcPYsWPZvn17hc9dVI2qGp9xcXG8/fbbPPzww6Zt0dHReHh4FGvr4eFR5jivyPj09vZm6dKlrF69mjVr1tCsWTMGDBjAjh07yjtlk5LOXdQuN3J8XqvKfP/09fXFysqKTp068dhjj5U5Vbwi18/mzZvj7+/PrFmzSEhIIDs7mzlz5hAdHV3mNV/cGLVxfF6LDz/8kLS0NMaPH1/hfeT6WftV5/g8e/YsCxcu5JFHHrnufl/L/dG13L/L/VHl3DKBr8cff5wjR46wYsWKYq9pNBqz54qiFNtWFkVR+N///oeHhwc7d+5k//79jB49mttvv930n3irVq2ws7PDzs6OYcOGlfneJW0vzc6dO03HtbOz44cffqj0eeXk5HD33XdjNBpZvHhxxU5aVKnaOj4roqwxXNb4rIyvv/6aSZMmSf2kGnIjx2erVq349ttv+fDDD7GxscHLy4tGjRrh6emJTqcztbmW6+eJEyd48sknee211zh48CAbN27k/Pnzpi8113r9NBqNAIwePZqnn36a9u3bM3PmTG6//fYKFy8VVacqxmdycjIjRoygZcuWvP7662Ue4+rjXOv4bNasGQ8++CAdO3akW7duLF68mBEjRjBv3jyg7PFZkXMXtcONHp/lud7vnzt37uTAgQN8/vnnLFiwwHQe13r91Ov1rF69mtDQUFxcXLCxsWHbtm0MGzbMdM0X1ae2js/KWLFiBW+88QYrV640/aJCrp91Q3WNz8jISIYOHcpdd91lFtyvifujynyvlvujyqn+XNQa8MQTT/D777+zY8cOfH19Tdu9vLwANSrr7e1t2h4TE1Ms2lqWLVu28Mcff5CQkGDKllq8eDGbNm3i22+/ZebMmWzYsMGU2lgwjcfLy6tYBDcmJgYoHsUuTadOncxWG/H09MTKygqdTlfisa8+bk5ODuPHj+f8+fNs2bJFsr1qQG0dnxVR2hi2sLDA1dUVR0fHYuOzsnbu3ElISAgrV66s9L7i+t3o8Qlq8fCJEydy+fJlbG1t0Wg0fPTRRzRs2BDgmq+fs2fPpkePHjz//PMAtG3bFltbW3r16sU777xzzddPNzc3LCwsaNmypVmbFi1ayFSdalYV4zMlJYWhQ4diZ2fHr7/+il6vNzvO5cuXi71vbGys6ThV+f97165d+f7774GS/3+vyLmL2uNGj8+KuN7xWXAdbtOmDZcvX+aNN97gnnvuua7vn4GBgQQHB5OUlER2djbu7u506dKFTp06VercxPWpreOzMlauXMkDDzzAL7/8YlZoXK6fN7/qGp+RkZH069ePbt26FVu8ozrvjypz/w5yf3Qt6nTGl6IoPP7446xZs4YtW7aY/vMu0LBhQ7y8vNi0aZNpW3Z2Ntu3b6d79+4Vfp/09HQAsxo1Bc8LMgP8/f0JCAggICCAevXqAdCtWzd27Nhhtmzq33//jY+PDw0aNKjQexsMBtNxAwICsLe3x9LSksDAQLPzAti0aZPZeRUEvU6fPs3mzZtxdXWt8DmL61fbx2dFdOvWrdg4+/vvv+nUqRN6vb7E8VlZX331FYGBgZVa1VRcv+oan0V5enpiZ2fHypUrsba2ZtCgQcC1Xz/T09OLjfuCjAJFUa75+mlpacltt91WbHnt0NBQ/P39r+ncReVU1fhMTk5m8ODBWFpa8vvvvxf7rWm3bt1ISkpi//79pm379u0jKSnJdJyq/P89KCjI9EW+tOtneecual51jc+KqMrxqSiKqUbX9Xz/LODo6Ii7uzunT5/mwIEDjB49utLnJyqvto/PilqxYgXTpk3jxx9/LFa7U66fN6/qHJ8RERH07duXjh078s033xT7zlid90eVvX7K/dE1uGFl82uBRx99VHF0dFS2bdumREVFmf6kp6eb2syZM0dxdHRU1qxZoxw9elS55557FG9vbyU5OdnUJioqSgkKClK++OIL0+p4QUFBSlxcnKIo6qp5rq6uytixY5Xg4GAlJCREee655xS9Xq8EBweX2r/ExETF09NTueeee5SjR48qa9asURwcHJR58+aZtQsKClKCgoKUwMBAZeLEiUpQUJBy/PjxMs/9p59+UvR6vfLVV18pJ06cUGbMmKHY2toqFy5cUBRFUXJycpRRo0Ypvr6+SnBwsNnnk5WVVenPWlRebR+fiqIox48fV4KCgpSRI0cqffv2NY3FAufOnVNsbGyUp59+Wjlx4oTy1VdfKXq9Xlm1alWZx01JSTEdC1A++ugjJSgoqNiKoklJSYqNjY3y2WefVfRjFVWkusanoijKwoULlYMHDyohISHKokWLFIPBoHz88cdl9q8i189vvvlGsbCwUBYvXqycPXtW+ffff5VOnTopnTt3LvPY5V0/FUVR1qxZo+j1emXp0qXK6dOnlYULFyo6nU7ZuXNnhT9jce2qYnwmJycrXbp0Udq0aaOcOXPG7Di5ubmm4wwdOlRp27atsmfPHmXPnj1KmzZtlNtvv73M/lVkfM6fP1/59ddfldDQUOXYsWPKzJkzFUBZvXr1dZ97XFycEhQUpKxfv14BlJ9++kkJCgpSoqKiKvU5i2tTnePz4sWLSlBQkPLmm28qdnZ2pv9bU1JSSu1fRcbnokWLlN9//10JDQ1VQkNDla+//lpxcHBQXn755TLPvSLXz59//lnZunWrcvbsWWXt2rWKv7+/Mnbs2Ep/zuLa1PbxqSjlf//88ccfFQsLC+XTTz81e+/ExMTrPne5ftas6hqfERERSkBAgNK/f3/l0qVLZm3Kc6Pujypy/VQUuT+6VnU68AWU+Oebb74xtTEajcrrr7+ueHl5KVZWVkrv3r2Vo0ePmh3n9ddfL/c4//33nzJ48GDFxcVFsbe3V7p27aps2LCh3D4eOXJE6dWrl2JlZaV4eXkpb7zxRrGlpEt6b39//3KP/emnnyr+/v6KpaWl0rFjR7OleguW6C3pz9atW8s9trh+N8P49Pf3L/HYRW3btk3p0KGDYmlpqTRo0KBCF+GtW7eWeNypU6eatVuyZIliMBjK/SIjql51js/JkycrLi4uiqWlpdK2bVtl+fLlFepjRa6fn3zyidKyZUvFYDAo3t7eyqRJk5RLly6Ve+yyrp8FvvrqKyUgIECxtrZW2rVrp6xdu7ZC/RbXryrGZ2nXIUA5f/68qV1cXJwyadIkxd7eXrG3t1cmTZqkJCQklNvH8sbn+++/rzRu3FixtrZWnJ2dlZ49eyrr16+vknP/5ptvSmzz+uuvl3t8cf2qc3xOnTr1mr7LlTc+P/nkE6VVq1aKjY2N4uDgoHTo0EFZvHixkpeXV+75l3f9/PjjjxVfX19Fr9cr9evXV1555RX5pWs1uhnGZ3nfP/v06VOh75HXcu5y/axZ1TU+S/s5X32fU5IbdX+kKBX7/in3R9dGoyj5ldaEEEIIIYQQQgghhKhD6nSNLyGEEEIIIYQQQghx65LAlxBCCCGEEEIIIYSokyTwJYQQQgghhBBCCCHqJAl8CSGEEEIIIYQQQog6SQJfQgghhBBCCCGEEKJOksCXEEIIIYQQQgghhKiTJPAlhBBCCCGEEEIIIeokCXwJIYQQQtQSffv2ZcaMGTXdDSGEEEKIOkMCX0IIIYQQN6Ft27ah0WhITEys6a4IIYQQQtRaEvgSQgghhBBCCCGEEHWSBL6EEEIIIWpAWloaU6ZMwc7ODm9vbz788EOz17///ns6deqEvb09Xl5eTJw4kZiYGAAuXLhAv379AHB2dkaj0TBt2jQAFEXhgw8+oFGjRhgMBtq1a8eqVauq9dyEEEIIIWoLCXwJIYQQQtSA559/nq1bt/Lrr7/y999/s23bNg4ePGh6PTs7m7fffpvDhw+zdu1azp8/bwpu+fn5sXr1agBCQkKIiori448/BuCVV17hm2++4bPPPuP48eM8/fTT3HvvvWzfvr3az1EIIYQQoqZpFEVRaroTQgghhBC3ktTUVFxdXVm+fDkTJkwAID4+Hl9fXx566CEWLFhQbJ///vuPzp07k5KSgp2dHdu2baNfv34kJCTg5OQEqFlkbm5ubNmyhW7dupn2nT59Ounp6fz444/VcXpCCCGEELWGRU13QAghhBDiVnP27Fmys7PNglMuLi40a9bM9DwoKIg33niD4OBg4uPjMRqNAISFhdGyZcsSj3vixAkyMzMZNGiQ2fbs7Gw6dOhwA85ECCGEEKJ2k8CXEEIIIUQ1Ky/hPi0tjcGDBzN48GC+//573N3dCQsLY8iQIWRnZ5e6X0FwbP369dSrV8/sNSsrq+vvuBBCCCHETUYCX0IIIYQQ1SwgIAC9Xs/evXupX78+AAkJCYSGhtKnTx9OnTrFlStXmDNnDn5+fgAcOHDA7BiWlpYA5OXlmba1bNkSKysrwsLC6NOnTzWdjRBCCCFE7SWBLyGEEEKIamZnZ8cDDzzA888/j6urK56enrz88stoteq6Q/Xr18fS0pKFCxfyyCOPcOzYMd5++22zY/j7+6PRaPjjjz8YPnw4BoMBe3t7nnvuOZ5++mmMRiM9e/YkOTmZ3bt3Y2dnx9SpU2vidIUQQgghaoys6iiEEEIIUQPmzp1L7969GTVqFAMHDqRnz54EBgYC4O7uzrJly/jll19o2bIlc+bMYd68eWb716tXjzfffJOZM2fi6enJ448/DsDbb7/Na6+9xuzZs2nRogVDhgxh3bp1NGzYsNrPUQghhBCipsmqjkIIIYQQQgghhBCiTpKMLyGEEEIIIYQQQghRJ0ngSwghhBBCCCGEEELUSRL4EkIIIYQQQgghhBB1kgS+hBBCCCGEEEIIIUSdJIEvIYQQQgghhBBCCFEnSeBLCCGEEEIIIYQQQtRJEvgSQgghhBBCCCGEEHWSBL6EEEIIIYQQQgghRJ0kgS8hhBBCCCGEEEIIUSdJ4EsIIYQQQgghhBBC1EkS+BJCCCGEEEIIIYQQdZIEvoQQQgghhBBCCCFEnfR/eg0tVWxqFIYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure();\n",
    "Graph.plot();"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
